{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightautoml","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:04:02.447813Z","iopub.execute_input":"2024-10-06T14:04:02.448257Z","iopub.status.idle":"2024-10-06T14:06:44.072306Z","shell.execute_reply.started":"2024-10-06T14:04:02.448200Z","shell.execute_reply":"2024-10-06T14:06:44.071187Z"},"_kg_hide-output":true,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting lightautoml\n  Downloading lightautoml-0.3.8.1-py3-none-any.whl.metadata (16 kB)\nCollecting autowoe>=1.2 (from lightautoml)\n  Downloading AutoWoE-1.3.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.2.7)\nCollecting cmaes (from lightautoml)\n  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml) (0.57)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (3.1.4)\nCollecting joblib<1.3.0 (from lightautoml)\n  Downloading joblib-1.2.0-py3-none-any.whl.metadata (5.3 kB)\nCollecting json2html (from lightautoml)\n  Downloading json2html-1.3.0.tar.gz (7.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting lightgbm<=3.2.1,>=2.3 (from lightautoml)\n  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml) (3.3)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.26.4)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml) (4.0.0)\nCollecting pandas<2.0.0 (from lightautoml)\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting poetry-core<2.0.0,>=1.0.0 (from lightautoml)\n  Downloading poetry_core-1.9.0-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml) (6.0.2)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.2.2)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml) (0.12.2)\nCollecting statsmodels<=0.14.0 (from lightautoml)\n  Downloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\nCollecting torch<=2.0.0,>=1.9.0 (from lightautoml)\n  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml) (4.66.4)\nCollecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.2->lightautoml)\n  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (3.7.5)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (8.3.3)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (2024.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (1.14.1)\nCollecting sphinx (from autowoe>=1.2->lightautoml)\n  Downloading sphinx-8.0.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (0.2.4)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (5.22.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (1.16.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.43.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml) (2.9.0.post0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml) (3.5.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml) (0.5.6)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (1.12)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.0,>=1.9.0->lightautoml) (70.0.0)\nCollecting cmake (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nCollecting lit (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml) (2.1.5)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (1.13.3)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (6.8.2)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (2.0.30)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.1.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (3.0.3)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml) (8.3.0)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.1)\nCollecting sphinxcontrib-applehelp (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-devhelp (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-jsmath (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting sphinxcontrib-qthelp (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: Pygments>=2.17 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.18.0)\nCollecting docutils<0.22,>=0.20 (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: snowballstemmer>=2.2 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\nRequirement already satisfied: babel>=2.13 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.15.0)\nCollecting alabaster>=0.7.14 (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting imagesize>=1.3 (from sphinx->autowoe>=1.2->lightautoml)\n  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: requests>=2.30.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.32.3)\nCollecting packaging>=21.3 (from statsmodels<=0.14.0->lightautoml)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (2024.8.30)\nDownloading lightautoml-0.3.8.1-py3-none-any.whl (416 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.4/416.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading AutoWoE-1.3.2-py3-none-any.whl (215 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.7/215.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading poetry_core-1.9.0-py3-none-any.whl (309 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m469.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cmaes-0.11.1-py3-none-any.whl (35 kB)\nDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\nDownloading sphinx-8.0.2-py3-none-any.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m400.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading alabaster-1.0.0-py3-none-any.whl (13 kB)\nDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\nDownloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m785.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m756.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading cmake-3.30.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m798.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m997.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m792.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\nDownloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m701.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: json2html\n  Building wheel for json2html (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7593 sha256=cb7ae5b9c60f28771a7d4fa5a75d06b084a8d47e9549e8e5ed9c683701787cee\n  Stored in directory: /root/.cache/pip/wheels/e0/d8/b3/6f83a04ab0ec00e691de794d108286bb0f8bcdf4ade19afb57\nSuccessfully built json2html\nInstalling collected packages: StrEnum, lit, json2html, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, poetry-core, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, joblib, imagesize, docutils, cmake, cmaes, alabaster, sphinx, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, statsmodels, lightgbm, autowoe, triton, torch, lightautoml\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.4.2\n    Uninstalling joblib-1.4.2:\n      Successfully uninstalled joblib-1.4.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n  Attempting uninstall: statsmodels\n    Found existing installation: statsmodels 0.14.2\n    Uninstalling statsmodels-0.14.2:\n      Successfully uninstalled statsmodels-0.14.2\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 4.2.0\n    Uninstalling lightgbm-4.2.0:\n      Successfully uninstalled lightgbm-4.2.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0+cpu\n    Uninstalling torch-2.4.0+cpu:\n      Successfully uninstalled torch-2.4.0+cpu\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.0.0 which is incompatible.\ntorchvision 0.19.0+cpu requires torch==2.4.0, but you have torch 2.0.0 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-1.0.0 autowoe-1.3.2 cmaes-0.11.1 cmake-3.30.4 docutils-0.21.2 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8.1 lightgbm-3.2.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 packaging-24.1 pandas-1.5.3 poetry-core-1.9.0 sphinx-8.0.2 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 statsmodels-0.14.0 torch-2.0.0 triton-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-06T14:06:44.074563Z","iopub.execute_input":"2024-10-06T14:06:44.074922Z","iopub.status.idle":"2024-10-06T14:06:44.489477Z","shell.execute_reply.started":"2024-10-06T14:06:44.074884Z","shell.execute_reply":"2024-10-06T14:06:44.488296Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Соревноание: [Многоклассовое прогнозирование риска ожирения](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)\n\nЦелевая переменная: SalePrice (числовая с плавающей точкой)\n\nМетрика: Mean Absolute Error","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:06:46.275284Z","iopub.execute_input":"2024-10-06T14:06:46.275683Z","iopub.status.idle":"2024-10-06T14:07:11.916272Z","shell.execute_reply.started":"2024-10-06T14:06:46.275641Z","shell.execute_reply":"2024-10-06T14:07:11.915063Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\nprint(data.shape)\npd.set_option('display.max_columns', None)\ndata.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:11.917541Z","iopub.execute_input":"2024-10-06T14:07:11.918132Z","iopub.status.idle":"2024-10-06T14:07:12.036572Z","shell.execute_reply.started":"2024-10-06T14:07:11.918091Z","shell.execute_reply":"2024-10-06T14:07:12.035553Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1460, 81)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0    1          60       RL         65.0     8450   Pave   NaN      Reg   \n1    2          20       RL         80.0     9600   Pave   NaN      Reg   \n2    3          60       RL         68.0    11250   Pave   NaN      IR1   \n3    4          70       RL         60.0     9550   Pave   NaN      IR1   \n4    5          60       RL         84.0    14260   Pave   NaN      IR1   \n5    6          50       RL         85.0    14115   Pave   NaN      IR1   \n6    7          20       RL         75.0    10084   Pave   NaN      Reg   \n7    8          60       RL          NaN    10382   Pave   NaN      IR1   \n8    9          50       RM         51.0     6120   Pave   NaN      Reg   \n9   10         190       RL         50.0     7420   Pave   NaN      Reg   \n10  11          20       RL         70.0    11200   Pave   NaN      Reg   \n11  12          60       RL         85.0    11924   Pave   NaN      IR1   \n12  13          20       RL          NaN    12968   Pave   NaN      IR2   \n13  14          20       RL         91.0    10652   Pave   NaN      IR1   \n14  15          20       RL          NaN    10920   Pave   NaN      IR1   \n15  16          45       RM         51.0     6120   Pave   NaN      Reg   \n16  17          20       RL          NaN    11241   Pave   NaN      IR1   \n17  18          90       RL         72.0    10791   Pave   NaN      Reg   \n18  19          20       RL         66.0    13695   Pave   NaN      Reg   \n19  20          20       RL         70.0     7560   Pave   NaN      Reg   \n\n   LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n0          Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n1          Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n2          Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n3          Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n4          Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n5          Lvl    AllPub    Inside       Gtl      Mitchel       Norm   \n6          Lvl    AllPub    Inside       Gtl      Somerst       Norm   \n7          Lvl    AllPub    Corner       Gtl       NWAmes       PosN   \n8          Lvl    AllPub    Inside       Gtl      OldTown     Artery   \n9          Lvl    AllPub    Corner       Gtl      BrkSide     Artery   \n10         Lvl    AllPub    Inside       Gtl       Sawyer       Norm   \n11         Lvl    AllPub    Inside       Gtl      NridgHt       Norm   \n12         Lvl    AllPub    Inside       Gtl       Sawyer       Norm   \n13         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n14         Lvl    AllPub    Corner       Gtl        NAmes       Norm   \n15         Lvl    AllPub    Corner       Gtl      BrkSide       Norm   \n16         Lvl    AllPub   CulDSac       Gtl        NAmes       Norm   \n17         Lvl    AllPub    Inside       Gtl       Sawyer       Norm   \n18         Lvl    AllPub    Inside       Gtl      SawyerW       RRAe   \n19         Lvl    AllPub    Inside       Gtl        NAmes       Norm   \n\n   Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n0        Norm     1Fam     2Story            7            5       2003   \n1        Norm     1Fam     1Story            6            8       1976   \n2        Norm     1Fam     2Story            7            5       2001   \n3        Norm     1Fam     2Story            7            5       1915   \n4        Norm     1Fam     2Story            8            5       2000   \n5        Norm     1Fam     1.5Fin            5            5       1993   \n6        Norm     1Fam     1Story            8            5       2004   \n7        Norm     1Fam     2Story            7            6       1973   \n8        Norm     1Fam     1.5Fin            7            5       1931   \n9      Artery   2fmCon     1.5Unf            5            6       1939   \n10       Norm     1Fam     1Story            5            5       1965   \n11       Norm     1Fam     2Story            9            5       2005   \n12       Norm     1Fam     1Story            5            6       1962   \n13       Norm     1Fam     1Story            7            5       2006   \n14       Norm     1Fam     1Story            6            5       1960   \n15       Norm     1Fam     1.5Unf            7            8       1929   \n16       Norm     1Fam     1Story            6            7       1970   \n17       Norm   Duplex     1Story            4            5       1967   \n18       Norm     1Fam     1Story            5            5       2004   \n19       Norm     1Fam     1Story            5            6       1958   \n\n    YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n0           2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n1           1976     Gable  CompShg     MetalSd     MetalSd       None   \n2           2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n3           1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n4           2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n5           1995     Gable  CompShg     VinylSd     VinylSd       None   \n6           2005     Gable  CompShg     VinylSd     VinylSd      Stone   \n7           1973     Gable  CompShg     HdBoard     HdBoard      Stone   \n8           1950     Gable  CompShg     BrkFace     Wd Shng       None   \n9           1950     Gable  CompShg     MetalSd     MetalSd       None   \n10          1965       Hip  CompShg     HdBoard     HdBoard       None   \n11          2006       Hip  CompShg     WdShing     Wd Shng      Stone   \n12          1962       Hip  CompShg     HdBoard     Plywood       None   \n13          2007     Gable  CompShg     VinylSd     VinylSd      Stone   \n14          1960       Hip  CompShg     MetalSd     MetalSd    BrkFace   \n15          2001     Gable  CompShg     Wd Sdng     Wd Sdng       None   \n16          1970     Gable  CompShg     Wd Sdng     Wd Sdng    BrkFace   \n17          1967     Gable  CompShg     MetalSd     MetalSd       None   \n18          2004     Gable  CompShg     VinylSd     VinylSd       None   \n19          1965       Hip  CompShg     BrkFace     Plywood       None   \n\n    MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n0        196.0        Gd        TA      PConc       Gd       TA           No   \n1          0.0        TA        TA     CBlock       Gd       TA           Gd   \n2        162.0        Gd        TA      PConc       Gd       TA           Mn   \n3          0.0        TA        TA     BrkTil       TA       Gd           No   \n4        350.0        Gd        TA      PConc       Gd       TA           Av   \n5          0.0        TA        TA       Wood       Gd       TA           No   \n6        186.0        Gd        TA      PConc       Ex       TA           Av   \n7        240.0        TA        TA     CBlock       Gd       TA           Mn   \n8          0.0        TA        TA     BrkTil       TA       TA           No   \n9          0.0        TA        TA     BrkTil       TA       TA           No   \n10         0.0        TA        TA     CBlock       TA       TA           No   \n11       286.0        Ex        TA      PConc       Ex       TA           No   \n12         0.0        TA        TA     CBlock       TA       TA           No   \n13       306.0        Gd        TA      PConc       Gd       TA           Av   \n14       212.0        TA        TA     CBlock       TA       TA           No   \n15         0.0        TA        TA     BrkTil       TA       TA           No   \n16       180.0        TA        TA     CBlock       TA       TA           No   \n17         0.0        TA        TA       Slab      NaN      NaN          NaN   \n18         0.0        TA        TA      PConc       TA       TA           No   \n19         0.0        TA        TA     CBlock       TA       TA           No   \n\n   BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n0           GLQ         706          Unf           0        150          856   \n1           ALQ         978          Unf           0        284         1262   \n2           GLQ         486          Unf           0        434          920   \n3           ALQ         216          Unf           0        540          756   \n4           GLQ         655          Unf           0        490         1145   \n5           GLQ         732          Unf           0         64          796   \n6           GLQ        1369          Unf           0        317         1686   \n7           ALQ         859          BLQ          32        216         1107   \n8           Unf           0          Unf           0        952          952   \n9           GLQ         851          Unf           0        140          991   \n10          Rec         906          Unf           0        134         1040   \n11          GLQ         998          Unf           0        177         1175   \n12          ALQ         737          Unf           0        175          912   \n13          Unf           0          Unf           0       1494         1494   \n14          BLQ         733          Unf           0        520         1253   \n15          Unf           0          Unf           0        832          832   \n16          ALQ         578          Unf           0        426         1004   \n17          NaN           0          NaN           0          0            0   \n18          GLQ         646          Unf           0        468         1114   \n19          LwQ         504          Unf           0        525         1029   \n\n   Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n0     GasA        Ex          Y      SBrkr       856       854             0   \n1     GasA        Ex          Y      SBrkr      1262         0             0   \n2     GasA        Ex          Y      SBrkr       920       866             0   \n3     GasA        Gd          Y      SBrkr       961       756             0   \n4     GasA        Ex          Y      SBrkr      1145      1053             0   \n5     GasA        Ex          Y      SBrkr       796       566             0   \n6     GasA        Ex          Y      SBrkr      1694         0             0   \n7     GasA        Ex          Y      SBrkr      1107       983             0   \n8     GasA        Gd          Y      FuseF      1022       752             0   \n9     GasA        Ex          Y      SBrkr      1077         0             0   \n10    GasA        Ex          Y      SBrkr      1040         0             0   \n11    GasA        Ex          Y      SBrkr      1182      1142             0   \n12    GasA        TA          Y      SBrkr       912         0             0   \n13    GasA        Ex          Y      SBrkr      1494         0             0   \n14    GasA        TA          Y      SBrkr      1253         0             0   \n15    GasA        Ex          Y      FuseA       854         0             0   \n16    GasA        Ex          Y      SBrkr      1004         0             0   \n17    GasA        TA          Y      SBrkr      1296         0             0   \n18    GasA        Ex          Y      SBrkr      1114         0             0   \n19    GasA        TA          Y      SBrkr      1339         0             0   \n\n    GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n0        1710             1             0         2         1             3   \n1        1262             0             1         2         0             3   \n2        1786             1             0         2         1             3   \n3        1717             1             0         1         0             3   \n4        2198             1             0         2         1             4   \n5        1362             1             0         1         1             1   \n6        1694             1             0         2         0             3   \n7        2090             1             0         2         1             3   \n8        1774             0             0         2         0             2   \n9        1077             1             0         1         0             2   \n10       1040             1             0         1         0             3   \n11       2324             1             0         3         0             4   \n12        912             1             0         1         0             2   \n13       1494             0             0         2         0             3   \n14       1253             1             0         1         1             2   \n15        854             0             0         1         0             2   \n16       1004             1             0         1         0             2   \n17       1296             0             0         2         0             2   \n18       1114             1             0         1         1             3   \n19       1339             0             0         1         0             3   \n\n    KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n0              1          Gd             8        Typ           0         NaN   \n1              1          TA             6        Typ           1          TA   \n2              1          Gd             6        Typ           1          TA   \n3              1          Gd             7        Typ           1          Gd   \n4              1          Gd             9        Typ           1          TA   \n5              1          TA             5        Typ           0         NaN   \n6              1          Gd             7        Typ           1          Gd   \n7              1          TA             7        Typ           2          TA   \n8              2          TA             8       Min1           2          TA   \n9              2          TA             5        Typ           2          TA   \n10             1          TA             5        Typ           0         NaN   \n11             1          Ex            11        Typ           2          Gd   \n12             1          TA             4        Typ           0         NaN   \n13             1          Gd             7        Typ           1          Gd   \n14             1          TA             5        Typ           1          Fa   \n15             1          TA             5        Typ           0         NaN   \n16             1          TA             5        Typ           1          TA   \n17             2          TA             6        Typ           0         NaN   \n18             1          Gd             6        Typ           0         NaN   \n19             1          TA             6       Min1           0         NaN   \n\n   GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n0      Attchd       2003.0          RFn           2         548         TA   \n1      Attchd       1976.0          RFn           2         460         TA   \n2      Attchd       2001.0          RFn           2         608         TA   \n3      Detchd       1998.0          Unf           3         642         TA   \n4      Attchd       2000.0          RFn           3         836         TA   \n5      Attchd       1993.0          Unf           2         480         TA   \n6      Attchd       2004.0          RFn           2         636         TA   \n7      Attchd       1973.0          RFn           2         484         TA   \n8      Detchd       1931.0          Unf           2         468         Fa   \n9      Attchd       1939.0          RFn           1         205         Gd   \n10     Detchd       1965.0          Unf           1         384         TA   \n11    BuiltIn       2005.0          Fin           3         736         TA   \n12     Detchd       1962.0          Unf           1         352         TA   \n13     Attchd       2006.0          RFn           3         840         TA   \n14     Attchd       1960.0          RFn           1         352         TA   \n15     Detchd       1991.0          Unf           2         576         TA   \n16     Attchd       1970.0          Fin           2         480         TA   \n17    CarPort       1967.0          Unf           2         516         TA   \n18     Detchd       2004.0          Unf           2         576         TA   \n19     Attchd       1958.0          Unf           1         294         TA   \n\n   GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n0          TA          Y           0           61              0          0   \n1          TA          Y         298            0              0          0   \n2          TA          Y           0           42              0          0   \n3          TA          Y           0           35            272          0   \n4          TA          Y         192           84              0          0   \n5          TA          Y          40           30              0        320   \n6          TA          Y         255           57              0          0   \n7          TA          Y         235          204            228          0   \n8          TA          Y          90            0            205          0   \n9          TA          Y           0            4              0          0   \n10         TA          Y           0            0              0          0   \n11         TA          Y         147           21              0          0   \n12         TA          Y         140            0              0          0   \n13         TA          Y         160           33              0          0   \n14         TA          Y           0          213            176          0   \n15         TA          Y          48          112              0          0   \n16         TA          Y           0            0              0          0   \n17         TA          Y           0            0              0          0   \n18         TA          Y           0          102              0          0   \n19         TA          Y           0            0              0          0   \n\n    ScreenPorch  PoolArea PoolQC  Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n0             0         0    NaN    NaN         NaN        0       2    2008   \n1             0         0    NaN    NaN         NaN        0       5    2007   \n2             0         0    NaN    NaN         NaN        0       9    2008   \n3             0         0    NaN    NaN         NaN        0       2    2006   \n4             0         0    NaN    NaN         NaN        0      12    2008   \n5             0         0    NaN  MnPrv        Shed      700      10    2009   \n6             0         0    NaN    NaN         NaN        0       8    2007   \n7             0         0    NaN    NaN        Shed      350      11    2009   \n8             0         0    NaN    NaN         NaN        0       4    2008   \n9             0         0    NaN    NaN         NaN        0       1    2008   \n10            0         0    NaN    NaN         NaN        0       2    2008   \n11            0         0    NaN    NaN         NaN        0       7    2006   \n12          176         0    NaN    NaN         NaN        0       9    2008   \n13            0         0    NaN    NaN         NaN        0       8    2007   \n14            0         0    NaN   GdWo         NaN        0       5    2008   \n15            0         0    NaN  GdPrv         NaN        0       7    2007   \n16            0         0    NaN    NaN        Shed      700       3    2010   \n17            0         0    NaN    NaN        Shed      500      10    2006   \n18            0         0    NaN    NaN         NaN        0       6    2008   \n19            0         0    NaN  MnPrv         NaN        0       5    2009   \n\n   SaleType SaleCondition  SalePrice  \n0        WD        Normal     208500  \n1        WD        Normal     181500  \n2        WD        Normal     223500  \n3        WD       Abnorml     140000  \n4        WD        Normal     250000  \n5        WD        Normal     143000  \n6        WD        Normal     307000  \n7        WD        Normal     200000  \n8        WD       Abnorml     129900  \n9        WD        Normal     118000  \n10       WD        Normal     129500  \n11      New       Partial     345000  \n12       WD        Normal     144000  \n13      New       Partial     279500  \n14       WD        Normal     157000  \n15       WD        Normal     132000  \n16       WD        Normal     149000  \n17       WD        Normal      90000  \n18       WD        Normal     159000  \n19      COD       Abnorml     139000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>LandSlope</th>\n      <th>Neighborhood</th>\n      <th>Condition1</th>\n      <th>Condition2</th>\n      <th>BldgType</th>\n      <th>HouseStyle</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>RoofStyle</th>\n      <th>RoofMatl</th>\n      <th>Exterior1st</th>\n      <th>Exterior2nd</th>\n      <th>MasVnrType</th>\n      <th>MasVnrArea</th>\n      <th>ExterQual</th>\n      <th>ExterCond</th>\n      <th>Foundation</th>\n      <th>BsmtQual</th>\n      <th>BsmtCond</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinType1</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinType2</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>TotalBsmtSF</th>\n      <th>Heating</th>\n      <th>HeatingQC</th>\n      <th>CentralAir</th>\n      <th>Electrical</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>LowQualFinSF</th>\n      <th>GrLivArea</th>\n      <th>BsmtFullBath</th>\n      <th>BsmtHalfBath</th>\n      <th>FullBath</th>\n      <th>HalfBath</th>\n      <th>BedroomAbvGr</th>\n      <th>KitchenAbvGr</th>\n      <th>KitchenQual</th>\n      <th>TotRmsAbvGrd</th>\n      <th>Functional</th>\n      <th>Fireplaces</th>\n      <th>FireplaceQu</th>\n      <th>GarageType</th>\n      <th>GarageYrBlt</th>\n      <th>GarageFinish</th>\n      <th>GarageCars</th>\n      <th>GarageArea</th>\n      <th>GarageQual</th>\n      <th>GarageCond</th>\n      <th>PavedDrive</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>CollgCr</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>2Story</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>BrkFace</td>\n      <td>196.0</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>GLQ</td>\n      <td>706</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>150</td>\n      <td>856</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>856</td>\n      <td>854</td>\n      <td>0</td>\n      <td>1710</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>8</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Attchd</td>\n      <td>2003.0</td>\n      <td>RFn</td>\n      <td>2</td>\n      <td>548</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>Gtl</td>\n      <td>Veenker</td>\n      <td>Feedr</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>MetalSd</td>\n      <td>MetalSd</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>Gd</td>\n      <td>ALQ</td>\n      <td>978</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>284</td>\n      <td>1262</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>6</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>Attchd</td>\n      <td>1976.0</td>\n      <td>RFn</td>\n      <td>2</td>\n      <td>460</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>CollgCr</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>2Story</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>BrkFace</td>\n      <td>162.0</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>Mn</td>\n      <td>GLQ</td>\n      <td>486</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>434</td>\n      <td>920</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>920</td>\n      <td>866</td>\n      <td>0</td>\n      <td>1786</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>6</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>Attchd</td>\n      <td>2001.0</td>\n      <td>RFn</td>\n      <td>2</td>\n      <td>608</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>Crawfor</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>2Story</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>Wd Sdng</td>\n      <td>Wd Shng</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>BrkTil</td>\n      <td>TA</td>\n      <td>Gd</td>\n      <td>No</td>\n      <td>ALQ</td>\n      <td>216</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>540</td>\n      <td>756</td>\n      <td>GasA</td>\n      <td>Gd</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>961</td>\n      <td>756</td>\n      <td>0</td>\n      <td>1717</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>7</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>Detchd</td>\n      <td>1998.0</td>\n      <td>Unf</td>\n      <td>3</td>\n      <td>642</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>Gtl</td>\n      <td>NoRidge</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>2Story</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>BrkFace</td>\n      <td>350.0</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>Av</td>\n      <td>GLQ</td>\n      <td>655</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>490</td>\n      <td>1145</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1145</td>\n      <td>1053</td>\n      <td>0</td>\n      <td>2198</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>9</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>Attchd</td>\n      <td>2000.0</td>\n      <td>RFn</td>\n      <td>3</td>\n      <td>836</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>14115</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Mitchel</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1.5Fin</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1993</td>\n      <td>1995</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Wood</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>GLQ</td>\n      <td>732</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>64</td>\n      <td>796</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>796</td>\n      <td>566</td>\n      <td>0</td>\n      <td>1362</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>5</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Attchd</td>\n      <td>1993.0</td>\n      <td>Unf</td>\n      <td>2</td>\n      <td>480</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>40</td>\n      <td>30</td>\n      <td>0</td>\n      <td>320</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>Shed</td>\n      <td>700</td>\n      <td>10</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>143000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>10084</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Somerst</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2004</td>\n      <td>2005</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>Stone</td>\n      <td>186.0</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>Ex</td>\n      <td>TA</td>\n      <td>Av</td>\n      <td>GLQ</td>\n      <td>1369</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>317</td>\n      <td>1686</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1694</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1694</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>7</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>Attchd</td>\n      <td>2004.0</td>\n      <td>RFn</td>\n      <td>2</td>\n      <td>636</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>255</td>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>307000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>10382</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>NWAmes</td>\n      <td>PosN</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>2Story</td>\n      <td>7</td>\n      <td>6</td>\n      <td>1973</td>\n      <td>1973</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>HdBoard</td>\n      <td>HdBoard</td>\n      <td>Stone</td>\n      <td>240.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>Mn</td>\n      <td>ALQ</td>\n      <td>859</td>\n      <td>BLQ</td>\n      <td>32</td>\n      <td>216</td>\n      <td>1107</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1107</td>\n      <td>983</td>\n      <td>0</td>\n      <td>2090</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>7</td>\n      <td>Typ</td>\n      <td>2</td>\n      <td>TA</td>\n      <td>Attchd</td>\n      <td>1973.0</td>\n      <td>RFn</td>\n      <td>2</td>\n      <td>484</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>235</td>\n      <td>204</td>\n      <td>228</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shed</td>\n      <td>350</td>\n      <td>11</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>200000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>50</td>\n      <td>RM</td>\n      <td>51.0</td>\n      <td>6120</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>OldTown</td>\n      <td>Artery</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1.5Fin</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1931</td>\n      <td>1950</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>BrkFace</td>\n      <td>Wd Shng</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>BrkTil</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>952</td>\n      <td>952</td>\n      <td>GasA</td>\n      <td>Gd</td>\n      <td>Y</td>\n      <td>FuseF</td>\n      <td>1022</td>\n      <td>752</td>\n      <td>0</td>\n      <td>1774</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>TA</td>\n      <td>8</td>\n      <td>Min1</td>\n      <td>2</td>\n      <td>TA</td>\n      <td>Detchd</td>\n      <td>1931.0</td>\n      <td>Unf</td>\n      <td>2</td>\n      <td>468</td>\n      <td>Fa</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>90</td>\n      <td>0</td>\n      <td>205</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>129900</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>190</td>\n      <td>RL</td>\n      <td>50.0</td>\n      <td>7420</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>BrkSide</td>\n      <td>Artery</td>\n      <td>Artery</td>\n      <td>2fmCon</td>\n      <td>1.5Unf</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1939</td>\n      <td>1950</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>MetalSd</td>\n      <td>MetalSd</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>BrkTil</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>GLQ</td>\n      <td>851</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>140</td>\n      <td>991</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1077</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1077</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>TA</td>\n      <td>5</td>\n      <td>Typ</td>\n      <td>2</td>\n      <td>TA</td>\n      <td>Attchd</td>\n      <td>1939.0</td>\n      <td>RFn</td>\n      <td>1</td>\n      <td>205</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>118000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>70.0</td>\n      <td>11200</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Sawyer</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>Hip</td>\n      <td>CompShg</td>\n      <td>HdBoard</td>\n      <td>HdBoard</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>Rec</td>\n      <td>906</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>134</td>\n      <td>1040</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1040</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1040</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>5</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Detchd</td>\n      <td>1965.0</td>\n      <td>Unf</td>\n      <td>1</td>\n      <td>384</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>129500</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>11924</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>NridgHt</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>2Story</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2005</td>\n      <td>2006</td>\n      <td>Hip</td>\n      <td>CompShg</td>\n      <td>WdShing</td>\n      <td>Wd Shng</td>\n      <td>Stone</td>\n      <td>286.0</td>\n      <td>Ex</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>Ex</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>GLQ</td>\n      <td>998</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>177</td>\n      <td>1175</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1182</td>\n      <td>1142</td>\n      <td>0</td>\n      <td>2324</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Ex</td>\n      <td>11</td>\n      <td>Typ</td>\n      <td>2</td>\n      <td>Gd</td>\n      <td>BuiltIn</td>\n      <td>2005.0</td>\n      <td>Fin</td>\n      <td>3</td>\n      <td>736</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>147</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2006</td>\n      <td>New</td>\n      <td>Partial</td>\n      <td>345000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>12968</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR2</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Sawyer</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1962</td>\n      <td>1962</td>\n      <td>Hip</td>\n      <td>CompShg</td>\n      <td>HdBoard</td>\n      <td>Plywood</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>ALQ</td>\n      <td>737</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>175</td>\n      <td>912</td>\n      <td>GasA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>912</td>\n      <td>0</td>\n      <td>0</td>\n      <td>912</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>4</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Detchd</td>\n      <td>1962.0</td>\n      <td>Unf</td>\n      <td>1</td>\n      <td>352</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>176</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>144000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>91.0</td>\n      <td>10652</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>CollgCr</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2006</td>\n      <td>2007</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>Stone</td>\n      <td>306.0</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>Gd</td>\n      <td>TA</td>\n      <td>Av</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>1494</td>\n      <td>1494</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1494</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1494</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>7</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>Attchd</td>\n      <td>2006.0</td>\n      <td>RFn</td>\n      <td>3</td>\n      <td>840</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>160</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>New</td>\n      <td>Partial</td>\n      <td>279500</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>10920</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>NAmes</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1960</td>\n      <td>1960</td>\n      <td>Hip</td>\n      <td>CompShg</td>\n      <td>MetalSd</td>\n      <td>MetalSd</td>\n      <td>BrkFace</td>\n      <td>212.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>BLQ</td>\n      <td>733</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>520</td>\n      <td>1253</td>\n      <td>GasA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1253</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1253</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>5</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>Fa</td>\n      <td>Attchd</td>\n      <td>1960.0</td>\n      <td>RFn</td>\n      <td>1</td>\n      <td>352</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>213</td>\n      <td>176</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdWo</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>157000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>45</td>\n      <td>RM</td>\n      <td>51.0</td>\n      <td>6120</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>BrkSide</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1.5Unf</td>\n      <td>7</td>\n      <td>8</td>\n      <td>1929</td>\n      <td>2001</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>Wd Sdng</td>\n      <td>Wd Sdng</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>BrkTil</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>832</td>\n      <td>832</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>FuseA</td>\n      <td>854</td>\n      <td>0</td>\n      <td>0</td>\n      <td>854</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>5</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Detchd</td>\n      <td>1991.0</td>\n      <td>Unf</td>\n      <td>2</td>\n      <td>576</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>48</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>132000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>11241</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>CulDSac</td>\n      <td>Gtl</td>\n      <td>NAmes</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1970</td>\n      <td>1970</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>Wd Sdng</td>\n      <td>Wd Sdng</td>\n      <td>BrkFace</td>\n      <td>180.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>ALQ</td>\n      <td>578</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>426</td>\n      <td>1004</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1004</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1004</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>5</td>\n      <td>Typ</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>Attchd</td>\n      <td>1970.0</td>\n      <td>Fin</td>\n      <td>2</td>\n      <td>480</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shed</td>\n      <td>700</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>149000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>90</td>\n      <td>RL</td>\n      <td>72.0</td>\n      <td>10791</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Sawyer</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>Duplex</td>\n      <td>1Story</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1967</td>\n      <td>1967</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>MetalSd</td>\n      <td>MetalSd</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Slab</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>GasA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1296</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1296</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>TA</td>\n      <td>6</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>CarPort</td>\n      <td>1967.0</td>\n      <td>Unf</td>\n      <td>2</td>\n      <td>516</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shed</td>\n      <td>500</td>\n      <td>10</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>90000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>13695</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>SawyerW</td>\n      <td>RRAe</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2004</td>\n      <td>2004</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>GLQ</td>\n      <td>646</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>468</td>\n      <td>1114</td>\n      <td>GasA</td>\n      <td>Ex</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1114</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1114</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Gd</td>\n      <td>6</td>\n      <td>Typ</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Detchd</td>\n      <td>2004.0</td>\n      <td>Unf</td>\n      <td>2</td>\n      <td>576</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>102</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>159000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>70.0</td>\n      <td>7560</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>NAmes</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1958</td>\n      <td>1965</td>\n      <td>Hip</td>\n      <td>CompShg</td>\n      <td>BrkFace</td>\n      <td>Plywood</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>CBlock</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>LwQ</td>\n      <td>504</td>\n      <td>Unf</td>\n      <td>0</td>\n      <td>525</td>\n      <td>1029</td>\n      <td>GasA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>1339</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1339</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>TA</td>\n      <td>6</td>\n      <td>Min1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Attchd</td>\n      <td>1958.0</td>\n      <td>Unf</td>\n      <td>1</td>\n      <td>294</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2009</td>\n      <td>COD</td>\n      <td>Abnorml</td>\n      <td>139000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.038015Z","iopub.execute_input":"2024-10-06T14:07:12.038711Z","iopub.status.idle":"2024-10-06T14:07:12.046789Z","shell.execute_reply.started":"2024-10-06T14:07:12.038668Z","shell.execute_reply":"2024-10-06T14:07:12.045399Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition', 'SalePrice'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"target_col = 'SalePrice'\nrs = 42","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.048493Z","iopub.execute_input":"2024-10-06T14:07:12.048949Z","iopub.status.idle":"2024-10-06T14:07:12.055672Z","shell.execute_reply.started":"2024-10-06T14:07:12.048900Z","shell.execute_reply":"2024-10-06T14:07:12.054541Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_prep = data.copy()\n\n# Scores\ndata_prep['OverallQualAndCondMean'] = (data_prep['OverallQual'] + data_prep['OverallCond'])/2\n\n# Time\ndata_prep['YrRemodAddAfterBuilt'] = data_prep['YearRemodAdd'] - data_prep['YearBuilt']\ndata_prep['YrSoldAfterBuilt'] = data_prep['YrSold'] - data_prep['YearBuilt']\ndata_prep['YrSoldAfterRemodAdd'] = data_prep['YrSold'] - data_prep['YearRemodAdd']\ndata_prep['HouseAgeYears'] = data_prep['YrSold'] - data_prep['YearBuilt']\n\n# Area\ndata_prep['SummerPorchSF'] = data_prep['OpenPorchSF'] + data_prep['3SsnPorch']\ndata_prep['WinterPorchSF'] = data_prep['EnclosedPorch'] + data_prep['3SsnPorch']\ndata_prep['AnyPorchSF'] = data_prep['OpenPorchSF'] + data_prep['EnclosedPorch'] + data_prep['3SsnPorch']\ndata_prep['1st2ndAndBsmtFlrSF'] = data_prep['1stFlrSF'] + data_prep['2ndFlrSF'] + data_prep['TotalBsmtSF']\nfor f in ['BedroomAbvGr', 'TotRmsAbvGrd']:\n    data_prep[f'1stFlrSFPer{f}'] = data_prep['1stFlrSF'] / data_prep[f]\n    data_prep[f'1st2ndAndBsmtFlrSFPer{f}'] = data_prep['1st2ndAndBsmtFlrSF'] / data_prep[f]\n    data_prep[f'2ndFlrSFPer{f}'] = data_prep['2ndFlrSF'] / data_prep[f]\n    data_prep[f'3SsnPorchSFPer{f}'] = data_prep['3SsnPorch'] / data_prep[f]\n    data_prep[f'AnyPorchSFPer{f}'] = data_prep['AnyPorchSF'] / data_prep[f]\n    data_prep[f'BsmtFinSF1Per{f}'] = data_prep['BsmtFinSF1'] / data_prep[f]\n    data_prep[f'BsmtFinSF2Per{f}'] = data_prep['BsmtFinSF2'] / data_prep[f]\n    data_prep[f'BsmtUnfSFPer{f}'] = data_prep['BsmtUnfSF'] / data_prep[f]\n    data_prep[f'EnclosedPorchSFPer{f}'] = data_prep['EnclosedPorch'] / data_prep[f]\n    data_prep[f'GarageAreaPer{f}'] = data_prep['GarageArea'] / data_prep[f]\n    data_prep[f'GrLivAreaPer{f}'] = data_prep['GrLivArea'] / data_prep[f]\n    data_prep[f'LotAreaPer{f}'] = data_prep['LotArea'] / data_prep[f]\n    data_prep[f'OpenPorchSFPer{f}'] = data_prep['OpenPorchSF'] / data_prep[f]\n    data_prep[f'PoolAreaPer{f}'] = data_prep['PoolArea'] / data_prep[f]\n    data_prep[f'ScreenPorchPer{f}'] = data_prep['ScreenPorch'] / data_prep[f]\n    data_prep[f'WinterPorchSFPer{f}'] = data_prep['WinterPorchSF'] / data_prep[f]\n    data_prep[f'WoodDeckSFPer{f}'] = data_prep['WoodDeckSF'] / data_prep[f]\n\n# Numeric\ndata_prep['AnyFullBath'] = data_prep['FullBath'] + data_prep['BsmtFullBath']\ndata_prep['BsmtAnyBath'] = data_prep['BsmtFullBath'] + data_prep['BsmtHalfBath'] * 0.5\ndata_prep['AnyBath'] = data_prep['FullBath'] + data_prep['HalfBath'] * 0.5\ndata_prep['AnyBathSum'] = data_prep['BsmtAnyBath'] + data_prep['AnyBath']\nfor f in ['GarageCars', 'TotRmsAbvGrd']:\n    data_prep[f'1stFlrSFPer{f}'] = data_prep['1stFlrSF'] / data_prep[f]\n    data_prep[f'FireplacesPer{f}'] = data_prep['Fireplaces'] / data_prep[f]\n    data_prep[f'KitchenAbvGrPer{f}'] = data_prep['KitchenAbvGr'] / data_prep[f]\n    data_prep[f'FullBathPer{f}'] = data_prep['FullBath'] / data_prep[f]\n    data_prep[f'BsmtAnyBathPer{f}'] = data_prep['BsmtAnyBath'] / data_prep[f]\n    data_prep[f'AnyBathPer{f}'] = data_prep['AnyBath'] / data_prep[f]\n    data_prep[f'AnyBathSumPer{f}'] = data_prep['AnyBathSum'] / data_prep[f]\n\n# Binary\ndata_prep['IsRemodeled'] = data_prep['YearRemodAdd'] != data_prep['YearRemodAdd']\ndata_prep['HasPool'] = data_prep['PoolArea'] > 0\ndata_prep['HasFireplace'] = data_prep['Fireplaces'] > 0\ndata_prep['HasPorch'] = data_prep['AnyPorchSF'] > 0\n    \ndata_prep.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.066365Z","iopub.execute_input":"2024-10-06T14:07:12.066781Z","iopub.status.idle":"2024-10-06T14:07:12.135814Z","shell.execute_reply.started":"2024-10-06T14:07:12.066729Z","shell.execute_reply":"2024-10-06T14:07:12.134627Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(1460, 145)"},"metadata":{}}]},{"cell_type":"markdown","source":"## AutoML","metadata":{}},{"cell_type":"code","source":"train, test = train_test_split(\n    data_prep,\n    test_size=0.2,\n    random_state=rs\n)\n\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.139750Z","iopub.execute_input":"2024-10-06T14:07:12.140121Z","iopub.status.idle":"2024-10-06T14:07:12.154977Z","shell.execute_reply.started":"2024-10-06T14:07:12.140085Z","shell.execute_reply":"2024-10-06T14:07:12.153612Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"((1168, 145), (292, 145))"},"metadata":{}}]},{"cell_type":"code","source":"task = Task('reg', metric='mae')\n\ntrain_nunique = train.nunique()\ncategorical = list(train_nunique[train_nunique < 30].keys())\n\nroles = {\n    'target': target_col,\n    'category': categorical\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.156473Z","iopub.execute_input":"2024-10-06T14:07:12.157233Z","iopub.status.idle":"2024-10-06T14:07:12.192783Z","shell.execute_reply.started":"2024-10-06T14:07:12.157183Z","shell.execute_reply":"2024-10-06T14:07:12.191660Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Пресет для табличных данных","metadata":{}},{"cell_type":"code","source":"timeout = 6000\nthreads = 4\ncv = 5","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.194117Z","iopub.execute_input":"2024-10-06T14:07:12.194509Z","iopub.status.idle":"2024-10-06T14:07:12.199572Z","shell.execute_reply.started":"2024-10-06T14:07:12.194469Z","shell.execute_reply":"2024-10-06T14:07:12.198368Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"%%time\nautoml = TabularAutoML(task = task,\n                       timeout = timeout,\n                       cpu_limit = threads,\n                       reader_params = {'n_jobs': threads, 'random_state': rs, 'cv': cv})\n\noof_pred = automl.fit_predict(train, roles = roles, verbose = 3)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:07:12.201195Z","iopub.execute_input":"2024-10-06T14:07:12.202215Z","iopub.status.idle":"2024-10-06T14:15:44.287236Z","shell.execute_reply.started":"2024-10-06T14:07:12.202164Z","shell.execute_reply":"2024-10-06T14:15:44.286057Z"},"_kg_hide-output":true,"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[14:07:12] Stdout logging level is INFO3.\n[14:07:12] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n[14:07:12] Task: reg\n\n[14:07:12] Start automl preset with listed constraints:\n[14:07:12] - time: 6000.00 seconds\n[14:07:12] - CPU: 4 cores\n[14:07:12] - memory: 16 GB\n\n[14:07:12] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[14:07:18] Feats was rejected during automatic roles guess: []\n[14:07:18] Layer \u001b[1m1\u001b[0m train process start. Time left 5993.39 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:07:19] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[14:07:19] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:07:19] Linear model: C = 1e-05 score = -38437.44207398504\n[14:07:19] Linear model: C = 5e-05 score = -23876.3640491453\n[14:07:20] Linear model: C = 0.0001 score = -20853.782118055555\n[14:07:20] Linear model: C = 0.0005 score = -17296.364817040598\n[14:07:20] Linear model: C = 0.001 score = -17296.364783653848\n[14:07:20] Linear model: C = 0.005 score = -16968.600727831195\n[14:07:20] Linear model: C = 0.01 score = -17575.74631076389\n[14:07:21] Linear model: C = 0.05 score = -19809.12483306624\n[14:07:21] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:07:21] Linear model: C = 1e-05 score = -37831.0640357906\n[14:07:21] Linear model: C = 5e-05 score = -23379.572165464742\n[14:07:21] Linear model: C = 0.0001 score = -20575.7175647703\n[14:07:21] Linear model: C = 0.0005 score = -18457.50475761218\n[14:07:22] Linear model: C = 0.001 score = -18378.786541800215\n[14:07:22] Linear model: C = 0.005 score = -18378.789479834402\n[14:07:22] Linear model: C = 0.01 score = -18803.51800380609\n[14:07:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:07:22] Linear model: C = 1e-05 score = -37300.01158520299\n[14:07:22] Linear model: C = 5e-05 score = -24500.791533119656\n[14:07:22] Linear model: C = 0.0001 score = -21517.886034321582\n[14:07:23] Linear model: C = 0.0005 score = -18192.01226232806\n[14:07:23] Linear model: C = 0.001 score = -17990.04738623464\n[14:07:23] Linear model: C = 0.005 score = -18140.44552951389\n[14:07:24] Linear model: C = 0.01 score = -18466.557592147437\n[14:07:24] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:07:24] Linear model: C = 1e-05 score = -34848.492120439914\n[14:07:24] Linear model: C = 5e-05 score = -24075.789364270386\n[14:07:24] Linear model: C = 0.0001 score = -21574.885528433475\n[14:07:24] Linear model: C = 0.0005 score = -18396.286849517168\n[14:07:24] Linear model: C = 0.001 score = -17625.34316322425\n[14:07:25] Linear model: C = 0.005 score = -16887.73678916309\n[14:07:25] Linear model: C = 0.01 score = -16887.73769447425\n[14:07:25] Linear model: C = 0.05 score = -17691.47864136266\n[14:07:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:07:25] Linear model: C = 1e-05 score = -33304.94450777897\n[14:07:25] Linear model: C = 5e-05 score = -21460.37536883047\n[14:07:25] Linear model: C = 0.0001 score = -19108.766362660943\n[14:07:26] Linear model: C = 0.0005 score = -16271.260779908798\n[14:07:26] Linear model: C = 0.001 score = -15908.611856223177\n[14:07:26] Linear model: C = 0.005 score = -15908.611017972104\n[14:07:26] Linear model: C = 0.01 score = -15908.61085032189\n[14:07:26] Linear model: C = 0.05 score = -17930.699872585836\n[14:07:26] Linear model: C = 0.1 score = -17930.698464324036\n[14:07:26] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17228.175264959467\u001b[0m\n[14:07:26] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[14:07:26] Time left 5985.57 secs\n\n[14:07:26] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:07:29] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[14:07:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[14:07:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:07:29] Training until validation scores don't improve for 200 rounds\n[14:07:31] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:07:31] Training until validation scores don't improve for 200 rounds\n[14:07:34] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:07:34] Training until validation scores don't improve for 200 rounds\n[14:07:36] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:07:36] Training until validation scores don't improve for 200 rounds\n[14:07:40] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:07:40] Training until validation scores don't improve for 200 rounds\n[14:07:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15856.072302413313\u001b[0m\n[14:07:41] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[14:07:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[14:07:41] Training until validation scores don't improve for 200 rounds\n[14:07:46] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15437.15030715812 in 0:00:04.140925\n[14:07:46] Training until validation scores don't improve for 200 rounds\n[14:07:48] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -15541.037560096154 in 0:00:02.159263\n[14:07:48] Training until validation scores don't improve for 200 rounds\n[14:07:50] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -15598.111144497863 in 0:00:02.143199\n[14:07:50] Training until validation scores don't improve for 200 rounds\n[14:07:53] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -15523.60126201923 in 0:00:02.625269\n[14:07:53] Training until validation scores don't improve for 200 rounds\n[14:07:54] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -15299.093015491453 in 0:00:01.723006\n[14:07:54] Training until validation scores don't improve for 200 rounds\n[14:07:57] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -15405.343382745727 in 0:00:02.214658\n[14:07:57] Training until validation scores don't improve for 200 rounds\n[14:07:59] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15475.027844551281 in 0:00:02.394816\n[14:07:59] Training until validation scores don't improve for 200 rounds\n[14:08:01] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -15064.250434027777 in 0:00:01.613093\n[14:08:01] Training until validation scores don't improve for 200 rounds\n[14:08:04] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15873.907535389957 in 0:00:03.908845\n[14:08:04] Training until validation scores don't improve for 200 rounds\n[14:08:06] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -15412.106537126068 in 0:00:01.672002\n[14:08:06] Training until validation scores don't improve for 200 rounds\n[14:08:08] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527} scored -15192.529280181623 in 0:00:01.773182\n[14:08:08] Training until validation scores don't improve for 200 rounds\n[14:08:10] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5075634079566923, 'num_leaves': 165, 'bagging_fraction': 0.6795146156302498, 'min_sum_hessian_in_leaf': 0.026738277166992196, 'reg_alpha': 0.0015258645761591619, 'reg_lambda': 0.01881061891210943} scored -15351.912626869658 in 0:00:01.753268\n[14:08:10] Training until validation scores don't improve for 200 rounds\n[14:08:12] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 129, 'bagging_fraction': 0.6794216628122437, 'min_sum_hessian_in_leaf': 0.01875620628228737, 'reg_alpha': 0.0437281057923299, 'reg_lambda': 0.008452229729634516} scored -15433.630542200855 in 0:00:01.935614\n[14:08:12] Training until validation scores don't improve for 200 rounds\n[14:08:14] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.580632857909944, 'num_leaves': 175, 'bagging_fraction': 0.6931449938963745, 'min_sum_hessian_in_leaf': 0.0012748888933395554, 'reg_alpha': 7.743660314424457e-05, 'reg_lambda': 0.004387238736364167} scored -15336.869791666666 in 0:00:02.166794\n[14:08:14] Training until validation scores don't improve for 200 rounds\n[14:08:16] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.6050778051161564, 'num_leaves': 117, 'bagging_fraction': 0.7406442464830113, 'min_sum_hessian_in_leaf': 0.49597135657371333, 'reg_alpha': 0.07389181849439323, 'reg_lambda': 3.806966588951351e-05} scored -15351.943209134615 in 0:00:01.944572\n[14:08:16] Training until validation scores don't improve for 200 rounds\n[14:08:20] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 185, 'bagging_fraction': 0.6223441463224709, 'min_sum_hessian_in_leaf': 3.113484383311032, 'reg_alpha': 4.150722101207275e-05, 'reg_lambda': 0.23706626312372373} scored -15707.40344551282 in 0:00:03.812150\n[14:08:20] Training until validation scores don't improve for 200 rounds\n[14:08:21] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5065701578589041, 'num_leaves': 153, 'bagging_fraction': 0.7382891993530122, 'min_sum_hessian_in_leaf': 0.1341831353198184, 'reg_alpha': 0.012787488060337839, 'reg_lambda': 0.0006027209302579824} scored -15211.438167735043 in 0:00:01.791902\n[14:08:21] Training until validation scores don't improve for 200 rounds\n[14:08:23] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6426075673808482, 'num_leaves': 105, 'bagging_fraction': 0.6461408885576574, 'min_sum_hessian_in_leaf': 0.03465743419765038, 'reg_alpha': 6.176204999488035e-06, 'reg_lambda': 1.4162462058323914e-06} scored -15549.351161858975 in 0:00:01.659710\n[14:08:23] Training until validation scores don't improve for 200 rounds\n[14:08:26] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.560545561591961, 'num_leaves': 203, 'bagging_fraction': 0.9790786324781682, 'min_sum_hessian_in_leaf': 1.7662420267092591, 'reg_alpha': 0.0003812005870016122, 'reg_lambda': 0.03988487774796662} scored -15443.449736244658 in 0:00:02.766395\n[14:08:26] Training until validation scores don't improve for 200 rounds\n[14:08:28] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8696664761533919, 'num_leaves': 21, 'bagging_fraction': 0.5011551454270256, 'min_sum_hessian_in_leaf': 0.31914768556465484, 'reg_alpha': 0.36714255469878165, 'reg_lambda': 0.0015579107174789602} scored -15549.27547409188 in 0:00:01.949474\n[14:08:28] Training until validation scores don't improve for 200 rounds\n[14:08:30] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.5542640757916181, 'num_leaves': 150, 'bagging_fraction': 0.8879124430248126, 'min_sum_hessian_in_leaf': 0.012701877952916336, 'reg_alpha': 6.308891891166231e-07, 'reg_lambda': 0.00010079030010438313} scored -15343.578125 in 0:00:02.345981\n[14:08:30] Training until validation scores don't improve for 200 rounds\n[14:08:32] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5217842204063585, 'num_leaves': 142, 'bagging_fraction': 0.7460102480615723, 'min_sum_hessian_in_leaf': 0.11757780283061718, 'reg_alpha': 0.004939190563635179, 'reg_lambda': 0.0007776998164278827} scored -15079.373631143162 in 0:00:01.984133\n[14:08:32] Training until validation scores don't improve for 200 rounds\n[14:08:34] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.6298581949137815, 'num_leaves': 95, 'bagging_fraction': 0.7752847229001597, 'min_sum_hessian_in_leaf': 0.06917430994658696, 'reg_alpha': 0.0031918818263396145, 'reg_lambda': 0.05190925408128149} scored -15466.611945779914 in 0:00:02.116351\n[14:08:34] Training until validation scores don't improve for 200 rounds\n[14:08:36] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.5014723328935634, 'num_leaves': 137, 'bagging_fraction': 0.7220335716501547, 'min_sum_hessian_in_leaf': 0.20603698965591502, 'reg_alpha': 7.756566674341428e-05, 'reg_lambda': 0.0029088409681667206} scored -15213.046307425213 in 0:00:01.790093\n[14:08:36] Training until validation scores don't improve for 200 rounds\n[14:08:38] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5446537895254564, 'num_leaves': 195, 'bagging_fraction': 0.6568471410965274, 'min_sum_hessian_in_leaf': 0.7567673750576145, 'reg_alpha': 0.00051500531389376, 'reg_lambda': 3.6244464006940615e-06} scored -15441.63374732906 in 0:00:01.711194\n[14:08:38] Training until validation scores don't improve for 200 rounds\n[14:08:40] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6792651342220943, 'num_leaves': 254, 'bagging_fraction': 0.5736306798333981, 'min_sum_hessian_in_leaf': 0.04227311657579579, 'reg_alpha': 0.013427845922787384, 'reg_lambda': 0.00019260169843213652} scored -15356.388888888889 in 0:00:01.832866\n[14:08:40] Training until validation scores don't improve for 200 rounds\n[14:08:42] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.6042882069236802, 'num_leaves': 225, 'bagging_fraction': 0.7146966192147806, 'min_sum_hessian_in_leaf': 0.01190308373671999, 'reg_alpha': 1.6595963980295608e-05, 'reg_lambda': 0.0017916358235073526} scored -15343.527143429486 in 0:00:02.013369\n[14:08:42] Training until validation scores don't improve for 200 rounds\n[14:08:43] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.5608977024645603, 'num_leaves': 139, 'bagging_fraction': 0.6332395074528491, 'min_sum_hessian_in_leaf': 0.1118867020013122, 'reg_alpha': 0.49950355102919425, 'reg_lambda': 0.20454056928511757} scored -15293.254640758547 in 0:00:01.630577\n[14:08:43] Training until validation scores don't improve for 200 rounds\n[14:08:45] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5326696634354824, 'num_leaves': 166, 'bagging_fraction': 0.7799866395392466, 'min_sum_hessian_in_leaf': 9.074966324558188, 'reg_alpha': 0.000252345142222476, 'reg_lambda': 0.00010147769546477605} scored -15238.552951388889 in 0:00:02.181127\n[14:08:46] Training until validation scores don't improve for 200 rounds\n[14:08:50] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6584176056288116, 'num_leaves': 122, 'bagging_fraction': 0.906708728779495, 'min_sum_hessian_in_leaf': 0.20548911823668425, 'reg_alpha': 6.994225394748239e-07, 'reg_lambda': 5.958769138211634e-07} scored -15378.413161057691 in 0:00:04.574047\n[14:08:50] Training until validation scores don't improve for 200 rounds\n[14:08:53] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.615096419362078, 'num_leaves': 213, 'bagging_fraction': 0.8293754533096087, 'min_sum_hessian_in_leaf': 0.2794558032782495, 'reg_alpha': 0.008953069722845533, 'reg_lambda': 9.243625021455677e-08} scored -15559.201655982906 in 0:00:02.480269\n[14:08:53] Training until validation scores don't improve for 200 rounds\n[14:08:54] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5063120577270553, 'num_leaves': 153, 'bagging_fraction': 0.7518065719207607, 'min_sum_hessian_in_leaf': 0.10376408959363408, 'reg_alpha': 0.02457217936422624, 'reg_lambda': 0.0008314575716456798} scored -15082.315104166666 in 0:00:01.839705\n[14:08:54] Training until validation scores don't improve for 200 rounds\n[14:08:56] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.5275506570340389, 'num_leaves': 152, 'bagging_fraction': 0.7635248482666039, 'min_sum_hessian_in_leaf': 0.0631630329448538, 'reg_alpha': 0.051052774768512714, 'reg_lambda': 0.015092944368301333} scored -15329.252871260684 in 0:00:02.046567\n[14:08:56] Training until validation scores don't improve for 200 rounds\n[14:08:58] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.571625292725493, 'num_leaves': 178, 'bagging_fraction': 0.7011209187716034, 'min_sum_hessian_in_leaf': 0.42414977180476177, 'reg_alpha': 0.2954452398540231, 'reg_lambda': 0.0007163366582284483} scored -15355.65281116453 in 0:00:01.874363\n[14:08:58] Training until validation scores don't improve for 200 rounds\n[14:09:01] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5007879202903434, 'num_leaves': 112, 'bagging_fraction': 0.8078109153905211, 'min_sum_hessian_in_leaf': 0.8947322901085024, 'reg_alpha': 0.003592687870844232, 'reg_lambda': 8.294667356727814} scored -15487.39953926282 in 0:00:02.412899\n[14:09:01] Training until validation scores don't improve for 200 rounds\n[14:09:03] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.576778129380054, 'num_leaves': 88, 'bagging_fraction': 0.6672185955354222, 'min_sum_hessian_in_leaf': 0.17175729935836545, 'reg_alpha': 0.0008518445302448704, 'reg_lambda': 3.431262209291715e-05} scored -15484.154013087607 in 0:00:01.919753\n[14:09:03] Training until validation scores don't improve for 200 rounds\n[14:09:05] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.5330157184101648, 'num_leaves': 77, 'bagging_fraction': 0.6154350921999799, 'min_sum_hessian_in_leaf': 0.09495171965450544, 'reg_alpha': 0.00022125643102403634, 'reg_lambda': 0.005644071850989258} scored -15177.227931356838 in 0:00:01.824832\n[14:09:05] Training until validation scores don't improve for 200 rounds\n[14:09:06] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.5355020150280779, 'num_leaves': 73, 'bagging_fraction': 0.578724284080113, 'min_sum_hessian_in_leaf': 0.09188661870628365, 'reg_alpha': 2.251188073676007e-06, 'reg_lambda': 0.0007471460069147712} scored -15212.866653311965 in 0:00:01.772086\n[14:09:06] Training until validation scores don't improve for 200 rounds\n[14:09:08] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.714580642711297, 'num_leaves': 42, 'bagging_fraction': 0.6063484186202988, 'min_sum_hessian_in_leaf': 0.4178887531961713, 'reg_alpha': 0.00013197745140308093, 'reg_lambda': 0.004706461163184023} scored -15301.330762553418 in 0:00:02.002329\n[14:09:08] Training until validation scores don't improve for 200 rounds\n[14:09:10] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.6836666147625345, 'num_leaves': 77, 'bagging_fraction': 0.5565482251355203, 'min_sum_hessian_in_leaf': 2.9374977241848526, 'reg_alpha': 3.762817262535499e-05, 'reg_lambda': 1.0487128386983097e-05} scored -15374.778345352564 in 0:00:01.811044\n[14:09:10] Training until validation scores don't improve for 200 rounds\n[14:09:13] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.5367164593053321, 'num_leaves': 224, 'bagging_fraction': 0.8574093452445455, 'min_sum_hessian_in_leaf': 0.05186964420886417, 'reg_alpha': 1.3631920761604949e-05, 'reg_lambda': 0.00018648171086037033} scored -15537.663561698719 in 0:00:02.463392\n[14:09:13] Training until validation scores don't improve for 200 rounds\n[14:09:14] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5276325940549338, 'num_leaves': 102, 'bagging_fraction': 0.6124661685791719, 'min_sum_hessian_in_leaf': 0.027050721891005918, 'reg_alpha': 0.006685307104863822, 'reg_lambda': 0.05978945728299267} scored -15153.48467548077 in 0:00:01.815442\n[14:09:14] Training until validation scores don't improve for 200 rounds\n[14:09:16] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5836210982986254, 'num_leaves': 94, 'bagging_fraction': 0.5324845669995677, 'min_sum_hessian_in_leaf': 0.08591644428044531, 'reg_alpha': 0.11693646114304511, 'reg_lambda': 1.4956621821488312} scored -15167.508313301281 in 0:00:01.764045\n[14:09:16] Training until validation scores don't improve for 200 rounds\n[14:09:18] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5765089884838233, 'num_leaves': 99, 'bagging_fraction': 0.5116937679835181, 'min_sum_hessian_in_leaf': 0.015330068188311438, 'reg_alpha': 0.15393039669359754, 'reg_lambda': 2.3047742910081093} scored -15184.674512553418 in 0:00:01.661693\n[14:09:18] Training until validation scores don't improve for 200 rounds\n[14:09:20] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.8611472869134348, 'num_leaves': 108, 'bagging_fraction': 0.5288271305037682, 'min_sum_hessian_in_leaf': 0.00557741662347585, 'reg_alpha': 0.9281508729505926, 'reg_lambda': 1.0753545379924625} scored -15470.053518963676 in 0:00:02.018140\n[14:09:20] Training until validation scores don't improve for 200 rounds\n[14:09:23] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.5895019286622576, 'num_leaves': 90, 'bagging_fraction': 0.5839853184721069, 'min_sum_hessian_in_leaf': 0.03583286398037884, 'reg_alpha': 8.920584909807767, 'reg_lambda': 0.5565037783983512} scored -15116.929453792734 in 0:00:03.360778\n[14:09:23] Training until validation scores don't improve for 200 rounds\n[14:09:25] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.5193966546482881, 'num_leaves': 124, 'bagging_fraction': 0.5873077972910129, 'min_sum_hessian_in_leaf': 0.009789443402268165, 'reg_alpha': 5.13631419732072, 'reg_lambda': 0.08698592051778735} scored -15355.609575320514 in 0:00:01.865995\n[14:09:25] Training until validation scores don't improve for 200 rounds\n[14:09:27] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.5527948361590476, 'num_leaves': 134, 'bagging_fraction': 0.5639442050894392, 'min_sum_hessian_in_leaf': 0.02793007072565349, 'reg_alpha': 5.840796733366603e-08, 'reg_lambda': 0.3632416599122077} scored -15377.37189503205 in 0:00:01.760336\n[14:09:27] Training until validation scores don't improve for 200 rounds\n[14:09:29] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.6285185762805123, 'num_leaves': 239, 'bagging_fraction': 0.6326549942530613, 'min_sum_hessian_in_leaf': 0.021962003920189047, 'reg_alpha': 0.028084672554982044, 'reg_lambda': 0.01592702418386994} scored -15417.186298076924 in 0:00:01.833961\n[14:09:29] Training until validation scores don't improve for 200 rounds\n[14:09:31] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.590116299520884, 'num_leaves': 43, 'bagging_fraction': 0.7241936806439971, 'min_sum_hessian_in_leaf': 0.0020453494572062005, 'reg_alpha': 2.293471855332165, 'reg_lambda': 3.7010255218627433} scored -15332.89563301282 in 0:00:02.193307\n[14:09:31] Training until validation scores don't improve for 200 rounds\n[14:09:33] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.7624591096964923, 'num_leaves': 59, 'bagging_fraction': 0.8022568646083734, 'min_sum_hessian_in_leaf': 0.007653069999781309, 'reg_alpha': 0.0010994672251300795, 'reg_lambda': 0.5694244860787799} scored -15383.823584401709 in 0:00:02.394148\n[14:09:33] Training until validation scores don't improve for 200 rounds\n[14:09:35] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.5189916045623812, 'num_leaves': 89, 'bagging_fraction': 0.5360308603144361, 'min_sum_hessian_in_leaf': 0.038330832585757146, 'reg_alpha': 0.11039582474766131, 'reg_lambda': 1.3315269897308686} scored -15258.464109241453 in 0:00:01.706553\n[14:09:35] Training until validation scores don't improve for 200 rounds\n[14:09:37] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.5539088981120355, 'num_leaves': 102, 'bagging_fraction': 0.59020435496124, 'min_sum_hessian_in_leaf': 0.07543597825858363, 'reg_alpha': 1.438618651331083, 'reg_lambda': 0.11513158001492198} scored -15272.82405181624 in 0:00:01.784520\n[14:09:37] Training until validation scores don't improve for 200 rounds\n[14:09:39] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.6034523107075161, 'num_leaves': 70, 'bagging_fraction': 0.5462362447669515, 'min_sum_hessian_in_leaf': 0.1546490702543751, 'reg_alpha': 0.005674017570597483, 'reg_lambda': 0.6479557262854649} scored -15296.987713675213 in 0:00:01.729748\n[14:09:39] Training until validation scores don't improve for 200 rounds\n[14:09:40] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.5171372018011359, 'num_leaves': 115, 'bagging_fraction': 0.6035544034911824, 'min_sum_hessian_in_leaf': 0.1256976287616443, 'reg_alpha': 0.022844178635476844, 'reg_lambda': 0.03688238947031864} scored -15027.94030448718 in 0:00:01.582201\n[14:09:40] Training until validation scores don't improve for 200 rounds\n[14:09:42] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5006480218125247, 'num_leaves': 118, 'bagging_fraction': 0.6049892583620229, 'min_sum_hessian_in_leaf': 0.2731953260064905, 'reg_alpha': 9.203233649831292, 'reg_lambda': 0.037260146871158605} scored -15103.362613514957 in 0:00:01.646242\n[14:09:42] Training until validation scores don't improve for 200 rounds\n[14:09:44] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.5007250058963767, 'num_leaves': 159, 'bagging_fraction': 0.6522080981600745, 'min_sum_hessian_in_leaf': 0.2895707794296115, 'reg_alpha': 6.36705221190793, 'reg_lambda': 0.0011364236743820033} scored -15448.960336538461 in 0:00:01.727459\n[14:09:44] Training until validation scores don't improve for 200 rounds\n[14:09:45] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.5167061250923789, 'num_leaves': 141, 'bagging_fraction': 0.673458585974486, 'min_sum_hessian_in_leaf': 0.8754712194069258, 'reg_alpha': 0.020856338457463798, 'reg_lambda': 0.03229593044954147} scored -15370.39673477564 in 0:00:01.815707\n[14:09:46] Training until validation scores don't improve for 200 rounds\n[14:09:47] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.5471026464224336, 'num_leaves': 116, 'bagging_fraction': 0.7028592783833295, 'min_sum_hessian_in_leaf': 0.5571023745230138, 'reg_alpha': 9.502743458065897, 'reg_lambda': 0.00028697979646693383} scored -15402.772268963676 in 0:00:01.920080\n[14:09:47] Training until validation scores don't improve for 200 rounds\n[14:09:49] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.5655551780058233, 'num_leaves': 126, 'bagging_fraction': 0.7500745903599736, 'min_sum_hessian_in_leaf': 0.11799006787909394, 'reg_alpha': 0.9559331407075351, 'reg_lambda': 0.0021638550265114195} scored -15252.15187633547 in 0:00:02.003134\n[14:09:49] Training until validation scores don't improve for 200 rounds\n[14:09:52] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.7906179812570138, 'num_leaves': 144, 'bagging_fraction': 0.5957202956591533, 'min_sum_hessian_in_leaf': 0.3515010938783362, 'reg_alpha': 3.0812184309056247, 'reg_lambda': 6.6168746281783e-05} scored -15531.058727297008 in 0:00:02.258576\n[14:09:52] Training until validation scores don't improve for 200 rounds\n[14:09:55] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.5178066488211249, 'num_leaves': 131, 'bagging_fraction': 0.6263817407751251, 'min_sum_hessian_in_leaf': 0.04736345202762902, 'reg_alpha': 0.0017463324358469982, 'reg_lambda': 0.009024385136874523} scored -15331.780749198719 in 0:00:03.267421\n[14:09:55] Training until validation scores don't improve for 200 rounds\n[14:09:57] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5380628210985368, 'num_leaves': 83, 'bagging_fraction': 0.6401891672647368, 'min_sum_hessian_in_leaf': 0.2180337794845355, 'reg_alpha': 0.028906232798047257, 'reg_lambda': 0.08782359329116181} scored -15424.256376869658 in 0:00:01.744147\n[14:09:57] Training until validation scores don't improve for 200 rounds\n[14:09:58] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.517422860718765, 'num_leaves': 105, 'bagging_fraction': 0.6025195177479694, 'min_sum_hessian_in_leaf': 1.4407951332835978, 'reg_alpha': 0.323704478491072, 'reg_lambda': 0.033743000452615635} scored -15081.597322382479 in 0:00:01.627807\n[14:09:58] Training until validation scores don't improve for 200 rounds\n[14:10:00] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.9690634132749897, 'num_leaves': 116, 'bagging_fraction': 0.5683107305084116, 'min_sum_hessian_in_leaf': 2.473004951717347, 'reg_alpha': 0.2126889581637217, 'reg_lambda': 0.03386561275109628} scored -15575.478098290598 in 0:00:01.898704\n[14:10:00] Training until validation scores don't improve for 200 rounds\n[14:10:02] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5030095470979491, 'num_leaves': 171, 'bagging_fraction': 0.6063364347900924, 'min_sum_hessian_in_leaf': 1.3545635170743144, 'reg_alpha': 0.46365885700550385, 'reg_lambda': 0.008393591016347257} scored -15086.54250133547 in 0:00:01.680316\n[14:10:02] Training until validation scores don't improve for 200 rounds\n[14:10:05] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.5036596851303135, 'num_leaves': 167, 'bagging_fraction': 0.9387272095841712, 'min_sum_hessian_in_leaf': 1.2980693791788052, 'reg_alpha': 0.7010390432294894, 'reg_lambda': 0.008186636344765187} scored -15542.936247996795 in 0:00:02.543551\n[14:10:05] Training until validation scores don't improve for 200 rounds\n[14:10:07] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.5181951601142113, 'num_leaves': 179, 'bagging_fraction': 0.6608647543181623, 'min_sum_hessian_in_leaf': 1.7042617462570513, 'reg_alpha': 0.06416060758188467, 'reg_lambda': 0.0024436027674454427} scored -15428.626502403846 in 0:00:02.318228\n[14:10:07] Training until validation scores don't improve for 200 rounds\n[14:10:11] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.5479046473086407, 'num_leaves': 187, 'bagging_fraction': 0.7848697786346471, 'min_sum_hessian_in_leaf': 0.6264634807659278, 'reg_alpha': 0.014684534066565665, 'reg_lambda': 0.000411125217579446} scored -15358.088241185897 in 0:00:03.912174\n[14:10:11] Training until validation scores don't improve for 200 rounds\n[14:10:15] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.8277733897747781, 'num_leaves': 146, 'bagging_fraction': 0.6895814811067853, 'min_sum_hessian_in_leaf': 4.608877159732367, 'reg_alpha': 0.4839384675020479, 'reg_lambda': 0.023548796939435256} scored -15621.598190438035 in 0:00:04.504947\n[14:10:15] Training until validation scores don't improve for 200 rounds\n[14:10:17] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.5622154453498555, 'num_leaves': 160, 'bagging_fraction': 0.6044255041276144, 'min_sum_hessian_in_leaf': 1.0987879013738422, 'reg_alpha': 2.118853991814503, 'reg_lambda': 0.0009168202492874088} scored -15126.314670138889 in 0:00:01.900660\n[14:10:17] Training until validation scores don't improve for 200 rounds\n[14:10:19] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.5015703855744372, 'num_leaves': 252, 'bagging_fraction': 0.5775561356982518, 'min_sum_hessian_in_leaf': 0.14951024953812553, 'reg_alpha': 3.6474346250535676, 'reg_lambda': 0.13844146937071336} scored -15215.82391826923 in 0:00:01.775953\n[14:10:19] Training until validation scores don't improve for 200 rounds\n[14:10:21] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.5253543142589759, 'num_leaves': 109, 'bagging_fraction': 0.6213986241797872, 'min_sum_hessian_in_leaf': 2.00741984683856, 'reg_alpha': 1.5170089803682465, 'reg_lambda': 0.004360232321182847} scored -15123.888888888889 in 0:00:01.633211\n[14:10:21] Training until validation scores don't improve for 200 rounds\n[14:10:23] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.5407137493135381, 'num_leaves': 205, 'bagging_fraction': 0.5540550103195954, 'min_sum_hessian_in_leaf': 0.23926502751861398, 'reg_alpha': 7.816682580289025, 'reg_lambda': 0.010927273339677173} scored -15287.075554220086 in 0:00:01.910857\n[14:10:23] Training until validation scores don't improve for 200 rounds\n[14:10:27] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.51825544096923, 'num_leaves': 121, 'bagging_fraction': 0.8192567240541611, 'min_sum_hessian_in_leaf': 4.859593287883086, 'reg_alpha': 0.31835241190094554, 'reg_lambda': 0.22914587078051063} scored -15431.932391826924 in 0:00:03.877547\n[14:10:27] Training until validation scores don't improve for 200 rounds\n[14:10:28] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.5658666118569555, 'num_leaves': 215, 'bagging_fraction': 0.6433401217500614, 'min_sum_hessian_in_leaf': 0.4427278886964028, 'reg_alpha': 0.04008441209929822, 'reg_lambda': 0.059728014464963515} scored -15445.054086538461 in 0:00:01.533990\n[14:10:28] Training until validation scores don't improve for 200 rounds\n[14:10:30] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.7173446385677641, 'num_leaves': 232, 'bagging_fraction': 0.6013331194953716, 'min_sum_hessian_in_leaf': 0.11469399807925683, 'reg_alpha': 0.21608684058086702, 'reg_lambda': 0.00017659945864324572} scored -15368.107204861111 in 0:00:02.073258\n[14:10:30] Training until validation scores don't improve for 200 rounds\n[14:10:32] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.6215686612327564, 'num_leaves': 132, 'bagging_fraction': 0.5829820288312422, 'min_sum_hessian_in_leaf': 0.16516116728680297, 'reg_alpha': 0.07064540540605004, 'reg_lambda': 0.0004552543109815039} scored -15281.519965277777 in 0:00:02.031441\n[14:10:32] Training until validation scores don't improve for 200 rounds\n[14:10:34] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.6553395094342704, 'num_leaves': 169, 'bagging_fraction': 0.7510015821567455, 'min_sum_hessian_in_leaf': 0.06019859318901422, 'reg_alpha': 1.7974250380348508e-08, 'reg_lambda': 0.005632757317910797} scored -15326.642761752137 in 0:00:01.968173\n[14:10:34] Training until validation scores don't improve for 200 rounds\n[14:10:36] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.5908480587836037, 'num_leaves': 155, 'bagging_fraction': 0.6135853500707823, 'min_sum_hessian_in_leaf': 0.7188392940319179, 'reg_alpha': 0.0037771395097992034, 'reg_lambda': 0.0016206784892770754} scored -15156.522836538461 in 0:00:01.931407\n[14:10:36] Training until validation scores don't improve for 200 rounds\n[14:10:38] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.5115405311399709, 'num_leaves': 97, 'bagging_fraction': 0.51734994754989, 'min_sum_hessian_in_leaf': 0.34133604163609643, 'reg_alpha': 9.00759059877195e-07, 'reg_lambda': 0.02410664212934526} scored -15241.369090544871 in 0:00:01.645651\n[14:10:38] Training until validation scores don't improve for 200 rounds\n[14:10:40] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.5279166927450683, 'num_leaves': 114, 'bagging_fraction': 0.6257677750379511, 'min_sum_hessian_in_leaf': 1.7595784039714761, 'reg_alpha': 1.4315301859913916, 'reg_lambda': 0.0032127523035828686} scored -15198.62720352564 in 0:00:01.940465\n[14:10:40] Training until validation scores don't improve for 200 rounds\n[14:10:42] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5284846767300698, 'num_leaves': 107, 'bagging_fraction': 0.5988374337230528, 'min_sum_hessian_in_leaf': 2.92935012642889, 'reg_alpha': 4.795972999734391, 'reg_lambda': 0.0037729903646507882} scored -15139.019798344018 in 0:00:01.762621\n[14:10:42] Training until validation scores don't improve for 200 rounds\n[14:10:43] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.542360248007481, 'num_leaves': 85, 'bagging_fraction': 0.6209517194094568, 'min_sum_hessian_in_leaf': 1.596449887388047, 'reg_alpha': 1.9781900574629097, 'reg_lambda': 0.012843822168990488} scored -15246.870225694445 in 0:00:01.646212\n[14:10:43] Training until validation scores don't improve for 200 rounds\n[14:10:45] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.5121210307822384, 'num_leaves': 121, 'bagging_fraction': 0.5589958689662093, 'min_sum_hessian_in_leaf': 2.3631323068898333, 'reg_alpha': 0.6691845008312176, 'reg_lambda': 0.0011580894465780104} scored -15371.821380876068 in 0:00:01.332552\n[14:10:45] Training until validation scores don't improve for 200 rounds\n[14:10:46] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.5752903637121796, 'num_leaves': 127, 'bagging_fraction': 0.6456526741364832, 'min_sum_hessian_in_leaf': 0.18585793877004664, 'reg_alpha': 1.3399213312638316, 'reg_lambda': 0.0072987791849551805} scored -15390.405381944445 in 0:00:01.737079\n[14:10:46] Training until validation scores don't improve for 200 rounds\n[14:10:48] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.5545552522274706, 'num_leaves': 110, 'bagging_fraction': 0.5888746752955547, 'min_sum_hessian_in_leaf': 0.9716094097381659, 'reg_alpha': 0.0006595479151007528, 'reg_lambda': 0.4223030342580451} scored -15212.715444711539 in 0:00:01.765744\n[14:10:48] Training until validation scores don't improve for 200 rounds\n[14:10:50] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.523601451024161, 'num_leaves': 95, 'bagging_fraction': 0.7279412822442628, 'min_sum_hessian_in_leaf': 4.092328348718507, 'reg_alpha': 2.1790737472115226e-07, 'reg_lambda': 0.020549582291447672} scored -15325.895032051281 in 0:00:01.825628\n[14:10:50] Training until validation scores don't improve for 200 rounds\n[14:10:52] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.5084180847315075, 'num_leaves': 135, 'bagging_fraction': 0.6647673871724389, 'min_sum_hessian_in_leaf': 1.427497336111076, 'reg_alpha': 9.819220872690206, 'reg_lambda': 0.0006523796422825048} scored -15467.968816773504 in 0:00:01.932608\n[14:10:52] Training until validation scores don't improve for 200 rounds\n[14:10:54] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.5280136298594643, 'num_leaves': 147, 'bagging_fraction': 0.5717936127471377, 'min_sum_hessian_in_leaf': 0.07952193105351388, 'reg_alpha': 0.11257831476736492, 'reg_lambda': 0.04344270915661932} scored -15428.51078392094 in 0:00:01.840461\n[14:10:54] Training until validation scores don't improve for 200 rounds\n[14:10:56] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.5442213169188592, 'num_leaves': 141, 'bagging_fraction': 0.6792227032063942, 'min_sum_hessian_in_leaf': 2.0914400636941965, 'reg_alpha': 4.218381475156108, 'reg_lambda': 0.00011365708015614283} scored -15584.795138888889 in 0:00:01.830001\n[14:10:56] Training until validation scores don't improve for 200 rounds\n[14:10:59] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.5648562377938504, 'num_leaves': 159, 'bagging_fraction': 0.6087886857949321, 'min_sum_hessian_in_leaf': 1.0874174101361158, 'reg_alpha': 2.1689662852165323, 'reg_lambda': 1.1404925485259998e-08} scored -15358.438635149572 in 0:00:03.519521\n[14:10:59] Training until validation scores don't improve for 200 rounds\n[14:11:01] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.5588412733317154, 'num_leaves': 160, 'bagging_fraction': 0.6045525958702508, 'min_sum_hessian_in_leaf': 0.6013752404956427, 'reg_alpha': 0.4514905117717611, 'reg_lambda': 0.0010836823695355106} scored -15044.237947382479 in 0:00:01.847573\n[14:11:01] Training until validation scores don't improve for 200 rounds\n[14:11:03] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.5315392569945341, 'num_leaves': 189, 'bagging_fraction': 0.6288404962579646, 'min_sum_hessian_in_leaf': 0.48071592237999156, 'reg_alpha': 0.5319930173339851, 'reg_lambda': 0.001467918193638974} scored -15180.94123931624 in 0:00:01.758769\n[14:11:03] Training until validation scores don't improve for 200 rounds\n[14:11:04] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.5020543628789133, 'num_leaves': 103, 'bagging_fraction': 0.6184003234620834, 'min_sum_hessian_in_leaf': 0.27292009390230204, 'reg_alpha': 0.3105949115143722, 'reg_lambda': 0.0003082179699800269} scored -15123.01201923077 in 0:00:01.633718\n[14:11:05] Training until validation scores don't improve for 200 rounds\n[14:11:06] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.5021571300851042, 'num_leaves': 171, 'bagging_fraction': 0.6370579967915316, 'min_sum_hessian_in_leaf': 0.2908674744759638, 'reg_alpha': 0.008321438206767545, 'reg_lambda': 2.980443404455195e-05} scored -15318.997696314103 in 0:00:01.836463\n[14:11:06] Training until validation scores don't improve for 200 rounds\n[14:11:08] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.5496613408167783, 'num_leaves': 90, 'bagging_fraction': 0.7648417090162151, 'min_sum_hessian_in_leaf': 0.12765940447331506, 'reg_alpha': 0.19379982161329853, 'reg_lambda': 0.00031698616965046653} scored -15370.631376869658 in 0:00:01.977035\n[14:11:08] Training until validation scores don't improve for 200 rounds\n[14:11:10] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.5122187274439013, 'num_leaves': 81, 'bagging_fraction': 0.6531535864367354, 'min_sum_hessian_in_leaf': 0.6531404486742577, 'reg_alpha': 0.040131148058867055, 'reg_lambda': 5.2589100279855865e-05} scored -15428.782118055555 in 0:00:01.701097\n[14:11:10] Training until validation scores don't improve for 200 rounds\n[14:11:12] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.5832670441613422, 'num_leaves': 103, 'bagging_fraction': 0.548999518423086, 'min_sum_hessian_in_leaf': 0.3606411613215119, 'reg_alpha': 0.10744966385836406, 'reg_lambda': 0.00017398095915645604} scored -15219.394631410256 in 0:00:01.881258\n[14:11:12] Training until validation scores don't improve for 200 rounds\n[14:11:14] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.5368684622444325, 'num_leaves': 67, 'bagging_fraction': 0.5910542532115441, 'min_sum_hessian_in_leaf': 0.09590387299689818, 'reg_alpha': 0.3454482750967686, 'reg_lambda': 0.0006537851760763406} scored -15137.050881410256 in 0:00:01.559748\n[14:11:14] Training until validation scores don't improve for 200 rounds\n[14:11:15] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.5125965823470884, 'num_leaves': 52, 'bagging_fraction': 0.7908006439671802, 'min_sum_hessian_in_leaf': 0.2320831925662456, 'reg_alpha': 0.002596600759310664, 'reg_lambda': 0.0023638935339042547} scored -15369.659922542734 in 0:00:01.842319\n[14:11:15] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[14:11:15] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5171372018011359, 'num_leaves': 115, 'bagging_fraction': 0.6035544034911824, 'min_sum_hessian_in_leaf': 0.1256976287616443, 'reg_alpha': 0.022844178635476844, 'reg_lambda': 0.03688238947031864}\u001b[0m\n achieve -15027.9403 mae\n[14:11:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[14:11:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:11:15] Training until validation scores don't improve for 100 rounds\n[14:11:16] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:11:16] Training until validation scores don't improve for 100 rounds\n[14:11:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:11:16] Training until validation scores don't improve for 100 rounds\n[14:11:17] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:11:17] Training until validation scores don't improve for 100 rounds\n[14:11:17] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:11:17] Training until validation scores don't improve for 100 rounds\n[14:11:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15837.101034086045\u001b[0m\n[14:11:18] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[14:11:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[14:11:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:11:18] 0:\tlearn: 53219.1887573\ttest: 57386.0243703\tbest: 57386.0243703 (0)\ttotal: 54.1ms\tremaining: 1m 48s\n[14:11:19] Stopped by overfitting detector  (300 iterations wait)\n[14:11:19] bestTest = 14507.72825\n[14:11:19] bestIteration = 286\n[14:11:19] Shrink model to first 287 iterations.\n[14:11:19] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:11:19] 0:\tlearn: 53778.9719357\ttest: 56700.4488879\tbest: 56700.4488879 (0)\ttotal: 2.64ms\tremaining: 5.27s\n[14:11:21] Stopped by overfitting detector  (300 iterations wait)\n[14:11:21] bestTest = 16568.54579\n[14:11:21] bestIteration = 797\n[14:11:21] Shrink model to first 798 iterations.\n[14:11:21] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:11:21] 0:\tlearn: 53881.0110594\ttest: 54837.2560226\tbest: 54837.2560226 (0)\ttotal: 2.73ms\tremaining: 5.46s\n[14:11:23] Stopped by overfitting detector  (300 iterations wait)\n[14:11:23] bestTest = 15110.25579\n[14:11:23] bestIteration = 403\n[14:11:23] Shrink model to first 404 iterations.\n[14:11:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:11:23] 0:\tlearn: 54862.5218994\ttest: 51352.0682253\tbest: 51352.0682253 (0)\ttotal: 2.7ms\tremaining: 5.4s\n[14:11:27] bestTest = 14220.279\n[14:11:27] bestIteration = 1756\n[14:11:27] Shrink model to first 1757 iterations.\n[14:11:27] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:11:27] 0:\tlearn: 54766.8306231\ttest: 51163.7618177\tbest: 51163.7618177 (0)\ttotal: 2.77ms\tremaining: 5.53s\n[14:11:28] Stopped by overfitting detector  (300 iterations wait)\n[14:11:28] bestTest = 13869.7739\n[14:11:28] bestIteration = 385\n[14:11:28] Shrink model to first 386 iterations.\n[14:11:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-14856.704091529324\u001b[0m\n[14:11:28] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[14:11:28] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[14:11:29] 0:\tlearn: 53498.9483382\ttest: 57659.8102869\tbest: 57659.8102869 (0)\ttotal: 2.41ms\tremaining: 4.82s\n[14:11:31] Stopped by overfitting detector  (300 iterations wait)\n[14:11:31] bestTest = 15153.65761\n[14:11:31] bestIteration = 845\n[14:11:31] Shrink model to first 846 iterations.\n[14:11:31] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -15153.657969417734 in 0:00:02.699924\n[14:11:31] 0:\tlearn: 53500.6099973\ttest: 57658.8947139\tbest: 57658.8947139 (0)\ttotal: 1.28ms\tremaining: 2.56s\n[14:11:32] Stopped by overfitting detector  (300 iterations wait)\n[14:11:32] bestTest = 14950.54595\n[14:11:32] bestIteration = 840\n[14:11:32] Shrink model to first 841 iterations.\n[14:11:32] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -14950.546240651709 in 0:00:01.417956\n[14:11:32] 0:\tlearn: 53500.5645531\ttest: 57658.8551869\tbest: 57658.8551869 (0)\ttotal: 1.42ms\tremaining: 2.85s\n[14:11:34] Stopped by overfitting detector  (300 iterations wait)\n[14:11:34] bestTest = 14643.57717\n[14:11:34] bestIteration = 953\n[14:11:34] Shrink model to first 954 iterations.\n[14:11:34] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -14643.577206864316 in 0:00:01.503957\n[14:11:34] 0:\tlearn: 53500.5659039\ttest: 57658.8563616\tbest: 57658.8563616 (0)\ttotal: 1.37ms\tremaining: 2.75s\n[14:11:36] bestTest = 14939.77617\n[14:11:36] bestIteration = 1870\n[14:11:36] Shrink model to first 1871 iterations.\n[14:11:36] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -14939.776125133547 in 0:00:02.286305\n[14:11:36] 0:\tlearn: 53206.4018524\ttest: 57399.1451784\tbest: 57399.1451784 (0)\ttotal: 4.06ms\tremaining: 8.12s\n[14:11:41] Stopped by overfitting detector  (300 iterations wait)\n[14:11:41] bestTest = 15036.75223\n[14:11:41] bestIteration = 1472\n[14:11:41] Shrink model to first 1473 iterations.\n[14:11:41] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -15036.751986511752 in 0:00:04.949406\n[14:11:41] 0:\tlearn: 53206.5777540\ttest: 57399.3312551\tbest: 57399.3312551 (0)\ttotal: 5.29ms\tremaining: 10.6s\n[14:11:43] Stopped by overfitting detector  (300 iterations wait)\n[14:11:43] bestTest = 15052.88569\n[14:11:43] bestIteration = 442\n[14:11:43] Shrink model to first 443 iterations.\n[14:11:43] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -15052.885550213676 in 0:00:02.202349\n[14:11:43] 0:\tlearn: 53387.0063489\ttest: 57580.7216117\tbest: 57580.7216117 (0)\ttotal: 3.56ms\tremaining: 7.11s\n[14:11:48] Stopped by overfitting detector  (300 iterations wait)\n[14:11:48] bestTest = 14913.82888\n[14:11:48] bestIteration = 1260\n[14:11:48] Shrink model to first 1261 iterations.\n[14:11:48] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -14913.82892628205 in 0:00:04.354602\n[14:11:48] 0:\tlearn: 53142.2320529\ttest: 57351.3662995\tbest: 57351.3662995 (0)\ttotal: 5.8ms\tremaining: 11.6s\n[14:11:54] Stopped by overfitting detector  (300 iterations wait)\n[14:11:54] bestTest = 15710.78945\n[14:11:54] bestIteration = 1166\n[14:11:54] Shrink model to first 1167 iterations.\n[14:11:54] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -15710.789930555555 in 0:00:06.078754\n[14:11:54] 0:\tlearn: 53525.6449035\ttest: 57681.7784116\tbest: 57681.7784116 (0)\ttotal: 1.22ms\tremaining: 2.45s\n[14:11:55] Stopped by overfitting detector  (300 iterations wait)\n[14:11:55] bestTest = 15068.043\n[14:11:55] bestIteration = 1084\n[14:11:55] Shrink model to first 1085 iterations.\n[14:11:55] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -15068.043102297008 in 0:00:01.645381\n[14:11:56] 0:\tlearn: 53206.4690971\ttest: 57399.2163176\tbest: 57399.2163176 (0)\ttotal: 3.4ms\tremaining: 6.8s\n[14:11:58] Stopped by overfitting detector  (300 iterations wait)\n[14:11:58] bestTest = 15053.09555\n[14:11:58] bestIteration = 488\n[14:11:58] Shrink model to first 489 iterations.\n[14:11:58] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -15053.095836672008 in 0:00:02.290112\n[14:11:58] 0:\tlearn: 53498.8546296\ttest: 57659.6609841\tbest: 57659.6609841 (0)\ttotal: 1.58ms\tremaining: 3.17s\n[14:11:59] Stopped by overfitting detector  (300 iterations wait)\n[14:11:59] bestTest = 14543.31031\n[14:11:59] bestIteration = 536\n[14:11:59] Shrink model to first 537 iterations.\n[14:11:59] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 14} scored -14543.310446714744 in 0:00:01.391388\n[14:11:59] 0:\tlearn: 53498.8546297\ttest: 57659.6609842\tbest: 57659.6609842 (0)\ttotal: 1.8ms\tremaining: 3.6s\n[14:12:00] Stopped by overfitting detector  (300 iterations wait)\n[14:12:00] bestTest = 14543.31031\n[14:12:00] bestIteration = 536\n[14:12:00] Shrink model to first 537 iterations.\n[14:12:00] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3578748871872542e-08, 'min_data_in_leaf': 16} scored -14543.310446714744 in 0:00:01.397510\n[14:12:01] 0:\tlearn: 53498.8546297\ttest: 57659.6609843\tbest: 57659.6609843 (0)\ttotal: 1.65ms\tremaining: 3.3s\n[14:12:02] Stopped by overfitting detector  (300 iterations wait)\n[14:12:02] bestTest = 14543.31031\n[14:12:02] bestIteration = 536\n[14:12:02] Shrink model to first 537 iterations.\n[14:12:02] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3859049893035638e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.710885\n[14:12:02] 0:\tlearn: 53498.8546299\ttest: 57659.6609846\tbest: 57659.6609846 (0)\ttotal: 1.94ms\tremaining: 3.88s\n[14:12:04] Stopped by overfitting detector  (300 iterations wait)\n[14:12:04] bestTest = 14543.31031\n[14:12:04] bestIteration = 536\n[14:12:04] Shrink model to first 537 iterations.\n[14:12:04] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.8992420291203052e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.617759\n[14:12:04] 0:\tlearn: 53218.5345661\ttest: 57385.1874497\tbest: 57385.1874497 (0)\ttotal: 2.29ms\tremaining: 4.58s\n[14:12:08] bestTest = 14556.46195\n[14:12:08] bestIteration = 1876\n[14:12:08] Shrink model to first 1877 iterations.\n[14:12:08] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 7.161723243485632e-07, 'min_data_in_leaf': 19} scored -14556.461705395299 in 0:00:04.127365\n[14:12:08] 0:\tlearn: 53218.5345446\ttest: 57385.1874221\tbest: 57385.1874221 (0)\ttotal: 2.09ms\tremaining: 4.18s\n[14:12:12] bestTest = 14556.4619\n[14:12:12] bestIteration = 1876\n[14:12:12] Shrink model to first 1877 iterations.\n[14:12:12] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.8794455088186337e-07, 'min_data_in_leaf': 17} scored -14556.46140491453 in 0:00:04.392246\n[14:12:13] 0:\tlearn: 53498.8546327\ttest: 57659.6609891\tbest: 57659.6609891 (0)\ttotal: 1.65ms\tremaining: 3.31s\n[14:12:14] Stopped by overfitting detector  (300 iterations wait)\n[14:12:14] bestTest = 14543.31031\n[14:12:14] bestIteration = 536\n[14:12:14] Shrink model to first 537 iterations.\n[14:12:14] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 9.247206024258267e-08, 'min_data_in_leaf': 12} scored -14543.310546875 in 0:00:01.391714\n[14:12:14] 0:\tlearn: 53218.5350479\ttest: 57385.1880667\tbest: 57385.1880667 (0)\ttotal: 2.35ms\tremaining: 4.71s\n[14:12:18] bestTest = 14556.46298\n[14:12:18] bestIteration = 1876\n[14:12:18] Shrink model to first 1877 iterations.\n[14:12:18] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 8.061173629825617e-06, 'min_data_in_leaf': 12} scored -14556.462840544871 in 0:00:04.094045\n[14:12:18] 0:\tlearn: 53503.5527657\ttest: 57667.0385007\tbest: 57667.0385007 (0)\ttotal: 1.59ms\tremaining: 3.17s\n[14:12:21] Stopped by overfitting detector  (300 iterations wait)\n[14:12:21] bestTest = 14660.53222\n[14:12:21] bestIteration = 1205\n[14:12:21] Shrink model to first 1206 iterations.\n[14:12:21] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1268411118823305, 'min_data_in_leaf': 13} scored -14660.532385149572 in 0:00:02.903442\n[14:12:21] 0:\tlearn: 53498.8548576\ttest: 57659.6613475\tbest: 57659.6613475 (0)\ttotal: 2.06ms\tremaining: 4.12s\n[14:12:24] bestTest = 14887.58641\n[14:12:24] bestIteration = 1993\n[14:12:24] Shrink model to first 1994 iterations.\n[14:12:24] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.950894703546006e-06, 'min_data_in_leaf': 18} scored -14887.586454994658 in 0:00:03.616351\n[14:12:25] 0:\tlearn: 53218.5345221\ttest: 57385.1873933\tbest: 57385.1873933 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[14:12:28] bestTest = 14556.46185\n[14:12:28] bestIteration = 1876\n[14:12:28] Shrink model to first 1877 iterations.\n[14:12:28] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 4.477777874073373e-08, 'min_data_in_leaf': 17} scored -14556.461338141025 in 0:00:04.107355\n[14:12:29] 0:\tlearn: 53498.8546296\ttest: 57659.6609841\tbest: 57659.6609841 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[14:12:30] Stopped by overfitting detector  (300 iterations wait)\n[14:12:30] bestTest = 14543.31031\n[14:12:30] bestIteration = 536\n[14:12:30] Shrink model to first 537 iterations.\n[14:12:30] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2104060894136663e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.427740\n[14:12:30] 0:\tlearn: 53498.8546337\ttest: 57659.6609906\tbest: 57659.6609906 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:12:31] Stopped by overfitting detector  (300 iterations wait)\n[14:12:31] bestTest = 14543.31031\n[14:12:31] bestIteration = 536\n[14:12:31] Shrink model to first 537 iterations.\n[14:12:31] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.184376204288474e-07, 'min_data_in_leaf': 14} scored -14543.310546875 in 0:00:01.417721\n[14:12:32] 0:\tlearn: 53500.5645389\ttest: 57658.8551746\tbest: 57658.8551746 (0)\ttotal: 1.33ms\tremaining: 2.65s\n[14:12:33] Stopped by overfitting detector  (300 iterations wait)\n[14:12:33] bestTest = 14643.52447\n[14:12:33] bestIteration = 953\n[14:12:33] Shrink model to first 954 iterations.\n[14:12:33] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0555012542222046e-08, 'min_data_in_leaf': 16} scored -14643.524272168803 in 0:00:01.533754\n[14:12:33] 0:\tlearn: 53498.8547050\ttest: 57659.6611042\tbest: 57659.6611042 (0)\ttotal: 1.78ms\tremaining: 3.56s\n[14:12:35] Stopped by overfitting detector  (300 iterations wait)\n[14:12:35] bestTest = 14543.3103\n[14:12:35] bestIteration = 536\n[14:12:35] Shrink model to first 537 iterations.\n[14:12:35] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.9747568224995754e-06, 'min_data_in_leaf': 11} scored -14543.310430021367 in 0:00:01.693979\n[14:12:35] 0:\tlearn: 53218.5346584\ttest: 57385.1875679\tbest: 57385.1875679 (0)\ttotal: 2.66ms\tremaining: 5.32s\n[14:12:39] bestTest = 14556.46214\n[14:12:39] bestIteration = 1876\n[14:12:39] Shrink model to first 1877 iterations.\n[14:12:39] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.123833541122055e-06, 'min_data_in_leaf': 9} scored -14556.46187232906 in 0:00:04.302712\n[14:12:39] 0:\tlearn: 53498.8546342\ttest: 57659.6609914\tbest: 57659.6609914 (0)\ttotal: 1.56ms\tremaining: 3.12s\n[14:12:41] Stopped by overfitting detector  (300 iterations wait)\n[14:12:41] bestTest = 14921.38069\n[14:12:41] bestIteration = 876\n[14:12:41] Shrink model to first 877 iterations.\n[14:12:41] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3129174195141652e-07, 'min_data_in_leaf': 11} scored -14921.38094284188 in 0:00:01.875290\n[14:12:41] 0:\tlearn: 53500.5652718\ttest: 57658.8558120\tbest: 57658.8558120 (0)\ttotal: 1.26ms\tremaining: 2.52s\n[14:12:43] bestTest = 14690.42937\n[14:12:43] bestIteration = 1871\n[14:12:43] Shrink model to first 1872 iterations.\n[14:12:43] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 4.144797856447396e-05, 'min_data_in_leaf': 13} scored -14690.429353632479 in 0:00:02.347149\n[14:12:43] 0:\tlearn: 53218.5345386\ttest: 57385.1874145\tbest: 57385.1874145 (0)\ttotal: 2.08ms\tremaining: 4.17s\n[14:12:47] bestTest = 14556.46189\n[14:12:47] bestIteration = 1876\n[14:12:47] Shrink model to first 1877 iterations.\n[14:12:47] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.973360579503011e-07, 'min_data_in_leaf': 8} scored -14556.461338141025 in 0:00:04.137707\n[14:12:47] 0:\tlearn: 53498.8547149\ttest: 57659.6611201\tbest: 57659.6611201 (0)\ttotal: 1.6ms\tremaining: 3.19s\n[14:12:49] Stopped by overfitting detector  (300 iterations wait)\n[14:12:49] bestTest = 14543.3103\n[14:12:49] bestIteration = 536\n[14:12:49] Shrink model to first 537 iterations.\n[14:12:49] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.2348760583840678e-06, 'min_data_in_leaf': 11} scored -14543.310496794871 in 0:00:01.381049\n[14:12:49] 0:\tlearn: 53498.8546312\ttest: 57659.6609867\tbest: 57659.6609867 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:12:50] Stopped by overfitting detector  (300 iterations wait)\n[14:12:50] bestTest = 14543.31031\n[14:12:50] bestIteration = 536\n[14:12:50] Shrink model to first 537 iterations.\n[14:12:50] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.32760737997366e-08, 'min_data_in_leaf': 13} scored -14543.310480101496 in 0:00:01.631227\n[14:12:50] 0:\tlearn: 53498.8546304\ttest: 57659.6609854\tbest: 57659.6609854 (0)\ttotal: 1.57ms\tremaining: 3.13s\n[14:12:52] Stopped by overfitting detector  (300 iterations wait)\n[14:12:52] bestTest = 14543.31031\n[14:12:52] bestIteration = 536\n[14:12:52] Shrink model to first 537 iterations.\n[14:12:52] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.284725140017754e-08, 'min_data_in_leaf': 17} scored -14543.310446714744 in 0:00:01.433245\n[14:12:52] 0:\tlearn: 53500.5645423\ttest: 57658.8551775\tbest: 57658.8551775 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:12:53] Stopped by overfitting detector  (300 iterations wait)\n[14:12:53] bestTest = 14643.57717\n[14:12:53] bestIteration = 953\n[14:12:53] Shrink model to first 954 iterations.\n[14:12:53] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.0227738718988404e-07, 'min_data_in_leaf': 15} scored -14643.577423878205 in 0:00:01.527439\n[14:12:53] 0:\tlearn: 53498.8546749\ttest: 57659.6610563\tbest: 57659.6610563 (0)\ttotal: 1.62ms\tremaining: 3.24s\n[14:12:55] Stopped by overfitting detector  (300 iterations wait)\n[14:12:55] bestTest = 14543.3103\n[14:12:55] bestIteration = 536\n[14:12:55] Shrink model to first 537 iterations.\n[14:12:55] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.192349774585452e-06, 'min_data_in_leaf': 14} scored -14543.31063034188 in 0:00:01.382575\n[14:12:55] 0:\tlearn: 53500.5663806\ttest: 57658.8567762\tbest: 57658.8567762 (0)\ttotal: 1.22ms\tremaining: 2.44s\n[14:12:57] bestTest = 14940.06032\n[14:12:57] bestIteration = 1870\n[14:12:57] Shrink model to first 1871 iterations.\n[14:12:57] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00010413311631145382, 'min_data_in_leaf': 16} scored -14940.060663728633 in 0:00:02.337538\n[14:12:57] 0:\tlearn: 53500.5645392\ttest: 57658.8551748\tbest: 57658.8551748 (0)\ttotal: 1.21ms\tremaining: 2.42s\n[14:12:59] Stopped by overfitting detector  (300 iterations wait)\n[14:12:59] bestTest = 14643.52447\n[14:12:59] bestIteration = 953\n[14:12:59] Shrink model to first 954 iterations.\n[14:12:59] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.8811669511864588e-08, 'min_data_in_leaf': 18} scored -14643.524272168803 in 0:00:01.547140\n[14:12:59] 0:\tlearn: 53498.8548465\ttest: 57659.6613298\tbest: 57659.6613298 (0)\ttotal: 1.65ms\tremaining: 3.29s\n[14:13:00] Stopped by overfitting detector  (300 iterations wait)\n[14:13:00] bestTest = 14921.43487\n[14:13:00] bestIteration = 876\n[14:13:00] Shrink model to first 877 iterations.\n[14:13:00] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 5.662622848495333e-06, 'min_data_in_leaf': 14} scored -14921.435062767094 in 0:00:01.917281\n[14:13:01] 0:\tlearn: 53218.5345489\ttest: 57385.1874276\tbest: 57385.1874276 (0)\ttotal: 2.11ms\tremaining: 4.21s\n[14:13:05] bestTest = 14556.46191\n[14:13:05] bestIteration = 1876\n[14:13:05] Shrink model to first 1877 iterations.\n[14:13:05] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 4.537548940256943e-07, 'min_data_in_leaf': 10} scored -14556.461304754273 in 0:00:04.182344\n[14:13:05] 0:\tlearn: 53140.5128227\ttest: 57349.6695260\tbest: 57349.6695260 (0)\ttotal: 4.42ms\tremaining: 8.84s\n[14:13:13] bestTest = 15593.33794\n[14:13:13] bestIteration = 1751\n[14:13:13] Shrink model to first 1752 iterations.\n[14:13:13] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0001649234434167209, 'min_data_in_leaf': 20} scored -15593.337606837607 in 0:00:08.680678\n[14:13:14] 0:\tlearn: 53498.8546318\ttest: 57659.6609877\tbest: 57659.6609877 (0)\ttotal: 1.62ms\tremaining: 3.24s\n[14:13:15] Stopped by overfitting detector  (300 iterations wait)\n[14:13:15] bestTest = 14921.38496\n[14:13:15] bestIteration = 876\n[14:13:15] Shrink model to first 877 iterations.\n[14:13:15] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 6.94670615788717e-08, 'min_data_in_leaf': 12} scored -14921.384448450855 in 0:00:01.909071\n[14:13:15] 0:\tlearn: 53500.8726682\ttest: 57659.1234983\tbest: 57659.1234983 (0)\ttotal: 1.26ms\tremaining: 2.53s\n[14:13:17] Stopped by overfitting detector  (300 iterations wait)\n[14:13:17] bestTest = 14857.08468\n[14:13:17] bestIteration = 1291\n[14:13:17] Shrink model to first 1292 iterations.\n[14:13:17] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.017448988513505306, 'min_data_in_leaf': 7} scored -14857.08436832265 in 0:00:01.903090\n[14:13:17] 0:\tlearn: 53498.8546297\ttest: 57659.6609843\tbest: 57659.6609843 (0)\ttotal: 1.73ms\tremaining: 3.47s\n[14:13:19] Stopped by overfitting detector  (300 iterations wait)\n[14:13:19] bestTest = 14543.31031\n[14:13:19] bestIteration = 536\n[14:13:19] Shrink model to first 537 iterations.\n[14:13:19] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.4602636214632681e-08, 'min_data_in_leaf': 16} scored -14543.310446714744 in 0:00:01.390438\n[14:13:19] 0:\tlearn: 53498.8546300\ttest: 57659.6609848\tbest: 57659.6609848 (0)\ttotal: 1.6ms\tremaining: 3.21s\n[14:13:20] Stopped by overfitting detector  (300 iterations wait)\n[14:13:20] bestTest = 14543.31031\n[14:13:20] bestIteration = 536\n[14:13:20] Shrink model to first 537 iterations.\n[14:13:20] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.2426949194741226e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.382012\n[14:13:20] 0:\tlearn: 53498.8546296\ttest: 57659.6609842\tbest: 57659.6609842 (0)\ttotal: 1.56ms\tremaining: 3.12s\n[14:13:21] Stopped by overfitting detector  (300 iterations wait)\n[14:13:21] bestTest = 14543.31031\n[14:13:21] bestIteration = 536\n[14:13:21] Shrink model to first 537 iterations.\n[14:13:21] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2387932038461251e-08, 'min_data_in_leaf': 18} scored -14543.310446714744 in 0:00:01.434712\n[14:13:22] 0:\tlearn: 53218.5345316\ttest: 57385.1874055\tbest: 57385.1874055 (0)\ttotal: 2.31ms\tremaining: 4.63s\n[14:13:26] bestTest = 14556.46187\n[14:13:26] bestIteration = 1876\n[14:13:26] Shrink model to first 1877 iterations.\n[14:13:26] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.906328667890875e-07, 'min_data_in_leaf': 14} scored -14556.461338141025 in 0:00:04.113204\n[14:13:26] 0:\tlearn: 53498.8546313\ttest: 57659.6609868\tbest: 57659.6609868 (0)\ttotal: 1.69ms\tremaining: 3.38s\n[14:13:27] Stopped by overfitting detector  (300 iterations wait)\n[14:13:27] bestTest = 14543.31031\n[14:13:27] bestIteration = 536\n[14:13:27] Shrink model to first 537 iterations.\n[14:13:27] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.570907652570733e-08, 'min_data_in_leaf': 16} scored -14543.310480101496 in 0:00:01.640163\n[14:13:27] 0:\tlearn: 53498.8546703\ttest: 57659.6610490\tbest: 57659.6610490 (0)\ttotal: 1.62ms\tremaining: 3.23s\n[14:13:29] Stopped by overfitting detector  (300 iterations wait)\n[14:13:29] bestTest = 14543.3103\n[14:13:29] bestIteration = 536\n[14:13:29] Shrink model to first 537 iterations.\n[14:13:29] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.073028019688178e-06, 'min_data_in_leaf': 13} scored -14543.310697115385 in 0:00:01.397365\n[14:13:29] 0:\tlearn: 53500.5648279\ttest: 57658.8554259\tbest: 57658.8554259 (0)\ttotal: 1.24ms\tremaining: 2.48s\n[14:13:31] bestTest = 14968.8323\n[14:13:31] bestIteration = 1858\n[14:13:31] Shrink model to first 1859 iterations.\n[14:13:31] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.6350848690175656e-05, 'min_data_in_leaf': 3} scored -14968.832932692309 in 0:00:02.311482\n[14:13:31] 0:\tlearn: 53218.5345212\ttest: 57385.1873921\tbest: 57385.1873921 (0)\ttotal: 2.1ms\tremaining: 4.19s\n[14:13:35] bestTest = 14556.46185\n[14:13:35] bestIteration = 1876\n[14:13:35] Shrink model to first 1877 iterations.\n[14:13:35] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.124444355902895e-08, 'min_data_in_leaf': 19} scored -14556.461338141025 in 0:00:04.247891\n[14:13:35] 0:\tlearn: 53218.5345262\ttest: 57385.1873986\tbest: 57385.1873986 (0)\ttotal: 2.07ms\tremaining: 4.14s\n[14:13:40] bestTest = 14556.46186\n[14:13:40] bestIteration = 1876\n[14:13:40] Shrink model to first 1877 iterations.\n[14:13:40] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0813738016783898e-07, 'min_data_in_leaf': 11} scored -14556.461471688035 in 0:00:04.380039\n[14:13:40] 0:\tlearn: 53206.4002364\ttest: 57399.1434687\tbest: 57399.1434687 (0)\ttotal: 3.63ms\tremaining: 7.26s\n[14:13:43] Stopped by overfitting detector  (300 iterations wait)\n[14:13:43] bestTest = 15418.77147\n[14:13:43] bestIteration = 863\n[14:13:43] Shrink model to first 864 iterations.\n[14:13:43] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.018015828251642e-07, 'min_data_in_leaf': 12} scored -15418.771718082266 in 0:00:03.507630\n[14:13:43] 0:\tlearn: 53498.8546297\ttest: 57659.6609843\tbest: 57659.6609843 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[14:13:45] Stopped by overfitting detector  (300 iterations wait)\n[14:13:45] bestTest = 14543.31031\n[14:13:45] bestIteration = 536\n[14:13:45] Shrink model to first 537 iterations.\n[14:13:45] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.4503582636351363e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.397152\n[14:13:45] 0:\tlearn: 53498.8546296\ttest: 57659.6609842\tbest: 57659.6609842 (0)\ttotal: 1.68ms\tremaining: 3.35s\n[14:13:46] Stopped by overfitting detector  (300 iterations wait)\n[14:13:46] bestTest = 14543.31031\n[14:13:46] bestIteration = 536\n[14:13:46] Shrink model to first 537 iterations.\n[14:13:46] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2664474012308807e-08, 'min_data_in_leaf': 17} scored -14543.310446714744 in 0:00:01.402185\n[14:13:46] 0:\tlearn: 53498.8546303\ttest: 57659.6609853\tbest: 57659.6609853 (0)\ttotal: 1.59ms\tremaining: 3.17s\n[14:13:47] Stopped by overfitting detector  (300 iterations wait)\n[14:13:47] bestTest = 14543.31031\n[14:13:47] bestIteration = 536\n[14:13:47] Shrink model to first 537 iterations.\n[14:13:47] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.0203338055414296e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.405064\n[14:13:48] 0:\tlearn: 53500.5645397\ttest: 57658.8551753\tbest: 57658.8551753 (0)\ttotal: 1.21ms\tremaining: 2.41s\n[14:13:49] Stopped by overfitting detector  (300 iterations wait)\n[14:13:49] bestTest = 14643.56737\n[14:13:49] bestIteration = 953\n[14:13:49] Shrink model to first 954 iterations.\n[14:13:49] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 5.966770612942647e-08, 'min_data_in_leaf': 14} scored -14643.567674946582 in 0:00:01.526129\n[14:13:49] 0:\tlearn: 53498.8546296\ttest: 57659.6609841\tbest: 57659.6609841 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:13:50] Stopped by overfitting detector  (300 iterations wait)\n[14:13:50] bestTest = 14543.31031\n[14:13:50] bestIteration = 536\n[14:13:50] Shrink model to first 537 iterations.\n[14:13:50] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0730407175056681e-08, 'min_data_in_leaf': 15} scored -14543.310446714744 in 0:00:01.385288\n[14:13:50] 0:\tlearn: 53218.5650904\ttest: 57385.2265410\tbest: 57385.2265410 (0)\ttotal: 2.07ms\tremaining: 4.13s\n[14:13:54] bestTest = 14633.42178\n[14:13:54] bestIteration = 1898\n[14:13:54] Shrink model to first 1899 iterations.\n[14:13:54] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00046610054876743373, 'min_data_in_leaf': 16} scored -14633.421674679486 in 0:00:04.163209\n[14:13:55] 0:\tlearn: 53498.8546339\ttest: 57659.6609910\tbest: 57659.6609910 (0)\ttotal: 2.06ms\tremaining: 4.12s\n[14:13:56] Stopped by overfitting detector  (300 iterations wait)\n[14:13:56] bestTest = 14543.31031\n[14:13:56] bestIteration = 536\n[14:13:56] Shrink model to first 537 iterations.\n[14:13:56] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.235485803636692e-07, 'min_data_in_leaf': 19} scored -14543.310546875 in 0:00:01.405100\n[14:13:56] 0:\tlearn: 53688.8998759\ttest: 57885.1287444\tbest: 57885.1287444 (0)\ttotal: 1.6ms\tremaining: 3.21s\n[14:13:58] Stopped by overfitting detector  (300 iterations wait)\n[14:13:58] bestTest = 14945.099\n[14:13:58] bestIteration = 1143\n[14:13:58] Shrink model to first 1144 iterations.\n[14:13:58] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 9.650554673574426, 'min_data_in_leaf': 9} scored -14945.098824786324 in 0:00:02.225489\n[14:13:59] 0:\tlearn: 53498.8546474\ttest: 57659.6610125\tbest: 57659.6610125 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:14:00] Stopped by overfitting detector  (300 iterations wait)\n[14:14:00] bestTest = 14921.42132\n[14:14:00] bestIteration = 876\n[14:14:00] Shrink model to first 877 iterations.\n[14:14:00] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 4.7532205637997977e-07, 'min_data_in_leaf': 13} scored -14921.421107104701 in 0:00:02.117562\n[14:14:00] 0:\tlearn: 53500.5645897\ttest: 57658.8552187\tbest: 57658.8552187 (0)\ttotal: 1.2ms\tremaining: 2.4s\n[14:14:03] bestTest = 14593.49935\n[14:14:03] bestIteration = 1848\n[14:14:03] Shrink model to first 1849 iterations.\n[14:14:03] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.8821035286185183e-06, 'min_data_in_leaf': 17} scored -14593.499399038461 in 0:00:02.336822\n[14:14:03] 0:\tlearn: 53498.8546302\ttest: 57659.6609850\tbest: 57659.6609850 (0)\ttotal: 1.62ms\tremaining: 3.23s\n[14:14:04] Stopped by overfitting detector  (300 iterations wait)\n[14:14:04] bestTest = 14543.31031\n[14:14:04] bestIteration = 536\n[14:14:04] Shrink model to first 537 iterations.\n[14:14:04] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.676617139878253e-08, 'min_data_in_leaf': 17} scored -14543.310446714744 in 0:00:01.392211\n[14:14:04] 0:\tlearn: 53498.8546311\ttest: 57659.6609865\tbest: 57659.6609865 (0)\ttotal: 1.62ms\tremaining: 3.24s\n[14:14:05] Stopped by overfitting detector  (300 iterations wait)\n[14:14:05] bestTest = 14543.31031\n[14:14:05] bestIteration = 536\n[14:14:05] Shrink model to first 537 iterations.\n[14:14:05] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.0254153525972845e-08, 'min_data_in_leaf': 16} scored -14543.310480101496 in 0:00:01.397719\n[14:14:06] 0:\tlearn: 53498.8546301\ttest: 57659.6609849\tbest: 57659.6609849 (0)\ttotal: 1.73ms\tremaining: 3.45s\n[14:14:07] Stopped by overfitting detector  (300 iterations wait)\n[14:14:07] bestTest = 14543.31031\n[14:14:07] bestIteration = 536\n[14:14:07] Shrink model to first 537 iterations.\n[14:14:07] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.3794479833442097e-08, 'min_data_in_leaf': 18} scored -14543.310446714744 in 0:00:01.374369\n[14:14:07] 0:\tlearn: 53498.8546363\ttest: 57659.6609948\tbest: 57659.6609948 (0)\ttotal: 1.68ms\tremaining: 3.36s\n[14:14:08] Stopped by overfitting detector  (300 iterations wait)\n[14:14:08] bestTest = 14543.31031\n[14:14:08] bestIteration = 536\n[14:14:08] Shrink model to first 537 iterations.\n[14:14:08] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.8614290209042682e-07, 'min_data_in_leaf': 14} scored -14543.310546875 in 0:00:01.377421\n[14:14:08] 0:\tlearn: 53218.5345261\ttest: 57385.1873985\tbest: 57385.1873985 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[14:14:13] bestTest = 14556.46186\n[14:14:13] bestIteration = 1876\n[14:14:13] Shrink model to first 1877 iterations.\n[14:14:13] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0704435557492669e-07, 'min_data_in_leaf': 17} scored -14556.461471688035 in 0:00:04.510962\n[14:14:13] 0:\tlearn: 53498.8546583\ttest: 57659.6610298\tbest: 57659.6610298 (0)\ttotal: 1.61ms\tremaining: 3.23s\n[14:14:14] Stopped by overfitting detector  (300 iterations wait)\n[14:14:14] bestTest = 14543.31031\n[14:14:14] bestIteration = 536\n[14:14:14] Shrink model to first 537 iterations.\n[14:14:14] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.586075082939695e-07, 'min_data_in_leaf': 15} scored -14543.310596955129 in 0:00:01.408939\n[14:14:14] 0:\tlearn: 53498.8546300\ttest: 57659.6609848\tbest: 57659.6609848 (0)\ttotal: 1.57ms\tremaining: 3.15s\n[14:14:16] Stopped by overfitting detector  (300 iterations wait)\n[14:14:16] bestTest = 14543.31031\n[14:14:16] bestIteration = 536\n[14:14:16] Shrink model to first 537 iterations.\n[14:14:16] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.2787402139621506e-08, 'min_data_in_leaf': 10} scored -14543.310446714744 in 0:00:01.384078\n[14:14:16] 0:\tlearn: 53498.9514216\ttest: 57659.8151981\tbest: 57659.8151981 (0)\ttotal: 1.61ms\tremaining: 3.23s\n[14:14:17] Stopped by overfitting detector  (300 iterations wait)\n[14:14:17] bestTest = 15153.65603\n[14:14:17] bestIteration = 845\n[14:14:17] Shrink model to first 846 iterations.\n[14:14:17] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.002523462123856813, 'min_data_in_leaf': 12} scored -15153.65599959936 in 0:00:01.829368\n[14:14:18] 0:\tlearn: 53500.5645394\ttest: 57658.8551750\tbest: 57658.8551750 (0)\ttotal: 1.22ms\tremaining: 2.44s\n[14:14:20] bestTest = 14968.72724\n[14:14:20] bestIteration = 1858\n[14:14:20] Shrink model to first 1859 iterations.\n[14:14:20] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 4.17540760319891e-08, 'min_data_in_leaf': 18} scored -14968.727180154914 in 0:00:02.287290\n[14:14:20] 0:\tlearn: 53218.5345198\ttest: 57385.1873904\tbest: 57385.1873904 (0)\ttotal: 2.05ms\tremaining: 4.1s\n[14:14:24] bestTest = 14556.46185\n[14:14:24] bestIteration = 1876\n[14:14:24] Shrink model to first 1877 iterations.\n[14:14:24] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0516823472138333e-08, 'min_data_in_leaf': 16} scored -14556.461338141025 in 0:00:04.166372\n[14:14:24] 0:\tlearn: 53498.8546298\ttest: 57659.6609844\tbest: 57659.6609844 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[14:14:25] Stopped by overfitting detector  (300 iterations wait)\n[14:14:25] bestTest = 14543.31031\n[14:14:25] bestIteration = 536\n[14:14:25] Shrink model to first 537 iterations.\n[14:14:25] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.6202686490029354e-08, 'min_data_in_leaf': 16} scored -14543.310446714744 in 0:00:01.392373\n[14:14:25] 0:\tlearn: 53498.8546317\ttest: 57659.6609875\tbest: 57659.6609875 (0)\ttotal: 1.58ms\tremaining: 3.17s\n[14:14:27] Stopped by overfitting detector  (300 iterations wait)\n[14:14:27] bestTest = 14543.31031\n[14:14:27] bestIteration = 536\n[14:14:27] Shrink model to first 537 iterations.\n[14:14:27] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 6.71064059281227e-08, 'min_data_in_leaf': 15} scored -14543.310480101496 in 0:00:01.392974\n[14:14:27] 0:\tlearn: 53498.8546299\ttest: 57659.6609845\tbest: 57659.6609845 (0)\ttotal: 1.69ms\tremaining: 3.38s\n[14:14:28] Stopped by overfitting detector  (300 iterations wait)\n[14:14:28] bestTest = 14543.31031\n[14:14:28] bestIteration = 536\n[14:14:28] Shrink model to first 537 iterations.\n[14:14:28] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.863091457558745e-08, 'min_data_in_leaf': 14} scored -14543.310446714744 in 0:00:01.414385\n[14:14:28] 0:\tlearn: 53498.8546307\ttest: 57659.6609859\tbest: 57659.6609859 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:14:29] Stopped by overfitting detector  (300 iterations wait)\n[14:14:29] bestTest = 14543.31031\n[14:14:29] bestIteration = 536\n[14:14:29] Shrink model to first 537 iterations.\n[14:14:30] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 4.098095482275575e-08, 'min_data_in_leaf': 13} scored -14543.310446714744 in 0:00:01.401229\n[14:14:30] 0:\tlearn: 53498.8546369\ttest: 57659.6609957\tbest: 57659.6609957 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:14:31] Stopped by overfitting detector  (300 iterations wait)\n[14:14:31] bestTest = 14543.31031\n[14:14:31] bestIteration = 536\n[14:14:31] Shrink model to first 537 iterations.\n[14:14:31] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.0151833461395866e-07, 'min_data_in_leaf': 17} scored -14543.310546875 in 0:00:01.645770\n[14:14:31] 0:\tlearn: 53507.0201497\ttest: 57672.3488651\tbest: 57672.3488651 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[14:14:33] Stopped by overfitting detector  (300 iterations wait)\n[14:14:33] bestTest = 14883.82898\n[14:14:33] bestIteration = 531\n[14:14:33] Shrink model to first 532 iterations.\n[14:14:33] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.22606610355162296, 'min_data_in_leaf': 19} scored -14883.828959668803 in 0:00:01.445912\n[14:14:33] 0:\tlearn: 53498.8546295\ttest: 57659.6609840\tbest: 57659.6609840 (0)\ttotal: 1.58ms\tremaining: 3.17s\n[14:14:34] Stopped by overfitting detector  (300 iterations wait)\n[14:14:34] bestTest = 14543.31031\n[14:14:34] bestIteration = 536\n[14:14:34] Shrink model to first 537 iterations.\n[14:14:34] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.01813188218327e-08, 'min_data_in_leaf': 16} scored -14543.310446714744 in 0:00:01.400136\n[14:14:34] 0:\tlearn: 53500.5645390\ttest: 57658.8551747\tbest: 57658.8551747 (0)\ttotal: 1.22ms\tremaining: 2.44s\n[14:14:36] Stopped by overfitting detector  (300 iterations wait)\n[14:14:36] bestTest = 14643.56737\n[14:14:36] bestIteration = 953\n[14:14:36] Shrink model to first 954 iterations.\n[14:14:36] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.9371877806891348e-08, 'min_data_in_leaf': 15} scored -14643.567674946582 in 0:00:01.529986\n[14:14:36] 0:\tlearn: 53498.8546322\ttest: 57659.6609883\tbest: 57659.6609883 (0)\ttotal: 1.66ms\tremaining: 3.33s\n[14:14:37] Stopped by overfitting detector  (300 iterations wait)\n[14:14:37] bestTest = 14543.31031\n[14:14:37] bestIteration = 536\n[14:14:37] Shrink model to first 537 iterations.\n[14:14:37] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.990913428260702e-08, 'min_data_in_leaf': 18} scored -14543.310546875 in 0:00:01.416242\n[14:14:37] 0:\tlearn: 53218.5345215\ttest: 57385.1873926\tbest: 57385.1873926 (0)\ttotal: 2.15ms\tremaining: 4.29s\n[14:14:39] Stopped by overfitting detector  (300 iterations wait)\n[14:14:39] bestTest = 14339.30892\n[14:14:39] bestIteration = 692\n[14:14:39] Shrink model to first 693 iterations.\n[14:14:39] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.699726019853544e-08, 'min_data_in_leaf': 13} scored -14339.30884415064 in 0:00:02.150607\n[14:14:39] 0:\tlearn: 53218.5345215\ttest: 57385.1873926\tbest: 57385.1873926 (0)\ttotal: 2.16ms\tremaining: 4.31s\n[14:14:41] Stopped by overfitting detector  (300 iterations wait)\n[14:14:41] bestTest = 14339.30892\n[14:14:41] bestIteration = 692\n[14:14:41] Shrink model to first 693 iterations.\n[14:14:41] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.671474904079656e-08, 'min_data_in_leaf': 13} scored -14339.30884415064 in 0:00:02.195988\n[14:14:42] 0:\tlearn: 53206.4002141\ttest: 57399.1434451\tbest: 57399.1434451 (0)\ttotal: 3.03ms\tremaining: 6.06s\n[14:14:47] Stopped by overfitting detector  (300 iterations wait)\n[14:14:47] bestTest = 15036.74865\n[14:14:47] bestIteration = 1472\n[14:14:47] Shrink model to first 1473 iterations.\n[14:14:47] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.222280980807304e-08, 'min_data_in_leaf': 12} scored -15036.748681223291 in 0:00:05.526463\n[14:14:47] 0:\tlearn: 53206.4002179\ttest: 57399.1434492\tbest: 57399.1434492 (0)\ttotal: 2.97ms\tremaining: 5.94s\n[14:14:52] Stopped by overfitting detector  (300 iterations wait)\n[14:14:52] bestTest = 15036.74866\n[14:14:52] bestIteration = 1472\n[14:14:52] Shrink model to first 1473 iterations.\n[14:14:52] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 7.880144038113984e-08, 'min_data_in_leaf': 13} scored -15036.748747996795 in 0:00:05.047972\n[14:14:52] 0:\tlearn: 53218.5345462\ttest: 57385.1874242\tbest: 57385.1874242 (0)\ttotal: 2.09ms\tremaining: 4.18s\n[14:14:54] Stopped by overfitting detector  (300 iterations wait)\n[14:14:54] bestTest = 14339.30903\n[14:14:54] bestIteration = 692\n[14:14:54] Shrink model to first 693 iterations.\n[14:14:54] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 4.126057046611068e-07, 'min_data_in_leaf': 11} scored -14339.309111244658 in 0:00:02.134414\n[14:14:54] 0:\tlearn: 53218.5345456\ttest: 57385.1874234\tbest: 57385.1874234 (0)\ttotal: 2.13ms\tremaining: 4.25s\n[14:14:56] Stopped by overfitting detector  (300 iterations wait)\n[14:14:56] bestTest = 14339.30903\n[14:14:56] bestIteration = 692\n[14:14:56] Shrink model to first 693 iterations.\n[14:14:56] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 4.0305452867740233e-07, 'min_data_in_leaf': 11} scored -14339.309111244658 in 0:00:02.116822\n[14:14:56] 0:\tlearn: 53218.5345533\ttest: 57385.1874332\tbest: 57385.1874332 (0)\ttotal: 2.11ms\tremaining: 4.21s\n[14:14:58] Stopped by overfitting detector  (300 iterations wait)\n[14:14:58] bestTest = 14339.30906\n[14:14:58] bestIteration = 692\n[14:14:58] Shrink model to first 693 iterations.\n[14:14:58] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.20522188547904e-07, 'min_data_in_leaf': 11} scored -14339.309244791666 in 0:00:02.151389\n[14:14:59] 0:\tlearn: 53218.5346218\ttest: 57385.1875210\tbest: 57385.1875210 (0)\ttotal: 2.1ms\tremaining: 4.2s\n[14:15:01] Stopped by overfitting detector  (300 iterations wait)\n[14:15:01] bestTest = 14339.30936\n[14:15:01] bestIteration = 692\n[14:15:01] Shrink model to first 693 iterations.\n[14:15:01] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5658606023084112e-06, 'min_data_in_leaf': 11} scored -14339.309511885684 in 0:00:02.144352\n[14:15:01] 0:\tlearn: 53218.5347970\ttest: 57385.1877454\tbest: 57385.1877454 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[14:15:03] Stopped by overfitting detector  (300 iterations wait)\n[14:15:03] bestTest = 14339.31012\n[14:15:03] bestIteration = 692\n[14:15:03] Shrink model to first 693 iterations.\n[14:15:03] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 4.236925117529518e-06, 'min_data_in_leaf': 10} scored -14339.309845753205 in 0:00:02.174140\n[14:15:03] 0:\tlearn: 53218.5346223\ttest: 57385.1875217\tbest: 57385.1875217 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[14:15:05] Stopped by overfitting detector  (300 iterations wait)\n[14:15:05] bestTest = 14339.30936\n[14:15:05] bestIteration = 692\n[14:15:05] Shrink model to first 693 iterations.\n[14:15:05] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5731784639308229e-06, 'min_data_in_leaf': 10} scored -14339.309511885684 in 0:00:02.121897\n[14:15:05] 0:\tlearn: 53218.5347781\ttest: 57385.1877212\tbest: 57385.1877212 (0)\ttotal: 2.07ms\tremaining: 4.13s\n[14:15:07] Stopped by overfitting detector  (300 iterations wait)\n[14:15:07] bestTest = 14339.31004\n[14:15:07] bestIteration = 692\n[14:15:07] Shrink model to first 693 iterations.\n[14:15:07] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.948496517769882e-06, 'min_data_in_leaf': 10} scored -14339.309712206197 in 0:00:02.385046\n[14:15:08] 0:\tlearn: 53218.5347797\ttest: 57385.1877232\tbest: 57385.1877232 (0)\ttotal: 2.11ms\tremaining: 4.22s\n[14:15:09] Stopped by overfitting detector  (300 iterations wait)\n[14:15:09] bestTest = 14339.31004\n[14:15:09] bestIteration = 692\n[14:15:09] Shrink model to first 693 iterations.\n[14:15:10] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.97217752577964e-06, 'min_data_in_leaf': 10} scored -14339.309712206197 in 0:00:02.154541\n[14:15:10] 0:\tlearn: 53218.5353350\ttest: 57385.1884344\tbest: 57385.1884344 (0)\ttotal: 2.13ms\tremaining: 4.25s\n[14:15:12] Stopped by overfitting detector  (300 iterations wait)\n[14:15:12] bestTest = 14339.31245\n[14:15:12] bestIteration = 692\n[14:15:12] Shrink model to first 693 iterations.\n[14:15:12] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2437385819545394e-05, 'min_data_in_leaf': 10} scored -14339.312650240385 in 0:00:02.176039\n[14:15:12] 0:\tlearn: 53218.5364229\ttest: 57385.1898277\tbest: 57385.1898277 (0)\ttotal: 2.15ms\tremaining: 4.29s\n[14:15:14] Stopped by overfitting detector  (300 iterations wait)\n[14:15:14] bestTest = 14339.31716\n[14:15:14] bestIteration = 692\n[14:15:14] Shrink model to first 693 iterations.\n[14:15:14] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.902199215827856e-05, 'min_data_in_leaf': 9} scored -14339.31742454594 in 0:00:02.185701\n[14:15:14] 0:\tlearn: 53218.5347523\ttest: 57385.1876882\tbest: 57385.1876882 (0)\ttotal: 2.09ms\tremaining: 4.18s\n[14:15:16] Stopped by overfitting detector  (300 iterations wait)\n[14:15:16] bestTest = 14339.30992\n[14:15:16] bestIteration = 692\n[14:15:16] Shrink model to first 693 iterations.\n[14:15:16] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.555240573332601e-06, 'min_data_in_leaf': 11} scored -14339.309678819445 in 0:00:02.288270\n[14:15:16] 0:\tlearn: 53218.5346094\ttest: 57385.1875051\tbest: 57385.1875051 (0)\ttotal: 2.54ms\tremaining: 5.08s\n[14:15:19] Stopped by overfitting detector  (300 iterations wait)\n[14:15:19] bestTest = 14339.3093\n[14:15:19] bestIteration = 692\n[14:15:19] Shrink model to first 693 iterations.\n[14:15:19] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3764771284494616e-06, 'min_data_in_leaf': 8} scored -14339.30944511218 in 0:00:02.532367\n[14:15:19] 0:\tlearn: 53218.5346220\ttest: 57385.1875212\tbest: 57385.1875212 (0)\ttotal: 2.12ms\tremaining: 4.23s\n[14:15:21] Stopped by overfitting detector  (300 iterations wait)\n[14:15:21] bestTest = 14339.30936\n[14:15:21] bestIteration = 692\n[14:15:21] Shrink model to first 693 iterations.\n[14:15:21] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5677719917695675e-06, 'min_data_in_leaf': 8} scored -14339.309511885684 in 0:00:02.122971\n[14:15:21] 0:\tlearn: 53218.5346272\ttest: 57385.1875280\tbest: 57385.1875280 (0)\ttotal: 2.1ms\tremaining: 4.2s\n[14:15:23] Stopped by overfitting detector  (300 iterations wait)\n[14:15:23] bestTest = 14339.30938\n[14:15:23] bestIteration = 692\n[14:15:23] Shrink model to first 693 iterations.\n[14:15:23] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.6481871968567693e-06, 'min_data_in_leaf': 8} scored -14339.309511885684 in 0:00:02.190733\n[14:15:23] 0:\tlearn: 53218.5346083\ttest: 57385.1875037\tbest: 57385.1875037 (0)\ttotal: 2.09ms\tremaining: 4.18s\n[14:15:25] Stopped by overfitting detector  (300 iterations wait)\n[14:15:25] bestTest = 14339.3093\n[14:15:25] bestIteration = 692\n[14:15:25] Shrink model to first 693 iterations.\n[14:15:25] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.358938200365785e-06, 'min_data_in_leaf': 6} scored -14339.30944511218 in 0:00:02.143635\n[14:15:25] 0:\tlearn: 53218.5345547\ttest: 57385.1874351\tbest: 57385.1874351 (0)\ttotal: 2.43ms\tremaining: 4.85s\n[14:15:27] Stopped by overfitting detector  (300 iterations wait)\n[14:15:27] bestTest = 14339.30907\n[14:15:27] bestIteration = 692\n[14:15:27] Shrink model to first 693 iterations.\n[14:15:27] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.425186106230448e-07, 'min_data_in_leaf': 6} scored -14339.309244791666 in 0:00:02.164929\n[14:15:28] 0:\tlearn: 53218.5345598\ttest: 57385.1874415\tbest: 57385.1874415 (0)\ttotal: 2.14ms\tremaining: 4.28s\n[14:15:30] Stopped by overfitting detector  (300 iterations wait)\n[14:15:30] bestTest = 14339.30909\n[14:15:30] bestIteration = 692\n[14:15:30] Shrink model to first 693 iterations.\n[14:15:30] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 6.195578463365459e-07, 'min_data_in_leaf': 6} scored -14339.309278178418 in 0:00:02.160825\n[14:15:30] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[14:15:30] The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.699726019853544e-08, 'min_data_in_leaf': 13}\u001b[0m\n achieve -14339.3088 mae\n[14:15:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[14:15:30] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:15:30] 0:\tlearn: 54069.7830276\ttest: 58249.7659023\tbest: 58249.7659023 (0)\ttotal: 2.07ms\tremaining: 6.21s\n[14:15:32] Stopped by overfitting detector  (100 iterations wait)\n[14:15:32] bestTest = 14995.1434\n[14:15:32] bestIteration = 800\n[14:15:32] Shrink model to first 801 iterations.\n[14:15:32] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:15:32] 0:\tlearn: 54620.8052183\ttest: 57485.4636282\tbest: 57485.4636282 (0)\ttotal: 2.27ms\tremaining: 6.81s\n[14:15:34] Stopped by overfitting detector  (100 iterations wait)\n[14:15:34] bestTest = 16566.87333\n[14:15:34] bestIteration = 1003\n[14:15:34] Shrink model to first 1004 iterations.\n[14:15:34] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:15:34] 0:\tlearn: 54689.9032944\ttest: 55575.8892349\tbest: 55575.8892349 (0)\ttotal: 2.38ms\tremaining: 7.13s\n[14:15:36] Stopped by overfitting detector  (100 iterations wait)\n[14:15:36] bestTest = 15115.70559\n[14:15:36] bestIteration = 985\n[14:15:36] Shrink model to first 986 iterations.\n[14:15:36] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:15:36] 0:\tlearn: 55807.0754490\ttest: 52124.0541820\tbest: 52124.0541820 (0)\ttotal: 2.8ms\tremaining: 8.4s\n[14:15:41] Stopped by overfitting detector  (100 iterations wait)\n[14:15:41] bestTest = 14208.357\n[14:15:41] bestIteration = 2493\n[14:15:41] Shrink model to first 2494 iterations.\n[14:15:41] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:15:41] 0:\tlearn: 55690.5744285\ttest: 52041.5896525\tbest: 52041.5896525 (0)\ttotal: 2.2ms\tremaining: 6.59s\n[14:15:44] Stopped by overfitting detector  (100 iterations wait)\n[14:15:44] bestTest = 13559.32811\n[14:15:44] bestIteration = 1093\n[14:15:44] Shrink model to first 1094 iterations.\n[14:15:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14890.80281464041\u001b[0m\n[14:15:44] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[14:15:44] Time left 5488.10 secs\n\n[14:15:44] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[14:15:44] Blending: optimization starts with equal weights and score \u001b[1m-14657.865950074915\u001b[0m\n[14:15:44] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14599.996943225598\u001b[0m, weights = \u001b[1m[0.17583425 0.15408148 0.05731606 0.39340064 0.21936755]\u001b[0m\n[14:15:44] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14586.999692315925\u001b[0m, weights = \u001b[1m[0.17334174 0.23991108 0.         0.381328   0.2054192 ]\u001b[0m\n[14:15:44] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14586.371495077055\u001b[0m, weights = \u001b[1m[0.16839232 0.25373396 0.         0.39503053 0.18284318]\u001b[0m\n[14:15:44] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14586.181643969392\u001b[0m, weights = \u001b[1m[0.16223502 0.2536411  0.         0.40134767 0.18277627]\u001b[0m\n[14:15:44] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14586.152915641052\u001b[0m, weights = \u001b[1m[0.1634833  0.25326315 0.         0.40074962 0.18250392]\u001b[0m\n[14:15:44] \u001b[1mAutoml preset training completed in 512.02 seconds\u001b[0m\n\n[14:15:44] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.16348 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.25326 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.40075 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.18250 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\nCPU times: user 29min 24s, sys: 1min 36s, total: 31min 1s\nWall time: 8min 32s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(automl.create_model_str_desc())","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:15:44.289141Z","iopub.execute_input":"2024-10-06T14:15:44.290142Z","iopub.status.idle":"2024-10-06T14:15:44.295438Z","shell.execute_reply.started":"2024-10-06T14:15:44.290076Z","shell.execute_reply":"2024-10-06T14:15:44.294370Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Final prediction for new objects (level 0) = \n\t 0.16348 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.25326 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.40075 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.18250 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:15:44.296746Z","iopub.execute_input":"2024-10-06T14:15:44.297077Z","iopub.status.idle":"2024-10-06T14:15:44.307014Z","shell.execute_reply.started":"2024-10-06T14:15:44.297042Z","shell.execute_reply":"2024-10-06T14:15:44.305943Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\ntest_pred = automl.predict(test)\n\nprint(f'train score: {mean_absolute_error(train[target_col].values, oof_pred.data[:, 0])}')\nprint(f'test score: {mean_absolute_error(test[target_col].values, test_pred.data[:, 0])}')","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:15:44.308229Z","iopub.execute_input":"2024-10-06T14:15:44.308745Z","iopub.status.idle":"2024-10-06T14:15:45.319078Z","shell.execute_reply.started":"2024-10-06T14:15:44.308709Z","shell.execute_reply":"2024-10-06T14:15:45.318013Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"train score: 14586.152915641052\ntest score: 15296.478582512842\n","output_type":"stream"}]},{"cell_type":"code","source":"automl.get_feature_scores('accurate', test)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:15:45.320724Z","iopub.execute_input":"2024-10-06T14:15:45.321180Z","iopub.status.idle":"2024-10-06T14:17:40.331543Z","shell.execute_reply.started":"2024-10-06T14:15:45.321133Z","shell.execute_reply":"2024-10-06T14:17:40.330407Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                       Feature   Importance\n0           1st2ndAndBsmtFlrSF  8462.057136\n1                  OverallQual  5724.808741\n2    KitchenAbvGrPerGarageCars  3093.599583\n3       OverallQualAndCondMean  1807.154016\n4                 Neighborhood  1721.860245\n..                         ...          ...\n139    1stFlrSFPerTotRmsAbvGrd   -60.341931\n140  AnyBathSumPerTotRmsAbvGrd   -77.072440\n141                 GarageType   -77.259284\n142                 MSSubClass   -79.777812\n143                LandContour   -84.360178\n\n[144 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1st2ndAndBsmtFlrSF</td>\n      <td>8462.057136</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OverallQual</td>\n      <td>5724.808741</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KitchenAbvGrPerGarageCars</td>\n      <td>3093.599583</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OverallQualAndCondMean</td>\n      <td>1807.154016</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neighborhood</td>\n      <td>1721.860245</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>1stFlrSFPerTotRmsAbvGrd</td>\n      <td>-60.341931</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>AnyBathSumPerTotRmsAbvGrd</td>\n      <td>-77.072440</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>GarageType</td>\n      <td>-77.259284</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>MSSubClass</td>\n      <td>-79.777812</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>LandContour</td>\n      <td>-84.360178</td>\n    </tr>\n  </tbody>\n</table>\n<p>144 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Тюнинг","metadata":{}},{"cell_type":"code","source":"%%time\nautoml_ut = TabularUtilizedAutoML(task = task,\n                       timeout = timeout,\n                       cpu_limit = threads,\n                       reader_params = {'n_jobs': threads, 'random_state': rs, 'cv': cv})\n\n\noof_pred = automl_ut.fit_predict(train, roles = roles, verbose = 3)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T14:18:56.553514Z","iopub.execute_input":"2024-10-06T14:18:56.554453Z","iopub.status.idle":"2024-10-06T15:54:29.081921Z","shell.execute_reply.started":"2024-10-06T14:18:56.554402Z","shell.execute_reply":"2024-10-06T15:54:29.080710Z"},"_kg_hide-output":true,"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[14:18:56] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n[14:18:56] - time: 6000.00 seconds\n[14:18:56] - CPU: 4 cores\n[14:18:56] - memory: 16 GB\n\n[14:18:56] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n\n[14:18:56] ==================================================\n[14:18:56] Start 0 automl preset configuration:\n[14:18:56] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n[14:18:56] Found reader_params in kwargs, need to combine\n[14:18:56] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 42, 'cv': 5}\n[14:18:56] Stdout logging level is INFO3.\n[14:18:56] Task: reg\n\n[14:18:56] Start automl preset with listed constraints:\n[14:18:56] - time: 6000.00 seconds\n[14:18:56] - CPU: 4 cores\n[14:18:56] - memory: 16 GB\n\n[14:18:56] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[14:19:04] Feats was rejected during automatic roles guess: []\n[14:19:04] Layer \u001b[1m1\u001b[0m train process start. Time left 5992.59 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:19:04] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[14:19:04] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:19:04] Linear model: C = 1e-05 score = -38437.44207398504\n[14:19:05] Linear model: C = 5e-05 score = -23876.3640491453\n[14:19:05] Linear model: C = 0.0001 score = -20853.782118055555\n[14:19:05] Linear model: C = 0.0005 score = -17296.364817040598\n[14:19:05] Linear model: C = 0.001 score = -17296.364783653848\n[14:19:05] Linear model: C = 0.005 score = -16968.600727831195\n[14:19:05] Linear model: C = 0.01 score = -17575.74631076389\n[14:19:06] Linear model: C = 0.05 score = -19809.12483306624\n[14:19:06] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:19:06] Linear model: C = 1e-05 score = -37831.0640357906\n[14:19:06] Linear model: C = 5e-05 score = -23379.572165464742\n[14:19:06] Linear model: C = 0.0001 score = -20575.7175647703\n[14:19:06] Linear model: C = 0.0005 score = -18457.50475761218\n[14:19:07] Linear model: C = 0.001 score = -18378.786541800215\n[14:19:07] Linear model: C = 0.005 score = -18378.789479834402\n[14:19:07] Linear model: C = 0.01 score = -18803.51800380609\n[14:19:07] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:19:07] Linear model: C = 1e-05 score = -37300.01158520299\n[14:19:07] Linear model: C = 5e-05 score = -24500.791533119656\n[14:19:07] Linear model: C = 0.0001 score = -21517.886034321582\n[14:19:08] Linear model: C = 0.0005 score = -18192.01226232806\n[14:19:08] Linear model: C = 0.001 score = -17990.04738623464\n[14:19:08] Linear model: C = 0.005 score = -18140.44552951389\n[14:19:09] Linear model: C = 0.01 score = -18466.557592147437\n[14:19:09] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:19:09] Linear model: C = 1e-05 score = -34848.492120439914\n[14:19:09] Linear model: C = 5e-05 score = -24075.789364270386\n[14:19:09] Linear model: C = 0.0001 score = -21574.885528433475\n[14:19:09] Linear model: C = 0.0005 score = -18396.286849517168\n[14:19:09] Linear model: C = 0.001 score = -17625.34316322425\n[14:19:09] Linear model: C = 0.005 score = -16887.73678916309\n[14:19:10] Linear model: C = 0.01 score = -16887.73769447425\n[14:19:10] Linear model: C = 0.05 score = -17691.47864136266\n[14:19:10] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:19:10] Linear model: C = 1e-05 score = -33304.94450777897\n[14:19:10] Linear model: C = 5e-05 score = -21460.37536883047\n[14:19:10] Linear model: C = 0.0001 score = -19108.766362660943\n[14:19:10] Linear model: C = 0.0005 score = -16271.260779908798\n[14:19:11] Linear model: C = 0.001 score = -15908.611856223177\n[14:19:11] Linear model: C = 0.005 score = -15908.611017972104\n[14:19:11] Linear model: C = 0.01 score = -15908.61085032189\n[14:19:11] Linear model: C = 0.05 score = -17930.699872585836\n[14:19:11] Linear model: C = 0.1 score = -17930.698464324036\n[14:19:11] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17228.175264959467\u001b[0m\n[14:19:11] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[14:19:11] Time left 5985.08 secs\n\n[14:19:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[14:19:12] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:19:12] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:19:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:19:14] Training until validation scores don't improve for 200 rounds\n[14:19:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:19:16] Training until validation scores don't improve for 200 rounds\n[14:19:18] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:19:18] Training until validation scores don't improve for 200 rounds\n[14:19:20] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:19:20] Training until validation scores don't improve for 200 rounds\n[14:19:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15704.791005591824\u001b[0m\n[14:19:22] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[14:19:22] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[14:19:22] Training until validation scores don't improve for 200 rounds\n[14:19:25] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15200.433927617521 in 0:00:02.442510\n[14:19:25] Training until validation scores don't improve for 200 rounds\n[14:19:27] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -15022.542134081197 in 0:00:02.380796\n[14:19:27] Training until validation scores don't improve for 200 rounds\n[14:19:29] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -15147.404814369658 in 0:00:01.954202\n[14:19:29] Training until validation scores don't improve for 200 rounds\n[14:19:31] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -14932.59710536859 in 0:00:02.377592\n[14:19:31] Training until validation scores don't improve for 200 rounds\n[14:19:35] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -14977.904914529914 in 0:00:03.893433\n[14:19:35] Training until validation scores don't improve for 200 rounds\n[14:19:37] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -14874.895365918803 in 0:00:02.088509\n[14:19:37] Training until validation scores don't improve for 200 rounds\n[14:19:40] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15035.715044070514 in 0:00:02.271336\n[14:19:40] Training until validation scores don't improve for 200 rounds\n[14:19:42] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -15069.742721688035 in 0:00:02.117712\n[14:19:42] Training until validation scores don't improve for 200 rounds\n[14:19:44] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15501.829811030982 in 0:00:02.842252\n[14:19:45] Training until validation scores don't improve for 200 rounds\n[14:19:47] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -14957.036525106838 in 0:00:02.080420\n[14:19:47] Training until validation scores don't improve for 200 rounds\n[14:19:49] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.977507794645142, 'num_leaves': 129, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 6.615753514282518, 'reg_alpha': 7.162524471389176, 'reg_lambda': 0.11000069496968241} scored -15135.410189636752 in 0:00:02.715457\n[14:19:49] Training until validation scores don't improve for 200 rounds\n[14:19:52] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.8433779752418191, 'num_leaves': 110, 'bagging_fraction': 0.7203947802202717, 'min_sum_hessian_in_leaf': 0.001129033764164707, 'reg_alpha': 0.00937675285585886, 'reg_lambda': 0.01881061891210943} scored -15207.423510950855 in 0:00:02.507554\n[14:19:52] Training until validation scores don't improve for 200 rounds\n[14:19:53] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.6277459590841789, 'num_leaves': 86, 'bagging_fraction': 0.515461689431987, 'min_sum_hessian_in_leaf': 5.987853603638032, 'reg_alpha': 0.06793132890636779, 'reg_lambda': 6.239844537679616e-06} scored -14973.496360844018 in 0:00:01.497449\n[14:19:53] Training until validation scores don't improve for 200 rounds\n[14:19:56] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.8465428114450315, 'num_leaves': 17, 'bagging_fraction': 0.9107311082354602, 'min_sum_hessian_in_leaf': 0.024142096469713267, 'reg_alpha': 5.610661224399163e-05, 'reg_lambda': 0.012341345845574348} scored -14863.633163060897 in 0:00:02.446219\n[14:19:56] Training until validation scores don't improve for 200 rounds\n[14:19:58] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.8825121684574232, 'num_leaves': 24, 'bagging_fraction': 0.9662896029467255, 'min_sum_hessian_in_leaf': 0.03234900423210684, 'reg_alpha': 0.00042462573201201744, 'reg_lambda': 0.03406100225091648} scored -15186.305572248932 in 0:00:02.233446\n[14:19:58] Training until validation scores don't improve for 200 rounds\n[14:20:02] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 170, 'bagging_fraction': 0.9073918595024488, 'min_sum_hessian_in_leaf': 0.021004805863831095, 'reg_alpha': 0.19329039126385797, 'reg_lambda': 0.0063396191326126295} scored -14989.138221153846 in 0:00:03.557886\n[14:20:02] Training until validation scores don't improve for 200 rounds\n[14:20:04] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.8264227656708034, 'num_leaves': 17, 'bagging_fraction': 0.7445756036011, 'min_sum_hessian_in_leaf': 2.6851947777251555, 'reg_alpha': 5.256865884361915e-05, 'reg_lambda': 0.5731660733537501} scored -14915.656834268162 in 0:00:02.239412\n[14:20:05] Training until validation scores don't improve for 200 rounds\n[14:20:08] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.9096977765335421, 'num_leaves': 45, 'bagging_fraction': 0.9102361265933461, 'min_sum_hessian_in_leaf': 0.17126975666943806, 'reg_alpha': 9.345346516967408e-05, 'reg_lambda': 0.004023774052558124} scored -15071.308693910256 in 0:00:04.609654\n[14:20:09] Training until validation scores don't improve for 200 rounds\n[14:20:11] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.872695752069157, 'num_leaves': 156, 'bagging_fraction': 0.6691360672124484, 'min_sum_hessian_in_leaf': 0.016656310286174276, 'reg_alpha': 0.381571800759793, 'reg_lambda': 0.2839324335227587} scored -15315.191606570514 in 0:00:02.427502\n[14:20:11] Training until validation scores don't improve for 200 rounds\n[14:20:14] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.776238259183459, 'num_leaves': 103, 'bagging_fraction': 0.7848590590714977, 'min_sum_hessian_in_leaf': 1.5709224758814602, 'reg_alpha': 0.00881846940418744, 'reg_lambda': 5.0107804034870345} scored -15177.824786324787 in 0:00:02.817949\n[14:20:14] Training until validation scores don't improve for 200 rounds\n[14:20:20] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.9479531437001762, 'num_leaves': 64, 'bagging_fraction': 0.9196546466934268, 'min_sum_hessian_in_leaf': 0.059457079571415376, 'reg_alpha': 0.0011622285955300564, 'reg_lambda': 0.0021448630886722986} scored -15208.919137286324 in 0:00:05.876032\n[14:20:20] Training until validation scores don't improve for 200 rounds\n[14:20:22] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.8341410469104864, 'num_leaves': 17, 'bagging_fraction': 0.7512644651029052, 'min_sum_hessian_in_leaf': 3.037313297370995, 'reg_alpha': 0.00011009823025321484, 'reg_lambda': 0.5067507492006814} scored -14800.035106169871 in 0:00:02.627560\n[14:20:22] Training until validation scores don't improve for 200 rounds\n[14:20:28] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.8235997537740286, 'num_leaves': 37, 'bagging_fraction': 0.7008945440579637, 'min_sum_hessian_in_leaf': 3.505207324782121, 'reg_alpha': 1.158789277695591e-06, 'reg_lambda': 0.05190925408128149} scored -15479.332765758547 in 0:00:05.391291\n[14:20:28] Training until validation scores don't improve for 200 rounds\n[14:20:32] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.8627714831811072, 'num_leaves': 23, 'bagging_fraction': 0.8537023979621762, 'min_sum_hessian_in_leaf': 8.596772708704396, 'reg_alpha': 7.265259184516192e-05, 'reg_lambda': 1.412518839550666} scored -15097.950270432691 in 0:00:04.628425\n[14:20:32] Training until validation scores don't improve for 200 rounds\n[14:20:35] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.7638451827791187, 'num_leaves': 48, 'bagging_fraction': 0.7651365422464476, 'min_sum_hessian_in_leaf': 0.8208790087788153, 'reg_alpha': 2.2121983558558695e-05, 'reg_lambda': 0.24105588524051244} scored -14958.821230635684 in 0:00:02.535416\n[14:20:35] Training until validation scores don't improve for 200 rounds\n[14:20:38] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.806518765504184, 'num_leaves': 16, 'bagging_fraction': 0.6275319267522527, 'min_sum_hessian_in_leaf': 3.0027562889207173, 'reg_alpha': 0.0003836573225802566, 'reg_lambda': 0.01965512913552387} scored -15053.762686965812 in 0:00:03.405299\n[14:20:38] Training until validation scores don't improve for 200 rounds\n[14:20:40] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.9175900661377836, 'num_leaves': 82, 'bagging_fraction': 0.5564400692428451, 'min_sum_hessian_in_leaf': 0.33068684899203726, 'reg_alpha': 0.014504522003258998, 'reg_lambda': 0.13707340333771456} scored -15038.581029647436 in 0:00:02.017555\n[14:20:40] Training until validation scores don't improve for 200 rounds\n[14:20:43] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.7447439543868675, 'num_leaves': 54, 'bagging_fraction': 0.65477426123904, 'min_sum_hessian_in_leaf': 9.24470755882726, 'reg_alpha': 1.6048757650810928, 'reg_lambda': 8.148265380715634} scored -15183.255341880342 in 0:00:02.383253\n[14:20:43] Training until validation scores don't improve for 200 rounds\n[14:20:46] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5796220576949027, 'num_leaves': 34, 'bagging_fraction': 0.9622481606235871, 'min_sum_hessian_in_leaf': 0.010056526466870122, 'reg_alpha': 0.0015358314682154606, 'reg_lambda': 1.1018808573333003} scored -15372.3203125 in 0:00:02.933113\n[14:20:46] Training until validation scores don't improve for 200 rounds\n[14:20:48] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6916062414734313, 'num_leaves': 70, 'bagging_fraction': 0.8284529010820383, 'min_sum_hessian_in_leaf': 0.20368854228550065, 'reg_alpha': 3.0136504165176863e-07, 'reg_lambda': 0.001986963078651844} scored -14995.850861378205 in 0:00:02.285787\n[14:20:48] Training until validation scores don't improve for 200 rounds\n[14:20:50] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.8414364400393614, 'num_leaves': 107, 'bagging_fraction': 0.7459114433147894, 'min_sum_hessian_in_leaf': 1.7951906831896542, 'reg_alpha': 8.911115832212404e-07, 'reg_lambda': 9.546729156467107e-05} scored -14998.103665865385 in 0:00:02.572652\n[14:20:51] Training until validation scores don't improve for 200 rounds\n[14:20:53] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.8077081353248909, 'num_leaves': 16, 'bagging_fraction': 0.7521164041517475, 'min_sum_hessian_in_leaf': 3.5530068000699817, 'reg_alpha': 7.396762722657652e-05, 'reg_lambda': 0.3072868632777221} scored -14896.21000267094 in 0:00:02.259338\n[14:20:53] Training until validation scores don't improve for 200 rounds\n[14:20:55] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.7957137232043281, 'num_leaves': 34, 'bagging_fraction': 0.8760075626679311, 'min_sum_hessian_in_leaf': 4.265044838535173, 'reg_alpha': 1.8784987773582978e-05, 'reg_lambda': 0.012618314673522445} scored -15167.817674946582 in 0:00:02.713651\n[14:20:56] Training until validation scores don't improve for 200 rounds\n[14:20:58] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.8905138329791813, 'num_leaves': 28, 'bagging_fraction': 0.7251752908127096, 'min_sum_hessian_in_leaf': 1.1598630173023612, 'reg_alpha': 0.00013625212377956893, 'reg_lambda': 2.84840996165844} scored -15177.97562767094 in 0:00:02.623775\n[14:20:58] Training until validation scores don't improve for 200 rounds\n[14:21:00] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.8478684057508008, 'num_leaves': 16, 'bagging_fraction': 0.7729457223984337, 'min_sum_hessian_in_leaf': 0.5476647739220536, 'reg_alpha': 1.2888394969425776e-05, 'reg_lambda': 0.07296126321558609} scored -14759.990251068377 in 0:00:01.994421\n[14:21:00] Training until validation scores don't improve for 200 rounds\n[14:21:03] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.9436632159813918, 'num_leaves': 50, 'bagging_fraction': 0.7948347881413136, 'min_sum_hessian_in_leaf': 0.4912810257989378, 'reg_alpha': 1.50123949129809e-05, 'reg_lambda': 0.053618506761915624} scored -15301.058193108975 in 0:00:02.927093\n[14:21:03] Training until validation scores don't improve for 200 rounds\n[14:21:06] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.8553302204072325, 'num_leaves': 37, 'bagging_fraction': 0.8684002572919135, 'min_sum_hessian_in_leaf': 0.8215089878926766, 'reg_alpha': 4.275804116046574e-06, 'reg_lambda': 0.1127889377177845} scored -14925.959735576924 in 0:00:02.777805\n[14:21:06] Training until validation scores don't improve for 200 rounds\n[14:21:08] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.7330921574437678, 'num_leaves': 73, 'bagging_fraction': 0.5007033487198402, 'min_sum_hessian_in_leaf': 0.08252816036617545, 'reg_alpha': 1.1544959676962314e-06, 'reg_lambda': 3.959375143012411e-07} scored -14919.388354700855 in 0:00:01.827013\n[14:21:08] Training until validation scores don't improve for 200 rounds\n[14:21:12] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.6940228382432525, 'num_leaves': 211, 'bagging_fraction': 0.8268830061228717, 'min_sum_hessian_in_leaf': 0.04120005259580022, 'reg_alpha': 0.00032654369868139496, 'reg_lambda': 0.007564410034612942} scored -15078.0546875 in 0:00:03.976555\n[14:21:12] Training until validation scores don't improve for 200 rounds\n[14:21:14] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.9164649645128049, 'num_leaves': 57, 'bagging_fraction': 0.5984950769696198, 'min_sum_hessian_in_leaf': 2.02661416798544, 'reg_alpha': 8.401397157833076e-06, 'reg_lambda': 0.00012225563601093415} scored -15026.917835202992 in 0:00:02.111162\n[14:21:14] Training until validation scores don't improve for 200 rounds\n[14:21:16] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.7785192365414697, 'num_leaves': 188, 'bagging_fraction': 0.8089306584434892, 'min_sum_hessian_in_leaf': 0.12311297010454918, 'reg_alpha': 6.819144570342553e-08, 'reg_lambda': 0.0009211821741745446} scored -15220.261902377137 in 0:00:02.511262\n[14:21:16] Training until validation scores don't improve for 200 rounds\n[14:21:18] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.8126501145252235, 'num_leaves': 17, 'bagging_fraction': 0.7648638591736923, 'min_sum_hessian_in_leaf': 5.4532651989882055, 'reg_alpha': 3.563153720550173e-05, 'reg_lambda': 0.556292322666966} scored -14946.435012686965 in 0:00:01.874354\n[14:21:18] Training until validation scores don't improve for 200 rounds\n[14:21:21] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.8363263192291415, 'num_leaves': 27, 'bagging_fraction': 0.7168328359323594, 'min_sum_hessian_in_leaf': 2.719068784069761, 'reg_alpha': 0.00019581436316056585, 'reg_lambda': 0.4156974576140985} scored -15359.637553418803 in 0:00:02.308261\n[14:21:21] Training until validation scores don't improve for 200 rounds\n[14:21:23] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.7927207453350015, 'num_leaves': 41, 'bagging_fraction': 0.6416991284819329, 'min_sum_hessian_in_leaf': 0.6156778673639656, 'reg_alpha': 0.0007984212737040288, 'reg_lambda': 1.8531969468737362} scored -15222.880542200855 in 0:00:02.642244\n[14:21:23] Training until validation scores don't improve for 200 rounds\n[14:21:26] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.8961723913449031, 'num_leaves': 27, 'bagging_fraction': 0.6931352256360404, 'min_sum_hessian_in_leaf': 0.0032250028795466263, 'reg_alpha': 0.003102796095172026, 'reg_lambda': 0.06255752960322215} scored -15296.858156383547 in 0:00:02.701525\n[14:21:26] Training until validation scores don't improve for 200 rounds\n[14:21:28] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.7532523001080302, 'num_leaves': 95, 'bagging_fraction': 0.7748319533569133, 'min_sum_hessian_in_leaf': 1.1505782995472729, 'reg_alpha': 3.8499252350744325e-06, 'reg_lambda': 0.1582986398749107} scored -14985.304036458334 in 0:00:02.582325\n[14:21:29] Training until validation scores don't improve for 200 rounds\n[14:21:31] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.7171265840140655, 'num_leaves': 254, 'bagging_fraction': 0.738485854436341, 'min_sum_hessian_in_leaf': 0.3410998199807265, 'reg_alpha': 5.177583357251708e-05, 'reg_lambda': 0.03403172622511185} scored -14980.246744791666 in 0:00:02.247850\n[14:21:31] Training until validation scores don't improve for 200 rounds\n[14:21:33] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.8512755601280625, 'num_leaves': 16, 'bagging_fraction': 0.5785661048448661, 'min_sum_hessian_in_leaf': 4.772938522231348, 'reg_alpha': 0.003938414846959915, 'reg_lambda': 1.7819653870832216e-08} scored -15172.656149839744 in 0:00:02.066976\n[14:21:33] Training until validation scores don't improve for 200 rounds\n[14:21:36] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.8686723217095728, 'num_leaves': 59, 'bagging_fraction': 0.9408781552008509, 'min_sum_hessian_in_leaf': 7.23727579914561, 'reg_alpha': 0.04033963730115344, 'reg_lambda': 0.7503368581944538} scored -15307.295038728633 in 0:00:02.827387\n[14:21:36] Training until validation scores don't improve for 200 rounds\n[14:21:38] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.6546995644112099, 'num_leaves': 45, 'bagging_fraction': 0.9899226356996809, 'min_sum_hessian_in_leaf': 1.7461209990839552, 'reg_alpha': 2.139903599956363e-06, 'reg_lambda': 2.9512028908617585} scored -15548.394731570514 in 0:00:02.554302\n[14:21:38] Training until validation scores don't improve for 200 rounds\n[14:21:43] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.8160096151390116, 'num_leaves': 81, 'bagging_fraction': 0.8101109093298853, 'min_sum_hessian_in_leaf': 0.021768679269204855, 'reg_alpha': 9.587092578237705e-06, 'reg_lambda': 0.02133974937687505} scored -15069.06610576923 in 0:00:04.307615\n[14:21:43] Training until validation scores don't improve for 200 rounds\n[14:21:45] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.8172131920049015, 'num_leaves': 16, 'bagging_fraction': 0.6778184730892899, 'min_sum_hessian_in_leaf': 2.644750311740303, 'reg_alpha': 4.991338603073626e-05, 'reg_lambda': 0.3399735041753066} scored -15156.679954594018 in 0:00:02.033273\n[14:21:45] Training until validation scores don't improve for 200 rounds\n[14:21:48] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.7884586519416261, 'num_leaves': 30, 'bagging_fraction': 0.881964567474754, 'min_sum_hessian_in_leaf': 4.168039958830334, 'reg_alpha': 0.00018223663563896625, 'reg_lambda': 0.7565944344843083} scored -15052.98335670406 in 0:00:03.351849\n[14:21:48] Training until validation scores don't improve for 200 rounds\n[14:21:50] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.8357361887119196, 'num_leaves': 40, 'bagging_fraction': 0.7475410519419302, 'min_sum_hessian_in_leaf': 2.6391021106472654, 'reg_alpha': 2.5652968575724925e-05, 'reg_lambda': 0.08860778674682092} scored -15115.972389155982 in 0:00:02.437598\n[14:21:50] Training until validation scores don't improve for 200 rounds\n[14:21:53] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.8818301040623546, 'num_leaves': 117, 'bagging_fraction': 0.7136340466419973, 'min_sum_hessian_in_leaf': 6.121168559219498, 'reg_alpha': 0.0008029682230490717, 'reg_lambda': 0.24400303458137226} scored -15169.09922542735 in 0:00:02.530742\n[14:21:53] Training until validation scores don't improve for 200 rounds\n[14:21:55] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.8264518859791372, 'num_leaves': 19, 'bagging_fraction': 0.5494926284472649, 'min_sum_hessian_in_leaf': 9.796732070593361, 'reg_alpha': 0.00011318278544337816, 'reg_lambda': 6.488168894550181} scored -15157.094350961539 in 0:00:02.231623\n[14:21:55] Training until validation scores don't improve for 200 rounds\n[14:21:57] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.7723268077915625, 'num_leaves': 138, 'bagging_fraction': 0.6196268472354605, 'min_sum_hessian_in_leaf': 0.9727621507897914, 'reg_alpha': 0.000573223647539819, 'reg_lambda': 0.007877620544795705} scored -15076.152310363248 in 0:00:02.169197\n[14:21:57] Training until validation scores don't improve for 200 rounds\n[14:22:00] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.8631515886965069, 'num_leaves': 27, 'bagging_fraction': 0.6608583747057708, 'min_sum_hessian_in_leaf': 2.188025226586447, 'reg_alpha': 8.577416614980677e-05, 'reg_lambda': 0.0033796833107400054} scored -15215.086972489316 in 0:00:02.506181\n[14:22:00] Training until validation scores don't improve for 200 rounds\n[14:22:04] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.9380752463556362, 'num_leaves': 50, 'bagging_fraction': 0.8454162624991464, 'min_sum_hessian_in_leaf': 3.8920432261026225, 'reg_alpha': 0.00026938602376805543, 'reg_lambda': 3.1341134493504446} scored -15445.854634081197 in 0:00:03.673425\n[14:22:04] Training until validation scores don't improve for 200 rounds\n[14:22:06] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.8020814124053945, 'num_leaves': 64, 'bagging_fraction': 0.7819074017478396, 'min_sum_hessian_in_leaf': 0.009452029946535963, 'reg_alpha': 5.598290867220712e-07, 'reg_lambda': 0.16831434239342952} scored -15220.699919871795 in 0:00:02.609279\n[14:22:06] Training until validation scores don't improve for 200 rounds\n[14:22:09] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.9003372927815922, 'num_leaves': 34, 'bagging_fraction': 0.7613724880768976, 'min_sum_hessian_in_leaf': 1.3197492753770033, 'reg_alpha': 0.871201724697021, 'reg_lambda': 1.5420767755261138} scored -15212.35687099359 in 0:00:02.899787\n[14:22:09] Training until validation scores don't improve for 200 rounds\n[14:22:11] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.7377779068770433, 'num_leaves': 74, 'bagging_fraction': 0.509307694532557, 'min_sum_hessian_in_leaf': 0.08357628674918278, 'reg_alpha': 1.581254818236967e-06, 'reg_lambda': 3.876340503126357e-08} scored -14877.694644764957 in 0:00:01.632144\n[14:22:11] Training until validation scores don't improve for 200 rounds\n[14:22:15] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.7383307418314812, 'num_leaves': 24, 'bagging_fraction': 0.5711320447014513, 'min_sum_hessian_in_leaf': 0.08184087374698308, 'reg_alpha': 1.990667847149776e-06, 'reg_lambda': 6.819456424697231e-08} scored -15306.559728899572 in 0:00:03.845663\n[14:22:15] Training until validation scores don't improve for 200 rounds\n[14:22:16] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.7648159968428981, 'num_leaves': 44, 'bagging_fraction': 0.5226271574233422, 'min_sum_hessian_in_leaf': 0.12821045412853885, 'reg_alpha': 1.218421438405192e-05, 'reg_lambda': 4.2025629396556955e-06} scored -14856.143529647436 in 0:00:01.720501\n[14:22:16] Training until validation scores don't improve for 200 rounds\n[14:22:18] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.7663124411046054, 'num_leaves': 73, 'bagging_fraction': 0.5285835643243906, 'min_sum_hessian_in_leaf': 0.1427391008520033, 'reg_alpha': 1.110980794845087e-05, 'reg_lambda': 8.655491071517892e-07} scored -14854.489783653846 in 0:00:01.671772\n[14:22:18] Training until validation scores don't improve for 200 rounds\n[14:22:20] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.715130385796142, 'num_leaves': 75, 'bagging_fraction': 0.5165584874799928, 'min_sum_hessian_in_leaf': 0.2294913641579252, 'reg_alpha': 1.229927927721377e-07, 'reg_lambda': 1.2777209122722812e-06} scored -14794.832598824787 in 0:00:01.563836\n[14:22:20] Training until validation scores don't improve for 200 rounds\n[14:22:22] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.6544887904166345, 'num_leaves': 90, 'bagging_fraction': 0.5288354616164201, 'min_sum_hessian_in_leaf': 0.13162627160295534, 'reg_alpha': 1.1607147072680777e-08, 'reg_lambda': 1.315838524255823e-06} scored -14661.20329193376 in 0:00:01.995249\n[14:22:22] Training until validation scores don't improve for 200 rounds\n[14:22:24] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.6572168099771456, 'num_leaves': 84, 'bagging_fraction': 0.5292381417479325, 'min_sum_hessian_in_leaf': 0.15118506833767573, 'reg_alpha': 1.2122909234162152e-08, 'reg_lambda': 1.2107248474830963e-06} scored -14674.643963675213 in 0:00:01.990131\n[14:22:24] Training until validation scores don't improve for 200 rounds\n[14:22:25] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.6054469461279384, 'num_leaves': 90, 'bagging_fraction': 0.5156434439922856, 'min_sum_hessian_in_leaf': 0.1579498261758125, 'reg_alpha': 1.2116455034761546e-08, 'reg_lambda': 2.312350072422355e-06} scored -14998.417901976496 in 0:00:01.442958\n[14:22:25] Training until validation scores don't improve for 200 rounds\n[14:22:27] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.672364525736424, 'num_leaves': 99, 'bagging_fraction': 0.5303813503257326, 'min_sum_hessian_in_leaf': 0.26002657781737165, 'reg_alpha': 3.299139769726444e-08, 'reg_lambda': 1.0204423878865362e-06} scored -14780.790231036324 in 0:00:01.604973\n[14:22:27] Training until validation scores don't improve for 200 rounds\n[14:22:29] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.6664403750212023, 'num_leaves': 121, 'bagging_fraction': 0.5351749283230405, 'min_sum_hessian_in_leaf': 0.3120521846105579, 'reg_alpha': 3.426099319542915e-08, 'reg_lambda': 7.723591113440313e-07} scored -14818.365751869658 in 0:00:01.749632\n[14:22:29] Training until validation scores don't improve for 200 rounds\n[14:22:30] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.6692663289935898, 'num_leaves': 118, 'bagging_fraction': 0.5340917248688957, 'min_sum_hessian_in_leaf': 0.21324517769472087, 'reg_alpha': 3.1253600692573936e-08, 'reg_lambda': 7.79806549551156e-07} scored -14856.787326388889 in 0:00:01.953475\n[14:22:31] Training until validation scores don't improve for 200 rounds\n[14:22:32] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.6271023682129249, 'num_leaves': 99, 'bagging_fraction': 0.5672594614365345, 'min_sum_hessian_in_leaf': 0.28793276043676247, 'reg_alpha': 1.1178820992561931e-07, 'reg_lambda': 1.1074391983317477e-06} scored -15170.745492788461 in 0:00:01.888908\n[14:22:32] Training until validation scores don't improve for 200 rounds\n[14:22:34] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.6793340264338124, 'num_leaves': 139, 'bagging_fraction': 0.5326699365473803, 'min_sum_hessian_in_leaf': 0.49900704968268067, 'reg_alpha': 2.5490454259169024e-08, 'reg_lambda': 1.9997114973374163e-05} scored -14733.287526709402 in 0:00:01.848355\n[14:22:34] Training until validation scores don't improve for 200 rounds\n[14:22:36] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.6721462350008409, 'num_leaves': 142, 'bagging_fraction': 0.5477322181146127, 'min_sum_hessian_in_leaf': 0.4263756309795003, 'reg_alpha': 2.1690393304920476e-08, 'reg_lambda': 1.9269184745824072e-05} scored -15178.992387820514 in 0:00:01.732193\n[14:22:36] Training until validation scores don't improve for 200 rounds\n[14:22:38] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.6328578694271475, 'num_leaves': 128, 'bagging_fraction': 0.586110162339068, 'min_sum_hessian_in_leaf': 0.6054892974600469, 'reg_alpha': 4.2909142889460566e-08, 'reg_lambda': 1.54753338624878e-07} scored -15017.77654246795 in 0:00:01.930719\n[14:22:38] Training until validation scores don't improve for 200 rounds\n[14:22:40] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.7058686742435409, 'num_leaves': 147, 'bagging_fraction': 0.5607033274435675, 'min_sum_hessian_in_leaf': 0.2536580402258778, 'reg_alpha': 2.0638326940206756e-07, 'reg_lambda': 1.1308516116544623e-05} scored -15190.786959134615 in 0:00:01.969885\n[14:22:40] Training until validation scores don't improve for 200 rounds\n[14:22:42] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.5825533242987612, 'num_leaves': 168, 'bagging_fraction': 0.6109517620299127, 'min_sum_hessian_in_leaf': 0.3966356604199902, 'reg_alpha': 1.095829185848962e-08, 'reg_lambda': 2.688104503138899e-07} scored -15013.974626068377 in 0:00:02.232090\n[14:22:42] Training until validation scores don't improve for 200 rounds\n[14:22:44] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.6741411947558784, 'num_leaves': 124, 'bagging_fraction': 0.5375511504764808, 'min_sum_hessian_in_leaf': 0.18714287976709684, 'reg_alpha': 6.433123782445437e-08, 'reg_lambda': 4.306208823152964e-05} scored -14815.25373931624 in 0:00:01.907051\n[14:22:44] Training until validation scores don't improve for 200 rounds\n[14:22:47] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.7038417078866124, 'num_leaves': 109, 'bagging_fraction': 0.5048826020057948, 'min_sum_hessian_in_leaf': 0.05566266356046464, 'reg_alpha': 6.907453740474624e-08, 'reg_lambda': 5.0770750255830644e-05} scored -14965.462306356838 in 0:00:03.256009\n[14:22:47] Training until validation scores don't improve for 200 rounds\n[14:22:49] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.681995329525277, 'num_leaves': 125, 'bagging_fraction': 0.5465357623576809, 'min_sum_hessian_in_leaf': 0.19197224034197746, 'reg_alpha': 1.927228235710008e-08, 'reg_lambda': 2.3168037025410182e-06} scored -15056.512887286324 in 0:00:01.822974\n[14:22:49] Training until validation scores don't improve for 200 rounds\n[14:22:51] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.6481842023410396, 'num_leaves': 117, 'bagging_fraction': 0.53519919358065, 'min_sum_hessian_in_leaf': 0.09599450682512364, 'reg_alpha': 5.7831333823900796e-08, 'reg_lambda': 3.945786310377661e-06} scored -14788.389189369658 in 0:00:01.926914\n[14:22:51] Training until validation scores don't improve for 200 rounds\n[14:22:53] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.6430029209824304, 'num_leaves': 104, 'bagging_fraction': 0.5228117699817632, 'min_sum_hessian_in_leaf': 0.09524392893885565, 'reg_alpha': 2.2680627927213742e-07, 'reg_lambda': 5.044513101841859e-06} scored -14914.384481837607 in 0:00:01.791207\n[14:22:53] Training until validation scores don't improve for 200 rounds\n[14:22:55] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.6039615517671939, 'num_leaves': 92, 'bagging_fraction': 0.5356701183172836, 'min_sum_hessian_in_leaf': 0.059892692151141215, 'reg_alpha': 6.18669489059761e-08, 'reg_lambda': 2.7388218280146002e-05} scored -14816.702791132479 in 0:00:01.617445\n[14:22:55] Training until validation scores don't improve for 200 rounds\n[14:22:57] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.7242481567486648, 'num_leaves': 113, 'bagging_fraction': 0.5591840206706609, 'min_sum_hessian_in_leaf': 0.2406283915147016, 'reg_alpha': 1.3747343599589543e-07, 'reg_lambda': 2.2911375643394746e-06} scored -15035.820846688035 in 0:00:02.017763\n[14:22:57] Training until validation scores don't improve for 200 rounds\n[14:22:59] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.6569054437573723, 'num_leaves': 153, 'bagging_fraction': 0.5970885345620478, 'min_sum_hessian_in_leaf': 0.5031638384404746, 'reg_alpha': 1.2987707617104033e-07, 'reg_lambda': 0.0003280349010395274} scored -15016.08296607906 in 0:00:01.862250\n[14:22:59] Training until validation scores don't improve for 200 rounds\n[14:23:01] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.6805080540553138, 'num_leaves': 135, 'bagging_fraction': 0.5788291377805889, 'min_sum_hessian_in_leaf': 0.16169040904578527, 'reg_alpha': 3.326580990207634e-07, 'reg_lambda': 9.525795505214357e-06} scored -15072.819277510684 in 0:00:02.026446\n[14:23:01] Training until validation scores don't improve for 200 rounds\n[14:23:03] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.6419434483274548, 'num_leaves': 83, 'bagging_fraction': 0.5133242445841538, 'min_sum_hessian_in_leaf': 0.11498151412942136, 'reg_alpha': 1.7861520991803452e-08, 'reg_lambda': 1.5425875737707856e-06} scored -14840.598090277777 in 0:00:01.975308\n[14:23:03] Training until validation scores don't improve for 200 rounds\n[14:23:05] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.6993677984935598, 'num_leaves': 97, 'bagging_fraction': 0.5382885505804877, 'min_sum_hessian_in_leaf': 0.04549220055031677, 'reg_alpha': 5.130151260273115e-07, 'reg_lambda': 3.937019659156546e-07} scored -14938.109441773504 in 0:00:01.925387\n[14:23:05] Training until validation scores don't improve for 200 rounds\n[14:23:06] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.5476918544655904, 'num_leaves': 133, 'bagging_fraction': 0.5234650971470545, 'min_sum_hessian_in_leaf': 0.0978137485211487, 'reg_alpha': 6.046391123477645e-08, 'reg_lambda': 6.255273456922974e-05} scored -14850.66877003205 in 0:00:01.882110\n[14:23:06] Training until validation scores don't improve for 200 rounds\n[14:23:09] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.6103811715344468, 'num_leaves': 166, 'bagging_fraction': 0.7309956906099913, 'min_sum_hessian_in_leaf': 0.7360817164590835, 'reg_alpha': 1.0575619212795992e-08, 'reg_lambda': 2.0385904952354022e-05} scored -14882.886702056623 in 0:00:02.560607\n[14:23:09] Training until validation scores don't improve for 200 rounds\n[14:23:11] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.6149382343026388, 'num_leaves': 93, 'bagging_fraction': 0.5542909249065974, 'min_sum_hessian_in_leaf': 0.06087048541929066, 'reg_alpha': 4.768619334461074e-08, 'reg_lambda': 3.1200314768149635e-05} scored -15009.662893963676 in 0:00:01.981200\n[14:23:11] Training until validation scores don't improve for 200 rounds\n[14:23:13] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.5936647077986542, 'num_leaves': 89, 'bagging_fraction': 0.542574116786551, 'min_sum_hessian_in_leaf': 0.02833793413715747, 'reg_alpha': 7.691249235763903e-08, 'reg_lambda': 4.052464007498056e-06} scored -14888.531617254273 in 0:00:01.751838\n[14:23:13] Training until validation scores don't improve for 200 rounds\n[14:23:15] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.6449673481419882, 'num_leaves': 101, 'bagging_fraction': 0.504984748575378, 'min_sum_hessian_in_leaf': 0.07050714123572195, 'reg_alpha': 2.9453417194737143e-08, 'reg_lambda': 0.000126345080819086} scored -14822.467080662393 in 0:00:01.871808\n[14:23:15] Training until validation scores don't improve for 200 rounds\n[14:23:17] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.6825068484239522, 'num_leaves': 79, 'bagging_fraction': 0.5734040075801062, 'min_sum_hessian_in_leaf': 0.041258360116784194, 'reg_alpha': 1.0440587745108494e-07, 'reg_lambda': 2.0444844763353957e-05} scored -15219.532218215812 in 0:00:01.894145\n[14:23:17] Training until validation scores don't improve for 200 rounds\n[14:23:20] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.6609118530576394, 'num_leaves': 112, 'bagging_fraction': 0.5300552102512547, 'min_sum_hessian_in_leaf': 0.21017634933920928, 'reg_alpha': 1.9222043557137535e-08, 'reg_lambda': 5.162735141951006e-07} scored -14703.003472222223 in 0:00:03.467480\n[14:23:20] Training until validation scores don't improve for 200 rounds\n[14:23:22] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.7141604978548858, 'num_leaves': 112, 'bagging_fraction': 0.5221594472524913, 'min_sum_hessian_in_leaf': 0.2020253581172953, 'reg_alpha': 1.5672948165612786e-08, 'reg_lambda': 1.0536283837875857e-07} scored -14687.065838675213 in 0:00:01.661421\n[14:23:22] Training until validation scores don't improve for 200 rounds\n[14:23:24] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.7136778520720609, 'num_leaves': 115, 'bagging_fraction': 0.798087808693723, 'min_sum_hessian_in_leaf': 0.22730127087767293, 'reg_alpha': 1.6511365397424082e-08, 'reg_lambda': 1.2038118050912958e-07} scored -14943.907234909188 in 0:00:02.393882\n[14:23:24] Training until validation scores don't improve for 200 rounds\n[14:23:26] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.6592217419560098, 'num_leaves': 109, 'bagging_fraction': 0.5181780758308477, 'min_sum_hessian_in_leaf': 0.3418464325158777, 'reg_alpha': 2.8256095015039228e-08, 'reg_lambda': 4.7296871725464085e-07} scored -14830.02968082265 in 0:00:01.953791\n[14:23:26] Training until validation scores don't improve for 200 rounds\n[14:23:28] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.6909598987746075, 'num_leaves': 106, 'bagging_fraction': 0.5890416684559879, 'min_sum_hessian_in_leaf': 0.5093440952582411, 'reg_alpha': 1.0004621571285642e-08, 'reg_lambda': 1.536598295151141e-07} scored -15060.288728632479 in 0:00:01.842630\n[14:23:28] Training until validation scores don't improve for 200 rounds\n[14:23:30] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.6305911655949491, 'num_leaves': 66, 'bagging_fraction': 0.5017314441781994, 'min_sum_hessian_in_leaf': 0.12933140875432805, 'reg_alpha': 2.0457158207766382e-08, 'reg_lambda': 1.3599482424519738e-06} scored -14954.762086004273 in 0:00:01.826981\n[14:23:30] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[14:23:30] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6544887904166345, 'num_leaves': 90, 'bagging_fraction': 0.5288354616164201, 'min_sum_hessian_in_leaf': 0.13162627160295534, 'reg_alpha': 1.1607147072680777e-08, 'reg_lambda': 1.315838524255823e-06}\u001b[0m\n achieve -14661.2033 mae\n[14:23:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[14:23:30] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:23:30] Training until validation scores don't improve for 100 rounds\n[14:23:30] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:23:30] Training until validation scores don't improve for 100 rounds\n[14:23:31] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:23:31] Training until validation scores don't improve for 100 rounds\n[14:23:32] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:23:32] Training until validation scores don't improve for 100 rounds\n[14:23:32] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:23:32] Training until validation scores don't improve for 100 rounds\n[14:23:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15703.555951680222\u001b[0m\n[14:23:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[14:23:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[14:23:33] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:23:33] 0:\tlearn: 53185.4029431\ttest: 57111.1216667\tbest: 57111.1216667 (0)\ttotal: 3.42ms\tremaining: 6.83s\n[14:23:38] Stopped by overfitting detector  (300 iterations wait)\n[14:23:38] bestTest = 14442.84202\n[14:23:38] bestIteration = 1461\n[14:23:38] Shrink model to first 1462 iterations.\n[14:23:38] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:23:38] 0:\tlearn: 53857.7216630\ttest: 56384.4982122\tbest: 56384.4982122 (0)\ttotal: 4.11ms\tremaining: 8.21s\n[14:23:41] Stopped by overfitting detector  (300 iterations wait)\n[14:23:41] bestTest = 15710.09173\n[14:23:41] bestIteration = 464\n[14:23:41] Shrink model to first 465 iterations.\n[14:23:41] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:23:41] 0:\tlearn: 53738.2369501\ttest: 54614.8900845\tbest: 54614.8900845 (0)\ttotal: 3.31ms\tremaining: 6.61s\n[14:23:43] Stopped by overfitting detector  (300 iterations wait)\n[14:23:43] bestTest = 15635.05917\n[14:23:43] bestIteration = 759\n[14:23:43] Shrink model to first 760 iterations.\n[14:23:43] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:23:44] 0:\tlearn: 54895.7560236\ttest: 51208.5689482\tbest: 51208.5689482 (0)\ttotal: 3.08ms\tremaining: 6.16s\n[14:23:48] bestTest = 14077.61412\n[14:23:48] bestIteration = 1753\n[14:23:48] Shrink model to first 1754 iterations.\n[14:23:49] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:23:49] 0:\tlearn: 54985.2493976\ttest: 51196.3761798\tbest: 51196.3761798 (0)\ttotal: 3.93ms\tremaining: 7.86s\n[14:23:51] Stopped by overfitting detector  (300 iterations wait)\n[14:23:51] bestTest = 14164.46137\n[14:23:51] bestIteration = 468\n[14:23:51] Shrink model to first 469 iterations.\n[14:23:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-14807.186740822988\u001b[0m\n[14:23:51] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[14:23:51] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[14:23:51] 0:\tlearn: 53396.4951070\ttest: 57498.6348456\tbest: 57498.6348456 (0)\ttotal: 2.13ms\tremaining: 4.25s\n[14:23:52] Stopped by overfitting detector  (300 iterations wait)\n[14:23:52] bestTest = 14069.67903\n[14:23:52] bestIteration = 570\n[14:23:53] Shrink model to first 571 iterations.\n[14:23:53] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -14069.678719284188 in 0:00:01.658426\n[14:23:53] 0:\tlearn: 53574.2675331\ttest: 57580.2547952\tbest: 57580.2547952 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[14:23:54] Stopped by overfitting detector  (300 iterations wait)\n[14:23:54] bestTest = 13375.97258\n[14:23:54] bestIteration = 724\n[14:23:54] Shrink model to first 725 iterations.\n[14:23:54] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -13375.972205528846 in 0:00:01.354689\n[14:23:54] 0:\tlearn: 53452.4170772\ttest: 57489.8388646\tbest: 57489.8388646 (0)\ttotal: 1.3ms\tremaining: 2.61s\n[14:23:55] Stopped by overfitting detector  (300 iterations wait)\n[14:23:55] bestTest = 14331.62932\n[14:23:55] bestIteration = 942\n[14:23:55] Shrink model to first 943 iterations.\n[14:23:55] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -14331.629407051281 in 0:00:01.607539\n[14:23:56] 0:\tlearn: 53574.2216582\ttest: 57580.2040553\tbest: 57580.2040553 (0)\ttotal: 1.38ms\tremaining: 2.75s\n[14:23:57] Stopped by overfitting detector  (300 iterations wait)\n[14:23:57] bestTest = 13522.9605\n[14:23:57] bestIteration = 1004\n[14:23:57] Shrink model to first 1005 iterations.\n[14:23:57] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -13522.960369925213 in 0:00:01.707211\n[14:23:57] 0:\tlearn: 53156.1208435\ttest: 57176.8010208\tbest: 57176.8010208 (0)\ttotal: 4.08ms\tremaining: 8.15s\n[14:24:00] Stopped by overfitting detector  (300 iterations wait)\n[14:24:00] bestTest = 14786.48914\n[14:24:00] bestIteration = 465\n[14:24:00] Shrink model to first 466 iterations.\n[14:24:00] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -14786.489115918803 in 0:00:02.430410\n[14:24:00] 0:\tlearn: 53156.3429473\ttest: 57176.9526284\tbest: 57176.9526284 (0)\ttotal: 4.03ms\tremaining: 8.06s\n[14:24:06] Stopped by overfitting detector  (300 iterations wait)\n[14:24:06] bestTest = 14804.87294\n[14:24:06] bestIteration = 1419\n[14:24:06] Shrink model to first 1420 iterations.\n[14:24:06] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -14804.872829861111 in 0:00:05.968529\n[14:24:06] 0:\tlearn: 53339.8928897\ttest: 57503.7039045\tbest: 57503.7039045 (0)\ttotal: 4.78ms\tremaining: 9.56s\n[14:24:09] Stopped by overfitting detector  (300 iterations wait)\n[14:24:09] bestTest = 14760.94262\n[14:24:09] bestIteration = 806\n[14:24:09] Shrink model to first 807 iterations.\n[14:24:09] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -14759.68546340812 in 0:00:03.822015\n[14:24:10] 0:\tlearn: 53051.4603496\ttest: 57314.2971348\tbest: 57314.2971348 (0)\ttotal: 5.5ms\tremaining: 11s\n[14:24:12] Stopped by overfitting detector  (300 iterations wait)\n[14:24:12] bestTest = 15186.33826\n[14:24:12] bestIteration = 362\n[14:24:12] Shrink model to first 363 iterations.\n[14:24:13] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -15186.338474893162 in 0:00:03.065251\n[14:24:13] 0:\tlearn: 53475.6809630\ttest: 57524.1578767\tbest: 57524.1578767 (0)\ttotal: 1.32ms\tremaining: 2.64s\n[14:24:14] Stopped by overfitting detector  (300 iterations wait)\n[14:24:14] bestTest = 14595.26045\n[14:24:14] bestIteration = 867\n[14:24:14] Shrink model to first 868 iterations.\n[14:24:14] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -14595.261067708334 in 0:00:01.534656\n[14:24:14] 0:\tlearn: 53156.2057434\ttest: 57176.8589650\tbest: 57176.8589650 (0)\ttotal: 3.28ms\tremaining: 6.55s\n[14:24:16] Stopped by overfitting detector  (300 iterations wait)\n[14:24:16] bestTest = 14974.83854\n[14:24:16] bestIteration = 400\n[14:24:16] Shrink model to first 401 iterations.\n[14:24:16] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -14974.838474893162 in 0:00:02.239755\n[14:24:17] 0:\tlearn: 53195.4143662\ttest: 57152.6328555\tbest: 57152.6328555 (0)\ttotal: 1.75ms\tremaining: 3.51s\n[14:24:19] Stopped by overfitting detector  (300 iterations wait)\n[14:24:19] bestTest = 14540.5904\n[14:24:19] bestIteration = 1234\n[14:24:19] Shrink model to first 1235 iterations.\n[14:24:19] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 17} scored -14540.590428018162 in 0:00:02.659843\n[14:24:19] 0:\tlearn: 53195.4148314\ttest: 57152.6334130\tbest: 57152.6334130 (0)\ttotal: 1.73ms\tremaining: 3.45s\n[14:24:21] Stopped by overfitting detector  (300 iterations wait)\n[14:24:21] bestTest = 14535.44543\n[14:24:21] bestIteration = 971\n[14:24:21] Shrink model to first 972 iterations.\n[14:24:21] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5624722374695954e-05, 'min_data_in_leaf': 14} scored -14535.445412660256 in 0:00:02.309336\n[14:24:22] 0:\tlearn: 53575.4480798\ttest: 57581.5601887\tbest: 57581.5601887 (0)\ttotal: 1.62ms\tremaining: 3.23s\n[14:24:23] Stopped by overfitting detector  (300 iterations wait)\n[14:24:23] bestTest = 13449.387\n[14:24:23] bestIteration = 725\n[14:24:23] Shrink model to first 726 iterations.\n[14:24:23] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0668602867950036, 'min_data_in_leaf': 14} scored -13449.386785523504 in 0:00:01.884377\n[14:24:23] 0:\tlearn: 53200.2235240\ttest: 57158.3709008\tbest: 57158.3709008 (0)\ttotal: 2.19ms\tremaining: 4.39s\n[14:24:26] Stopped by overfitting detector  (300 iterations wait)\n[14:24:26] bestTest = 14235.65987\n[14:24:26] bestIteration = 1086\n[14:24:26] Shrink model to first 1087 iterations.\n[14:24:26] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1627382593096612, 'min_data_in_leaf': 14} scored -14235.660189636752 in 0:00:02.394010\n[14:24:26] 0:\tlearn: 53188.1062420\ttest: 57114.7206583\tbest: 57114.7206583 (0)\ttotal: 2.37ms\tremaining: 4.74s\n[14:24:28] Stopped by overfitting detector  (300 iterations wait)\n[14:24:28] bestTest = 14666.68151\n[14:24:28] bestIteration = 524\n[14:24:28] Shrink model to first 525 iterations.\n[14:24:28] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.060486127828111746, 'min_data_in_leaf': 14} scored -14666.681223290598 in 0:00:01.955651\n[14:24:28] 0:\tlearn: 53581.6224364\ttest: 57588.3767687\tbest: 57588.3767687 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[14:24:29] Stopped by overfitting detector  (300 iterations wait)\n[14:24:29] bestTest = 13596.1475\n[14:24:29] bestIteration = 1042\n[14:24:29] Shrink model to first 1043 iterations.\n[14:24:29] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4069826105176487, 'min_data_in_leaf': 17} scored -13596.148287259615 in 0:00:01.810003\n[14:24:30] 0:\tlearn: 53185.9399144\ttest: 57111.8375409\tbest: 57111.8375409 (0)\ttotal: 2.35ms\tremaining: 4.69s\n[14:24:31] Stopped by overfitting detector  (300 iterations wait)\n[14:24:31] bestTest = 14670.76711\n[14:24:31] bestIteration = 536\n[14:24:31] Shrink model to first 537 iterations.\n[14:24:31] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.019974340907638524, 'min_data_in_leaf': 12} scored -14670.766927083334 in 0:00:02.044420\n[14:24:32] 0:\tlearn: 53722.9594022\ttest: 57740.0640563\tbest: 57740.0640563 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:24:34] Stopped by overfitting detector  (300 iterations wait)\n[14:24:34] bestTest = 13996.18826\n[14:24:34] bestIteration = 1655\n[14:24:34] Shrink model to first 1656 iterations.\n[14:24:34] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 9.86874546485378, 'min_data_in_leaf': 17} scored -13996.18843482906 in 0:00:02.453541\n[14:24:34] 0:\tlearn: 53195.4189547\ttest: 57152.6383547\tbest: 57152.6383547 (0)\ttotal: 1.74ms\tremaining: 3.49s\n[14:24:36] Stopped by overfitting detector  (300 iterations wait)\n[14:24:36] bestTest = 14462.67396\n[14:24:36] bestIteration = 643\n[14:24:36] Shrink model to first 644 iterations.\n[14:24:36] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0001540337348416222, 'min_data_in_leaf': 20} scored -14462.673494257479 in 0:00:01.718011\n[14:24:36] 0:\tlearn: 53184.8631488\ttest: 57110.4015476\tbest: 57110.4015476 (0)\ttotal: 2.35ms\tremaining: 4.69s\n[14:24:38] Stopped by overfitting detector  (300 iterations wait)\n[14:24:38] bestTest = 14626.17844\n[14:24:38] bestIteration = 762\n[14:24:38] Shrink model to first 763 iterations.\n[14:24:38] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 4.648765661147256e-07, 'min_data_in_leaf': 12} scored -14626.178819444445 in 0:00:02.515937\n[14:24:38] 0:\tlearn: 53574.4935516\ttest: 57580.5047681\tbest: 57580.5047681 (0)\ttotal: 1.37ms\tremaining: 2.75s\n[14:24:40] Stopped by overfitting detector  (300 iterations wait)\n[14:24:40] bestTest = 13227.04746\n[14:24:40] bestIteration = 1139\n[14:24:40] Shrink model to first 1140 iterations.\n[14:24:40] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.014860567937462947, 'min_data_in_leaf': 16} scored -13227.047142094018 in 0:00:01.882013\n[14:24:40] 0:\tlearn: 53574.3864380\ttest: 57580.3863053\tbest: 57580.3863053 (0)\ttotal: 1.3ms\tremaining: 2.6s\n[14:24:42] Stopped by overfitting detector  (300 iterations wait)\n[14:24:42] bestTest = 13185.53661\n[14:24:42] bestIteration = 1222\n[14:24:42] Shrink model to first 1223 iterations.\n[14:24:42] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.009035078527798947, 'min_data_in_leaf': 16} scored -13185.536107772436 in 0:00:02.021340\n[14:24:42] 0:\tlearn: 53574.4186267\ttest: 57580.4219051\tbest: 57580.4219051 (0)\ttotal: 1.29ms\tremaining: 2.59s\n[14:24:44] Stopped by overfitting detector  (300 iterations wait)\n[14:24:44] bestTest = 13214.35188\n[14:24:44] bestIteration = 989\n[14:24:44] Shrink model to first 990 iterations.\n[14:24:44] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.010785486006783461, 'min_data_in_leaf': 18} scored -13214.352130074787 in 0:00:01.714002\n[14:24:44] 0:\tlearn: 53195.7227339\ttest: 57153.0023205\tbest: 57153.0023205 (0)\ttotal: 1.75ms\tremaining: 3.5s\n[14:24:47] Stopped by overfitting detector  (300 iterations wait)\n[14:24:47] bestTest = 13966.27845\n[14:24:47] bestIteration = 1596\n[14:24:47] Shrink model to first 1597 iterations.\n[14:24:47] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.010356467500874647, 'min_data_in_leaf': 18} scored -13966.278545673076 in 0:00:03.427222\n[14:24:47] 0:\tlearn: 53580.9052771\ttest: 57587.5859198\tbest: 57587.5859198 (0)\ttotal: 1.3ms\tremaining: 2.61s\n[14:24:48] Stopped by overfitting detector  (300 iterations wait)\n[14:24:48] bestTest = 13569.3935\n[14:24:48] bestIteration = 618\n[14:24:48] Shrink model to first 619 iterations.\n[14:24:48] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.36714255469878165, 'min_data_in_leaf': 19} scored -13569.393529647436 in 0:00:01.288659\n[14:24:49] 0:\tlearn: 53195.4311896\ttest: 57152.6530178\tbest: 57152.6530178 (0)\ttotal: 1.7ms\tremaining: 3.41s\n[14:24:50] Stopped by overfitting detector  (300 iterations wait)\n[14:24:50] bestTest = 14447.6687\n[14:24:50] bestIteration = 848\n[14:24:50] Shrink model to first 849 iterations.\n[14:24:50] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0005647432507081098, 'min_data_in_leaf': 16} scored -14447.668586404914 in 0:00:02.003209\n[14:24:51] 0:\tlearn: 53452.5406615\ttest: 57490.0358231\tbest: 57490.0358231 (0)\ttotal: 1.31ms\tremaining: 2.63s\n[14:24:53] bestTest = 14332.41882\n[14:24:53] bestIteration = 1877\n[14:24:53] Shrink model to first 1878 iterations.\n[14:24:53] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007564662168695893, 'min_data_in_leaf': 18} scored -14332.418586404914 in 0:00:02.560706\n[14:24:53] 0:\tlearn: 53142.3665991\ttest: 57160.5737676\tbest: 57160.5737676 (0)\ttotal: 6.64ms\tremaining: 13.3s\n[14:24:56] Stopped by overfitting detector  (300 iterations wait)\n[14:24:56] bestTest = 14664.25574\n[14:24:56] bestIteration = 284\n[14:24:56] Shrink model to first 285 iterations.\n[14:24:56] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04453712260615368, 'min_data_in_leaf': 12} scored -14664.25560897436 in 0:00:03.127705\n[14:24:56] 0:\tlearn: 53207.2926960\ttest: 57166.7208935\tbest: 57166.7208935 (0)\ttotal: 1.66ms\tremaining: 3.31s\n[14:24:58] Stopped by overfitting detector  (300 iterations wait)\n[14:24:58] bestTest = 14166.31495\n[14:24:58] bestIteration = 678\n[14:24:58] Shrink model to first 679 iterations.\n[14:24:58] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4066646509539474, 'min_data_in_leaf': 16} scored -14166.315688434828 in 0:00:01.755998\n[14:24:58] 0:\tlearn: 53452.4829657\ttest: 57489.9438977\tbest: 57489.9438977 (0)\ttotal: 1.4ms\tremaining: 2.79s\n[14:24:59] Stopped by overfitting detector  (300 iterations wait)\n[14:24:59] bestTest = 14508.18739\n[14:24:59] bestIteration = 625\n[14:24:59] Shrink model to first 626 iterations.\n[14:24:59] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0040325835146663444, 'min_data_in_leaf': 19} scored -14526.556406917734 in 0:00:01.297591\n[14:24:59] 0:\tlearn: 53184.9161146\ttest: 57110.4722284\tbest: 57110.4722284 (0)\ttotal: 2.51ms\tremaining: 5.02s\n[14:25:03] Stopped by overfitting detector  (300 iterations wait)\n[14:25:03] bestTest = 14559.24767\n[14:25:03] bestIteration = 1135\n[14:25:03] Shrink model to first 1136 iterations.\n[14:25:03] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000980428139414022, 'min_data_in_leaf': 9} scored -14559.247913327992 in 0:00:03.298318\n[14:25:03] 0:\tlearn: 53574.2740200\ttest: 57580.2619700\tbest: 57580.2619700 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[14:25:04] Stopped by overfitting detector  (300 iterations wait)\n[14:25:04] bestTest = 13358.88423\n[14:25:04] bestIteration = 1004\n[14:25:04] Shrink model to first 1005 iterations.\n[14:25:04] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0029232132743533933, 'min_data_in_leaf': 15} scored -13358.88446514423 in 0:00:01.737219\n[14:25:05] 0:\tlearn: 53574.2667772\ttest: 57580.2539591\tbest: 57580.2539591 (0)\ttotal: 1.41ms\tremaining: 2.81s\n[14:25:06] Stopped by overfitting detector  (300 iterations wait)\n[14:25:06] bestTest = 13375.96862\n[14:25:06] bestIteration = 724\n[14:25:06] Shrink model to first 725 iterations.\n[14:25:06] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0025295134871902484, 'min_data_in_leaf': 15} scored -13375.96866653312 in 0:00:01.402190\n[14:25:06] 0:\tlearn: 53574.2257817\ttest: 57580.2086161\tbest: 57580.2086161 (0)\ttotal: 1.3ms\tremaining: 2.6s\n[14:25:07] Stopped by overfitting detector  (300 iterations wait)\n[14:25:07] bestTest = 13522.9804\n[14:25:07] bestIteration = 1004\n[14:25:07] Shrink model to first 1005 iterations.\n[14:25:07] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00030129049687316556, 'min_data_in_leaf': 16} scored -13522.979984642094 in 0:00:01.707248\n[14:25:08] 0:\tlearn: 53574.2211574\ttest: 57580.2035014\tbest: 57580.2035014 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:25:09] Stopped by overfitting detector  (300 iterations wait)\n[14:25:09] bestTest = 13522.38236\n[14:25:09] bestIteration = 1004\n[14:25:09] Shrink model to first 1005 iterations.\n[14:25:09] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 4.996307971029681e-05, 'min_data_in_leaf': 13} scored -13522.38272903312 in 0:00:01.955672\n[14:25:10] 0:\tlearn: 53196.2997824\ttest: 57153.6931162\tbest: 57153.6931162 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:25:11] Stopped by overfitting detector  (300 iterations wait)\n[14:25:11] bestTest = 14515.46588\n[14:25:11] bestIteration = 652\n[14:25:11] Shrink model to first 653 iterations.\n[14:25:11] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.029765480104655757, 'min_data_in_leaf': 18} scored -14515.465177617521 in 0:00:01.714455\n[14:25:11] 0:\tlearn: 53576.6108446\ttest: 57582.8452651\tbest: 57582.8452651 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:25:12] Stopped by overfitting detector  (300 iterations wait)\n[14:25:12] bestTest = 13469.49287\n[14:25:12] bestIteration = 626\n[14:25:12] Shrink model to first 627 iterations.\n[14:25:12] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.13041461050727446, 'min_data_in_leaf': 15} scored -13469.492337740385 in 0:00:01.336161\n[14:25:13] 0:\tlearn: 53452.4874982\ttest: 57489.9511209\tbest: 57489.9511209 (0)\ttotal: 1.43ms\tremaining: 2.87s\n[14:25:14] Stopped by overfitting detector  (300 iterations wait)\n[14:25:14] bestTest = 14521.94352\n[14:25:14] bestIteration = 625\n[14:25:14] Shrink model to first 626 iterations.\n[14:25:14] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00431000425889245, 'min_data_in_leaf': 11} scored -14540.312132745727 in 0:00:01.286383\n[14:25:14] 0:\tlearn: 53195.4145775\ttest: 57152.6331088\tbest: 57152.6331088 (0)\ttotal: 1.74ms\tremaining: 3.48s\n[14:25:16] Stopped by overfitting detector  (300 iterations wait)\n[14:25:16] bestTest = 14506.76048\n[14:25:16] bestIteration = 1214\n[14:25:16] Shrink model to first 1215 iterations.\n[14:25:16] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 7.104228167938725e-06, 'min_data_in_leaf': 19} scored -14506.760750534188 in 0:00:02.625659\n[14:25:17] 0:\tlearn: 53452.4419122\ttest: 57489.8784611\tbest: 57489.8784611 (0)\ttotal: 1.34ms\tremaining: 2.68s\n[14:25:18] Stopped by overfitting detector  (300 iterations wait)\n[14:25:18] bestTest = 14403.28066\n[14:25:18] bestIteration = 615\n[14:25:18] Shrink model to first 616 iterations.\n[14:25:18] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0015202560425075255, 'min_data_in_leaf': 16} scored -14421.391326121795 in 0:00:01.268124\n[14:25:18] 0:\tlearn: 53574.2240541\ttest: 57580.2067053\tbest: 57580.2067053 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[14:25:19] Stopped by overfitting detector  (300 iterations wait)\n[14:25:19] bestTest = 13522.45872\n[14:25:19] bestIteration = 1004\n[14:25:19] Shrink model to first 1005 iterations.\n[14:25:19] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0002073947063342501, 'min_data_in_leaf': 7} scored -13522.458650507479 in 0:00:01.706924\n[14:25:20] 0:\tlearn: 53574.2850940\ttest: 57580.2742182\tbest: 57580.2742182 (0)\ttotal: 1.34ms\tremaining: 2.68s\n[14:25:21] Stopped by overfitting detector  (300 iterations wait)\n[14:25:21] bestTest = 13358.90987\n[14:25:21] bestIteration = 1004\n[14:25:21] Shrink model to first 1005 iterations.\n[14:25:21] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0035251806902014474, 'min_data_in_leaf': 13} scored -13358.909705528846 in 0:00:01.736871\n[14:25:21] 0:\tlearn: 53574.3711830\ttest: 57580.3694335\tbest: 57580.3694335 (0)\ttotal: 1.4ms\tremaining: 2.8s\n[14:25:23] Stopped by overfitting detector  (300 iterations wait)\n[14:25:23] bestTest = 13143.68396\n[14:25:23] bestIteration = 1010\n[14:25:23] Shrink model to first 1011 iterations.\n[14:25:23] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.008205576919727354, 'min_data_in_leaf': 13} scored -13143.684027777777 in 0:00:01.744534\n[14:25:23] 0:\tlearn: 53574.4366176\ttest: 57580.4418024\tbest: 57580.4418024 (0)\ttotal: 1.3ms\tremaining: 2.6s\n[14:25:24] Stopped by overfitting detector  (300 iterations wait)\n[14:25:24] bestTest = 13304.47\n[14:25:24] bestIteration = 612\n[14:25:24] Shrink model to first 613 iterations.\n[14:25:24] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.011763907334666812, 'min_data_in_leaf': 15} scored -13304.469734909188 in 0:00:01.281000\n[14:25:24] 0:\tlearn: 53195.6437176\ttest: 57152.9076695\tbest: 57152.9076695 (0)\ttotal: 1.67ms\tremaining: 3.33s\n[14:25:27] Stopped by overfitting detector  (300 iterations wait)\n[14:25:27] bestTest = 14157.11831\n[14:25:27] bestIteration = 1018\n[14:25:27] Shrink model to first 1019 iterations.\n[14:25:27] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00770169699911956, 'min_data_in_leaf': 17} scored -14157.118389423076 in 0:00:02.585647\n[14:25:27] 0:\tlearn: 53598.3933218\ttest: 57606.8080552\tbest: 57606.8080552 (0)\ttotal: 1.56ms\tremaining: 3.13s\n[14:25:29] Stopped by overfitting detector  (300 iterations wait)\n[14:25:29] bestTest = 13921.93914\n[14:25:29] bestIteration = 1058\n[14:25:29] Shrink model to first 1059 iterations.\n[14:25:29] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.363673406705274, 'min_data_in_leaf': 13} scored -13921.939135950855 in 0:00:01.896322\n[14:25:29] 0:\tlearn: 53574.5258016\ttest: 57580.5404341\tbest: 57580.5404341 (0)\ttotal: 1.34ms\tremaining: 2.69s\n[14:25:31] Stopped by overfitting detector  (300 iterations wait)\n[14:25:31] bestTest = 13325.26181\n[14:25:31] bestIteration = 1013\n[14:25:31] Shrink model to first 1014 iterations.\n[14:25:31] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.01661490302493271, 'min_data_in_leaf': 10} scored -13325.26171875 in 0:00:01.713865\n[14:25:31] 0:\tlearn: 53199.5231663\ttest: 57157.5383540\tbest: 57157.5383540 (0)\ttotal: 1.8ms\tremaining: 3.6s\n[14:25:33] Stopped by overfitting detector  (300 iterations wait)\n[14:25:33] bestTest = 14395.35468\n[14:25:33] bestIteration = 1214\n[14:25:33] Shrink model to first 1215 iterations.\n[14:25:33] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.13887641806953563, 'min_data_in_leaf': 20} scored -14395.354333600428 in 0:00:02.640748\n[14:25:34] 0:\tlearn: 53396.4130070\ttest: 57498.4859799\tbest: 57498.4859799 (0)\ttotal: 1.75ms\tremaining: 3.49s\n[14:25:35] Stopped by overfitting detector  (300 iterations wait)\n[14:25:35] bestTest = 13975.43298\n[14:25:35] bestIteration = 710\n[14:25:35] Shrink model to first 711 iterations.\n[14:25:35] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0005761795630568751, 'min_data_in_leaf': 14} scored -13975.433193108975 in 0:00:01.822332\n[14:25:35] 0:\tlearn: 53574.9082804\ttest: 57580.9633873\tbest: 57580.9633873 (0)\ttotal: 1.38ms\tremaining: 2.76s\n[14:25:37] Stopped by overfitting detector  (300 iterations wait)\n[14:25:37] bestTest = 13246.97613\n[14:25:37] bestIteration = 1033\n[14:25:37] Shrink model to first 1034 iterations.\n[14:25:37] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.037434557353000684, 'min_data_in_leaf': 15} scored -13246.975594284188 in 0:00:01.744346\n[14:25:37] 0:\tlearn: 53595.5584972\ttest: 57603.7006152\tbest: 57603.7006152 (0)\ttotal: 1.28ms\tremaining: 2.55s\n[14:25:38] Stopped by overfitting detector  (300 iterations wait)\n[14:25:38] bestTest = 13862.53246\n[14:25:38] bestIteration = 630\n[14:25:38] Shrink model to first 631 iterations.\n[14:25:38] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1985936043673706, 'min_data_in_leaf': 1} scored -13862.532385149572 in 0:00:01.284022\n[14:25:38] 0:\tlearn: 53574.9154290\ttest: 57580.9712917\tbest: 57580.9712917 (0)\ttotal: 1.32ms\tremaining: 2.64s\n[14:25:40] Stopped by overfitting detector  (300 iterations wait)\n[14:25:40] bestTest = 13129.37156\n[14:25:40] bestIteration = 1051\n[14:25:40] Shrink model to first 1052 iterations.\n[14:25:40] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.037823914847674084, 'min_data_in_leaf': 15} scored -13129.371661324787 in 0:00:01.824718\n[14:25:40] 0:\tlearn: 53575.2936663\ttest: 57581.3894837\tbest: 57581.3894837 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:25:42] Stopped by overfitting detector  (300 iterations wait)\n[14:25:42] bestTest = 13449.82163\n[14:25:42] bestIteration = 1038\n[14:25:42] Shrink model to first 1039 iterations.\n[14:25:42] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.058437751786408004, 'min_data_in_leaf': 16} scored -13449.821647970086 in 0:00:01.789840\n[14:25:42] 0:\tlearn: 53574.6995192\ttest: 57580.7325435\tbest: 57580.7325435 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:25:44] Stopped by overfitting detector  (300 iterations wait)\n[14:25:44] bestTest = 13268.09415\n[14:25:44] bestIteration = 975\n[14:25:44] Shrink model to first 976 iterations.\n[14:25:44] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.026067855370762612, 'min_data_in_leaf': 18} scored -13268.094417735043 in 0:00:01.699575\n[14:25:44] 0:\tlearn: 53167.8022504\ttest: 57184.8680212\tbest: 57184.8680212 (0)\ttotal: 3.43ms\tremaining: 6.85s\n[14:25:49] Stopped by overfitting detector  (300 iterations wait)\n[14:25:49] bestTest = 14707.63378\n[14:25:49] bestIteration = 1503\n[14:25:49] Shrink model to first 1504 iterations.\n[14:25:49] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.11460641347598241, 'min_data_in_leaf': 14} scored -14707.63391426282 in 0:00:05.485499\n[14:25:49] 0:\tlearn: 53574.7458739\ttest: 57580.7838034\tbest: 57580.7838034 (0)\ttotal: 1.31ms\tremaining: 2.63s\n[14:25:50] Stopped by overfitting detector  (300 iterations wait)\n[14:25:50] bestTest = 13412.64155\n[14:25:50] bestIteration = 618\n[14:25:50] Shrink model to first 619 iterations.\n[14:25:50] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.028591146219040433, 'min_data_in_leaf': 17} scored -13412.64155982906 in 0:00:01.273389\n[14:25:51] 0:\tlearn: 53583.1443064\ttest: 57590.0542459\tbest: 57590.0542459 (0)\ttotal: 1.37ms\tremaining: 2.74s\n[14:25:52] Stopped by overfitting detector  (300 iterations wait)\n[14:25:52] bestTest = 13518.25211\n[14:25:52] bestIteration = 630\n[14:25:52] Shrink model to first 631 iterations.\n[14:25:52] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.49181741449944416, 'min_data_in_leaf': 11} scored -13518.252053285256 in 0:00:01.344837\n[14:25:52] 0:\tlearn: 53195.5895648\ttest: 57152.8427933\tbest: 57152.8427933 (0)\ttotal: 1.71ms\tremaining: 3.43s\n[14:25:54] Stopped by overfitting detector  (300 iterations wait)\n[14:25:54] bestTest = 13896.22137\n[14:25:54] bestIteration = 1048\n[14:25:54] Shrink model to first 1049 iterations.\n[14:25:54] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.005882690229992188, 'min_data_in_leaf': 17} scored -13896.221103766025 in 0:00:02.589726\n[14:25:55] 0:\tlearn: 53574.2492122\ttest: 57580.2345315\tbest: 57580.2345315 (0)\ttotal: 1.4ms\tremaining: 2.79s\n[14:25:56] Stopped by overfitting detector  (300 iterations wait)\n[14:25:56] bestTest = 13549.57893\n[14:25:56] bestIteration = 986\n[14:25:56] Shrink model to first 987 iterations.\n[14:25:56] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001574770600000494, 'min_data_in_leaf': 13} scored -13549.578942975428 in 0:00:01.688421\n[14:25:56] 0:\tlearn: 53202.4261937\ttest: 57160.9828464\tbest: 57160.9828464 (0)\ttotal: 1.82ms\tremaining: 3.64s\n[14:25:58] Stopped by overfitting detector  (300 iterations wait)\n[14:25:58] bestTest = 14133.50936\n[14:25:58] bestIteration = 578\n[14:25:58] Shrink model to first 579 iterations.\n[14:25:58] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.2381441288190837, 'min_data_in_leaf': 3} scored -14133.509698851496 in 0:00:01.580966\n[14:25:58] 0:\tlearn: 53453.4733418\ttest: 57491.5157403\tbest: 57491.5157403 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[14:25:59] Stopped by overfitting detector  (300 iterations wait)\n[14:25:59] bestTest = 14305.55828\n[14:25:59] bestIteration = 743\n[14:25:59] Shrink model to first 744 iterations.\n[14:25:59] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0648712459530318, 'min_data_in_leaf': 15} scored -14305.557725694445 in 0:00:01.652402\n[14:25:59] 0:\tlearn: 53574.5875260\ttest: 57580.6086950\tbest: 57580.6086950 (0)\ttotal: 1.52ms\tremaining: 3.04s\n[14:26:01] Stopped by overfitting detector  (300 iterations wait)\n[14:26:01] bestTest = 13504.39803\n[14:26:01] bestIteration = 615\n[14:26:01] Shrink model to first 616 iterations.\n[14:26:01] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.019973082231601685, 'min_data_in_leaf': 18} scored -13504.39813701923 in 0:00:01.367586\n[14:26:01] 0:\tlearn: 53574.8458689\ttest: 57580.8943762\tbest: 57580.8943762 (0)\ttotal: 1.29ms\tremaining: 2.59s\n[14:26:03] Stopped by overfitting detector  (300 iterations wait)\n[14:26:03] bestTest = 13416.6071\n[14:26:03] bestIteration = 1435\n[14:26:03] Shrink model to first 1436 iterations.\n[14:26:03] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.03403557098753716, 'min_data_in_leaf': 18} scored -13416.60733840812 in 0:00:02.250684\n[14:26:03] 0:\tlearn: 53574.3941174\ttest: 57580.3947985\tbest: 57580.3947985 (0)\ttotal: 1.38ms\tremaining: 2.77s\n[14:26:04] Stopped by overfitting detector  (300 iterations wait)\n[14:26:04] bestTest = 13206.2658\n[14:26:04] bestIteration = 897\n[14:26:04] Shrink model to first 898 iterations.\n[14:26:05] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.009452665525735492, 'min_data_in_leaf': 19} scored -13206.265741853633 in 0:00:01.592854\n[14:26:05] 0:\tlearn: 53574.4224268\ttest: 57580.4261079\tbest: 57580.4261079 (0)\ttotal: 1.35ms\tremaining: 2.71s\n[14:26:06] Stopped by overfitting detector  (300 iterations wait)\n[14:26:06] bestTest = 13190.68921\n[14:26:06] bestIteration = 963\n[14:26:06] Shrink model to first 964 iterations.\n[14:26:06] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.010992148072536815, 'min_data_in_leaf': 20} scored -13190.68928619124 in 0:00:01.713979\n[14:26:06] 0:\tlearn: 53574.3660511\ttest: 57580.3637576\tbest: 57580.3637576 (0)\ttotal: 1.3ms\tremaining: 2.6s\n[14:26:08] Stopped by overfitting detector  (300 iterations wait)\n[14:26:08] bestTest = 13378.98919\n[14:26:08] bestIteration = 727\n[14:26:08] Shrink model to first 728 iterations.\n[14:26:08] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.007926536744786529, 'min_data_in_leaf': 19} scored -13378.988898904914 in 0:00:01.388588\n[14:26:08] 0:\tlearn: 53574.2202392\ttest: 57580.2024857\tbest: 57580.2024857 (0)\ttotal: 1.5ms\tremaining: 3.01s\n[14:26:09] Stopped by overfitting detector  (300 iterations wait)\n[14:26:09] bestTest = 13522.37794\n[14:26:09] bestIteration = 1004\n[14:26:09] Shrink model to first 1005 iterations.\n[14:26:09] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 5.840796733366603e-08, 'min_data_in_leaf': 20} scored -13522.377704326924 in 0:00:01.723028\n[14:26:10] 0:\tlearn: 53138.2656945\ttest: 57157.8202945\tbest: 57157.8202945 (0)\ttotal: 5.47ms\tremaining: 10.9s\n[14:26:12] Stopped by overfitting detector  (300 iterations wait)\n[14:26:12] bestTest = 14901.80465\n[14:26:12] bestIteration = 337\n[14:26:12] Shrink model to first 338 iterations.\n[14:26:12] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.011351670665587942, 'min_data_in_leaf': 19} scored -14901.804787660256 in 0:00:02.937012\n[14:26:13] 0:\tlearn: 53574.2327757\ttest: 57580.2163519\tbest: 57580.2163519 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[14:26:14] Stopped by overfitting detector  (300 iterations wait)\n[14:26:14] bestTest = 13522.5007\n[14:26:14] bestIteration = 1004\n[14:26:14] Shrink model to first 1005 iterations.\n[14:26:14] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006814143220049968, 'min_data_in_leaf': 20} scored -13522.500283787393 in 0:00:01.754363\n[14:26:15] 0:\tlearn: 53195.4598151\ttest: 57152.6873230\tbest: 57152.6873230 (0)\ttotal: 1.73ms\tremaining: 3.47s\n[14:26:17] Stopped by overfitting detector  (300 iterations wait)\n[14:26:17] bestTest = 14130.83526\n[14:26:17] bestIteration = 1475\n[14:26:17] Shrink model to first 1476 iterations.\n[14:26:17] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001525723368028297, 'min_data_in_leaf': 17} scored -14130.834568643162 in 0:00:03.258791\n[14:26:18] 0:\tlearn: 53156.1278294\ttest: 57176.8057882\tbest: 57176.8057882 (0)\ttotal: 3.17ms\tremaining: 6.34s\n[14:26:20] Stopped by overfitting detector  (300 iterations wait)\n[14:26:20] bestTest = 14786.49205\n[14:26:20] bestIteration = 465\n[14:26:20] Shrink model to first 466 iterations.\n[14:26:20] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 8.668646909495326e-05, 'min_data_in_leaf': 19} scored -14786.492304353633 in 0:00:02.411051\n[14:26:20] 0:\tlearn: 53575.5005900\ttest: 57581.6182365\tbest: 57581.6182365 (0)\ttotal: 1.36ms\tremaining: 2.73s\n[14:26:21] Stopped by overfitting detector  (300 iterations wait)\n[14:26:21] bestTest = 13560.88412\n[14:26:21] bestIteration = 618\n[14:26:21] Shrink model to first 619 iterations.\n[14:26:21] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0697254000308098, 'min_data_in_leaf': 16} scored -13560.884198050213 in 0:00:01.249172\n[14:26:21] 0:\tlearn: 53574.4687280\ttest: 57580.4773148\tbest: 57580.4773148 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:26:23] Stopped by overfitting detector  (300 iterations wait)\n[14:26:23] bestTest = 13245.97055\n[14:26:23] bestIteration = 1029\n[14:26:23] Shrink model to first 1030 iterations.\n[14:26:23] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.013510334354779729, 'min_data_in_leaf': 15} scored -13245.970486111111 in 0:00:01.797957\n[14:26:23] 0:\tlearn: 53574.4953177\ttest: 57580.5067213\tbest: 57580.5067213 (0)\ttotal: 1.32ms\tremaining: 2.65s\n[14:26:25] Stopped by overfitting detector  (300 iterations wait)\n[14:26:25] bestTest = 13235.39982\n[14:26:25] bestIteration = 1139\n[14:26:25] Shrink model to first 1140 iterations.\n[14:26:25] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.014956633828406252, 'min_data_in_leaf': 17} scored -13235.399889823719 in 0:00:01.895664\n[14:26:25] 0:\tlearn: 53574.3222527\ttest: 57580.3153165\tbest: 57580.3153165 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[14:26:26] Stopped by overfitting detector  (300 iterations wait)\n[14:26:26] bestTest = 13419.39462\n[14:26:26] bestIteration = 626\n[14:26:26] Shrink model to first 627 iterations.\n[14:26:26] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.005545228302780485, 'min_data_in_leaf': 18} scored -13419.394497863248 in 0:00:01.307103\n[14:26:26] 0:\tlearn: 53574.2668966\ttest: 57580.2540912\tbest: 57580.2540912 (0)\ttotal: 1.32ms\tremaining: 2.64s\n[14:26:28] Stopped by overfitting detector  (300 iterations wait)\n[14:26:28] bestTest = 13371.21995\n[14:26:28] bestIteration = 1004\n[14:26:28] Shrink model to first 1005 iterations.\n[14:26:28] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00253600247571211, 'min_data_in_leaf': 17} scored -13371.220269097223 in 0:00:01.715866\n[14:26:28] 0:\tlearn: 53453.9612287\ttest: 57492.2853962\tbest: 57492.2853962 (0)\ttotal: 1.33ms\tremaining: 2.67s\n[14:26:29] Stopped by overfitting detector  (300 iterations wait)\n[14:26:29] bestTest = 14337.36031\n[14:26:29] bestIteration = 605\n[14:26:29] Shrink model to first 606 iterations.\n[14:26:29] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.09500320522549686, 'min_data_in_leaf': 16} scored -14337.360543536324 in 0:00:01.266329\n[14:26:29] 0:\tlearn: 53578.4491648\ttest: 57584.8756513\tbest: 57584.8756513 (0)\ttotal: 1.27ms\tremaining: 2.53s\n[14:26:30] Stopped by overfitting detector  (300 iterations wait)\n[14:26:30] bestTest = 13499.21271\n[14:26:30] bestIteration = 600\n[14:26:30] Shrink model to first 601 iterations.\n[14:26:30] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.2313650278750046, 'min_data_in_leaf': 20} scored -13499.212556757479 in 0:00:01.237704\n[14:26:31] 0:\tlearn: 53574.5093529\ttest: 57580.5222432\tbest: 57580.5222432 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[14:26:32] Stopped by overfitting detector  (300 iterations wait)\n[14:26:32] bestTest = 13387.6527\n[14:26:32] bestIteration = 741\n[14:26:32] Shrink model to first 742 iterations.\n[14:26:32] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.01572010560977657, 'min_data_in_leaf': 19} scored -13387.652327056623 in 0:00:01.802517\n[14:26:32] 0:\tlearn: 53574.2273093\ttest: 57580.2103057\tbest: 57580.2103057 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[14:26:34] Stopped by overfitting detector  (300 iterations wait)\n[14:26:34] bestTest = 13522.98777\n[14:26:34] bestIteration = 1004\n[14:26:34] Shrink model to first 1005 iterations.\n[14:26:34] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00038431118661160657, 'min_data_in_leaf': 18} scored -13522.98798076923 in 0:00:01.758475\n[14:26:34] 0:\tlearn: 53195.4458435\ttest: 57152.6705795\tbest: 57152.6705795 (0)\ttotal: 1.69ms\tremaining: 3.38s\n[14:26:36] Stopped by overfitting detector  (300 iterations wait)\n[14:26:36] bestTest = 14483.18662\n[14:26:36] bestIteration = 846\n[14:26:36] Shrink model to first 847 iterations.\n[14:26:36] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001056673922413103, 'min_data_in_leaf': 16} scored -14483.186732104701 in 0:00:02.025801\n[14:26:36] 0:\tlearn: 53574.4723651\ttest: 57580.4813373\tbest: 57580.4813373 (0)\ttotal: 1.45ms\tremaining: 2.9s\n[14:26:38] Stopped by overfitting detector  (300 iterations wait)\n[14:26:38] bestTest = 13241.3365\n[14:26:38] bestIteration = 1166\n[14:26:38] Shrink model to first 1167 iterations.\n[14:26:38] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.013708160864427006, 'min_data_in_leaf': 15} scored -13241.33610443376 in 0:00:02.144577\n[14:26:38] 0:\tlearn: 53574.3009498\ttest: 57580.2917551\tbest: 57580.2917551 (0)\ttotal: 1.34ms\tremaining: 2.69s\n[14:26:40] Stopped by overfitting detector  (300 iterations wait)\n[14:26:40] bestTest = 13358.57432\n[14:26:40] bestIteration = 1004\n[14:26:40] Shrink model to first 1005 iterations.\n[14:26:40] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0043871180135594086, 'min_data_in_leaf': 17} scored -13358.57430221688 in 0:00:01.718799\n[14:26:40] 0:\tlearn: 53574.3515920\ttest: 57580.3477660\tbest: 57580.3477660 (0)\ttotal: 1.38ms\tremaining: 2.77s\n[14:26:42] bestTest = 13313.50727\n[14:26:42] bestIteration = 1920\n[14:26:42] Shrink model to first 1921 iterations.\n[14:26:42] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0071403638445760404, 'min_data_in_leaf': 14} scored -13313.506977831197 in 0:00:02.567686\n[14:26:43] 0:\tlearn: 53574.2699755\ttest: 57580.2574966\tbest: 57580.2574966 (0)\ttotal: 1.31ms\tremaining: 2.61s\n[14:26:44] Stopped by overfitting detector  (300 iterations wait)\n[14:26:44] bestTest = 13358.86251\n[14:26:44] bestIteration = 1004\n[14:26:44] Shrink model to first 1005 iterations.\n[14:26:44] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0027033657673631918, 'min_data_in_leaf': 12} scored -13358.863431490385 in 0:00:01.706374\n[14:26:44] 0:\tlearn: 53574.5216651\ttest: 57580.5358595\tbest: 57580.5358595 (0)\ttotal: 1.28ms\tremaining: 2.57s\n[14:26:46] Stopped by overfitting detector  (300 iterations wait)\n[14:26:46] bestTest = 13325.22727\n[14:26:46] bestIteration = 1013\n[14:26:46] Shrink model to first 1014 iterations.\n[14:26:46] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.01638987609282202, 'min_data_in_leaf': 16} scored -13325.226846287393 in 0:00:01.723687\n[14:26:46] 0:\tlearn: 53575.0624470\ttest: 57581.1338480\tbest: 57581.1338480 (0)\ttotal: 1.29ms\tremaining: 2.57s\n[14:26:47] Stopped by overfitting detector  (300 iterations wait)\n[14:26:47] bestTest = 13406.61563\n[14:26:47] bestIteration = 618\n[14:26:47] Shrink model to first 619 iterations.\n[14:26:47] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04583345344721052, 'min_data_in_leaf': 14} scored -13406.61548477564 in 0:00:01.266013\n[14:26:47] 0:\tlearn: 53574.3956769\ttest: 57580.3965233\tbest: 57580.3965233 (0)\ttotal: 1.32ms\tremaining: 2.63s\n[14:26:49] Stopped by overfitting detector  (300 iterations wait)\n[14:26:49] bestTest = 13206.27928\n[14:26:49] bestIteration = 897\n[14:26:49] Shrink model to first 898 iterations.\n[14:26:49] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.009537468856891659, 'min_data_in_leaf': 13} scored -13206.27984775641 in 0:00:01.597110\n[14:26:49] 0:\tlearn: 53452.5697970\ttest: 57490.0822270\tbest: 57490.0822270 (0)\ttotal: 1.33ms\tremaining: 2.65s\n[14:26:51] bestTest = 14141.09462\n[14:26:51] bestIteration = 1927\n[14:26:51] Shrink model to first 1928 iterations.\n[14:26:51] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00934888031092095, 'min_data_in_leaf': 13} scored -14141.094801682691 in 0:00:02.611367\n[14:26:52] 0:\tlearn: 53186.2329033\ttest: 57112.2279416\tbest: 57112.2279416 (0)\ttotal: 2.85ms\tremaining: 5.71s\n[14:26:54] Stopped by overfitting detector  (300 iterations wait)\n[14:26:54] bestTest = 14274.04804\n[14:26:54] bestIteration = 649\n[14:26:54] Shrink model to first 650 iterations.\n[14:26:54] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.02542801694801318, 'min_data_in_leaf': 18} scored -14274.047609508547 in 0:00:02.274326\n[14:26:54] 0:\tlearn: 53574.3022576\ttest: 57580.2932015\tbest: 57580.2932015 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[14:26:55] Stopped by overfitting detector  (300 iterations wait)\n[14:26:55] bestTest = 13358.58203\n[14:26:55] bestIteration = 1004\n[14:26:55] Shrink model to first 1005 iterations.\n[14:26:55] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.004458209088199782, 'min_data_in_leaf': 12} scored -13358.581697382479 in 0:00:01.750574\n[14:26:56] 0:\tlearn: 53575.0233856\ttest: 57581.0906592\tbest: 57581.0906592 (0)\ttotal: 1.81ms\tremaining: 3.62s\n[14:26:57] Stopped by overfitting detector  (300 iterations wait)\n[14:26:57] bestTest = 13452.26741\n[14:26:57] bestIteration = 621\n[14:26:57] Shrink model to first 622 iterations.\n[14:26:57] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04370502578642243, 'min_data_in_leaf': 15} scored -13452.267444577992 in 0:00:01.318694\n[14:26:57] 0:\tlearn: 53574.2561455\ttest: 57580.2422000\tbest: 57580.2422000 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[14:26:58] Stopped by overfitting detector  (300 iterations wait)\n[14:26:58] bestTest = 13476.03418\n[14:26:58] bestIteration = 593\n[14:26:58] Shrink model to first 594 iterations.\n[14:26:58] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0019516217891213299, 'min_data_in_leaf': 8} scored -13476.034588675213 in 0:00:01.246968\n[14:26:59] 0:\tlearn: 53574.5989129\ttest: 57580.6212876\tbest: 57580.6212876 (0)\ttotal: 1.44ms\tremaining: 2.88s\n[14:27:00] Stopped by overfitting detector  (300 iterations wait)\n[14:27:00] bestTest = 13429.91335\n[14:27:00] bestIteration = 1309\n[14:27:00] Shrink model to first 1310 iterations.\n[14:27:00] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.020592670543315816, 'min_data_in_leaf': 11} scored -13429.913428151709 in 0:00:02.361165\n[14:27:01] 0:\tlearn: 53574.3478448\ttest: 57580.3436215\tbest: 57580.3436215 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:27:03] Stopped by overfitting detector  (300 iterations wait)\n[14:27:03] bestTest = 13367.83053\n[14:27:03] bestIteration = 1555\n[14:27:03] Shrink model to first 1556 iterations.\n[14:27:03] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.006936622547777718, 'min_data_in_leaf': 15} scored -13367.830211672008 in 0:00:02.550582\n[14:27:03] 0:\tlearn: 53587.8379246\ttest: 57595.2213467\tbest: 57595.2213467 (0)\ttotal: 1.91ms\tremaining: 3.81s\n[14:27:05] Stopped by overfitting detector  (300 iterations wait)\n[14:27:05] bestTest = 13731.19369\n[14:27:05] bestIteration = 612\n[14:27:05] Shrink model to first 613 iterations.\n[14:27:05] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.7559479586540164, 'min_data_in_leaf': 16} scored -13731.19344284188 in 0:00:01.518182\n[14:27:05] 0:\tlearn: 53575.7979443\ttest: 57581.9469236\tbest: 57581.9469236 (0)\ttotal: 1.31ms\tremaining: 2.61s\n[14:27:06] Stopped by overfitting detector  (300 iterations wait)\n[14:27:06] bestTest = 13459.17635\n[14:27:06] bestIteration = 1029\n[14:27:06] Shrink model to first 1030 iterations.\n[14:27:06] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.08595884191193895, 'min_data_in_leaf': 17} scored -13459.176282051281 in 0:00:01.773593\n[14:27:07] 0:\tlearn: 53574.4025823\ttest: 57580.4041605\tbest: 57580.4041605 (0)\ttotal: 1.31ms\tremaining: 2.63s\n[14:27:08] Stopped by overfitting detector  (300 iterations wait)\n[14:27:08] bestTest = 13186.48244\n[14:27:08] bestIteration = 1047\n[14:27:08] Shrink model to first 1048 iterations.\n[14:27:08] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.009912976001509097, 'min_data_in_leaf': 14} scored -13186.48272235577 in 0:00:01.798536\n[14:27:08] 0:\tlearn: 53621.6599571\ttest: 57632.1912470\tbest: 57632.1912470 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[14:27:10] Stopped by overfitting detector  (300 iterations wait)\n[14:27:10] bestTest = 13784.33427\n[14:27:10] bestIteration = 1101\n[14:27:10] Shrink model to first 1102 iterations.\n[14:27:10] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 2.769436571036397, 'min_data_in_leaf': 13} scored -13784.33415130876 in 0:00:01.836869\n[14:27:10] 0:\tlearn: 53574.2378355\ttest: 57580.2219483\tbest: 57580.2219483 (0)\ttotal: 1.29ms\tremaining: 2.58s\n[14:27:12] Stopped by overfitting detector  (300 iterations wait)\n[14:27:12] bestTest = 13539.94658\n[14:27:12] bestIteration = 1004\n[14:27:12] Shrink model to first 1005 iterations.\n[14:27:12] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000956419028156934, 'min_data_in_leaf': 14} scored -13539.946764823719 in 0:00:01.810725\n[14:27:12] 0:\tlearn: 53574.2812323\ttest: 57580.2699471\tbest: 57580.2699471 (0)\ttotal: 1.82ms\tremaining: 3.63s\n[14:27:14] Stopped by overfitting detector  (300 iterations wait)\n[14:27:14] bestTest = 13358.97143\n[14:27:14] bestIteration = 1004\n[14:27:14] Shrink model to first 1005 iterations.\n[14:27:14] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0033152635301384433, 'min_data_in_leaf': 19} scored -13358.971971821582 in 0:00:01.751463\n[14:27:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[14:27:14] The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.037823914847674084, 'min_data_in_leaf': 15}\u001b[0m\n achieve -13129.3717 mae\n[14:27:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[14:27:14] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:27:14] 0:\tlearn: 54284.6538556\ttest: 58375.6651374\tbest: 58375.6651374 (0)\ttotal: 1.34ms\tremaining: 4.01s\n[14:27:15] Stopped by overfitting detector  (100 iterations wait)\n[14:27:15] bestTest = 13761.40102\n[14:27:15] bestIteration = 1193\n[14:27:15] Shrink model to first 1194 iterations.\n[14:27:15] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:27:15] 0:\tlearn: 54816.1183435\ttest: 57458.1203037\tbest: 57458.1203037 (0)\ttotal: 1.34ms\tremaining: 4.03s\n[14:27:17] Stopped by overfitting detector  (100 iterations wait)\n[14:27:17] bestTest = 15855.54499\n[14:27:17] bestIteration = 1275\n[14:27:17] Shrink model to first 1276 iterations.\n[14:27:17] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:27:17] 0:\tlearn: 54643.1221084\ttest: 55422.3940607\tbest: 55422.3940607 (0)\ttotal: 1.32ms\tremaining: 3.96s\n[14:27:18] Stopped by overfitting detector  (100 iterations wait)\n[14:27:18] bestTest = 15833.67928\n[14:27:18] bestIteration = 1033\n[14:27:18] Shrink model to first 1034 iterations.\n[14:27:18] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:27:18] 0:\tlearn: 56031.6585456\ttest: 52220.2681802\tbest: 52220.2681802 (0)\ttotal: 1.34ms\tremaining: 4.03s\n[14:27:21] Stopped by overfitting detector  (100 iterations wait)\n[14:27:21] bestTest = 14523.55135\n[14:27:21] bestIteration = 2130\n[14:27:21] Shrink model to first 2131 iterations.\n[14:27:21] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:27:21] 0:\tlearn: 55942.6136528\ttest: 52153.8746999\tbest: 52153.8746999 (0)\ttotal: 2.38ms\tremaining: 7.14s\n[14:27:22] Stopped by overfitting detector  (100 iterations wait)\n[14:27:22] bestTest = 14396.9425\n[14:27:22] bestIteration = 612\n[14:27:22] Shrink model to first 613 iterations.\n[14:27:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14874.932934904751\u001b[0m\n[14:27:22] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[14:27:22] Time left 5494.06 secs\n\n[14:27:22] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[14:27:22] Blending: optimization starts with equal weights and score \u001b[1m-14610.802563811001\u001b[0m\n[14:27:22] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14506.214041095891\u001b[0m, weights = \u001b[1m[0.15430091 0.10635176 0.         0.37518388 0.3641635 ]\u001b[0m\n[14:27:22] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14501.021109803081\u001b[0m, weights = \u001b[1m[0.12376779 0.14321007 0.         0.38196602 0.3510561 ]\u001b[0m\n[14:27:22] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14500.862779591182\u001b[0m, weights = \u001b[1m[0.12669611 0.14591232 0.         0.37903205 0.34835956]\u001b[0m\n[14:27:22] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14500.862522072988\u001b[0m, weights = \u001b[1m[0.12669724 0.14590469 0.         0.3790354  0.34836265]\u001b[0m\n[14:27:22] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14500.862522072988\u001b[0m, weights = \u001b[1m[0.12669724 0.14590469 0.         0.3790354  0.34836265]\u001b[0m\n[14:27:22] Blending: no score update. Terminated\n\n[14:27:22] \u001b[1mAutoml preset training completed in 506.05 seconds\u001b[0m\n\n[14:27:22] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.12670 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.14590 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.37904 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.34836 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[14:27:22] ==================================================\n[14:27:22] Start 1 automl preset configuration:\n[14:27:22] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n[14:27:22] Found reader_params in kwargs, need to combine\n[14:27:22] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 43, 'cv': 5}\n[14:27:22] Stdout logging level is INFO3.\n[14:27:22] Task: reg\n\n[14:27:22] Start automl preset with listed constraints:\n[14:27:22] - time: 5493.90 seconds\n[14:27:22] - CPU: 4 cores\n[14:27:22] - memory: 16 GB\n\n[14:27:22] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[14:27:29] Feats was rejected during automatic roles guess: []\n[14:27:29] Layer \u001b[1m1\u001b[0m train process start. Time left 5487.35 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:27:29] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[14:27:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:27:30] Linear model: C = 1e-05 score = -32770.709468482906\n[14:27:30] Linear model: C = 5e-05 score = -20395.560430021367\n[14:27:30] Linear model: C = 0.0001 score = -18589.711638621793\n[14:27:30] Linear model: C = 0.0005 score = -16828.47791466346\n[14:27:31] Linear model: C = 0.001 score = -16583.924946581195\n[14:27:31] Linear model: C = 0.005 score = -16540.10067775107\n[14:27:31] Linear model: C = 0.01 score = -16540.10067775107\n[14:27:31] Linear model: C = 0.05 score = -16540.10181290064\n[14:27:31] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:27:31] Linear model: C = 1e-05 score = -35534.608039529914\n[14:27:32] Linear model: C = 5e-05 score = -23190.812950721152\n[14:27:32] Linear model: C = 0.0001 score = -20309.769013755344\n[14:27:32] Linear model: C = 0.0005 score = -17049.6724603115\n[14:27:32] Linear model: C = 0.001 score = -16777.88167630709\n[14:27:32] Linear model: C = 0.005 score = -16777.879839514055\n[14:27:33] Linear model: C = 0.01 score = -16877.74873547676\n[14:27:33] Linear model: C = 0.05 score = -17816.278779380344\n[14:27:33] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:27:33] Linear model: C = 1e-05 score = -35341.298210470086\n[14:27:33] Linear model: C = 5e-05 score = -22732.689169337606\n[14:27:34] Linear model: C = 0.0001 score = -20367.29266826923\n[14:27:34] Linear model: C = 0.0005 score = -17461.983690571582\n[14:27:34] Linear model: C = 0.001 score = -17461.983690571582\n[14:27:34] Linear model: C = 0.005 score = -17461.986611912394\n[14:27:34] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:27:34] Linear model: C = 1e-05 score = -42654.2346097103\n[14:27:34] Linear model: C = 5e-05 score = -28460.523236319743\n[14:27:35] Linear model: C = 0.0001 score = -25215.950979077254\n[14:27:35] Linear model: C = 0.0005 score = -21313.208338921675\n[14:27:35] Linear model: C = 0.001 score = -20419.255348041846\n[14:27:35] Linear model: C = 0.005 score = -20419.255348041846\n[14:27:35] Linear model: C = 0.01 score = -20419.254208020386\n[14:27:37] Linear model: C = 0.05 score = -21539.14164766631\n[14:27:37] Linear model: C = 0.1 score = -21539.142016496782\n[14:27:37] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:27:37] Linear model: C = 1e-05 score = -35382.364404506436\n[14:27:37] Linear model: C = 5e-05 score = -23513.125201180257\n[14:27:37] Linear model: C = 0.0001 score = -21098.954030311157\n[14:27:38] Linear model: C = 0.0005 score = -18425.848041845493\n[14:27:38] Linear model: C = 0.001 score = -18233.93287285408\n[14:27:38] Linear model: C = 0.005 score = -18233.931548417382\n[14:27:38] Linear model: C = 0.01 score = -18379.656400885193\n[14:27:38] Linear model: C = 0.05 score = -19521.986370037554\n[14:27:38] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17884.164302982696\u001b[0m\n[14:27:38] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[14:27:38] Time left 5477.69 secs\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:27:39] Training until validation scores don't improve for 200 rounds\n[14:27:41] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[14:27:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[14:27:42] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:27:42] Training until validation scores don't improve for 200 rounds\n[14:27:44] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:27:44] Training until validation scores don't improve for 200 rounds\n[14:27:46] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:27:46] Training until validation scores don't improve for 200 rounds\n[14:27:48] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:27:48] Training until validation scores don't improve for 200 rounds\n[14:27:52] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:27:52] Training until validation scores don't improve for 200 rounds\n[14:27:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15756.337114726028\u001b[0m\n[14:27:54] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[14:27:54] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[14:27:54] Training until validation scores don't improve for 200 rounds\n[14:27:57] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -14807.862580128205 in 0:00:02.848711\n[14:27:57] Training until validation scores don't improve for 200 rounds\n[14:27:59] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -14558.554954594018 in 0:00:02.185959\n[14:27:59] Training until validation scores don't improve for 200 rounds\n[14:28:01] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -14616.091312767094 in 0:00:02.170050\n[14:28:01] Training until validation scores don't improve for 200 rounds\n[14:28:03] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -14768.24375667735 in 0:00:02.180547\n[14:28:03] Training until validation scores don't improve for 200 rounds\n[14:28:05] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -14534.765090811965 in 0:00:01.843172\n[14:28:05] Training until validation scores don't improve for 200 rounds\n[14:28:07] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -14309.886685363248 in 0:00:01.789719\n[14:28:07] Training until validation scores don't improve for 200 rounds\n[14:28:11] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -14821.72766426282 in 0:00:03.889601\n[14:28:11] Training until validation scores don't improve for 200 rounds\n[14:28:13] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -14299.935263087607 in 0:00:01.917037\n[14:28:13] Training until validation scores don't improve for 200 rounds\n[14:28:16] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15211.789930555555 in 0:00:03.177182\n[14:28:16] Training until validation scores don't improve for 200 rounds\n[14:28:18] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -14533.11531784188 in 0:00:01.767240\n[14:28:18] Training until validation scores don't improve for 200 rounds\n[14:28:19] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527} scored -14372.664463141025 in 0:00:01.850354\n[14:28:20] Training until validation scores don't improve for 200 rounds\n[14:28:22] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.9039431109063885, 'num_leaves': 121, 'bagging_fraction': 0.511126240123034, 'min_sum_hessian_in_leaf': 9.234443507663274, 'reg_alpha': 5.103027507670214, 'reg_lambda': 0.053277972058578184} scored -14641.803919604701 in 0:00:02.006423\n[14:28:22] Training until validation scores don't improve for 200 rounds\n[14:28:24] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 182, 'bagging_fraction': 0.6753019709216435, 'min_sum_hessian_in_leaf': 6.830673380118658, 'reg_alpha': 0.2573579784498118, 'reg_lambda': 0.020083559980881335} scored -14566.579493856838 in 0:00:02.049832\n[14:28:24] Training until validation scores don't improve for 200 rounds\n[14:28:26] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.8574118559379542, 'num_leaves': 115, 'bagging_fraction': 0.6778683866930582, 'min_sum_hessian_in_leaf': 1.762020252671106, 'reg_alpha': 4.548670779377984e-05, 'reg_lambda': 0.2946625004837124} scored -14652.335970886752 in 0:00:02.416392\n[14:28:26] Training until validation scores don't improve for 200 rounds\n[14:28:28] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.9734659535545915, 'num_leaves': 24, 'bagging_fraction': 0.6040480561972923, 'min_sum_hessian_in_leaf': 3.111980842995842, 'reg_alpha': 0.12307258184704516, 'reg_lambda': 0.002360156841828863} scored -14616.713575053418 in 0:00:02.398339\n[14:28:28] Training until validation scores don't improve for 200 rounds\n[14:28:30] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.6116958727112423, 'num_leaves': 156, 'bagging_fraction': 0.5127747474052715, 'min_sum_hessian_in_leaf': 0.3829729720068569, 'reg_alpha': 0.00029769294502556345, 'reg_lambda': 7.911959893594241e-06} scored -14442.185096153846 in 0:00:01.515107\n[14:28:30] Training until validation scores don't improve for 200 rounds\n[14:28:32] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.7903425434288254, 'num_leaves': 104, 'bagging_fraction': 0.730504187985871, 'min_sum_hessian_in_leaf': 3.2995575446337932, 'reg_alpha': 0.01932052301442315, 'reg_lambda': 9.94888334138137e-05} scored -14577.124432425213 in 0:00:02.161939\n[14:28:32] Training until validation scores don't improve for 200 rounds\n[14:28:34] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.8583557962540768, 'num_leaves': 181, 'bagging_fraction': 0.6148765375430065, 'min_sum_hessian_in_leaf': 0.03465743419765038, 'reg_alpha': 1.608772349877424e-05, 'reg_lambda': 0.002026402376936678} scored -14636.992087339744 in 0:00:02.035786\n[14:28:34] Training until validation scores don't improve for 200 rounds\n[14:28:36] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.56391216214132, 'num_leaves': 147, 'bagging_fraction': 0.5576105703757511, 'min_sum_hessian_in_leaf': 0.15802513584344455, 'reg_alpha': 0.00013737454587539895, 'reg_lambda': 0.22105914047644526} scored -14370.065337873932 in 0:00:01.673551\n[14:28:36] Training until validation scores don't improve for 200 rounds\n[14:28:38] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.6599362867984437, 'num_leaves': 82, 'bagging_fraction': 0.6548429730283009, 'min_sum_hessian_in_leaf': 0.49327279404801977, 'reg_alpha': 4.89032500302694e-07, 'reg_lambda': 8.197345997313042e-07} scored -14570.133847489316 in 0:00:01.992307\n[14:28:38] Training until validation scores don't improve for 200 rounds\n[14:28:42] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.8285726521637806, 'num_leaves': 185, 'bagging_fraction': 0.7224747406143589, 'min_sum_hessian_in_leaf': 1.0379492246260293, 'reg_alpha': 0.0018780797504261795, 'reg_lambda': 0.004247249175708189} scored -14592.444077190172 in 0:00:04.195016\n[14:28:42] Training until validation scores don't improve for 200 rounds\n[14:28:44] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5621243005829862, 'num_leaves': 150, 'bagging_fraction': 0.5559100847862147, 'min_sum_hessian_in_leaf': 0.15975854857247104, 'reg_alpha': 0.00012415396063510047, 'reg_lambda': 0.3127063911013714} scored -14349.123764690172 in 0:00:01.613195\n[14:28:44] Training until validation scores don't improve for 200 rounds\n[14:28:46] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.545944296895301, 'num_leaves': 207, 'bagging_fraction': 0.5576731058250861, 'min_sum_hessian_in_leaf': 0.014332912045937398, 'reg_alpha': 1.5949783981171654e-06, 'reg_lambda': 4.583696862999996} scored -14406.52250267094 in 0:00:02.167562\n[14:28:46] Training until validation scores don't improve for 200 rounds\n[14:28:48] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.5015608431085424, 'num_leaves': 131, 'bagging_fraction': 0.6281434427250049, 'min_sum_hessian_in_leaf': 0.09644452282656286, 'reg_alpha': 7.265259184516192e-05, 'reg_lambda': 0.2232633372412605} scored -14470.149105235043 in 0:00:01.729149\n[14:28:48] Training until validation scores don't improve for 200 rounds\n[14:28:49] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.6067126711416584, 'num_leaves': 96, 'bagging_fraction': 0.502131626930973, 'min_sum_hessian_in_leaf': 0.23125582887002397, 'reg_alpha': 0.016368247117553233, 'reg_lambda': 1.1544254127097269} scored -14442.225494123932 in 0:00:01.733278\n[14:28:49] Training until validation scores don't improve for 200 rounds\n[14:28:51] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.5812926964254653, 'num_leaves': 16, 'bagging_fraction': 0.5638828433696425, 'min_sum_hessian_in_leaf': 3.1330979395005367, 'reg_alpha': 0.0006222128971650054, 'reg_lambda': 0.049226309941907694} scored -14214.06670673077 in 0:00:01.463465\n[14:28:51] Training until validation scores don't improve for 200 rounds\n[14:28:53] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.641532355686778, 'num_leaves': 18, 'bagging_fraction': 0.6453114561513258, 'min_sum_hessian_in_leaf': 2.9927990921913863, 'reg_alpha': 0.9204823612429993, 'reg_lambda': 0.017905639811074944} scored -14621.814302884615 in 0:00:02.012466\n[14:28:53] Training until validation scores don't improve for 200 rounds\n[14:28:55] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.7447439543868675, 'num_leaves': 46, 'bagging_fraction': 0.5744083568270161, 'min_sum_hessian_in_leaf': 5.30692723223034, 'reg_alpha': 0.02620074033052668, 'reg_lambda': 7.134970648711683e-05} scored -14375.551315438035 in 0:00:01.893409\n[14:28:55] Training until validation scores don't improve for 200 rounds\n[14:28:56] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5796220576949027, 'num_leaves': 34, 'bagging_fraction': 0.5294710045907527, 'min_sum_hessian_in_leaf': 1.8173073516870142, 'reg_alpha': 0.0006827796790079165, 'reg_lambda': 0.08205719101649174} scored -14203.544003739316 in 0:00:01.602513\n[14:28:56] Training until validation scores don't improve for 200 rounds\n[14:28:59] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6917008694201543, 'num_leaves': 255, 'bagging_fraction': 0.9313235884212911, 'min_sum_hessian_in_leaf': 0.0013030133773607152, 'reg_alpha': 0.0012810785758707213, 'reg_lambda': 0.006649127501265266} scored -14816.947549412393 in 0:00:02.803706\n[14:28:59] Training until validation scores don't improve for 200 rounds\n[14:29:01] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5823043529418483, 'num_leaves': 36, 'bagging_fraction': 0.7181260263697475, 'min_sum_hessian_in_leaf': 0.7955110174517759, 'reg_alpha': 0.0005190774684305524, 'reg_lambda': 0.0005437955316995379} scored -14671.228532318377 in 0:00:01.959499\n[14:29:01] Training until validation scores don't improve for 200 rounds\n[14:29:03] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.6236869687397621, 'num_leaves': 56, 'bagging_fraction': 0.5286139372921727, 'min_sum_hessian_in_leaf': 1.9840442735453987, 'reg_alpha': 1.5074274937759915e-05, 'reg_lambda': 0.08270163017739991} scored -14358.300647702992 in 0:00:01.691324\n[14:29:03] Training until validation scores don't improve for 200 rounds\n[14:29:04] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.6808394488173629, 'num_leaves': 18, 'bagging_fraction': 0.5744292639102994, 'min_sum_hessian_in_leaf': 5.131764425278185, 'reg_alpha': 0.0070760021003865685, 'reg_lambda': 1.3039404094765001} scored -14417.01358840812 in 0:00:01.547758\n[14:29:04] Training until validation scores don't improve for 200 rounds\n[14:29:07] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5314839714647016, 'num_leaves': 66, 'bagging_fraction': 0.7753582018714796, 'min_sum_hessian_in_leaf': 0.3838184831883009, 'reg_alpha': 0.13101211886302097, 'reg_lambda': 3.0335197390900053} scored -14644.913728632479 in 0:00:02.251497\n[14:29:07] Training until validation scores don't improve for 200 rounds\n[14:29:08] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5686406010636814, 'num_leaves': 32, 'bagging_fraction': 0.5279565620091456, 'min_sum_hessian_in_leaf': 1.643536765874475, 'reg_alpha': 1.1037302968419513e-06, 'reg_lambda': 0.05835436042143973} scored -14249.415598290598 in 0:00:01.553526\n[14:29:08] Training until validation scores don't improve for 200 rounds\n[14:29:10] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5693149858435682, 'num_leaves': 31, 'bagging_fraction': 0.5843696995898392, 'min_sum_hessian_in_leaf': 0.6393927751840541, 'reg_alpha': 1.3145174842777787e-06, 'reg_lambda': 0.0561731033842224} scored -14347.807859241453 in 0:00:01.639827\n[14:29:10] Training until validation scores don't improve for 200 rounds\n[14:29:13] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.5367500976308146, 'num_leaves': 72, 'bagging_fraction': 0.6239986708705293, 'min_sum_hessian_in_leaf': 1.542352183583116, 'reg_alpha': 1.0671859924395377e-07, 'reg_lambda': 0.0008784118063152061} scored -14473.050848023504 in 0:00:03.432142\n[14:29:13] Training until validation scores don't improve for 200 rounds\n[14:29:15] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.5131207408825653, 'num_leaves': 44, 'bagging_fraction': 0.533238736589426, 'min_sum_hessian_in_leaf': 2.4786728534204476, 'reg_alpha': 7.100692480925044e-06, 'reg_lambda': 3.959375143012411e-07} scored -14124.250634348291 in 0:00:01.460130\n[14:29:15] Training until validation scores don't improve for 200 rounds\n[14:29:16] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.5875240868659167, 'num_leaves': 45, 'bagging_fraction': 0.5313579490534822, 'min_sum_hessian_in_leaf': 2.5471653178047093, 'reg_alpha': 2.1932159154744498e-05, 'reg_lambda': 2.9936787073789606e-08} scored -14179.038327991453 in 0:00:01.462830\n[14:29:16] Training until validation scores don't improve for 200 rounds\n[14:29:18] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.632763639701376, 'num_leaves': 47, 'bagging_fraction': 0.5004375539910199, 'min_sum_hessian_in_leaf': 3.0149350958489207, 'reg_alpha': 0.0004504892954060695, 'reg_lambda': 1.0886808766009548e-08} scored -14461.625667735043 in 0:00:01.517985\n[14:29:18] Training until validation scores don't improve for 200 rounds\n[14:29:20] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.6701985336132845, 'num_leaves': 79, 'bagging_fraction': 0.8824934599898315, 'min_sum_hessian_in_leaf': 9.666717290708089, 'reg_alpha': 3.603111203982749e-05, 'reg_lambda': 2.951293500697409e-07} scored -14837.27186832265 in 0:00:02.274719\n[14:29:20] Training until validation scores don't improve for 200 rounds\n[14:29:22] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5926082112010844, 'num_leaves': 43, 'bagging_fraction': 0.5375131836424517, 'min_sum_hessian_in_leaf': 2.138556981483536, 'reg_alpha': 2.806970345869133e-06, 'reg_lambda': 7.106162864567931e-08} scored -14267.939135950855 in 0:00:01.530837\n[14:29:22] Training until validation scores don't improve for 200 rounds\n[14:29:23] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5458797372564783, 'num_leaves': 32, 'bagging_fraction': 0.5251497807550235, 'min_sum_hessian_in_leaf': 1.1640690239967741, 'reg_alpha': 9.230567161045187e-06, 'reg_lambda': 7.266761453538328e-07} scored -14037.072783119658 in 0:00:01.493885\n[14:29:23] Training until validation scores don't improve for 200 rounds\n[14:29:25] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5487848315096822, 'num_leaves': 48, 'bagging_fraction': 0.5916113726898842, 'min_sum_hessian_in_leaf': 1.0781514628099038, 'reg_alpha': 7.277528729410607e-06, 'reg_lambda': 9.374304121832397e-07} scored -14308.43439503205 in 0:00:01.692756\n[14:29:25] Training until validation scores don't improve for 200 rounds\n[14:29:26] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.5024076824966371, 'num_leaves': 28, 'bagging_fraction': 0.5575098693058498, 'min_sum_hessian_in_leaf': 4.400427491887366, 'reg_alpha': 1.420246201737241e-05, 'reg_lambda': 1.2837759843212557e-07} scored -14347.609375 in 0:00:01.532382\n[14:29:26] Training until validation scores don't improve for 200 rounds\n[14:29:28] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.5230663818848045, 'num_leaves': 55, 'bagging_fraction': 0.5260998974391204, 'min_sum_hessian_in_leaf': 0.8437740674968955, 'reg_alpha': 0.00021351080161856705, 'reg_lambda': 2.1106332034283603e-06} scored -14139.797208867521 in 0:00:01.456090\n[14:29:28] Training until validation scores don't improve for 200 rounds\n[14:29:29] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.5223473058377552, 'num_leaves': 55, 'bagging_fraction': 0.5276611589636688, 'min_sum_hessian_in_leaf': 0.872133811117769, 'reg_alpha': 0.00018822543255176565, 'reg_lambda': 1.549776221440805e-06} scored -14123.76906383547 in 0:00:01.489906\n[14:29:29] Training until validation scores don't improve for 200 rounds\n[14:29:31] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.525084540498457, 'num_leaves': 94, 'bagging_fraction': 0.5967391904973347, 'min_sum_hessian_in_leaf': 0.7549678250930306, 'reg_alpha': 0.0001680309355412671, 'reg_lambda': 2.8388385823843067e-06} scored -14434.135950854701 in 0:00:01.838290\n[14:29:31] Training until validation scores don't improve for 200 rounds\n[14:29:33] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.5220613614454319, 'num_leaves': 58, 'bagging_fraction': 0.5263780042015708, 'min_sum_hessian_in_leaf': 0.2858415691806503, 'reg_alpha': 5.0907299561425245e-05, 'reg_lambda': 4.282918486601898e-08} scored -14134.507946047008 in 0:00:01.570793\n[14:29:33] Training until validation scores don't improve for 200 rounds\n[14:29:34] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.5233346743968339, 'num_leaves': 67, 'bagging_fraction': 0.5435174722786514, 'min_sum_hessian_in_leaf': 0.26911676301303317, 'reg_alpha': 4.3136728968230905e-06, 'reg_lambda': 4.531775685597552e-07} scored -14155.718416132479 in 0:00:01.510571\n[14:29:34] Training until validation scores don't improve for 200 rounds\n[14:29:36] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.5490306850498926, 'num_leaves': 58, 'bagging_fraction': 0.5118695481243514, 'min_sum_hessian_in_leaf': 0.2565478435716807, 'reg_alpha': 5.491137710071764e-05, 'reg_lambda': 2.4152600025120716e-06} scored -14288.385950854701 in 0:00:02.112875\n[14:29:36] Training until validation scores don't improve for 200 rounds\n[14:29:38] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.5177654660016782, 'num_leaves': 74, 'bagging_fraction': 0.548292860681018, 'min_sum_hessian_in_leaf': 0.24498057108216464, 'reg_alpha': 5.346164002896132e-06, 'reg_lambda': 4.360178086419232e-07} scored -14153.493022168803 in 0:00:01.516375\n[14:29:38] Training until validation scores don't improve for 200 rounds\n[14:29:39] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.5170288224368115, 'num_leaves': 73, 'bagging_fraction': 0.521040764448028, 'min_sum_hessian_in_leaf': 0.5597281697894185, 'reg_alpha': 4.589051873021363e-07, 'reg_lambda': 1.0312052800097427e-07} scored -14031.806757478633 in 0:00:01.436256\n[14:29:39] Training until validation scores don't improve for 200 rounds\n[14:29:41] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.5376353453735339, 'num_leaves': 56, 'bagging_fraction': 0.5168516828855994, 'min_sum_hessian_in_leaf': 0.6241983386955244, 'reg_alpha': 1.452982563776765e-07, 'reg_lambda': 9.672730550235806e-08} scored -14039.215211004273 in 0:00:01.495818\n[14:29:41] Training until validation scores don't improve for 200 rounds\n[14:29:42] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.5497706566633331, 'num_leaves': 93, 'bagging_fraction': 0.500292721505808, 'min_sum_hessian_in_leaf': 0.5230895422218307, 'reg_alpha': 6.342487812338424e-08, 'reg_lambda': 8.478316326890375e-08} scored -14432.223290598291 in 0:00:01.588835\n[14:29:43] Training until validation scores don't improve for 200 rounds\n[14:29:46] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5015997000147255, 'num_leaves': 107, 'bagging_fraction': 0.5787244045262859, 'min_sum_hessian_in_leaf': 0.137689952677812, 'reg_alpha': 3.1927809427503695e-07, 'reg_lambda': 3.1761485815075666e-08} scored -14418.493723290598 in 0:00:03.419100\n[14:29:46] Training until validation scores don't improve for 200 rounds\n[14:29:48] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.6076877235847358, 'num_leaves': 64, 'bagging_fraction': 0.6072958344322157, 'min_sum_hessian_in_leaf': 1.3429033408525175, 'reg_alpha': 1.499148613542966e-08, 'reg_lambda': 1.340049648067832e-07} scored -14495.557291666666 in 0:00:01.641527\n[14:29:48] Training until validation scores don't improve for 200 rounds\n[14:29:49] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.5379711499558487, 'num_leaves': 84, 'bagging_fraction': 0.5157827392027571, 'min_sum_hessian_in_leaf': 0.07997611372277884, 'reg_alpha': 3.933684359973407e-08, 'reg_lambda': 1.0645800280651669e-08} scored -13956.595753205129 in 0:00:01.475160\n[14:29:49] Training until validation scores don't improve for 200 rounds\n[14:29:52] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.5566781383030013, 'num_leaves': 87, 'bagging_fraction': 0.9932926902330947, 'min_sum_hessian_in_leaf': 0.05954269013583004, 'reg_alpha': 2.5170196978642633e-08, 'reg_lambda': 1.0680046304394334e-08} scored -14880.908787393162 in 0:00:03.014393\n[14:29:52] Training until validation scores don't improve for 200 rounds\n[14:29:54] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.5355821072454338, 'num_leaves': 74, 'bagging_fraction': 0.8181305925293505, 'min_sum_hessian_in_leaf': 0.04274875719573639, 'reg_alpha': 5.598290867220712e-07, 'reg_lambda': 1.3146311071959938e-05} scored -14759.401342147436 in 0:00:02.135784\n[14:29:54] Training until validation scores don't improve for 200 rounds\n[14:29:56] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.6204826595169504, 'num_leaves': 115, 'bagging_fraction': 0.5143674997075034, 'min_sum_hessian_in_leaf': 0.08518655643445745, 'reg_alpha': 6.711432044800528e-08, 'reg_lambda': 9.573804987702413e-07} scored -14288.38030849359 in 0:00:01.560021\n[14:29:56] Training until validation scores don't improve for 200 rounds\n[14:29:57] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.5152419697430335, 'num_leaves': 53, 'bagging_fraction': 0.5450234144609714, 'min_sum_hessian_in_leaf': 0.3516166083166337, 'reg_alpha': 2.601383798362193e-07, 'reg_lambda': 4.895635067132562e-08} scored -14202.76188568376 in 0:00:01.516952\n[14:29:57] Training until validation scores don't improve for 200 rounds\n[14:29:59] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5445127519123655, 'num_leaves': 40, 'bagging_fraction': 0.5211862979411783, 'min_sum_hessian_in_leaf': 0.4974273914343692, 'reg_alpha': 1.5059377980514383e-07, 'reg_lambda': 1.8345659249815678e-07} scored -14045.292534722223 in 0:00:01.460718\n[14:29:59] Training until validation scores don't improve for 200 rounds\n[14:30:01] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.5633181509573824, 'num_leaves': 40, 'bagging_fraction': 0.5639307058903231, 'min_sum_hessian_in_leaf': 0.5787494685970768, 'reg_alpha': 1.3278819816626594e-07, 'reg_lambda': 1.928371233384829e-07} scored -14242.502370459402 in 0:00:01.672899\n[14:30:01] Training until validation scores don't improve for 200 rounds\n[14:30:03] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.9690634132749897, 'num_leaves': 22, 'bagging_fraction': 0.515537022134129, 'min_sum_hessian_in_leaf': 0.017785726407441492, 'reg_alpha': 5.093776146351648e-08, 'reg_lambda': 1.826467932517778e-08} scored -14466.568977029914 in 0:00:02.152253\n[14:30:03] Training until validation scores don't improve for 200 rounds\n[14:30:04] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5384294848452005, 'num_leaves': 26, 'bagging_fraction': 0.5689750791214936, 'min_sum_hessian_in_leaf': 1.0170335776658463, 'reg_alpha': 2.78863920279078e-08, 'reg_lambda': 5.4423246114843444e-06} scored -14255.224192040598 in 0:00:01.637895\n[14:30:04] Training until validation scores don't improve for 200 rounds\n[14:30:06] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.5056499065860985, 'num_leaves': 81, 'bagging_fraction': 0.5163883755724074, 'min_sum_hessian_in_leaf': 0.19293182165569406, 'reg_alpha': 1.0482546978639071e-08, 'reg_lambda': 3.3961462641501717e-05} scored -14102.185129540598 in 0:00:01.446708\n[14:30:06] Training until validation scores don't improve for 200 rounds\n[14:30:07] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.5739080741603827, 'num_leaves': 83, 'bagging_fraction': 0.5153955790820463, 'min_sum_hessian_in_leaf': 0.1817811239994866, 'reg_alpha': 1.222378979759987e-08, 'reg_lambda': 1.3229349961914345e-06} scored -14210.24689503205 in 0:00:01.476341\n[14:30:07] Training until validation scores don't improve for 200 rounds\n[14:30:09] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.5993262120797317, 'num_leaves': 104, 'bagging_fraction': 0.5450461875879472, 'min_sum_hessian_in_leaf': 0.07283386705458833, 'reg_alpha': 1.6764996574424714e-07, 'reg_lambda': 2.124063573089396e-05} scored -14316.167901976496 in 0:00:01.633139\n[14:30:09] Training until validation scores don't improve for 200 rounds\n[14:30:11] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.5021428599310794, 'num_leaves': 133, 'bagging_fraction': 0.6559933326184464, 'min_sum_hessian_in_leaf': 0.11605738496271245, 'reg_alpha': 2.9524799119954143e-08, 'reg_lambda': 4.127742510854233e-05} scored -14325.027143429486 in 0:00:01.800047\n[14:30:11] Training until validation scores don't improve for 200 rounds\n[14:30:13] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.5448657881342219, 'num_leaves': 68, 'bagging_fraction': 0.5874452101850588, 'min_sum_hessian_in_leaf': 0.41673787378664634, 'reg_alpha': 5.845017548394141e-07, 'reg_lambda': 5.4317660793517725e-06} scored -14303.943342681623 in 0:00:01.778245\n[14:30:13] Training until validation scores don't improve for 200 rounds\n[14:30:14] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.5157434514466486, 'num_leaves': 37, 'bagging_fraction': 0.5015153426740954, 'min_sum_hessian_in_leaf': 0.1844896100590961, 'reg_alpha': 1.0684514819408486e-08, 'reg_lambda': 3.6173062602344115e-07} scored -14425.286057692309 in 0:00:01.571486\n[14:30:14] Training until validation scores don't improve for 200 rounds\n[14:30:17] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.5328965446352055, 'num_leaves': 51, 'bagging_fraction': 0.5386700844928921, 'min_sum_hessian_in_leaf': 1.0047544703139208, 'reg_alpha': 2.049367499127363e-06, 'reg_lambda': 2.213432487193956e-07} scored -14197.190204326924 in 0:00:03.141880\n[14:30:17] Training until validation scores don't improve for 200 rounds\n[14:30:19] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.5595307863511166, 'num_leaves': 63, 'bagging_fraction': 0.5248471206628851, 'min_sum_hessian_in_leaf': 0.5562878444908399, 'reg_alpha': 4.7530608303963495e-08, 'reg_lambda': 7.192324702009257e-08} scored -14108.759715544871 in 0:00:01.515774\n[14:30:19] Training until validation scores don't improve for 200 rounds\n[14:30:20] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.557155633089433, 'num_leaves': 88, 'bagging_fraction': 0.5555022275889222, 'min_sum_hessian_in_leaf': 0.6154307853098661, 'reg_alpha': 4.193793055516272e-08, 'reg_lambda': 0.0001952166133397249} scored -14327.245459401709 in 0:00:01.630048\n[14:30:21] Training until validation scores don't improve for 200 rounds\n[14:30:22] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.7168468894626762, 'num_leaves': 78, 'bagging_fraction': 0.5139282201031173, 'min_sum_hessian_in_leaf': 0.3506730604118606, 'reg_alpha': 1.8815226589833425e-07, 'reg_lambda': 8.29986975964581e-08} scored -14240.427450587607 in 0:00:01.699925\n[14:30:22] Training until validation scores don't improve for 200 rounds\n[14:30:24] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.574977483423472, 'num_leaves': 62, 'bagging_fraction': 0.5218336210712494, 'min_sum_hessian_in_leaf': 0.49691535916835966, 'reg_alpha': 8.72882742270551e-08, 'reg_lambda': 6.208083333192477e-07} scored -14299.960670405982 in 0:00:01.507340\n[14:30:24] Training until validation scores don't improve for 200 rounds\n[14:30:25] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.5319407892955988, 'num_leaves': 71, 'bagging_fraction': 0.5757123750482652, 'min_sum_hessian_in_leaf': 0.7884147425459379, 'reg_alpha': 7.311567713051792e-07, 'reg_lambda': 1.8348545036238036e-08} scored -14346.044905181623 in 0:00:01.604009\n[14:30:25] Training until validation scores don't improve for 200 rounds\n[14:30:27] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.5884216427944323, 'num_leaves': 165, 'bagging_fraction': 0.546553042810004, 'min_sum_hessian_in_leaf': 1.2367716159926436, 'reg_alpha': 3.088041761720787e-07, 'reg_lambda': 1.378669121706947e-07} scored -14142.437099358975 in 0:00:01.659524\n[14:30:27] Training until validation scores don't improve for 200 rounds\n[14:30:29] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.7647057119900891, 'num_leaves': 39, 'bagging_fraction': 0.5648731659434165, 'min_sum_hessian_in_leaf': 0.3353327039370521, 'reg_alpha': 2.3042655123951045e-08, 'reg_lambda': 5.840792690791857e-08} scored -14306.216813568377 in 0:00:01.634484\n[14:30:29] Training until validation scores don't improve for 200 rounds\n[14:30:32] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.560799544155425, 'num_leaves': 100, 'bagging_fraction': 0.9494999414808015, 'min_sum_hessian_in_leaf': 0.13401225827324834, 'reg_alpha': 1.0241555833499712e-07, 'reg_lambda': 2.4164922295064496e-08} scored -14739.96704727564 in 0:00:03.677667\n[14:30:32] Training until validation scores don't improve for 200 rounds\n[14:30:35] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.5103749316680379, 'num_leaves': 52, 'bagging_fraction': 0.5284195315453839, 'min_sum_hessian_in_leaf': 2.3280956171046783, 'reg_alpha': 8.954546045565813e-06, 'reg_lambda': 1.4406358962458572e-06} scored -14169.36889022436 in 0:00:02.107785\n[14:30:35] Training until validation scores don't improve for 200 rounds\n[14:30:37] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5380978869172142, 'num_leaves': 62, 'bagging_fraction': 0.5355007621013219, 'min_sum_hessian_in_leaf': 1.3848066854427505, 'reg_alpha': 9.097975692718997e-07, 'reg_lambda': 1.9087793436428496e-07} scored -14123.443476228633 in 0:00:02.272046\n[14:30:37] Training until validation scores don't improve for 200 rounds\n[14:30:40] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.5427654694101278, 'num_leaves': 66, 'bagging_fraction': 0.505948223699995, 'min_sum_hessian_in_leaf': 1.3777033983597775, 'reg_alpha': 2.605745023942781e-06, 'reg_lambda': 2.155958686611612e-07} scored -14314.77704326923 in 0:00:02.933290\n[14:30:40] Training until validation scores don't improve for 200 rounds\n[14:30:45] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.552577399839891, 'num_leaves': 79, 'bagging_fraction': 0.5200312826537644, 'min_sum_hessian_in_leaf': 0.9006917317197153, 'reg_alpha': 4.375535950917809e-08, 'reg_lambda': 9.902373081498702e-08} scored -14163.716279380342 in 0:00:05.649353\n[14:30:45] Training until validation scores don't improve for 200 rounds\n[14:30:47] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.5291666634929609, 'num_leaves': 61, 'bagging_fraction': 0.5351048037680349, 'min_sum_hessian_in_leaf': 0.6771622201640756, 'reg_alpha': 4.2832254822561595e-07, 'reg_lambda': 6.442532146105578e-07} scored -14151.239483173076 in 0:00:01.497727\n[14:30:47] Training until validation scores don't improve for 200 rounds\n[14:30:50] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.5000392302193996, 'num_leaves': 89, 'bagging_fraction': 0.5567919484999239, 'min_sum_hessian_in_leaf': 0.4518385004882277, 'reg_alpha': 1.0005290432528463e-06, 'reg_lambda': 5.1726212495509103e-08} scored -14258.097689636752 in 0:00:03.253720\n[14:30:50] Training until validation scores don't improve for 200 rounds\n[14:30:52] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.8260549482972521, 'num_leaves': 31, 'bagging_fraction': 0.7093198046338698, 'min_sum_hessian_in_leaf': 0.2177944652525344, 'reg_alpha': 1.9713799744119452e-07, 'reg_lambda': 2.4682019702152365e-07} scored -14524.581997863248 in 0:00:02.087352\n[14:30:52] Training until validation scores don't improve for 200 rounds\n[14:30:54] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.894176044326739, 'num_leaves': 47, 'bagging_fraction': 0.540525277070481, 'min_sum_hessian_in_leaf': 1.646158863724097, 'reg_alpha': 2.0216301768008228e-08, 'reg_lambda': 1.4188727672042278e-08} scored -14525.94220753205 in 0:00:01.859140\n[14:30:54] Training until validation scores don't improve for 200 rounds\n[14:30:56] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.5795293182033521, 'num_leaves': 59, 'bagging_fraction': 0.5102811599786105, 'min_sum_hessian_in_leaf': 4.116125612331418, 'reg_alpha': 8.166707063365696e-08, 'reg_lambda': 3.31704191712761e-08} scored -14237.046841613248 in 0:00:01.561189\n[14:30:56] Training until validation scores don't improve for 200 rounds\n[14:30:58] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.5671732865532617, 'num_leaves': 126, 'bagging_fraction': 0.6050803108032037, 'min_sum_hessian_in_leaf': 1.1367232401107474, 'reg_alpha': 4.2640702297090356e-08, 'reg_lambda': 9.457878898958828e-08} scored -14247.176315438035 in 0:00:01.815929\n[14:30:58] Training until validation scores don't improve for 200 rounds\n[14:30:59] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.5130710404218363, 'num_leaves': 44, 'bagging_fraction': 0.5313804275014228, 'min_sum_hessian_in_leaf': 0.630208416214291, 'reg_alpha': 9.450420828544047e-07, 'reg_lambda': 3.6798449735624263e-07} scored -14130.461304754273 in 0:00:01.532636\n[14:30:59] Training until validation scores don't improve for 200 rounds\n[14:31:01] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.5434164361261229, 'num_leaves': 75, 'bagging_fraction': 0.5216624543846555, 'min_sum_hessian_in_leaf': 0.7951645338560102, 'reg_alpha': 9.731666976269818, 'reg_lambda': 3.4554308489597943e-06} scored -14050.443075587607 in 0:00:01.546594\n[14:31:01] Training until validation scores don't improve for 200 rounds\n[14:31:02] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.5394875166163327, 'num_leaves': 76, 'bagging_fraction': 0.5509542708364643, 'min_sum_hessian_in_leaf': 0.49314785491327995, 'reg_alpha': 0.005018891826295874, 'reg_lambda': 5.23171430151395e-06} scored -14218.566339476496 in 0:00:01.710224\n[14:31:03] Training until validation scores don't improve for 200 rounds\n[14:31:04] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.5237382501242147, 'num_leaves': 70, 'bagging_fraction': 0.7685505336642675, 'min_sum_hessian_in_leaf': 0.3007537088890117, 'reg_alpha': 1.8950289142997556, 'reg_lambda': 3.3842674991909685e-06} scored -14672.36047676282 in 0:00:02.002633\n[14:31:05] Training until validation scores don't improve for 200 rounds\n[14:31:06] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.6003764509178686, 'num_leaves': 143, 'bagging_fraction': 0.5225110554375141, 'min_sum_hessian_in_leaf': 0.7758636130702659, 'reg_alpha': 0.33406173746927037, 'reg_lambda': 2.980443404455195e-05} scored -14230.234809027777 in 0:00:01.595863\n[14:31:06] Training until validation scores don't improve for 200 rounds\n[14:31:08] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.5541309761379822, 'num_leaves': 85, 'bagging_fraction': 0.5024757036765426, 'min_sum_hessian_in_leaf': 0.028193083690920415, 'reg_alpha': 1.2481304921608177e-07, 'reg_lambda': 1.0973302570445607e-05} scored -14420.43796741453 in 0:00:01.587629\n[14:31:08] Training until validation scores don't improve for 200 rounds\n[14:31:10] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.539168473749936, 'num_leaves': 55, 'bagging_fraction': 0.860621168004452, 'min_sum_hessian_in_leaf': 1.489833132181899, 'reg_alpha': 3.6427210457850924e-07, 'reg_lambda': 1.5309685638845116e-06} scored -14755.672375801281 in 0:00:02.122027\n[14:31:10] Training until validation scores don't improve for 200 rounds\n[14:31:12] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.5235824219540258, 'num_leaves': 22, 'bagging_fraction': 0.5687040364556375, 'min_sum_hessian_in_leaf': 0.008050338602213986, 'reg_alpha': 1.5366951090100882e-08, 'reg_lambda': 6.552883576410088e-07} scored -14304.071047008547 in 0:00:01.722630\n[14:31:12] Training until validation scores don't improve for 200 rounds\n[14:31:13] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.5693231317497689, 'num_leaves': 111, 'bagging_fraction': 0.5177503188848129, 'min_sum_hessian_in_leaf': 2.0013390255991736, 'reg_alpha': 8.410005541826055e-05, 'reg_lambda': 7.760331643898929e-05} scored -14112.991786858975 in 0:00:01.552659\n[14:31:13] Training until validation scores don't improve for 200 rounds\n[14:31:15] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.5703677998086206, 'num_leaves': 98, 'bagging_fraction': 0.5188553199720013, 'min_sum_hessian_in_leaf': 0.040765795032605266, 'reg_alpha': 3.426667751950841e-05, 'reg_lambda': 0.0001391933811693456} scored -14313.023504273504 in 0:00:01.518496\n[14:31:15] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[14:31:15] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5379711499558487, 'num_leaves': 84, 'bagging_fraction': 0.5157827392027571, 'min_sum_hessian_in_leaf': 0.07997611372277884, 'reg_alpha': 3.933684359973407e-08, 'reg_lambda': 1.0645800280651669e-08}\u001b[0m\n achieve -13956.5958 mae\n[14:31:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[14:31:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:31:15] Training until validation scores don't improve for 100 rounds\n[14:31:15] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:31:15] Training until validation scores don't improve for 100 rounds\n[14:31:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:31:16] Training until validation scores don't improve for 100 rounds\n[14:31:16] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:31:16] Training until validation scores don't improve for 100 rounds\n[14:31:17] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:31:17] Training until validation scores don't improve for 100 rounds\n[14:31:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15726.384063302654\u001b[0m\n[14:31:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[14:31:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[14:31:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:31:17] 0:\tlearn: 55023.2185987\ttest: 50588.8982268\tbest: 50588.8982268 (0)\ttotal: 2.81ms\tremaining: 5.61s\n[14:31:19] Stopped by overfitting detector  (300 iterations wait)\n[14:31:19] bestTest = 14201.36186\n[14:31:19] bestIteration = 571\n[14:31:19] Shrink model to first 572 iterations.\n[14:31:19] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:31:19] 0:\tlearn: 54642.1709838\ttest: 52558.7405701\tbest: 52558.7405701 (0)\ttotal: 3.4ms\tremaining: 6.8s\n[14:31:22] Stopped by overfitting detector  (300 iterations wait)\n[14:31:22] bestTest = 13937.25655\n[14:31:22] bestIteration = 774\n[14:31:22] Shrink model to first 775 iterations.\n[14:31:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:31:22] 0:\tlearn: 54685.4600370\ttest: 53490.1040743\tbest: 53490.1040743 (0)\ttotal: 2.72ms\tremaining: 5.44s\n[14:31:23] Stopped by overfitting detector  (300 iterations wait)\n[14:31:23] bestTest = 15911.92556\n[14:31:23] bestIteration = 577\n[14:31:23] Shrink model to first 578 iterations.\n[14:31:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:31:24] 0:\tlearn: 52751.8352615\ttest: 60978.8409682\tbest: 60978.8409682 (0)\ttotal: 2.53ms\tremaining: 5.06s\n[14:31:25] Stopped by overfitting detector  (300 iterations wait)\n[14:31:25] bestTest = 17657.31731\n[14:31:25] bestIteration = 367\n[14:31:25] Shrink model to first 368 iterations.\n[14:31:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:31:25] 0:\tlearn: 54364.1003679\ttest: 53892.9845447\tbest: 53892.9845447 (0)\ttotal: 2.27ms\tremaining: 4.53s\n[14:31:27] Stopped by overfitting detector  (300 iterations wait)\n[14:31:27] bestTest = 15139.51427\n[14:31:27] bestIteration = 690\n[14:31:27] Shrink model to first 691 iterations.\n[14:31:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15367.713201653467\u001b[0m\n[14:31:27] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[14:31:27] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[14:31:27] 0:\tlearn: 55290.6493333\ttest: 50825.2066951\tbest: 50825.2066951 (0)\ttotal: 1.92ms\tremaining: 3.84s\n[14:31:30] Stopped by overfitting detector  (300 iterations wait)\n[14:31:30] bestTest = 14175.29723\n[14:31:30] bestIteration = 1402\n[14:31:30] Shrink model to first 1403 iterations.\n[14:31:30] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -14175.297559428418 in 0:00:02.662652\n[14:31:30] 0:\tlearn: 55583.8211400\ttest: 51206.6370650\tbest: 51206.6370650 (0)\ttotal: 1.7ms\tremaining: 3.4s\n[14:31:31] Stopped by overfitting detector  (300 iterations wait)\n[14:31:31] bestTest = 14053.49028\n[14:31:31] bestIteration = 1227\n[14:31:31] Shrink model to first 1228 iterations.\n[14:31:31] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -14053.490501469018 in 0:00:01.849021\n[14:31:32] 0:\tlearn: 55583.7672076\ttest: 51206.5810908\tbest: 51206.5810908 (0)\ttotal: 1.34ms\tremaining: 2.68s\n[14:31:34] bestTest = 13657.26296\n[14:31:34] bestIteration = 1777\n[14:31:34] Shrink model to first 1778 iterations.\n[14:31:34] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -13675.229967948719 in 0:00:02.343863\n[14:31:34] 0:\tlearn: 55583.7688103\ttest: 51206.5827542\tbest: 51206.5827542 (0)\ttotal: 1.2ms\tremaining: 2.4s\n[14:31:35] Stopped by overfitting detector  (300 iterations wait)\n[14:31:35] bestTest = 14006.14707\n[14:31:35] bestIteration = 658\n[14:31:35] Shrink model to first 659 iterations.\n[14:31:35] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -14006.14750267094 in 0:00:01.200810\n[14:31:35] 0:\tlearn: 55020.9372513\ttest: 50617.3511113\tbest: 50617.3511113 (0)\ttotal: 3.94ms\tremaining: 7.88s\n[14:31:38] Stopped by overfitting detector  (300 iterations wait)\n[14:31:38] bestTest = 13676.35864\n[14:31:38] bestIteration = 705\n[14:31:38] Shrink model to first 706 iterations.\n[14:31:38] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -13676.35835670406 in 0:00:02.906347\n[14:31:38] 0:\tlearn: 55021.1355059\ttest: 50617.5184158\tbest: 50617.5184158 (0)\ttotal: 3.51ms\tremaining: 7.01s\n[14:31:41] Stopped by overfitting detector  (300 iterations wait)\n[14:31:41] bestTest = 13630.60457\n[14:31:41] bestIteration = 811\n[14:31:41] Shrink model to first 812 iterations.\n[14:31:41] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -13630.60466746795 in 0:00:03.171971\n[14:31:41] 0:\tlearn: 55223.3832261\ttest: 50803.2379996\tbest: 50803.2379996 (0)\ttotal: 5.79ms\tremaining: 11.6s\n[14:31:44] Stopped by overfitting detector  (300 iterations wait)\n[14:31:44] bestTest = 14299.77671\n[14:31:44] bestIteration = 755\n[14:31:44] Shrink model to first 756 iterations.\n[14:31:44] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -14306.10164596688 in 0:00:03.055910\n[14:31:44] 0:\tlearn: 54990.1024602\ttest: 50544.1760088\tbest: 50544.1760088 (0)\ttotal: 4.9ms\tremaining: 9.8s\n[14:31:47] Stopped by overfitting detector  (300 iterations wait)\n[14:31:47] bestTest = 14578.63312\n[14:31:47] bestIteration = 378\n[14:31:47] Shrink model to first 379 iterations.\n[14:31:47] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -14611.984274839744 in 0:00:02.850437\n[14:31:47] 0:\tlearn: 55614.8374030\ttest: 51238.5675802\tbest: 51238.5675802 (0)\ttotal: 1.23ms\tremaining: 2.46s\n[14:31:49] Stopped by overfitting detector  (300 iterations wait)\n[14:31:49] bestTest = 13763.63646\n[14:31:49] bestIteration = 1627\n[14:31:49] Shrink model to first 1628 iterations.\n[14:31:49] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -13782.421457665598 in 0:00:02.217239\n[14:31:49] 0:\tlearn: 55021.0130416\ttest: 50617.4150571\tbest: 50617.4150571 (0)\ttotal: 3.18ms\tremaining: 6.36s\n[14:31:53] Stopped by overfitting detector  (300 iterations wait)\n[14:31:53] bestTest = 13662.15115\n[14:31:53] bestIteration = 940\n[14:31:53] Shrink model to first 941 iterations.\n[14:31:53] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -13662.151141826924 in 0:00:03.773181\n[14:31:53] 0:\tlearn: 55022.6685374\ttest: 50588.5317435\tbest: 50588.5317435 (0)\ttotal: 2.85ms\tremaining: 5.7s\n[14:31:56] Stopped by overfitting detector  (300 iterations wait)\n[14:31:56] bestTest = 14187.51789\n[14:31:56] bestIteration = 876\n[14:31:56] Shrink model to first 877 iterations.\n[14:31:56] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 1} scored -14187.51842948718 in 0:00:02.911457\n[14:31:56] 0:\tlearn: 55025.0450737\ttest: 50620.8388175\tbest: 50620.8388175 (0)\ttotal: 2.98ms\tremaining: 5.96s\n[14:31:59] Stopped by overfitting detector  (300 iterations wait)\n[14:31:59] bestTest = 14173.02998\n[14:31:59] bestIteration = 700\n[14:31:59] Shrink model to first 701 iterations.\n[14:31:59] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.044622880406566943, 'min_data_in_leaf': 1} scored -14173.029797676281 in 0:00:02.894573\n[14:31:59] 0:\tlearn: 54987.7154627\ttest: 50541.4552482\tbest: 50541.4552482 (0)\ttotal: 4.37ms\tremaining: 8.74s\n[14:32:03] Stopped by overfitting detector  (300 iterations wait)\n[14:32:03] bestTest = 14841.42437\n[14:32:03] bestIteration = 630\n[14:32:03] Shrink model to first 631 iterations.\n[14:32:03] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 4.555280480305051e-06, 'min_data_in_leaf': 1} scored -14841.424111912393 in 0:00:03.926432\n[14:32:03] 0:\tlearn: 55031.4982264\ttest: 50594.7609898\tbest: 50594.7609898 (0)\ttotal: 2.13ms\tremaining: 4.27s\n[14:32:05] Stopped by overfitting detector  (300 iterations wait)\n[14:32:05] bestTest = 13976.88181\n[14:32:05] bestIteration = 663\n[14:32:05] Shrink model to first 664 iterations.\n[14:32:05] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.16505863700695908, 'min_data_in_leaf': 14} scored -13976.881760817309 in 0:00:02.064905\n[14:32:05] 0:\tlearn: 55020.9929076\ttest: 50617.3980681\tbest: 50617.3980681 (0)\ttotal: 3.09ms\tremaining: 6.18s\n[14:32:08] Stopped by overfitting detector  (300 iterations wait)\n[14:32:08] bestTest = 13676.22907\n[14:32:08] bestIteration = 705\n[14:32:08] Shrink model to first 706 iterations.\n[14:32:08] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006165844312481064, 'min_data_in_leaf': 5} scored -13676.229550614316 in 0:00:02.913916\n[14:32:08] 0:\tlearn: 54987.7423000\ttest: 50541.4858895\tbest: 50541.4858895 (0)\ttotal: 4.22ms\tremaining: 8.44s\n[14:32:10] Stopped by overfitting detector  (300 iterations wait)\n[14:32:10] bestTest = 14984.40286\n[14:32:10] bestIteration = 270\n[14:32:10] Shrink model to first 271 iterations.\n[14:32:10] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0001653282123997984, 'min_data_in_leaf': 8} scored -14984.402844551281 in 0:00:02.429969\n[14:32:10] 0:\tlearn: 55022.6685505\ttest: 50588.5317522\tbest: 50588.5317522 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[14:32:13] Stopped by overfitting detector  (300 iterations wait)\n[14:32:13] bestTest = 14187.51778\n[14:32:13] bestIteration = 876\n[14:32:13] Shrink model to first 877 iterations.\n[14:32:13] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.484727505872848e-07, 'min_data_in_leaf': 13} scored -14187.518162393162 in 0:00:02.525192\n[14:32:13] 0:\tlearn: 55296.5260534\ttest: 50828.3986135\tbest: 50828.3986135 (0)\ttotal: 1.59ms\tremaining: 3.17s\n[14:32:15] Stopped by overfitting detector  (300 iterations wait)\n[14:32:15] bestTest = 14028.09365\n[14:32:15] bestIteration = 1097\n[14:32:15] Shrink model to first 1098 iterations.\n[14:32:15] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1948476396837376, 'min_data_in_leaf': 3} scored -14028.093382745727 in 0:00:02.217231\n[14:32:15] 0:\tlearn: 55021.1725950\ttest: 50617.5497267\tbest: 50617.5497267 (0)\ttotal: 2.95ms\tremaining: 5.9s\n[14:32:17] Stopped by overfitting detector  (300 iterations wait)\n[14:32:17] bestTest = 13980.81417\n[14:32:17] bestIteration = 370\n[14:32:17] Shrink model to first 371 iterations.\n[14:32:17] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0025446490101466734, 'min_data_in_leaf': 7} scored -13980.814169337607 in 0:00:01.998875\n[14:32:17] 0:\tlearn: 55290.5739375\ttest: 50825.1711611\tbest: 50825.1711611 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[14:32:19] Stopped by overfitting detector  (300 iterations wait)\n[14:32:19] bestTest = 14062.76573\n[14:32:19] bestIteration = 1247\n[14:32:19] Shrink model to first 1248 iterations.\n[14:32:19] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 2.7058862922603515e-05, 'min_data_in_leaf': 3} scored -14062.765424679486 in 0:00:02.431622\n[14:32:20] 0:\tlearn: 55023.3775161\ttest: 50589.0046953\tbest: 50589.0046953 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[14:32:22] Stopped by overfitting detector  (300 iterations wait)\n[14:32:22] bestTest = 13965.96981\n[14:32:22] bestIteration = 659\n[14:32:22] Shrink model to first 660 iterations.\n[14:32:22] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.012896420485192985, 'min_data_in_leaf': 12} scored -13965.96985176282 in 0:00:02.144270\n[14:32:22] 0:\tlearn: 55020.9355140\ttest: 50617.3496457\tbest: 50617.3496457 (0)\ttotal: 2.87ms\tremaining: 5.73s\n[14:32:24] Stopped by overfitting detector  (300 iterations wait)\n[14:32:24] bestTest = 13963.24594\n[14:32:24] bestIteration = 701\n[14:32:24] Shrink model to first 702 iterations.\n[14:32:24] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2026466315006702e-06, 'min_data_in_leaf': 3} scored -13963.246043669871 in 0:00:02.881523\n[14:32:25] 0:\tlearn: 55022.6685525\ttest: 50588.5317535\tbest: 50588.5317535 (0)\ttotal: 2.52ms\tremaining: 5.04s\n[14:32:27] Stopped by overfitting detector  (300 iterations wait)\n[14:32:27] bestTest = 13968.93676\n[14:32:27] bestIteration = 871\n[14:32:27] Shrink model to first 872 iterations.\n[14:32:27] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.852196860818722e-07, 'min_data_in_leaf': 4} scored -13968.936314770299 in 0:00:02.934062\n[14:32:28] 0:\tlearn: 54987.7147080\ttest: 50541.4543864\tbest: 50541.4543864 (0)\ttotal: 4.29ms\tremaining: 8.59s\n[14:32:31] Stopped by overfitting detector  (300 iterations wait)\n[14:32:31] bestTest = 14521.15332\n[14:32:31] bestIteration = 485\n[14:32:31] Shrink model to first 486 iterations.\n[14:32:31] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.436463237819878e-08, 'min_data_in_leaf': 17} scored -14554.312550080129 in 0:00:03.917654\n[14:32:32] 0:\tlearn: 55290.5850193\ttest: 50825.1763741\tbest: 50825.1763741 (0)\ttotal: 1.93ms\tremaining: 3.85s\n[14:32:34] Stopped by overfitting detector  (300 iterations wait)\n[14:32:34] bestTest = 14115.47966\n[14:32:34] bestIteration = 1336\n[14:32:34] Shrink model to first 1337 iterations.\n[14:32:34] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0003820689506819156, 'min_data_in_leaf': 2} scored -14115.479350293803 in 0:00:02.836869\n[14:32:35] 0:\tlearn: 55020.9361702\ttest: 50617.3501993\tbest: 50617.3501993 (0)\ttotal: 2.96ms\tremaining: 5.93s\n[14:32:37] Stopped by overfitting detector  (300 iterations wait)\n[14:32:37] bestTest = 13963.24319\n[14:32:37] bestIteration = 701\n[14:32:37] Shrink model to first 702 iterations.\n[14:32:37] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 8.236831985358842e-06, 'min_data_in_leaf': 5} scored -13963.243522970086 in 0:00:03.146980\n[14:32:37] 0:\tlearn: 55022.6686085\ttest: 50588.5317907\tbest: 50588.5317907 (0)\ttotal: 2.11ms\tremaining: 4.21s\n[14:32:40] Stopped by overfitting detector  (300 iterations wait)\n[14:32:40] bestTest = 13968.93677\n[14:32:40] bestIteration = 871\n[14:32:40] Shrink model to first 872 iterations.\n[14:32:40] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.301639788596718e-06, 'min_data_in_leaf': 7} scored -13968.936381543803 in 0:00:02.499017\n[14:32:40] 0:\tlearn: 54987.9062291\ttest: 50541.6730288\tbest: 50541.6730288 (0)\ttotal: 4.17ms\tremaining: 8.33s\n[14:32:46] Stopped by overfitting detector  (300 iterations wait)\n[14:32:46] bestTest = 14959.03237\n[14:32:46] bestIteration = 1169\n[14:32:46] Shrink model to first 1170 iterations.\n[14:32:46] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0011478504688945974, 'min_data_in_leaf': 2} scored -14959.032251602564 in 0:00:06.079274\n[14:32:46] 0:\tlearn: 55020.9465941\ttest: 50617.3589932\tbest: 50617.3589932 (0)\ttotal: 3.04ms\tremaining: 6.09s\n[14:32:48] Stopped by overfitting detector  (300 iterations wait)\n[14:32:48] bestTest = 14238.38834\n[14:32:48] bestIteration = 473\n[14:32:48] Shrink model to first 474 iterations.\n[14:32:48] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00011998760863771788, 'min_data_in_leaf': 10} scored -14238.388621794871 in 0:00:02.308045\n[14:32:48] 0:\tlearn: 55290.8074866\ttest: 50825.2817417\tbest: 50825.2817417 (0)\ttotal: 1.78ms\tremaining: 3.55s\n[14:32:51] Stopped by overfitting detector  (300 iterations wait)\n[14:32:51] bestTest = 14242.87641\n[14:32:51] bestIteration = 1610\n[14:32:51] Shrink model to first 1611 iterations.\n[14:32:51] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007515571723249176, 'min_data_in_leaf': 4} scored -14242.87670272436 in 0:00:03.001024\n[14:32:51] 0:\tlearn: 55585.9343035\ttest: 51208.8287679\tbest: 51208.8287679 (0)\ttotal: 1.24ms\tremaining: 2.47s\n[14:32:53] Stopped by overfitting detector  (300 iterations wait)\n[14:32:53] bestTest = 14046.9231\n[14:32:53] bestIteration = 1457\n[14:32:53] Shrink model to first 1458 iterations.\n[14:32:53] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.103479380677169, 'min_data_in_leaf': 5} scored -14046.922776442309 in 0:00:02.097340\n[14:32:54] 0:\tlearn: 55021.0000458\ttest: 50617.4040911\tbest: 50617.4040911 (0)\ttotal: 2.87ms\tremaining: 5.73s\n[14:32:56] Stopped by overfitting detector  (300 iterations wait)\n[14:32:56] bestTest = 13676.21246\n[14:32:56] bestIteration = 705\n[14:32:56] Shrink model to first 706 iterations.\n[14:32:56] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006931361076802233, 'min_data_in_leaf': 5} scored -13676.213090945514 in 0:00:02.909139\n[14:32:56] 0:\tlearn: 55021.2118124\ttest: 50617.5828384\tbest: 50617.5828384 (0)\ttotal: 2.87ms\tremaining: 5.73s\n[14:32:59] Stopped by overfitting detector  (300 iterations wait)\n[14:32:59] bestTest = 13795.2183\n[14:32:59] bestIteration = 430\n[14:32:59] Shrink model to first 431 iterations.\n[14:32:59] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0029657438066196078, 'min_data_in_leaf': 3} scored -13795.218299278846 in 0:00:02.660881\n[14:32:59] 0:\tlearn: 55022.6709289\ttest: 50588.5333300\tbest: 50588.5333300 (0)\ttotal: 2.24ms\tremaining: 4.48s\n[14:33:01] Stopped by overfitting detector  (300 iterations wait)\n[14:33:01] bestTest = 14187.49903\n[14:33:01] bestIteration = 876\n[14:33:01] Shrink model to first 877 iterations.\n[14:33:01] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 4.340290398807059e-05, 'min_data_in_leaf': 6} scored -14187.499298878205 in 0:00:02.560692\n[14:33:02] 0:\tlearn: 55020.9680337\ttest: 50617.3770811\tbest: 50617.3770811 (0)\ttotal: 3.38ms\tremaining: 6.76s\n[14:33:04] Stopped by overfitting detector  (300 iterations wait)\n[14:33:04] bestTest = 13676.28697\n[14:33:04] bestIteration = 705\n[14:33:04] Shrink model to first 706 iterations.\n[14:33:04] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0003498553928267916, 'min_data_in_leaf': 8} scored -13676.28685897436 in 0:00:02.886408\n[14:33:05] 0:\tlearn: 55583.7918324\ttest: 51206.6066481\tbest: 51206.6066481 (0)\ttotal: 1.24ms\tremaining: 2.47s\n[14:33:06] Stopped by overfitting detector  (300 iterations wait)\n[14:33:06] bestTest = 14033.32952\n[14:33:06] bestIteration = 823\n[14:33:06] Shrink model to first 824 iterations.\n[14:33:06] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0011741101956024116, 'min_data_in_leaf': 2} scored -14033.328759348291 in 0:00:01.372661\n[14:33:06] 0:\tlearn: 54987.7335285\ttest: 50541.4758748\tbest: 50541.4758748 (0)\ttotal: 4.54ms\tremaining: 9.09s\n[14:33:08] Stopped by overfitting detector  (300 iterations wait)\n[14:33:08] bestTest = 14984.43544\n[14:33:08] bestIteration = 270\n[14:33:08] Shrink model to first 271 iterations.\n[14:33:08] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00011277863183885031, 'min_data_in_leaf': 4} scored -14984.435396634615 in 0:00:02.402244\n[14:33:08] 0:\tlearn: 55024.7318500\ttest: 50620.5713621\tbest: 50620.5713621 (0)\ttotal: 3ms\tremaining: 6s\n[14:33:11] Stopped by overfitting detector  (300 iterations wait)\n[14:33:11] bestTest = 13966.64132\n[14:33:11] bestIteration = 597\n[14:33:11] Shrink model to first 598 iterations.\n[14:33:11] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04118211493187025, 'min_data_in_leaf': 17} scored -13966.641676682691 in 0:00:02.582774\n[14:33:11] 0:\tlearn: 55023.0734161\ttest: 50588.8011894\tbest: 50588.8011894 (0)\ttotal: 2.1ms\tremaining: 4.21s\n[14:33:13] Stopped by overfitting detector  (300 iterations wait)\n[14:33:13] bestTest = 13804.15619\n[14:33:13] bestIteration = 953\n[14:33:13] Shrink model to first 954 iterations.\n[14:33:13] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007356775801831516, 'min_data_in_leaf': 6} scored -13804.15608306624 in 0:00:02.662023\n[14:33:14] 0:\tlearn: 55097.7413688\ttest: 50686.5026727\tbest: 50686.5026727 (0)\ttotal: 2.89ms\tremaining: 5.77s\n[14:33:16] Stopped by overfitting detector  (300 iterations wait)\n[14:33:16] bestTest = 13806.05864\n[14:33:16] bestIteration = 573\n[14:33:16] Shrink model to first 574 iterations.\n[14:33:16] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.013929538003361, 'min_data_in_leaf': 11} scored -13806.058627136752 in 0:00:02.525449\n[14:33:16] 0:\tlearn: 54987.7164010\ttest: 50541.4563195\tbest: 50541.4563195 (0)\ttotal: 4.07ms\tremaining: 8.14s\n[14:33:20] Stopped by overfitting detector  (300 iterations wait)\n[14:33:20] bestTest = 14841.42134\n[14:33:20] bestIteration = 630\n[14:33:20] Shrink model to first 631 iterations.\n[14:33:20] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.01758456585977e-05, 'min_data_in_leaf': 1} scored -14841.420840010684 in 0:00:04.067162\n[14:33:20] 0:\tlearn: 55021.0179284\ttest: 50617.4191807\tbest: 50617.4191807 (0)\ttotal: 2.92ms\tremaining: 5.84s\n[14:33:24] Stopped by overfitting detector  (300 iterations wait)\n[14:33:24] bestTest = 13662.14358\n[14:33:24] bestIteration = 940\n[14:33:24] Shrink model to first 941 iterations.\n[14:33:24] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008849299239384554, 'min_data_in_leaf': 5} scored -13662.143462873932 in 0:00:03.590203\n[14:33:24] 0:\tlearn: 55021.0382606\ttest: 50617.4363383\tbest: 50617.4363383 (0)\ttotal: 3.03ms\tremaining: 6.06s\n[14:33:27] Stopped by overfitting detector  (300 iterations wait)\n[14:33:27] bestTest = 13695.30378\n[14:33:27] bestIteration = 977\n[14:33:27] Shrink model to first 978 iterations.\n[14:33:27] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001103021868106488, 'min_data_in_leaf': 5} scored -13695.30328525641 in 0:00:03.643349\n[14:33:27] 0:\tlearn: 55021.2295703\ttest: 50617.5978330\tbest: 50617.5978330 (0)\ttotal: 2.92ms\tremaining: 5.84s\n[14:33:29] Stopped by overfitting detector  (300 iterations wait)\n[14:33:29] bestTest = 13795.20594\n[14:33:30] bestIteration = 430\n[14:33:30] Shrink model to first 431 iterations.\n[14:33:30] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.003156453072204763, 'min_data_in_leaf': 7} scored -13795.205695779914 in 0:00:02.214712\n[14:33:30] 0:\tlearn: 55020.9407862\ttest: 50617.3540934\tbest: 50617.3540934 (0)\ttotal: 3.7ms\tremaining: 7.4s\n[14:33:33] Stopped by overfitting detector  (300 iterations wait)\n[14:33:33] bestTest = 13676.3504\n[14:33:33] bestIteration = 705\n[14:33:33] Shrink model to first 706 iterations.\n[14:33:33] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 5.7722015963771084e-05, 'min_data_in_leaf': 2} scored -13676.350477430555 in 0:00:03.310278\n[14:33:33] 0:\tlearn: 55583.7720651\ttest: 51206.5861322\tbest: 51206.5861322 (0)\ttotal: 1.18ms\tremaining: 2.35s\n[14:33:34] Stopped by overfitting detector  (300 iterations wait)\n[14:33:34] bestTest = 14006.14355\n[14:33:34] bestIteration = 658\n[14:33:34] Shrink model to first 659 iterations.\n[14:33:34] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00023225496921808534, 'min_data_in_leaf': 9} scored -14006.143896901709 in 0:00:01.190708\n[14:33:34] 0:\tlearn: 54992.9128012\ttest: 50547.3675880\tbest: 50547.3675880 (0)\ttotal: 4.99ms\tremaining: 9.98s\n[14:33:37] Stopped by overfitting detector  (300 iterations wait)\n[14:33:37] bestTest = 15106.9627\n[14:33:37] bestIteration = 299\n[14:33:37] Shrink model to first 300 iterations.\n[14:33:37] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.03155536659877094, 'min_data_in_leaf': 4} scored -15106.962673611111 in 0:00:02.534950\n[14:33:37] 0:\tlearn: 55022.7014312\ttest: 50588.5535697\tbest: 50588.5535697 (0)\ttotal: 2.12ms\tremaining: 4.25s\n[14:33:39] Stopped by overfitting detector  (300 iterations wait)\n[14:33:39] bestTest = 13968.94427\n[14:33:39] bestIteration = 871\n[14:33:39] Shrink model to first 872 iterations.\n[14:33:39] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0005968994109134424, 'min_data_in_leaf': 6} scored -13968.943993723291 in 0:00:02.463836\n[14:33:39] 0:\tlearn: 55021.6371496\ttest: 50617.9422236\tbest: 50617.9422236 (0)\ttotal: 2.99ms\tremaining: 5.97s\n[14:33:41] Stopped by overfitting detector  (300 iterations wait)\n[14:33:41] bestTest = 14205.394\n[14:33:41] bestIteration = 350\n[14:33:41] Shrink model to first 351 iterations.\n[14:33:41] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.007539426029412634, 'min_data_in_leaf': 1} scored -14205.394197382479 in 0:00:01.966256\n[14:33:41] 0:\tlearn: 55022.7512003\ttest: 50588.5866151\tbest: 50588.5866151 (0)\ttotal: 3.5ms\tremaining: 6.99s\n[14:33:43] Stopped by overfitting detector  (300 iterations wait)\n[14:33:43] bestTest = 14186.76388\n[14:33:43] bestIteration = 767\n[14:33:43] Shrink model to first 768 iterations.\n[14:33:43] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0015002765068685773, 'min_data_in_leaf': 8} scored -14186.763738648504 in 0:00:02.312755\n[14:33:44] 0:\tlearn: 55020.9370165\ttest: 50617.3509133\tbest: 50617.3509133 (0)\ttotal: 3.01ms\tremaining: 6.03s\n[14:33:46] Stopped by overfitting detector  (300 iterations wait)\n[14:33:46] bestTest = 13676.35918\n[14:33:46] bestIteration = 705\n[14:33:46] Shrink model to first 706 iterations.\n[14:33:46] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.731006520878817e-05, 'min_data_in_leaf': 3} scored -13676.358924278846 in 0:00:02.933988\n[14:33:47] 0:\tlearn: 55020.9764283\ttest: 50617.3841638\tbest: 50617.3841638 (0)\ttotal: 2.97ms\tremaining: 5.93s\n[14:33:49] Stopped by overfitting detector  (300 iterations wait)\n[14:33:49] bestTest = 13676.26743\n[14:33:49] bestIteration = 705\n[14:33:49] Shrink model to first 706 iterations.\n[14:33:49] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00043986859205011856, 'min_data_in_leaf': 5} scored -13676.267311030982 in 0:00:02.895845\n[14:33:49] 0:\tlearn: 55020.9538568\ttest: 50617.3651203\tbest: 50617.3651203 (0)\ttotal: 2.89ms\tremaining: 5.78s\n[14:33:52] Stopped by overfitting detector  (300 iterations wait)\n[14:33:52] bestTest = 13676.31997\n[14:33:52] bestIteration = 705\n[14:33:52] Shrink model to first 706 iterations.\n[14:33:52] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00019785186452626698, 'min_data_in_leaf': 5} scored -13676.320112179486 in 0:00:02.960682\n[14:33:52] 0:\tlearn: 54988.2993788\ttest: 50542.1216648\tbest: 50542.1216648 (0)\ttotal: 4.11ms\tremaining: 8.22s\n[14:33:56] Stopped by overfitting detector  (300 iterations wait)\n[14:33:56] bestTest = 14982.73109\n[14:33:56] bestIteration = 661\n[14:33:56] Shrink model to first 662 iterations.\n[14:33:56] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.003507606591838928, 'min_data_in_leaf': 7} scored -14982.730836004273 in 0:00:03.972636\n[14:33:56] 0:\tlearn: 55020.9979869\ttest: 50617.4023539\tbest: 50617.4023539 (0)\ttotal: 2.88ms\tremaining: 5.76s\n[14:33:59] Stopped by overfitting detector  (300 iterations wait)\n[14:33:59] bestTest = 13676.21725\n[14:33:59] bestIteration = 705\n[14:33:59] Shrink model to first 706 iterations.\n[14:33:59] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006710556153093214, 'min_data_in_leaf': 4} scored -13676.217431223291 in 0:00:02.890026\n[14:33:59] 0:\tlearn: 55023.1529323\ttest: 50619.2268889\tbest: 50619.2268889 (0)\ttotal: 2.93ms\tremaining: 5.86s\n[14:34:02] Stopped by overfitting detector  (300 iterations wait)\n[14:34:02] bestTest = 14171.76974\n[14:34:02] bestIteration = 543\n[14:34:02] Shrink model to first 544 iterations.\n[14:34:02] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.023937480566899174, 'min_data_in_leaf': 2} scored -14171.76944778312 in 0:00:02.516727\n[14:34:02] 0:\tlearn: 55020.9354028\ttest: 50617.3495519\tbest: 50617.3495519 (0)\ttotal: 3.52ms\tremaining: 7.03s\n[14:34:05] Stopped by overfitting detector  (300 iterations wait)\n[14:34:05] bestTest = 13963.2464\n[14:34:05] bestIteration = 701\n[14:34:05] Shrink model to first 702 iterations.\n[14:34:05] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0829694936079614e-08, 'min_data_in_leaf': 4} scored -13963.246277377137 in 0:00:03.192894\n[14:34:05] 0:\tlearn: 55022.6718353\ttest: 50588.5339313\tbest: 50588.5339313 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[14:34:08] Stopped by overfitting detector  (300 iterations wait)\n[14:34:08] bestTest = 14187.49189\n[14:34:08] bestIteration = 876\n[14:34:08] Shrink model to first 877 iterations.\n[14:34:08] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.9847443858738505e-05, 'min_data_in_leaf': 3} scored -14187.492304353633 in 0:00:02.515234\n[14:34:08] 0:\tlearn: 55290.5731823\ttest: 50825.1708060\tbest: 50825.1708060 (0)\ttotal: 2.17ms\tremaining: 4.33s\n[14:34:09] Stopped by overfitting detector  (300 iterations wait)\n[14:34:09] bestTest = 14220.62051\n[14:34:09] bestIteration = 807\n[14:34:09] Shrink model to first 808 iterations.\n[14:34:09] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 2.869751403551741e-06, 'min_data_in_leaf': 4} scored -14220.620576255342 in 0:00:01.800899\n[14:34:10] 0:\tlearn: 54987.7147233\ttest: 50541.4544039\tbest: 50541.4544039 (0)\ttotal: 4.34ms\tremaining: 8.67s\n[14:34:13] Stopped by overfitting detector  (300 iterations wait)\n[14:34:13] bestTest = 14521.15329\n[14:34:13] bestIteration = 485\n[14:34:13] Shrink model to first 486 iterations.\n[14:34:13] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2613593911945544e-07, 'min_data_in_leaf': 6} scored -14554.31241653312 in 0:00:03.292011\n[14:34:13] 0:\tlearn: 55020.9991202\ttest: 50617.4033102\tbest: 50617.4033102 (0)\ttotal: 2.91ms\tremaining: 5.82s\n[14:34:16] Stopped by overfitting detector  (300 iterations wait)\n[14:34:16] bestTest = 13676.21462\n[14:34:16] bestIteration = 705\n[14:34:16] Shrink model to first 706 iterations.\n[14:34:16] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006832102471081098, 'min_data_in_leaf': 1} scored -13676.214559962607 in 0:00:02.903602\n[14:34:16] 0:\tlearn: 55021.0809262\ttest: 50617.4723460\tbest: 50617.4723460 (0)\ttotal: 2.89ms\tremaining: 5.78s\n[14:34:18] Stopped by overfitting detector  (300 iterations wait)\n[14:34:18] bestTest = 13715.72323\n[14:34:18] bestIteration = 463\n[14:34:18] Shrink model to first 464 iterations.\n[14:34:18] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001560762251601224, 'min_data_in_leaf': 1} scored -13715.723157051281 in 0:00:02.244152\n[14:34:18] 0:\tlearn: 55021.0046392\ttest: 50617.4079670\tbest: 50617.4079670 (0)\ttotal: 2.92ms\tremaining: 5.84s\n[14:34:21] Stopped by overfitting detector  (300 iterations wait)\n[14:34:21] bestTest = 13676.20177\n[14:34:21] bestIteration = 705\n[14:34:21] Shrink model to first 706 iterations.\n[14:34:21] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0007423990972489678, 'min_data_in_leaf': 2} scored -13676.201238648504 in 0:00:02.923965\n[14:34:21] 0:\tlearn: 55021.3680402\ttest: 50617.7147850\tbest: 50617.7147850 (0)\ttotal: 2.86ms\tremaining: 5.72s\n[14:34:24] Stopped by overfitting detector  (300 iterations wait)\n[14:34:24] bestTest = 13984.65214\n[14:34:24] bestIteration = 964\n[14:34:24] Shrink model to first 965 iterations.\n[14:34:24] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.004644261249000122, 'min_data_in_leaf': 1} scored -13984.652160122863 in 0:00:03.635927\n[14:34:25] 0:\tlearn: 55020.9485680\ttest: 50617.3606584\tbest: 50617.3606584 (0)\ttotal: 2.85ms\tremaining: 5.7s\n[14:34:27] Stopped by overfitting detector  (300 iterations wait)\n[14:34:27] bestTest = 13676.33228\n[14:34:27] bestIteration = 705\n[14:34:27] Shrink model to first 706 iterations.\n[14:34:27] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0001411494042470857, 'min_data_in_leaf': 2} scored -13676.332131410256 in 0:00:02.902162\n[14:34:28] 0:\tlearn: 55022.4319460\ttest: 50618.6150799\tbest: 50618.6150799 (0)\ttotal: 2.96ms\tremaining: 5.92s\n[14:34:29] Stopped by overfitting detector  (300 iterations wait)\n[14:34:29] bestTest = 13810.968\n[14:34:29] bestIteration = 364\n[14:34:29] Shrink model to first 365 iterations.\n[14:34:29] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.016118487987783415, 'min_data_in_leaf': 3} scored -13810.967564770299 in 0:00:02.003883\n[14:34:30] 0:\tlearn: 55022.6865637\ttest: 50588.5437032\tbest: 50588.5437032 (0)\ttotal: 2.21ms\tremaining: 4.41s\n[14:34:32] Stopped by overfitting detector  (300 iterations wait)\n[14:34:32] bestTest = 13968.94087\n[14:34:32] bestIteration = 871\n[14:34:32] Shrink model to first 872 iterations.\n[14:34:32] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0003270975380518659, 'min_data_in_leaf': 2} scored -13968.940588274572 in 0:00:02.548906\n[14:34:32] 0:\tlearn: 54987.8521419\ttest: 50541.6112884\tbest: 50541.6112884 (0)\ttotal: 4.22ms\tremaining: 8.44s\n[14:34:36] Stopped by overfitting detector  (300 iterations wait)\n[14:34:36] bestTest = 14974.48677\n[14:34:36] bestIteration = 444\n[14:34:36] Shrink model to first 445 iterations.\n[14:34:36] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008235825531888799, 'min_data_in_leaf': 3} scored -14974.487012553418 in 0:00:03.560562\n[14:34:36] 0:\tlearn: 55020.9389436\ttest: 50617.3525390\tbest: 50617.3525390 (0)\ttotal: 3.55ms\tremaining: 7.1s\n[14:34:38] Stopped by overfitting detector  (300 iterations wait)\n[14:34:39] bestTest = 13676.3547\n[14:34:39] bestIteration = 705\n[14:34:39] Shrink model to first 706 iterations.\n[14:34:39] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.7968713108238224e-05, 'min_data_in_leaf': 20} scored -13676.355452056623 in 0:00:02.957042\n[14:34:39] 0:\tlearn: 55290.6392624\ttest: 50825.2019396\tbest: 50825.2019396 (0)\ttotal: 1.56ms\tremaining: 3.12s\n[14:34:41] Stopped by overfitting detector  (300 iterations wait)\n[14:34:41] bestTest = 14175.7883\n[14:34:41] bestIteration = 1402\n[14:34:41] Shrink model to first 1403 iterations.\n[14:34:41] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0021202228018305444, 'min_data_in_leaf': 1} scored -14175.788528311965 in 0:00:02.646266\n[14:34:42] 0:\tlearn: 55370.5114664\ttest: 50978.5857769\tbest: 50978.5857769 (0)\ttotal: 2.94ms\tremaining: 5.89s\n[14:34:45] Stopped by overfitting detector  (300 iterations wait)\n[14:34:45] bestTest = 14127.5897\n[14:34:45] bestIteration = 929\n[14:34:45] Shrink model to first 930 iterations.\n[14:34:45] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 9.722286010927427, 'min_data_in_leaf': 2} scored -14127.589877136752 in 0:00:03.735806\n[14:34:45] 0:\tlearn: 55020.9924941\ttest: 50617.3977192\tbest: 50617.3977192 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[14:34:48] Stopped by overfitting detector  (300 iterations wait)\n[14:34:48] bestTest = 13676.23003\n[14:34:48] bestIteration = 705\n[14:34:48] Shrink model to first 706 iterations.\n[14:34:48] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006121496593029671, 'min_data_in_leaf': 4} scored -13676.23030181624 in 0:00:02.892870\n[14:34:48] 0:\tlearn: 55021.5333023\ttest: 50617.8544336\tbest: 50617.8544336 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[14:34:52] Stopped by overfitting detector  (300 iterations wait)\n[14:34:52] bestTest = 14341.80953\n[14:34:52] bestIteration = 1033\n[14:34:52] Shrink model to first 1034 iterations.\n[14:34:52] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.006421627340923506, 'min_data_in_leaf': 5} scored -14341.809511885684 in 0:00:03.822432\n[14:34:52] 0:\tlearn: 55020.9452968\ttest: 50617.3578987\tbest: 50617.3578987 (0)\ttotal: 2.89ms\tremaining: 5.78s\n[14:34:55] Stopped by overfitting detector  (300 iterations wait)\n[14:34:55] bestTest = 13676.3399\n[14:34:55] bestIteration = 705\n[14:34:55] Shrink model to first 706 iterations.\n[14:34:55] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00010607954842122639, 'min_data_in_leaf': 3} scored -13676.340027377137 in 0:00:02.879320\n[14:34:55] 0:\tlearn: 55021.0004488\ttest: 50617.4044312\tbest: 50617.4044312 (0)\ttotal: 2.96ms\tremaining: 5.92s\n[14:34:57] Stopped by overfitting detector  (300 iterations wait)\n[14:34:57] bestTest = 13676.21152\n[14:34:57] bestIteration = 705\n[14:34:57] Shrink model to first 706 iterations.\n[14:34:57] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006974583345491312, 'min_data_in_leaf': 4} scored -13676.211204594018 in 0:00:02.889636\n[14:34:58] 0:\tlearn: 55020.9559318\ttest: 50617.3668709\tbest: 50617.3668709 (0)\ttotal: 2.78ms\tremaining: 5.57s\n[14:35:00] Stopped by overfitting detector  (300 iterations wait)\n[14:35:00] bestTest = 13676.31514\n[14:35:00] bestIteration = 705\n[14:35:00] Shrink model to first 706 iterations.\n[14:35:00] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00022009923440113202, 'min_data_in_leaf': 1} scored -13676.31492053953 in 0:00:02.883213\n[14:35:01] 0:\tlearn: 55022.7784652\ttest: 50588.6047294\tbest: 50588.6047294 (0)\ttotal: 2.14ms\tremaining: 4.28s\n[14:35:02] Stopped by overfitting detector  (300 iterations wait)\n[14:35:02] bestTest = 14307.09597\n[14:35:02] bestIteration = 638\n[14:35:02] Shrink model to first 639 iterations.\n[14:35:02] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001995309797978604, 'min_data_in_leaf': 2} scored -14307.096237313035 in 0:00:02.099433\n[14:35:03] 0:\tlearn: 55021.9556196\ttest: 50618.2116311\tbest: 50618.2116311 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[14:35:05] Stopped by overfitting detector  (300 iterations wait)\n[14:35:05] bestTest = 13733.58599\n[14:35:05] bestIteration = 493\n[14:35:05] Shrink model to first 494 iterations.\n[14:35:05] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.010971913480740418, 'min_data_in_leaf': 3} scored -13733.58568709936 in 0:00:02.328520\n[14:35:05] 0:\tlearn: 55583.7869242\ttest: 51206.6015540\tbest: 51206.6015540 (0)\ttotal: 1.19ms\tremaining: 2.37s\n[14:35:07] Stopped by overfitting detector  (300 iterations wait)\n[14:35:07] bestTest = 13664.69347\n[14:35:07] bestIteration = 1464\n[14:35:07] Shrink model to first 1465 iterations.\n[14:35:07] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0009402440152064555, 'min_data_in_leaf': 15} scored -13682.661391559828 in 0:00:02.190577\n[14:35:07] 0:\tlearn: 54987.7147077\ttest: 50541.4543861\tbest: 50541.4543861 (0)\ttotal: 5.29ms\tremaining: 10.6s\n[14:35:11] Stopped by overfitting detector  (300 iterations wait)\n[14:35:11] bestTest = 14841.42681\n[14:35:11] bestIteration = 630\n[14:35:11] Shrink model to first 631 iterations.\n[14:35:11] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 3.251023766698464e-08, 'min_data_in_leaf': 5} scored -14841.426515758547 in 0:00:04.128413\n[14:35:11] 0:\tlearn: 55027.2791510\ttest: 50622.7532951\tbest: 50622.7532951 (0)\ttotal: 2.9ms\tremaining: 5.79s\n[14:35:14] Stopped by overfitting detector  (300 iterations wait)\n[14:35:14] bestTest = 13794.90753\n[14:35:14] bestIteration = 488\n[14:35:14] Shrink model to first 489 iterations.\n[14:35:14] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.06935379011908599, 'min_data_in_leaf': 6} scored -13794.907719017094 in 0:00:02.322178\n[14:35:14] 0:\tlearn: 55020.9912174\ttest: 50617.3966419\tbest: 50617.3966419 (0)\ttotal: 3.01ms\tremaining: 6.01s\n[14:35:16] Stopped by overfitting detector  (300 iterations wait)\n[14:35:16] bestTest = 13676.23301\n[14:35:16] bestIteration = 705\n[14:35:16] Shrink model to first 706 iterations.\n[14:35:16] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0005984582352501391, 'min_data_in_leaf': 4} scored -13676.23297275641 in 0:00:02.909237\n[14:35:17] 0:\tlearn: 55021.1716576\ttest: 50617.5489353\tbest: 50617.5489353 (0)\ttotal: 3.45ms\tremaining: 6.89s\n[14:35:18] Stopped by overfitting detector  (300 iterations wait)\n[14:35:18] bestTest = 13980.81598\n[14:35:18] bestIteration = 370\n[14:35:18] Shrink model to first 371 iterations.\n[14:35:18] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0025345850582224245, 'min_data_in_leaf': 4} scored -13980.816089075855 in 0:00:02.006209\n[14:35:19] 0:\tlearn: 55020.9665936\ttest: 50617.3758662\tbest: 50617.3758662 (0)\ttotal: 2.93ms\tremaining: 5.86s\n[14:35:22] Stopped by overfitting detector  (300 iterations wait)\n[14:35:22] bestTest = 13676.29032\n[14:35:22] bestIteration = 705\n[14:35:22] Shrink model to first 706 iterations.\n[14:35:22] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00033441513313576827, 'min_data_in_leaf': 5} scored -13676.290147569445 in 0:00:03.239474\n[14:35:22] 0:\tlearn: 55020.9434246\ttest: 50617.3563193\tbest: 50617.3563193 (0)\ttotal: 2.9ms\tremaining: 5.79s\n[14:35:25] Stopped by overfitting detector  (300 iterations wait)\n[14:35:25] bestTest = 13676.34426\n[14:35:25] bestIteration = 705\n[14:35:25] Shrink model to first 706 iterations.\n[14:35:25] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 8.600799628906361e-05, 'min_data_in_leaf': 3} scored -13676.343900240385 in 0:00:02.920030\n[14:35:25] 0:\tlearn: 55021.0214844\ttest: 50617.4221814\tbest: 50617.4221814 (0)\ttotal: 2.97ms\tremaining: 5.95s\n[14:35:28] Stopped by overfitting detector  (300 iterations wait)\n[14:35:28] bestTest = 13662.13807\n[14:35:28] bestIteration = 940\n[14:35:28] Shrink model to first 941 iterations.\n[14:35:28] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0009230712879669019, 'min_data_in_leaf': 2} scored -13662.138338007479 in 0:00:03.562403\n[14:35:28] 0:\tlearn: 55021.2797885\ttest: 50617.6402414\tbest: 50617.6402414 (0)\ttotal: 2.89ms\tremaining: 5.78s\n[14:35:31] Stopped by overfitting detector  (300 iterations wait)\n[14:35:31] bestTest = 13993.75806\n[14:35:31] bestIteration = 489\n[14:35:31] Shrink model to first 490 iterations.\n[14:35:31] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0036958799163696204, 'min_data_in_leaf': 2} scored -13993.758530315172 in 0:00:02.324140\n[14:35:31] 0:\tlearn: 55022.7261051\ttest: 50588.5699492\tbest: 50588.5699492 (0)\ttotal: 2.12ms\tremaining: 4.23s\n[14:35:33] Stopped by overfitting detector  (300 iterations wait)\n[14:35:33] bestTest = 14224.40604\n[14:35:33] bestIteration = 703\n[14:35:33] Shrink model to first 704 iterations.\n[14:35:33] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0010447235193806201, 'min_data_in_leaf': 1} scored -14224.406316773504 in 0:00:02.220076\n[14:35:33] 0:\tlearn: 55020.9531506\ttest: 50617.3645246\tbest: 50617.3645246 (0)\ttotal: 2.92ms\tremaining: 5.83s\n[14:35:35] Stopped by overfitting detector  (300 iterations wait)\n[14:35:35] bestTest = 14238.37597\n[14:35:35] bestIteration = 473\n[14:35:35] Shrink model to first 474 iterations.\n[14:35:35] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00019028106212623045, 'min_data_in_leaf': 2} scored -14238.37610176282 in 0:00:02.319783\n[14:35:35] 0:\tlearn: 55021.3851859\ttest: 50617.7292698\tbest: 50617.7292698 (0)\ttotal: 2.94ms\tremaining: 5.87s\n[14:35:38] Stopped by overfitting detector  (300 iterations wait)\n[14:35:38] bestTest = 14061.17616\n[14:35:38] bestIteration = 729\n[14:35:38] Shrink model to first 730 iterations.\n[14:35:38] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.004828573966251701, 'min_data_in_leaf': 1} scored -14061.176499065172 in 0:00:02.976907\n[14:35:38] 0:\tlearn: 54987.7867342\ttest: 50541.5366193\tbest: 50541.5366193 (0)\ttotal: 4.03ms\tremaining: 8.06s\n[14:35:41] Stopped by overfitting detector  (300 iterations wait)\n[14:35:41] bestTest = 14984.23783\n[14:35:41] bestIteration = 270\n[14:35:41] Shrink model to first 271 iterations.\n[14:35:41] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00043156603980101365, 'min_data_in_leaf': 7} scored -14984.238080929486 in 0:00:02.891959\n[14:35:41] 0:\tlearn: 55021.0081091\ttest: 50617.4108950\tbest: 50617.4108950 (0)\ttotal: 3.7ms\tremaining: 7.4s\n[14:35:44] Stopped by overfitting detector  (300 iterations wait)\n[14:35:44] bestTest = 13676.1937\n[14:35:44] bestIteration = 705\n[14:35:44] Shrink model to first 706 iterations.\n[14:35:44] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0007796141061531002, 'min_data_in_leaf': 4} scored -13676.193926949787 in 0:00:02.948218\n[14:35:44] 0:\tlearn: 55021.0964739\ttest: 50617.4854687\tbest: 50617.4854687 (0)\ttotal: 2.87ms\tremaining: 5.73s\n[14:35:48] Stopped by overfitting detector  (300 iterations wait)\n[14:35:48] bestTest = 13689.91202\n[14:35:48] bestIteration = 1126\n[14:35:48] Shrink model to first 1127 iterations.\n[14:35:48] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0017275967930032838, 'min_data_in_leaf': 6} scored -13689.911341479701 in 0:00:04.033968\n[14:35:48] 0:\tlearn: 55020.9588002\ttest: 50617.3692910\tbest: 50617.3692910 (0)\ttotal: 2.85ms\tremaining: 5.7s\n[14:35:51] Stopped by overfitting detector  (300 iterations wait)\n[14:35:51] bestTest = 13676.30846\n[14:35:51] bestIteration = 705\n[14:35:51] Shrink model to first 706 iterations.\n[14:35:51] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00025085362922727184, 'min_data_in_leaf': 3} scored -13676.308276575855 in 0:00:02.910144\n[14:35:51] 0:\tlearn: 55021.0455313\ttest: 50617.4424741\tbest: 50617.4424741 (0)\ttotal: 2.86ms\tremaining: 5.71s\n[14:35:55] Stopped by overfitting detector  (300 iterations wait)\n[14:35:55] bestTest = 13695.28856\n[14:35:55] bestIteration = 977\n[14:35:55] Shrink model to first 978 iterations.\n[14:35:55] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0011810176440362472, 'min_data_in_leaf': 4} scored -13695.288578392094 in 0:00:03.679247\n[14:35:55] 0:\tlearn: 55020.9790439\ttest: 50617.3863706\tbest: 50617.3863706 (0)\ttotal: 2.87ms\tremaining: 5.73s\n[14:35:58] Stopped by overfitting detector  (300 iterations wait)\n[14:35:58] bestTest = 13676.26134\n[14:35:58] bestIteration = 705\n[14:35:58] Shrink model to first 706 iterations.\n[14:35:58] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0004679150590334578, 'min_data_in_leaf': 18} scored -13676.26091746795 in 0:00:02.913561\n[14:35:58] 0:\tlearn: 55021.0094893\ttest: 50617.4120596\tbest: 50617.4120596 (0)\ttotal: 2.89ms\tremaining: 5.78s\n[14:36:01] Stopped by overfitting detector  (300 iterations wait)\n[14:36:01] bestTest = 13676.19049\n[14:36:01] bestIteration = 705\n[14:36:01] Shrink model to first 706 iterations.\n[14:36:01] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0007944171922949833, 'min_data_in_leaf': 5} scored -13676.191038995727 in 0:00:02.924188\n[14:36:01] 0:\tlearn: 55021.1620829\ttest: 50617.5408519\tbest: 50617.5408519 (0)\ttotal: 2.92ms\tremaining: 5.84s\n[14:36:04] Stopped by overfitting detector  (300 iterations wait)\n[14:36:04] bestTest = 13630.56127\n[14:36:04] bestIteration = 811\n[14:36:04] Shrink model to first 812 iterations.\n[14:36:04] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0024317931976121786, 'min_data_in_leaf': 5} scored -13630.561331463676 in 0:00:03.252955\n[14:36:04] 0:\tlearn: 55022.3265241\ttest: 50618.5257357\tbest: 50618.5257357 (0)\ttotal: 3.09ms\tremaining: 6.17s\n[14:36:07] Stopped by overfitting detector  (300 iterations wait)\n[14:36:07] bestTest = 14054.04004\n[14:36:07] bestIteration = 821\n[14:36:07] Shrink model to first 822 iterations.\n[14:36:07] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0149781208833083, 'min_data_in_leaf': 12} scored -14063.92922008547 in 0:00:03.251321\n[14:36:08] 0:\tlearn: 55022.8082231\ttest: 50588.6245089\tbest: 50588.6245089 (0)\ttotal: 2.26ms\tremaining: 4.51s\n[14:36:10] Stopped by overfitting detector  (300 iterations wait)\n[14:36:10] bestTest = 14044.35708\n[14:36:10] bestIteration = 701\n[14:36:10] Shrink model to first 702 iterations.\n[14:36:10] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0025357165584820353, 'min_data_in_leaf': 8} scored -14044.356921073719 in 0:00:02.428407\n[14:36:10] 0:\tlearn: 55583.9474517\ttest: 51206.7681512\tbest: 51206.7681512 (0)\ttotal: 1.22ms\tremaining: 2.44s\n[14:36:11] Stopped by overfitting detector  (300 iterations wait)\n[14:36:11] bestTest = 14070.43589\n[14:36:11] bestIteration = 1120\n[14:36:11] Shrink model to first 1121 iterations.\n[14:36:11] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.008590227898937663, 'min_data_in_leaf': 5} scored -14070.43656517094 in 0:00:01.772825\n[14:36:11] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[14:36:11] The set of hyperparameters \u001b[1m{'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0024317931976121786, 'min_data_in_leaf': 5}\u001b[0m\n achieve -13630.5613 mae\n[14:36:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[14:36:11] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:36:11] 0:\tlearn: 55888.9122080\ttest: 51432.1677023\tbest: 51432.1677023 (0)\ttotal: 3.61ms\tremaining: 10.8s\n[14:36:15] Stopped by overfitting detector  (100 iterations wait)\n[14:36:15] bestTest = 13824.37693\n[14:36:15] bestIteration = 891\n[14:36:15] Shrink model to first 892 iterations.\n[14:36:15] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:36:15] 0:\tlearn: 55507.1796636\ttest: 53372.1763977\tbest: 53372.1763977 (0)\ttotal: 3.3ms\tremaining: 9.91s\n[14:36:16] Stopped by overfitting detector  (100 iterations wait)\n[14:36:16] bestTest = 14060.12003\n[14:36:16] bestIteration = 558\n[14:36:16] Shrink model to first 559 iterations.\n[14:36:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:36:17] 0:\tlearn: 55567.7233976\ttest: 54375.0973237\tbest: 54375.0973237 (0)\ttotal: 2.9ms\tremaining: 8.69s\n[14:36:18] Stopped by overfitting detector  (100 iterations wait)\n[14:36:18] bestTest = 15904.85149\n[14:36:18] bestIteration = 427\n[14:36:18] Shrink model to first 428 iterations.\n[14:36:18] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:36:18] 0:\tlearn: 53388.6991516\ttest: 61670.2133349\tbest: 61670.2133349 (0)\ttotal: 3.23ms\tremaining: 9.68s\n[14:36:21] Stopped by overfitting detector  (100 iterations wait)\n[14:36:21] bestTest = 17549.1551\n[14:36:21] bestIteration = 928\n[14:36:21] Shrink model to first 929 iterations.\n[14:36:21] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:36:21] 0:\tlearn: 54971.3294605\ttest: 54608.7748628\tbest: 54608.7748628 (0)\ttotal: 3.77ms\tremaining: 11.3s\n[14:36:24] Stopped by overfitting detector  (100 iterations wait)\n[14:36:24] bestTest = 15594.98076\n[14:36:24] bestIteration = 867\n[14:36:24] Shrink model to first 868 iterations.\n[14:36:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15384.666677814641\u001b[0m\n[14:36:24] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[14:36:24] Time left 4952.54 secs\n\n[14:36:24] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[14:36:24] Blending: optimization starts with equal weights and score \u001b[1m-14872.349228114297\u001b[0m\n[14:36:24] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14864.767059744221\u001b[0m, weights = \u001b[1m[0.16700666 0.19148567 0.18454391 0.23827095 0.2186928 ]\u001b[0m\n[14:36:24] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14864.09786025792\u001b[0m, weights = \u001b[1m[0.16085331 0.19719541 0.19053277 0.24387468 0.20754384]\u001b[0m\n[14:36:24] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14863.89721010809\u001b[0m, weights = \u001b[1m[0.15644449 0.19820005 0.19118145 0.24557278 0.2086012 ]\u001b[0m\n[14:36:24] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14863.89721010809\u001b[0m, weights = \u001b[1m[0.15644449 0.19820005 0.19118145 0.24557278 0.2086012 ]\u001b[0m\n[14:36:24] Blending: no score update. Terminated\n\n[14:36:24] \u001b[1mAutoml preset training completed in 541.46 seconds\u001b[0m\n\n[14:36:24] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.15644 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.19820 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.19118 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.24557 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.20860 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[14:36:24] ==================================================\n[14:36:24] Start 2 automl preset configuration:\n[14:36:24] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n[14:36:24] Found reader_params in kwargs, need to combine\n[14:36:24] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 44, 'cv': 5}\n[14:36:24] Stdout logging level is INFO3.\n[14:36:24] Task: reg\n\n[14:36:24] Start automl preset with listed constraints:\n[14:36:24] - time: 4952.40 seconds\n[14:36:24] - CPU: 4 cores\n[14:36:24] - memory: 16 GB\n\n[14:36:24] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[14:36:24] Layer \u001b[1m1\u001b[0m train process start. Time left 4952.32 secs\n[14:36:24] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[14:36:24] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:36:25] Linear model: C = 1e-05 score = -37578.5875400641\n[14:36:25] Linear model: C = 5e-05 score = -25169.486444978633\n[14:36:25] Linear model: C = 0.0001 score = -21649.592314369656\n[14:36:25] Linear model: C = 0.0005 score = -19124.697916666668\n[14:36:25] Linear model: C = 0.001 score = -18351.51557491987\n[14:36:25] Linear model: C = 0.005 score = -16503.176983173078\n[14:36:26] Linear model: C = 0.01 score = -16252.410189636752\n[14:36:26] Linear model: C = 0.05 score = -17354.6988681891\n[14:36:26] Linear model: C = 0.1 score = -17354.70032051282\n[14:36:26] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:36:26] Linear model: C = 1e-05 score = -45121.52056623931\n[14:36:26] Linear model: C = 5e-05 score = -31456.345085470086\n[14:36:27] Linear model: C = 0.0001 score = -27254.889122596152\n[14:36:27] Linear model: C = 0.0005 score = -22000.819828392094\n[14:36:27] Linear model: C = 0.001 score = -22000.819828392094\n[14:36:27] Linear model: C = 0.005 score = -19901.195930154914\n[14:36:27] Linear model: C = 0.01 score = -19901.196981837606\n[14:36:27] Linear model: C = 0.05 score = -20657.73649505876\n[14:36:27] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:36:28] Linear model: C = 1e-05 score = -40116.526442307695\n[14:36:28] Linear model: C = 5e-05 score = -25348.240685096152\n[14:36:28] Linear model: C = 0.0001 score = -21949.420439369656\n[14:36:28] Linear model: C = 0.0005 score = -18607.263354700855\n[14:36:28] Linear model: C = 0.001 score = -17923.32957732372\n[14:36:29] Linear model: C = 0.005 score = -16958.25530849359\n[14:36:29] Linear model: C = 0.01 score = -17173.72065304487\n[14:36:29] Linear model: C = 0.05 score = -18764.222205528848\n[14:36:29] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:36:29] Linear model: C = 1e-05 score = -43354.49483637339\n[14:36:29] Linear model: C = 5e-05 score = -27311.43069340129\n[14:36:30] Linear model: C = 0.0001 score = -22840.536480686696\n[14:36:30] Linear model: C = 0.0005 score = -18251.74657993562\n[14:36:30] Linear model: C = 0.001 score = -17174.783496512875\n[14:36:30] Linear model: C = 0.005 score = -16939.806682537554\n[14:36:31] Linear model: C = 0.01 score = -17259.498558208154\n[14:36:31] Linear model: C = 0.05 score = -17753.321754291846\n[14:36:31] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:36:31] Linear model: C = 1e-05 score = -42704.4237526824\n[14:36:31] Linear model: C = 5e-05 score = -28498.56615477468\n[14:36:31] Linear model: C = 0.0001 score = -24520.010863733907\n[14:36:32] Linear model: C = 0.0005 score = -20094.84569474249\n[14:36:32] Linear model: C = 0.001 score = -18935.587111051504\n[14:36:32] Linear model: C = 0.005 score = -18935.58469688841\n[14:36:32] Linear model: C = 0.01 score = -17745.442831276825\n[14:36:32] Linear model: C = 0.05 score = -19451.60498256438\n[14:36:32] Linear model: C = 0.1 score = -19451.604714324036\n[14:36:32] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17559.793416898545\u001b[0m\n[14:36:32] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[14:36:32] Time left 4943.68 secs\n\n[14:36:33] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:36:38] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[14:36:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[14:36:38] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:36:38] Training until validation scores don't improve for 200 rounds\n[14:36:43] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:36:43] Training until validation scores don't improve for 200 rounds\n[14:36:47] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:36:47] Training until validation scores don't improve for 200 rounds\n[14:36:49] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:36:49] Training until validation scores don't improve for 200 rounds\n[14:36:51] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:36:51] Training until validation scores don't improve for 200 rounds\n[14:36:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15702.543246334546\u001b[0m\n[14:36:53] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[14:36:53] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[14:36:53] Training until validation scores don't improve for 200 rounds\n[14:36:57] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -14659.153111645299 in 0:00:03.904992\n[14:36:57] Training until validation scores don't improve for 200 rounds\n[14:37:00] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -14352.234007745727 in 0:00:03.301269\n[14:37:00] Training until validation scores don't improve for 200 rounds\n[14:37:05] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -14562.103565705129 in 0:00:04.290057\n[14:37:05] Training until validation scores don't improve for 200 rounds\n[14:37:08] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -14728.898070245727 in 0:00:03.682709\n[14:37:08] Training until validation scores don't improve for 200 rounds\n[14:37:10] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -14746.810596955129 in 0:00:01.573599\n[14:37:10] Training until validation scores don't improve for 200 rounds\n[14:37:12] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -14528.154246794871 in 0:00:02.573569\n[14:37:12] Training until validation scores don't improve for 200 rounds\n[14:37:18] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -14450.975060096154 in 0:00:05.937310\n[14:37:18] Training until validation scores don't improve for 200 rounds\n[14:37:20] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -14408.500600961539 in 0:00:01.956572\n[14:37:20] Training until validation scores don't improve for 200 rounds\n[14:37:25] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15044.611645299145 in 0:00:04.243935\n[14:37:25] Training until validation scores don't improve for 200 rounds\n[14:37:28] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -14485.400607638889 in 0:00:03.072972\n[14:37:28] Training until validation scores don't improve for 200 rounds\n[14:37:30] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102651048435158, 'num_leaves': 155, 'bagging_fraction': 0.7149885992524331, 'min_sum_hessian_in_leaf': 5.376638637951059, 'reg_alpha': 0.005764962972197527, 'reg_lambda': 0.03969950572380466} scored -14505.671307425213 in 0:00:02.663470\n[14:37:30] Training until validation scores don't improve for 200 rounds\n[14:37:34] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5075721185513784, 'num_leaves': 179, 'bagging_fraction': 0.7025137667980199, 'min_sum_hessian_in_leaf': 0.7346357719250239, 'reg_alpha': 3.4477069862338166e-05, 'reg_lambda': 0.01881061891210943} scored -14499.501001602564 in 0:00:03.475571\n[14:37:34] Training until validation scores don't improve for 200 rounds\n[14:37:37] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 120, 'bagging_fraction': 0.6564693652315678, 'min_sum_hessian_in_leaf': 0.037775037754547804, 'reg_alpha': 1.1558133227552828e-08, 'reg_lambda': 9.10189010859569} scored -14439.587373130342 in 0:00:03.331165\n[14:37:37] Training until validation scores don't improve for 200 rounds\n[14:37:40] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.5800774395585261, 'num_leaves': 214, 'bagging_fraction': 0.7771823696259716, 'min_sum_hessian_in_leaf': 0.9116035835913278, 'reg_alpha': 0.0001653282123997984, 'reg_lambda': 0.001874488738261752} scored -14582.547075320514 in 0:00:03.367053\n[14:37:41] Training until validation scores don't improve for 200 rounds\n[14:37:45] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5901603359684289, 'num_leaves': 254, 'bagging_fraction': 0.896321054953914, 'min_sum_hessian_in_leaf': 0.37947060877945143, 'reg_alpha': 7.498863259157094e-07, 'reg_lambda': 8.521786809444864} scored -14564.46123798077 in 0:00:04.622646\n[14:37:45] Training until validation scores don't improve for 200 rounds\n[14:37:48] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 189, 'bagging_fraction': 0.6398946357624273, 'min_sum_hessian_in_leaf': 0.021004805863831095, 'reg_alpha': 0.05160906119324121, 'reg_lambda': 6.170708682186698e-06} scored -14710.05485443376 in 0:00:02.877796\n[14:37:49] Training until validation scores don't improve for 200 rounds\n[14:37:53] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5421362409556731, 'num_leaves': 142, 'bagging_fraction': 0.9270627421637063, 'min_sum_hessian_in_leaf': 1.8610231826843653, 'reg_alpha': 6.360801805093107e-06, 'reg_lambda': 0.0072619186476959125} scored -14501.85109508547 in 0:00:04.828223\n[14:37:53] Training until validation scores don't improve for 200 rounds\n[14:37:55] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6409631872524091, 'num_leaves': 223, 'bagging_fraction': 0.7361609808336007, 'min_sum_hessian_in_leaf': 0.14141787338927225, 'reg_alpha': 0.00020947057791764452, 'reg_lambda': 9.979794006141637e-05} scored -14535.393195779914 in 0:00:02.656641\n[14:37:56] Training until validation scores don't improve for 200 rounds\n[14:37:59] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.8671516207368495, 'num_leaves': 169, 'bagging_fraction': 0.6675597279072907, 'min_sum_hessian_in_leaf': 2.807983016675388, 'reg_alpha': 3.866235560185625e-07, 'reg_lambda': 0.3142699396328411} scored -14571.407518696582 in 0:00:03.248574\n[14:37:59] Training until validation scores don't improve for 200 rounds\n[14:38:01] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.549654081747049, 'num_leaves': 116, 'bagging_fraction': 0.5006131299816939, 'min_sum_hessian_in_leaf': 0.36717604911374274, 'reg_alpha': 5.955347751121389e-08, 'reg_lambda': 8.197345997313042e-07} scored -14555.711137820514 in 0:00:02.107511\n[14:38:01] Training until validation scores don't improve for 200 rounds\n[14:38:04] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.6287780095784405, 'num_leaves': 202, 'bagging_fraction': 0.7732162791713864, 'min_sum_hessian_in_leaf': 0.012701877952916336, 'reg_alpha': 1.0025757876059058e-06, 'reg_lambda': 1.6340250254137068e-08} scored -14567.900373931623 in 0:00:03.471763\n[14:38:04] Training until validation scores don't improve for 200 rounds\n[14:38:08] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5935496828065205, 'num_leaves': 111, 'bagging_fraction': 0.6552806901772025, 'min_sum_hessian_in_leaf': 0.041131855616065735, 'reg_alpha': 2.1219899323605756e-08, 'reg_lambda': 9.490555804813473} scored -14314.037593482906 in 0:00:03.454090\n[14:38:08] Training until validation scores don't improve for 200 rounds\n[14:38:12] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.5043258591979808, 'num_leaves': 95, 'bagging_fraction': 0.6188484938305487, 'min_sum_hessian_in_leaf': 0.001487522590280137, 'reg_alpha': 1.1850473465839268e-08, 'reg_lambda': 1.120729020700119} scored -14274.081263354701 in 0:00:03.927933\n[14:38:12] Training until validation scores don't improve for 200 rounds\n[14:38:15] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.5625326296190768, 'num_leaves': 98, 'bagging_fraction': 0.6904270734818668, 'min_sum_hessian_in_leaf': 0.0010294755969121614, 'reg_alpha': 1.1754004409662418e-08, 'reg_lambda': 1.2013964638259438} scored -14375.217080662393 in 0:00:02.873157\n[14:38:15] Training until validation scores don't improve for 200 rounds\n[14:38:17] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.6091330191487014, 'num_leaves': 93, 'bagging_fraction': 0.5805716005997525, 'min_sum_hessian_in_leaf': 0.0012954788527934178, 'reg_alpha': 7.643464581139391e-08, 'reg_lambda': 1.2115849366224278} scored -14511.567741720086 in 0:00:02.092430\n[14:38:17] Training until validation scores don't improve for 200 rounds\n[14:38:20] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6696690495110619, 'num_leaves': 24, 'bagging_fraction': 0.8170721858815565, 'min_sum_hessian_in_leaf': 0.04777803490101216, 'reg_alpha': 4.996570019753506e-08, 'reg_lambda': 0.1267583193006026} scored -14659.698651175213 in 0:00:03.365272\n[14:38:22] Training until validation scores don't improve for 200 rounds\n[14:38:26] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.54322113237657, 'num_leaves': 117, 'bagging_fraction': 0.7709495444232378, 'min_sum_hessian_in_leaf': 0.0028353459605003637, 'reg_alpha': 1.4447201520460305e-06, 'reg_lambda': 3.5823454001382267} scored -14362.89623397436 in 0:00:05.583888\n[14:38:26] Training until validation scores don't improve for 200 rounds\n[14:38:27] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.5078841427757593, 'num_leaves': 141, 'bagging_fraction': 0.6069089747929703, 'min_sum_hessian_in_leaf': 0.00937426699865382, 'reg_alpha': 2.7217278948374945e-05, 'reg_lambda': 0.41541762882348654} scored -14659.967481303418 in 0:00:01.717809\n[14:38:27] Training until validation scores don't improve for 200 rounds\n[14:38:31] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.6166087120397832, 'num_leaves': 75, 'bagging_fraction': 0.7402488765731432, 'min_sum_hessian_in_leaf': 0.0203046770865456, 'reg_alpha': 1.3201870393500124e-08, 'reg_lambda': 0.054009157387182656} scored -14512.923310630342 in 0:00:03.201148\n[14:38:31] Training until validation scores don't improve for 200 rounds\n[14:38:34] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6936189365004498, 'num_leaves': 108, 'bagging_fraction': 0.6803222620640018, 'min_sum_hessian_in_leaf': 0.19038025426783808, 'reg_alpha': 2.720087560657903e-07, 'reg_lambda': 3.0865717032712494} scored -14503.492321047008 in 0:00:03.744031\n[14:38:34] Training until validation scores don't improve for 200 rounds\n[14:38:38] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5695449658593257, 'num_leaves': 158, 'bagging_fraction': 0.8847999420520885, 'min_sum_hessian_in_leaf': 0.002062175286022851, 'reg_alpha': 0.21549895303348443, 'reg_lambda': 0.006710363169509494} scored -14703.854300213676 in 0:00:03.733227\n[14:38:38] Training until validation scores don't improve for 200 rounds\n[14:38:42] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5398291080244821, 'num_leaves': 125, 'bagging_fraction': 0.7903306940837708, 'min_sum_hessian_in_leaf': 0.0024352388097699995, 'reg_alpha': 1.329753107966693e-06, 'reg_lambda': 2.826850311630852} scored -14335.48000133547 in 0:00:03.571870\n[14:38:42] Training until validation scores don't improve for 200 rounds\n[14:38:45] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.5366891293008504, 'num_leaves': 127, 'bagging_fraction': 0.8396284282952572, 'min_sum_hessian_in_leaf': 0.0016773258404583246, 'reg_alpha': 1.5640552285662712e-07, 'reg_lambda': 2.9379008869209797} scored -14617.341179220086 in 0:00:02.950681\n[14:38:45] Training until validation scores don't improve for 200 rounds\n[14:38:48] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5566238305961725, 'num_leaves': 83, 'bagging_fraction': 0.8117223888233313, 'min_sum_hessian_in_leaf': 0.004435041895087522, 'reg_alpha': 3.6226870723811705e-08, 'reg_lambda': 0.5895360724598284} scored -14509.13842147436 in 0:00:03.653315\n[14:38:48] Training until validation scores don't improve for 200 rounds\n[14:38:52] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5011323990502966, 'num_leaves': 133, 'bagging_fraction': 0.5627238213612521, 'min_sum_hessian_in_leaf': 0.0857034043622334, 'reg_alpha': 1.9796903290468175e-06, 'reg_lambda': 8.294667356727814} scored -14515.476195245727 in 0:00:03.182721\n[14:38:52] Training until validation scores don't improve for 200 rounds\n[14:38:56] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5807180249158063, 'num_leaves': 107, 'bagging_fraction': 0.7266860078682997, 'min_sum_hessian_in_leaf': 0.0025835510861943667, 'reg_alpha': 4.298925454992623e-07, 'reg_lambda': 0.18463879830567473} scored -14395.719918536324 in 0:00:04.767472\n[14:38:56] Training until validation scores don't improve for 200 rounds\n[14:38:59] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.5335315715136941, 'num_leaves': 46, 'bagging_fraction': 0.7925258878001126, 'min_sum_hessian_in_leaf': 0.007885839127360536, 'reg_alpha': 1.321679588615632e-07, 'reg_lambda': 1.9223809897221222} scored -14434.479033119658 in 0:00:02.980036\n[14:38:59] Training until validation scores don't improve for 200 rounds\n[14:39:02] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.7247003447388138, 'num_leaves': 73, 'bagging_fraction': 0.849546226415591, 'min_sum_hessian_in_leaf': 0.02152418849126221, 'reg_alpha': 2.455380303202428e-05, 'reg_lambda': 0.09034929973437378} scored -14734.804553952992 in 0:00:02.696634\n[14:39:02] Training until validation scores don't improve for 200 rounds\n[14:39:05] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.6738784274841162, 'num_leaves': 150, 'bagging_fraction': 0.6124235276034026, 'min_sum_hessian_in_leaf': 0.0046918288467234495, 'reg_alpha': 2.9569222941250443e-08, 'reg_lambda': 0.5231329385215829} scored -14571.415397970086 in 0:00:02.899613\n[14:39:05] Training until validation scores don't improve for 200 rounds\n[14:39:09] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.8754515193548504, 'num_leaves': 91, 'bagging_fraction': 0.7566595599387839, 'min_sum_hessian_in_leaf': 0.08904967511596545, 'reg_alpha': 0.001281362004296082, 'reg_lambda': 8.581229931301823e-08} scored -14615.993556356838 in 0:00:03.761145\n[14:39:09] Training until validation scores don't improve for 200 rounds\n[14:39:13] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.7605501051559491, 'num_leaves': 102, 'bagging_fraction': 0.9214003990376576, 'min_sum_hessian_in_leaf': 2.9446086722141604, 'reg_alpha': 1.0210971885263753e-08, 'reg_lambda': 0.02467136570769367} scored -14685.424946581197 in 0:00:04.436702\n[14:39:13] Training until validation scores don't improve for 200 rounds\n[14:39:17] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5319466868578688, 'num_leaves': 124, 'bagging_fraction': 0.8193960191862802, 'min_sum_hessian_in_leaf': 0.0027179286369058363, 'reg_alpha': 1.6008198907585e-06, 'reg_lambda': 3.4492539250085397} scored -14459.67497996795 in 0:00:03.377931\n[14:39:17] Training until validation scores don't improve for 200 rounds\n[14:39:20] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5615798776864336, 'num_leaves': 112, 'bagging_fraction': 0.7615959738229249, 'min_sum_hessian_in_leaf': 0.0031074755053277867, 'reg_alpha': 1.54823069332129e-07, 'reg_lambda': 3.75312068901819} scored -14334.073450854701 in 0:00:03.286047\n[14:39:20] Training until validation scores don't improve for 200 rounds\n[14:39:23] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.6078945725087013, 'num_leaves': 81, 'bagging_fraction': 0.6515566065673013, 'min_sum_hessian_in_leaf': 0.0014329804576267366, 'reg_alpha': 1.6048848046984703e-07, 'reg_lambda': 9.764211280398534} scored -14391.398971688035 in 0:00:03.428603\n[14:39:23] Training until validation scores don't improve for 200 rounds\n[14:39:27] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.5729039918980633, 'num_leaves': 64, 'bagging_fraction': 0.709813017928555, 'min_sum_hessian_in_leaf': 0.013175451173077139, 'reg_alpha': 6.023376922233649e-08, 'reg_lambda': 0.9064565993333272} scored -14511.525574252137 in 0:00:03.938410\n[14:39:27] Training until validation scores don't improve for 200 rounds\n[14:39:31] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.5231731573602448, 'num_leaves': 135, 'bagging_fraction': 0.7947433376487916, 'min_sum_hessian_in_leaf': 8.389496620512308, 'reg_alpha': 2.754344984140031e-08, 'reg_lambda': 3.9422731710598238} scored -14452.000901442309 in 0:00:03.588403\n[14:39:31] Training until validation scores don't improve for 200 rounds\n[14:39:34] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.6478698683834716, 'num_leaves': 162, 'bagging_fraction': 0.7531387815508571, 'min_sum_hessian_in_leaf': 0.006148700657921519, 'reg_alpha': 2.9713259604280387e-07, 'reg_lambda': 0.3565423765319227} scored -14776.004907852564 in 0:00:03.338990\n[14:39:34] Training until validation scores don't improve for 200 rounds\n[14:39:37] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.5942521171613321, 'num_leaves': 111, 'bagging_fraction': 0.6267409329737792, 'min_sum_hessian_in_leaf': 0.003470283295551348, 'reg_alpha': 2.6840737464526926e-06, 'reg_lambda': 1.1793533318442513} scored -14271.652310363248 in 0:00:03.014330\n[14:39:37] Training until validation scores don't improve for 200 rounds\n[14:39:41] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.5953027502170579, 'num_leaves': 111, 'bagging_fraction': 0.6307713905463086, 'min_sum_hessian_in_leaf': 0.003590739762886464, 'reg_alpha': 3.2829826747425262e-06, 'reg_lambda': 1.538729072274926} scored -14260.131610576924 in 0:00:03.529872\n[14:39:41] Training until validation scores don't improve for 200 rounds\n[14:39:43] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.5965217856238068, 'num_leaves': 109, 'bagging_fraction': 0.5675595416203624, 'min_sum_hessian_in_leaf': 0.0037776778995227, 'reg_alpha': 6.92183211482152e-05, 'reg_lambda': 0.01219313929217694} scored -14679.17938701923 in 0:00:01.807607\n[14:39:43] Training until validation scores don't improve for 200 rounds\n[14:39:47] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.705763119301335, 'num_leaves': 49, 'bagging_fraction': 0.6276190344182576, 'min_sum_hessian_in_leaf': 0.033101676735387185, 'reg_alpha': 1.1151489055749679e-05, 'reg_lambda': 0.0026618946491641514} scored -14545.996694711539 in 0:00:03.964691\n[14:39:47] Training until validation scores don't improve for 200 rounds\n[14:39:50] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.5833602509959637, 'num_leaves': 90, 'bagging_fraction': 0.6232715769616812, 'min_sum_hessian_in_leaf': 0.0010141334378066605, 'reg_alpha': 1.1669331169108458e-05, 'reg_lambda': 1.2588301531365886} scored -14105.874565972223 in 0:00:03.557817\n[14:39:50] Training until validation scores don't improve for 200 rounds\n[14:39:54] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.6383885510145398, 'num_leaves': 89, 'bagging_fraction': 0.6236053187712525, 'min_sum_hessian_in_leaf': 0.001059080102510604, 'reg_alpha': 6.5446370961766825e-06, 'reg_lambda': 1.250561657331408} scored -14434.540998931623 in 0:00:03.730699\n[14:39:54] Training until validation scores don't improve for 200 rounds\n[14:39:56] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.6209958015737695, 'num_leaves': 99, 'bagging_fraction': 0.5393416964350205, 'min_sum_hessian_in_leaf': 0.0016700848666540526, 'reg_alpha': 2.6151948215737332e-06, 'reg_lambda': 0.20475127077577635} scored -14778.969517895299 in 0:00:01.938416\n[14:39:56] Training until validation scores don't improve for 200 rounds\n[14:40:01] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.6622068429146852, 'num_leaves': 114, 'bagging_fraction': 0.5935829679532316, 'min_sum_hessian_in_leaf': 0.0035239343504440217, 'reg_alpha': 0.0006280231672137301, 'reg_lambda': 0.06927770911821172} scored -14510.203358707266 in 0:00:04.758698\n[14:40:01] Training until validation scores don't improve for 200 rounds\n[14:40:03] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5931604743510446, 'num_leaves': 101, 'bagging_fraction': 0.667916446637788, 'min_sum_hessian_in_leaf': 0.00612326628853431, 'reg_alpha': 1.333164183366353e-05, 'reg_lambda': 1.7142569550686997} scored -14454.318376068377 in 0:00:02.854281\n[14:40:04] Training until validation scores don't improve for 200 rounds\n[14:40:07] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.5721808812289184, 'num_leaves': 74, 'bagging_fraction': 0.6470376743687646, 'min_sum_hessian_in_leaf': 0.0017182728927177162, 'reg_alpha': 0.00010064064630824832, 'reg_lambda': 0.6803528572409054} scored -14128.321447649572 in 0:00:03.741119\n[14:40:07] Training until validation scores don't improve for 200 rounds\n[14:40:11] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.6027576457876112, 'num_leaves': 56, 'bagging_fraction': 0.6421020920877304, 'min_sum_hessian_in_leaf': 0.001877354844203189, 'reg_alpha': 8.940617133714539e-05, 'reg_lambda': 0.5447482828773432} scored -14285.220352564103 in 0:00:03.773060\n[14:40:11] Training until validation scores don't improve for 200 rounds\n[14:40:14] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.6326836962403697, 'num_leaves': 58, 'bagging_fraction': 0.5188498188567277, 'min_sum_hessian_in_leaf': 0.001913670196953843, 'reg_alpha': 5.439373861061238e-05, 'reg_lambda': 0.21215819683220047} scored -14572.481036324787 in 0:00:03.137980\n[14:40:14] Training until validation scores don't improve for 200 rounds\n[14:40:16] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.5175487314054277, 'num_leaves': 31, 'bagging_fraction': 0.6396337387406753, 'min_sum_hessian_in_leaf': 0.0010247992328153582, 'reg_alpha': 0.003920622095817866, 'reg_lambda': 4.660144176104289e-05} scored -14332.23140357906 in 0:00:01.743070\n[14:40:16] Training until validation scores don't improve for 200 rounds\n[14:40:19] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.5764779065133137, 'num_leaves': 69, 'bagging_fraction': 0.5801839742942901, 'min_sum_hessian_in_leaf': 0.0014102024475937211, 'reg_alpha': 8.535546226110903e-05, 'reg_lambda': 0.03405430997920261} scored -14455.835737179486 in 0:00:02.833022\n[14:40:19] Training until validation scores don't improve for 200 rounds\n[14:40:22] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.6038608321558158, 'num_leaves': 80, 'bagging_fraction': 0.6914713003109542, 'min_sum_hessian_in_leaf': 0.0019375060385799496, 'reg_alpha': 0.0003318011182018469, 'reg_lambda': 0.8106176030520337} scored -14491.729433760684 in 0:00:03.171140\n[14:40:22] Training until validation scores don't improve for 200 rounds\n[14:40:26] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5879700008097656, 'num_leaves': 54, 'bagging_fraction': 0.6535752895058046, 'min_sum_hessian_in_leaf': 0.008910521061029887, 'reg_alpha': 0.0001290260610480542, 'reg_lambda': 0.5986081678684044} scored -14363.339610042734 in 0:00:03.901635\n[14:40:26] Training until validation scores don't improve for 200 rounds\n[14:40:32] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.6194761593949885, 'num_leaves': 93, 'bagging_fraction': 0.612852566387637, 'min_sum_hessian_in_leaf': 0.0012890918710721396, 'reg_alpha': 1.3410910400960992e-05, 'reg_lambda': 5.951925169514399} scored -14436.814803685897 in 0:00:05.951255\n[14:40:32] Training until validation scores don't improve for 200 rounds\n[14:40:35] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.9690634132749897, 'num_leaves': 76, 'bagging_fraction': 0.6703585557074304, 'min_sum_hessian_in_leaf': 0.0022066875367599517, 'reg_alpha': 4.4730126811518755e-06, 'reg_lambda': 0.11289385091269144} scored -14636.375367254273 in 0:00:03.664296\n[14:40:36] Training until validation scores don't improve for 200 rounds\n[14:40:38] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5516163940683847, 'num_leaves': 42, 'bagging_fraction': 0.6377623244076969, 'min_sum_hessian_in_leaf': 0.003880322589118568, 'reg_alpha': 0.013724013535891326, 'reg_lambda': 1.5035716720350994e-06} scored -14260.724492521367 in 0:00:02.558869\n[14:40:38] Training until validation scores don't improve for 200 rounds\n[14:40:42] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.5539047548997645, 'num_leaves': 35, 'bagging_fraction': 0.6386630510295715, 'min_sum_hessian_in_leaf': 0.004029643128836518, 'reg_alpha': 0.011798846365567162, 'reg_lambda': 3.96270747422451e-06} scored -14293.827390491453 in 0:00:03.730833\n[14:40:42] Training until validation scores don't improve for 200 rounds\n[14:40:45] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.554090842150989, 'num_leaves': 41, 'bagging_fraction': 0.5656691560343001, 'min_sum_hessian_in_leaf': 0.005655910657509174, 'reg_alpha': 0.00048427498204984377, 'reg_lambda': 5.046097789659389e-07} scored -14499.352731036324 in 0:00:02.842022\n[14:40:45] Training until validation scores don't improve for 200 rounds\n[14:40:49] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.787536910338129, 'num_leaves': 65, 'bagging_fraction': 0.5810150614608138, 'min_sum_hessian_in_leaf': 0.0029998566344609677, 'reg_alpha': 0.12232260747125466, 'reg_lambda': 0.00039027321199014653} scored -14541.953859508547 in 0:00:04.050410\n[14:40:49] Training until validation scores don't improve for 200 rounds\n[14:40:52] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.8277733897747781, 'num_leaves': 30, 'bagging_fraction': 0.6000157463592469, 'min_sum_hessian_in_leaf': 0.01518922214740786, 'reg_alpha': 0.027316222217497504, 'reg_lambda': 0.00012025180825029472} scored -14670.37189503205 in 0:00:02.887866\n[14:40:52] Training until validation scores don't improve for 200 rounds\n[14:40:55] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.5006234715579047, 'num_leaves': 17, 'bagging_fraction': 0.6237892622964489, 'min_sum_hessian_in_leaf': 0.001549537567699848, 'reg_alpha': 6.700805264030597e-07, 'reg_lambda': 0.0009168202492874088} scored -14507.379941239316 in 0:00:02.858235\n[14:40:55] Training until validation scores don't improve for 200 rounds\n[14:40:58] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.5495850447230903, 'num_leaves': 36, 'bagging_fraction': 0.6371809450096035, 'min_sum_hessian_in_leaf': 0.0042391735160251034, 'reg_alpha': 0.011546508782979045, 'reg_lambda': 3.0987052072686636e-06} scored -14231.717013888889 in 0:00:03.047714\n[14:40:58] Training until validation scores don't improve for 200 rounds\n[14:41:07] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.5242480960944623, 'num_leaves': 52, 'bagging_fraction': 0.6800195565863331, 'min_sum_hessian_in_leaf': 0.0022503978237879358, 'reg_alpha': 0.5683058913949111, 'reg_lambda': 5.316383769709142e-06} scored -14310.512219551281 in 0:00:08.967778\n[14:41:07] Training until validation scores don't improve for 200 rounds\n[14:41:10] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.5656932845878172, 'num_leaves': 39, 'bagging_fraction': 0.6434925274846898, 'min_sum_hessian_in_leaf': 0.007514546775233604, 'reg_alpha': 0.0018601161531018391, 'reg_lambda': 2.8472944266938836e-06} scored -14104.821547809828 in 0:00:03.739894\n[14:41:10] Training until validation scores don't improve for 200 rounds\n[14:41:13] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.5684315121021262, 'num_leaves': 43, 'bagging_fraction': 0.5524954747884533, 'min_sum_hessian_in_leaf': 0.0073919418047394235, 'reg_alpha': 0.0021559619310195376, 'reg_lambda': 1.7606229052195106e-06} scored -14531.074786324787 in 0:00:03.032102\n[14:41:13] Training until validation scores don't improve for 200 rounds\n[14:41:16] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.5398584605896191, 'num_leaves': 21, 'bagging_fraction': 0.6121759511538606, 'min_sum_hessian_in_leaf': 0.0052175340526885924, 'reg_alpha': 0.0062518157835603815, 'reg_lambda': 1.4296915158369863e-05} scored -14642.921307425213 in 0:00:02.876143\n[14:41:16] Training until validation scores don't improve for 200 rounds\n[14:41:20] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.5492031308607285, 'num_leaves': 36, 'bagging_fraction': 0.6913890641101063, 'min_sum_hessian_in_leaf': 0.009573320200010118, 'reg_alpha': 0.01660908783540656, 'reg_lambda': 2.6768363961911464e-07} scored -14419.544437767094 in 0:00:03.625966\n[14:41:20] Training until validation scores don't improve for 200 rounds\n[14:41:24] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.5116684699238548, 'num_leaves': 87, 'bagging_fraction': 0.6614693210661503, 'min_sum_hessian_in_leaf': 0.0032010139654474563, 'reg_alpha': 0.09814737259062872, 'reg_lambda': 6.213321763788111e-08} scored -14399.93048878205 in 0:00:03.814945\n[14:41:24] Training until validation scores don't improve for 200 rounds\n[14:41:27] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.5797064469626256, 'num_leaves': 26, 'bagging_fraction': 0.5867886034028816, 'min_sum_hessian_in_leaf': 0.004013881401088681, 'reg_alpha': 0.004420301831066064, 'reg_lambda': 1.3630135048330802e-06} scored -14475.89015758547 in 0:00:02.991747\n[14:41:27] Training until validation scores don't improve for 200 rounds\n[14:41:30] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.529231959412494, 'num_leaves': 72, 'bagging_fraction': 0.7192250876764772, 'min_sum_hessian_in_leaf': 0.0012193321573827692, 'reg_alpha': 0.0006593977433925355, 'reg_lambda': 2.3187075603285575e-06} scored -14512.170973557691 in 0:00:02.967070\n[14:41:30] Training until validation scores don't improve for 200 rounds\n[14:41:32] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.567358469108686, 'num_leaves': 65, 'bagging_fraction': 0.6013537142546411, 'min_sum_hessian_in_leaf': 0.011572590231301817, 'reg_alpha': 0.001405084871762093, 'reg_lambda': 1.8672493688472983e-05} scored -14595.857438568377 in 0:00:02.557287\n[14:41:32] Training until validation scores don't improve for 200 rounds\n[14:41:36] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.6061464594553722, 'num_leaves': 49, 'bagging_fraction': 0.6439031602346668, 'min_sum_hessian_in_leaf': 0.0019046495027947568, 'reg_alpha': 3.341652912848569e-05, 'reg_lambda': 7.072231950184447e-07} scored -14472.69875133547 in 0:00:03.879976\n[14:41:36] Training until validation scores don't improve for 200 rounds\n[14:41:40] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5882122825708179, 'num_leaves': 62, 'bagging_fraction': 0.6333936882920755, 'min_sum_hessian_in_leaf': 0.002232898172165314, 'reg_alpha': 0.03596575198994988, 'reg_lambda': 1.8161701669514232} scored -14246.616519764957 in 0:00:03.719614\n[14:41:40] Training until validation scores don't improve for 200 rounds\n[14:41:42] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.5820395244897021, 'num_leaves': 61, 'bagging_fraction': 0.6255691742814512, 'min_sum_hessian_in_leaf': 0.0025447268447201534, 'reg_alpha': 0.040502066204968774, 'reg_lambda': 1.0567766942564716e-05} scored -14357.021601228633 in 0:00:02.333897\n[14:41:42] Training until validation scores don't improve for 200 rounds\n[14:41:45] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.5592017001064713, 'num_leaves': 84, 'bagging_fraction': 0.6779768332044899, 'min_sum_hessian_in_leaf': 0.003376316042774258, 'reg_alpha': 0.009757557990055642, 'reg_lambda': 1.6537727447430421} scored -14357.248530982906 in 0:00:02.932128\n[14:41:45] Training until validation scores don't improve for 200 rounds\n[14:41:47] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.5450595564197765, 'num_leaves': 95, 'bagging_fraction': 0.613728932322905, 'min_sum_hessian_in_leaf': 0.004926883292110494, 'reg_alpha': 0.27516500823699497, 'reg_lambda': 4.340076997512488e-05} scored -14517.507311698719 in 0:00:02.164312\n[14:41:48] Training until validation scores don't improve for 200 rounds\n[14:41:51] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.6550771507053119, 'num_leaves': 105, 'bagging_fraction': 0.9895810892549581, 'min_sum_hessian_in_leaf': 0.0010055652656005465, 'reg_alpha': 0.0025941424823058236, 'reg_lambda': 2.899719679953197e-07} scored -14760.660590277777 in 0:00:03.846662\n[14:41:51] Training until validation scores don't improve for 200 rounds\n[14:41:55] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.6263579973307154, 'num_leaves': 122, 'bagging_fraction': 0.6359794821974195, 'min_sum_hessian_in_leaf': 0.006908253861466705, 'reg_alpha': 0.03388391073708085, 'reg_lambda': 0.29843240326865633} scored -14406.50110176282 in 0:00:03.633688\n[14:41:55] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[14:41:55] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5656932845878172, 'num_leaves': 39, 'bagging_fraction': 0.6434925274846898, 'min_sum_hessian_in_leaf': 0.007514546775233604, 'reg_alpha': 0.0018601161531018391, 'reg_lambda': 2.8472944266938836e-06}\u001b[0m\n achieve -14104.8215 mae\n[14:41:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[14:41:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:41:55] Training until validation scores don't improve for 100 rounds\n[14:41:56] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:41:56] Training until validation scores don't improve for 100 rounds\n[14:41:56] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:41:56] Training until validation scores don't improve for 100 rounds\n[14:41:57] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:41:57] Training until validation scores don't improve for 100 rounds\n[14:41:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:41:57] Training until validation scores don't improve for 100 rounds\n[14:41:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15775.253190550085\u001b[0m\n[14:41:58] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[14:41:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[14:41:58] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:41:58] 0:\tlearn: 55751.0386124\ttest: 48610.5577016\tbest: 48610.5577016 (0)\ttotal: 2.54ms\tremaining: 5.08s\n[14:42:01] Stopped by overfitting detector  (300 iterations wait)\n[14:42:01] bestTest = 13921.76137\n[14:42:01] bestIteration = 1372\n[14:42:01] Shrink model to first 1373 iterations.\n[14:42:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:42:01] 0:\tlearn: 53100.1067655\ttest: 57125.0123442\tbest: 57125.0123442 (0)\ttotal: 2.71ms\tremaining: 5.42s\n[14:42:03] Stopped by overfitting detector  (300 iterations wait)\n[14:42:03] bestTest = 16008.52125\n[14:42:03] bestIteration = 832\n[14:42:03] Shrink model to first 833 iterations.\n[14:42:03] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:42:03] 0:\tlearn: 54832.6246711\ttest: 52810.7456864\tbest: 52810.7456864 (0)\ttotal: 2.79ms\tremaining: 5.57s\n[14:42:06] Stopped by overfitting detector  (300 iterations wait)\n[14:42:06] bestTest = 16324.30467\n[14:42:06] bestIteration = 992\n[14:42:06] Shrink model to first 993 iterations.\n[14:42:06] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:42:06] 0:\tlearn: 53258.5435468\ttest: 57522.8702638\tbest: 57522.8702638 (0)\ttotal: 3.46ms\tremaining: 6.91s\n[14:42:08] Stopped by overfitting detector  (300 iterations wait)\n[14:42:08] bestTest = 13940.95731\n[14:42:08] bestIteration = 683\n[14:42:08] Shrink model to first 684 iterations.\n[14:42:08] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:42:09] 0:\tlearn: 53835.0494839\ttest: 55576.6900569\tbest: 55576.6900569 (0)\ttotal: 2.98ms\tremaining: 5.96s\n[14:42:12] bestTest = 15149.08066\n[14:42:12] bestIteration = 1994\n[14:42:12] Shrink model to first 1995 iterations.\n[14:42:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15069.822489699272\u001b[0m\n[14:42:12] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[14:42:12] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[14:42:13] 0:\tlearn: 55744.4747867\ttest: 48572.6955519\tbest: 48572.6955519 (0)\ttotal: 1.97ms\tremaining: 3.93s\n[14:42:14] Stopped by overfitting detector  (300 iterations wait)\n[14:42:14] bestTest = 14109.20659\n[14:42:14] bestIteration = 598\n[14:42:14] Shrink model to first 599 iterations.\n[14:42:14] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -14114.330194978633 in 0:00:01.470927\n[14:42:14] 0:\tlearn: 56053.3656767\ttest: 48911.7788003\tbest: 48911.7788003 (0)\ttotal: 1.22ms\tremaining: 2.43s\n[14:42:16] Stopped by overfitting detector  (300 iterations wait)\n[14:42:16] bestTest = 14277.44493\n[14:42:16] bestIteration = 1268\n[14:42:16] Shrink model to first 1269 iterations.\n[14:42:16] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -14277.445279113248 in 0:00:01.839955\n[14:42:16] 0:\tlearn: 56053.3249298\ttest: 48911.7505309\tbest: 48911.7505309 (0)\ttotal: 1.26ms\tremaining: 2.52s\n[14:42:18] bestTest = 14179.10428\n[14:42:18] bestIteration = 1916\n[14:42:18] Shrink model to first 1917 iterations.\n[14:42:18] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -14179.10466746795 in 0:00:02.338336\n[14:42:18] 0:\tlearn: 56053.3261407\ttest: 48911.7513710\tbest: 48911.7513710 (0)\ttotal: 1.2ms\tremaining: 2.4s\n[14:42:20] Stopped by overfitting detector  (300 iterations wait)\n[14:42:20] bestTest = 14505.50368\n[14:42:20] bestIteration = 952\n[14:42:20] Shrink model to first 953 iterations.\n[14:42:20] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -14505.503872863248 in 0:00:01.477253\n[14:42:20] 0:\tlearn: 55751.1782604\ttest: 48652.3968611\tbest: 48652.3968611 (0)\ttotal: 4.21ms\tremaining: 8.43s\n[14:42:23] Stopped by overfitting detector  (300 iterations wait)\n[14:42:23] bestTest = 13774.79774\n[14:42:23] bestIteration = 1012\n[14:42:23] Shrink model to first 1013 iterations.\n[14:42:23] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -13774.798010149572 in 0:00:03.757899\n[14:42:24] 0:\tlearn: 55751.4048660\ttest: 48652.4683543\tbest: 48652.4683543 (0)\ttotal: 3.12ms\tremaining: 6.23s\n[14:42:26] Stopped by overfitting detector  (300 iterations wait)\n[14:42:26] bestTest = 13839.52638\n[14:42:26] bestIteration = 628\n[14:42:26] Shrink model to first 629 iterations.\n[14:42:26] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -13839.526141826924 in 0:00:02.936545\n[14:42:27] 0:\tlearn: 55891.8272844\ttest: 48820.2493070\tbest: 48820.2493070 (0)\ttotal: 4.49ms\tremaining: 8.98s\n[14:42:30] Stopped by overfitting detector  (300 iterations wait)\n[14:42:30] bestTest = 13936.26677\n[14:42:30] bestIteration = 1223\n[14:42:30] Shrink model to first 1224 iterations.\n[14:42:31] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -13936.759181356838 in 0:00:04.184229\n[14:42:31] 0:\tlearn: 55719.4499483\ttest: 48606.3944449\tbest: 48606.3944449 (0)\ttotal: 4.85ms\tremaining: 9.7s\n[14:42:36] Stopped by overfitting detector  (300 iterations wait)\n[14:42:36] bestTest = 14263.68047\n[14:42:36] bestIteration = 1115\n[14:42:36] Shrink model to first 1116 iterations.\n[14:42:36] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -14247.151375534188 in 0:00:05.698926\n[14:42:36] 0:\tlearn: 56077.0771643\ttest: 48928.6899165\tbest: 48928.6899165 (0)\ttotal: 1.29ms\tremaining: 2.57s\n[14:42:39] Stopped by overfitting detector  (300 iterations wait)\n[14:42:39] bestTest = 14424.53793\n[14:42:39] bestIteration = 1667\n[14:42:39] Shrink model to first 1668 iterations.\n[14:42:39] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -14424.537459935897 in 0:00:02.526123\n[14:42:39] 0:\tlearn: 55751.2649033\ttest: 48652.4241835\tbest: 48652.4241835 (0)\ttotal: 3.69ms\tremaining: 7.37s\n[14:42:43] Stopped by overfitting detector  (300 iterations wait)\n[14:42:43] bestTest = 13893.55952\n[14:42:43] bestIteration = 992\n[14:42:43] Shrink model to first 993 iterations.\n[14:42:43] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -13893.559361645299 in 0:00:03.801195\n[14:42:43] 0:\tlearn: 55750.4350661\ttest: 48610.3653920\tbest: 48610.3653920 (0)\ttotal: 2.19ms\tremaining: 4.39s\n[14:42:45] Stopped by overfitting detector  (300 iterations wait)\n[14:42:45] bestTest = 13778.99706\n[14:42:45] bestIteration = 1005\n[14:42:45] Shrink model to first 1006 iterations.\n[14:42:45] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 13} scored -13778.996828258547 in 0:00:02.718395\n[14:42:45] 0:\tlearn: 55750.4350662\ttest: 48610.3653920\tbest: 48610.3653920 (0)\ttotal: 2.27ms\tremaining: 4.53s\n[14:42:48] Stopped by overfitting detector  (300 iterations wait)\n[14:42:48] bestTest = 13778.99706\n[14:42:48] bestIteration = 1005\n[14:42:48] Shrink model to first 1006 iterations.\n[14:42:48] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3815073407783029e-08, 'min_data_in_leaf': 13} scored -13778.996828258547 in 0:00:02.727554\n[14:42:48] 0:\tlearn: 55750.4350662\ttest: 48610.3653920\tbest: 48610.3653920 (0)\ttotal: 2.17ms\tremaining: 4.33s\n[14:42:51] Stopped by overfitting detector  (300 iterations wait)\n[14:42:51] bestTest = 13778.99706\n[14:42:51] bestIteration = 1005\n[14:42:51] Shrink model to first 1006 iterations.\n[14:42:51] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2820587907159323e-08, 'min_data_in_leaf': 12} scored -13778.996828258547 in 0:00:02.730391\n[14:42:51] 0:\tlearn: 55717.2988677\ttest: 48605.2849566\tbest: 48605.2849566 (0)\ttotal: 4.35ms\tremaining: 8.7s\n[14:42:55] Stopped by overfitting detector  (300 iterations wait)\n[14:42:55] bestTest = 14353.4041\n[14:42:55] bestIteration = 855\n[14:42:55] Shrink model to first 856 iterations.\n[14:42:56] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 4.183377121911168e-06, 'min_data_in_leaf': 16} scored -14353.403979700855 in 0:00:04.753077\n[14:42:56] 0:\tlearn: 55744.3796105\ttest: 48572.6506483\tbest: 48572.6506483 (0)\ttotal: 1.66ms\tremaining: 3.32s\n[14:42:59] bestTest = 13820.07133\n[14:42:59] bestIteration = 1999\n[14:42:59] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 6.018589232494447e-07, 'min_data_in_leaf': 9} scored -13820.07111378205 in 0:00:03.061200\n[14:42:59] 0:\tlearn: 55750.4354235\ttest: 48610.3655056\tbest: 48610.3655056 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[14:43:01] Stopped by overfitting detector  (300 iterations wait)\n[14:43:01] bestTest = 13778.99679\n[14:43:01] bestIteration = 1005\n[14:43:01] Shrink model to first 1006 iterations.\n[14:43:01] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.923549977797673e-06, 'min_data_in_leaf': 18} scored -13778.996761485043 in 0:00:02.759308\n[14:43:02] 0:\tlearn: 55751.1789441\ttest: 48652.3970766\tbest: 48652.3970766 (0)\ttotal: 3.01ms\tremaining: 6.01s\n[14:43:05] Stopped by overfitting detector  (300 iterations wait)\n[14:43:05] bestTest = 13774.79639\n[14:43:05] bestIteration = 1012\n[14:43:05] Shrink model to first 1013 iterations.\n[14:43:05] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.6237827783921903e-05, 'min_data_in_leaf': 20} scored -13774.796774839744 in 0:00:03.703055\n[14:43:05] 0:\tlearn: 55751.1817008\ttest: 48652.3979457\tbest: 48652.3979457 (0)\ttotal: 2.88ms\tremaining: 5.77s\n[14:43:09] Stopped by overfitting detector  (300 iterations wait)\n[14:43:09] bestTest = 13774.79096\n[14:43:09] bestIteration = 1012\n[14:43:09] Shrink model to first 1013 iterations.\n[14:43:09] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 5.20869762003628e-05, 'min_data_in_leaf': 10} scored -13774.790698450855 in 0:00:03.672543\n[14:43:09] 0:\tlearn: 55730.5008350\ttest: 48612.1413426\tbest: 48612.1413426 (0)\ttotal: 4.64ms\tremaining: 9.28s\n[14:43:13] Stopped by overfitting detector  (300 iterations wait)\n[14:43:13] bestTest = 14152.07266\n[14:43:13] bestIteration = 716\n[14:43:13] Shrink model to first 717 iterations.\n[14:43:13] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.09108166383441309, 'min_data_in_leaf': 20} scored -14152.072682959402 in 0:00:04.652307\n[14:43:14] 0:\tlearn: 55751.1915264\ttest: 48652.4010434\tbest: 48652.4010434 (0)\ttotal: 3.02ms\tremaining: 6.04s\n[14:43:17] Stopped by overfitting detector  (300 iterations wait)\n[14:43:17] bestTest = 13774.77158\n[14:43:17] bestIteration = 1012\n[14:43:17] Shrink model to first 1013 iterations.\n[14:43:17] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00014422243561457965, 'min_data_in_leaf': 15} scored -13774.771467681623 in 0:00:03.682304\n[14:43:17] 0:\tlearn: 55744.3886786\ttest: 48572.6549257\tbest: 48572.6549257 (0)\ttotal: 1.58ms\tremaining: 3.17s\n[14:43:20] Stopped by overfitting detector  (300 iterations wait)\n[14:43:20] bestTest = 13819.64672\n[14:43:20] bestIteration = 1307\n[14:43:20] Shrink model to first 1308 iterations.\n[14:43:20] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00023323394909551925, 'min_data_in_leaf': 16} scored -13819.64673477564 in 0:00:02.511180\n[14:43:20] 0:\tlearn: 55751.1828536\ttest: 48652.3983091\tbest: 48652.3983091 (0)\ttotal: 3.08ms\tremaining: 6.15s\n[14:43:23] Stopped by overfitting detector  (300 iterations wait)\n[14:43:23] bestTest = 13774.78868\n[14:43:23] bestIteration = 1012\n[14:43:23] Shrink model to first 1013 iterations.\n[14:43:23] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 6.289636617943233e-05, 'min_data_in_leaf': 18} scored -13774.788561698719 in 0:00:03.731439\n[14:43:24] 0:\tlearn: 55751.2038282\ttest: 48652.4049221\tbest: 48652.4049221 (0)\ttotal: 3.69ms\tremaining: 7.38s\n[14:43:28] Stopped by overfitting detector  (300 iterations wait)\n[14:43:28] bestTest = 13891.02851\n[14:43:28] bestIteration = 1553\n[14:43:28] Shrink model to first 1554 iterations.\n[14:43:29] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0002595887757063849, 'min_data_in_leaf': 18} scored -13891.028679220086 in 0:00:05.150008\n[14:43:29] 0:\tlearn: 55717.2982908\ttest: 48605.2846595\tbest: 48605.2846595 (0)\ttotal: 5.2ms\tremaining: 10.4s\n[14:43:33] Stopped by overfitting detector  (300 iterations wait)\n[14:43:33] bestTest = 14353.40401\n[14:43:33] bestIteration = 855\n[14:43:33] Shrink model to first 856 iterations.\n[14:43:33] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 3.4831857502020587e-07, 'min_data_in_leaf': 15} scored -14353.40421340812 in 0:00:04.964131\n[14:43:34] 0:\tlearn: 55754.4542256\ttest: 48653.4411533\tbest: 48653.4411533 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[14:43:36] Stopped by overfitting detector  (300 iterations wait)\n[14:43:36] bestTest = 13524.94407\n[14:43:36] bestIteration = 654\n[14:43:36] Shrink model to first 655 iterations.\n[14:43:36] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.031133641645417234, 'min_data_in_leaf': 12} scored -13524.944077190172 in 0:00:02.730428\n[14:43:36] 0:\tlearn: 55732.3474221\ttest: 48613.1094963\tbest: 48613.1094963 (0)\ttotal: 4.13ms\tremaining: 8.27s\n[14:43:42] Stopped by overfitting detector  (300 iterations wait)\n[14:43:42] bestTest = 14551.90894\n[14:43:42] bestIteration = 1143\n[14:43:42] Shrink model to first 1144 iterations.\n[14:43:42] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.10435365780987681, 'min_data_in_leaf': 18} scored -14551.908854166666 in 0:00:05.860715\n[14:43:42] 0:\tlearn: 55754.3059818\ttest: 48653.3933995\tbest: 48653.3933995 (0)\ttotal: 2.92ms\tremaining: 5.85s\n[14:43:46] Stopped by overfitting detector  (300 iterations wait)\n[14:43:46] bestTest = 14110.27787\n[14:43:46] bestIteration = 971\n[14:43:46] Shrink model to first 972 iterations.\n[14:43:46] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.029708517757829896, 'min_data_in_leaf': 12} scored -14110.028679220086 in 0:00:04.104225\n[14:43:46] 0:\tlearn: 55791.5710353\ttest: 48625.4725227\tbest: 48625.4725227 (0)\ttotal: 2.12ms\tremaining: 4.24s\n[14:43:50] Stopped by overfitting detector  (300 iterations wait)\n[14:43:50] bestTest = 13447.74322\n[14:43:50] bestIteration = 1585\n[14:43:50] Shrink model to first 1586 iterations.\n[14:43:50] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.7604421202662073, 'min_data_in_leaf': 14} scored -13447.743189102564 in 0:00:03.901223\n[14:43:50] 0:\tlearn: 55782.1035549\ttest: 48621.6864005\tbest: 48621.6864005 (0)\ttotal: 2.52ms\tremaining: 5.04s\n[14:43:54] bestTest = 13495.30071\n[14:43:54] bestIteration = 1902\n[14:43:54] Shrink model to first 1903 iterations.\n[14:43:54] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.5715754700747747, 'min_data_in_leaf': 14} scored -13495.300881410256 in 0:00:04.148844\n[14:43:54] 0:\tlearn: 55784.9608266\ttest: 48622.8121245\tbest: 48622.8121245 (0)\ttotal: 2.38ms\tremaining: 4.76s\n[14:43:57] Stopped by overfitting detector  (300 iterations wait)\n[14:43:57] bestTest = 13835.4114\n[14:43:57] bestIteration = 1113\n[14:43:57] Shrink model to first 1114 iterations.\n[14:43:57] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.6277210875181715, 'min_data_in_leaf': 13} scored -13835.411224626068 in 0:00:02.938966\n[14:43:57] 0:\tlearn: 56168.9697820\ttest: 48940.4756303\tbest: 48940.4756303 (0)\ttotal: 1.72ms\tremaining: 3.43s\n[14:44:00] bestTest = 13776.38611\n[14:44:00] bestIteration = 1997\n[14:44:00] Shrink model to first 1998 iterations.\n[14:44:00] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 7.74528691790928, 'min_data_in_leaf': 8} scored -13776.385683760684 in 0:00:03.050045\n[14:44:00] 0:\tlearn: 55769.3883388\ttest: 48616.8684314\tbest: 48616.8684314 (0)\ttotal: 2.43ms\tremaining: 4.86s\n[14:44:04] bestTest = 13756.34022\n[14:44:04] bestIteration = 1862\n[14:44:04] Shrink model to first 1863 iterations.\n[14:44:04] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.330783311670112, 'min_data_in_leaf': 14} scored -13756.339877136752 in 0:00:04.121240\n[14:44:05] 0:\tlearn: 55773.5872891\ttest: 48618.4233405\tbest: 48618.4233405 (0)\ttotal: 2.34ms\tremaining: 4.67s\n[14:44:08] Stopped by overfitting detector  (300 iterations wait)\n[14:44:08] bestTest = 13900.17021\n[14:44:08] bestIteration = 1431\n[14:44:08] Shrink model to first 1432 iterations.\n[14:44:08] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4086523438553717, 'min_data_in_leaf': 14} scored -13900.170339209402 in 0:00:03.559647\n[14:44:08] 0:\tlearn: 55744.7805981\ttest: 48572.8399652\tbest: 48572.8399652 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[14:44:10] Stopped by overfitting detector  (300 iterations wait)\n[14:44:10] bestTest = 13825.99657\n[14:44:10] bestIteration = 1200\n[14:44:10] Shrink model to first 1201 iterations.\n[14:44:10] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.010302409363783679, 'min_data_in_leaf': 11} scored -13825.996928418803 in 0:00:02.369738\n[14:44:11] 0:\tlearn: 55767.9710577\ttest: 48616.3521284\tbest: 48616.3521284 (0)\ttotal: 2.25ms\tremaining: 4.5s\n[14:44:14] Stopped by overfitting detector  (300 iterations wait)\n[14:44:14] bestTest = 13746.34934\n[14:44:14] bestIteration = 1487\n[14:44:14] Shrink model to first 1488 iterations.\n[14:44:14] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.3048702274000228, 'min_data_in_leaf': 16} scored -13746.349626068377 in 0:00:03.700261\n[14:44:14] 0:\tlearn: 55756.4990878\ttest: 48612.3453316\tbest: 48612.3453316 (0)\ttotal: 2.14ms\tremaining: 4.27s\n[14:44:17] Stopped by overfitting detector  (300 iterations wait)\n[14:44:17] bestTest = 13975.68999\n[14:44:17] bestIteration = 722\n[14:44:17] Shrink model to first 723 iterations.\n[14:44:17] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.10208944520918796, 'min_data_in_leaf': 16} scored -13975.689970619658 in 0:00:02.523714\n[14:44:17] 0:\tlearn: 55795.2553606\ttest: 48626.9880044\tbest: 48626.9880044 (0)\ttotal: 2.62ms\tremaining: 5.23s\n[14:44:20] Stopped by overfitting detector  (300 iterations wait)\n[14:44:20] bestTest = 13399.08232\n[14:44:20] bestIteration = 1496\n[14:44:20] Shrink model to first 1497 iterations.\n[14:44:20] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.8361210701855486, 'min_data_in_leaf': 11} scored -13399.082264957266 in 0:00:03.725346\n[14:44:21] 0:\tlearn: 56211.4328899\ttest: 48973.3959296\tbest: 48973.3959296 (0)\ttotal: 1.87ms\tremaining: 3.74s\n[14:44:23] bestTest = 13991.01581\n[14:44:23] bestIteration = 1999\n[14:44:23] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 9.73058849817012, 'min_data_in_leaf': 11} scored -13991.015658386752 in 0:00:03.061707\n[14:44:24] 0:\tlearn: 55834.2829971\ttest: 48644.3165692\tbest: 48644.3165692 (0)\ttotal: 2.29ms\tremaining: 4.58s\n[14:44:27] Stopped by overfitting detector  (300 iterations wait)\n[14:44:27] bestTest = 13728.62456\n[14:44:27] bestIteration = 1453\n[14:44:27] Shrink model to first 1454 iterations.\n[14:44:27] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.7112727444010971, 'min_data_in_leaf': 7} scored -13728.62419871795 in 0:00:03.561124\n[14:44:27] 0:\tlearn: 55750.7927199\ttest: 48610.4792203\tbest: 48610.4792203 (0)\ttotal: 2.1ms\tremaining: 4.19s\n[14:44:29] Stopped by overfitting detector  (300 iterations wait)\n[14:44:29] bestTest = 14472.65412\n[14:44:29] bestIteration = 517\n[14:44:29] Shrink model to first 518 iterations.\n[14:44:29] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0059215538598838815, 'min_data_in_leaf': 12} scored -14472.654113247863 in 0:00:01.744795\n[14:44:29] 0:\tlearn: 55745.7978777\ttest: 48573.3218078\tbest: 48573.3218078 (0)\ttotal: 1.64ms\tremaining: 3.29s\n[14:44:32] Stopped by overfitting detector  (300 iterations wait)\n[14:44:32] bestTest = 13703.88907\n[14:44:32] bestIteration = 1499\n[14:44:32] Shrink model to first 1500 iterations.\n[14:44:32] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.03657370735900002, 'min_data_in_leaf': 9} scored -13703.88858840812 in 0:00:03.069829\n[14:44:32] 0:\tlearn: 55746.1814771\ttest: 48573.5040771\tbest: 48573.5040771 (0)\ttotal: 1.58ms\tremaining: 3.15s\n[14:44:34] Stopped by overfitting detector  (300 iterations wait)\n[14:44:34] bestTest = 13932.43424\n[14:44:34] bestIteration = 1022\n[14:44:34] Shrink model to first 1023 iterations.\n[14:44:34] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04653049352432379, 'min_data_in_leaf': 9} scored -13932.433627136752 in 0:00:02.085204\n[14:44:34] 0:\tlearn: 56074.3160569\ttest: 48926.6844343\tbest: 48926.6844343 (0)\ttotal: 1.23ms\tremaining: 2.46s\n[14:44:36] Stopped by overfitting detector  (300 iterations wait)\n[14:44:36] bestTest = 14352.10201\n[14:44:36] bestIteration = 1615\n[14:44:36] Shrink model to first 1616 iterations.\n[14:44:36] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3467323000747136, 'min_data_in_leaf': 11} scored -14352.101896367521 in 0:00:02.221382\n[14:44:36] 0:\tlearn: 55744.5025754\ttest: 48572.7086661\tbest: 48572.7086661 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:44:38] Stopped by overfitting detector  (300 iterations wait)\n[14:44:38] bestTest = 13973.41777\n[14:44:38] bestIteration = 912\n[14:44:38] Shrink model to first 913 iterations.\n[14:44:38] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.003156453072204763, 'min_data_in_leaf': 8} scored -13973.417601495727 in 0:00:01.964919\n[14:44:38] 0:\tlearn: 56105.2946286\ttest: 48949.5962444\tbest: 48949.5962444 (0)\ttotal: 1.26ms\tremaining: 2.52s\n[14:44:40] Stopped by overfitting detector  (300 iterations wait)\n[14:44:40] bestTest = 14520.83045\n[14:44:40] bestIteration = 1613\n[14:44:40] Shrink model to first 1614 iterations.\n[14:44:40] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 3.413366071160021, 'min_data_in_leaf': 14} scored -14520.831296741453 in 0:00:02.195829\n[14:44:41] 0:\tlearn: 55752.9111069\ttest: 48611.1611905\tbest: 48611.1611905 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[14:44:43] Stopped by overfitting detector  (300 iterations wait)\n[14:44:43] bestTest = 13932.30875\n[14:44:43] bestIteration = 1014\n[14:44:43] Shrink model to first 1015 iterations.\n[14:44:43] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04125211921449582, 'min_data_in_leaf': 10} scored -13932.308493589744 in 0:00:02.793338\n[14:44:43] 0:\tlearn: 55750.5330285\ttest: 48610.3965316\tbest: 48610.3965316 (0)\ttotal: 2.12ms\tremaining: 4.23s\n[14:44:47] Stopped by overfitting detector  (300 iterations wait)\n[14:44:47] bestTest = 13755.71829\n[14:44:47] bestIteration = 1657\n[14:44:47] Shrink model to first 1658 iterations.\n[14:44:47] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001620687033399177, 'min_data_in_leaf': 5} scored -13755.718416132479 in 0:00:04.009226\n[14:44:47] 0:\tlearn: 55752.3993044\ttest: 48576.5007234\tbest: 48576.5007234 (0)\ttotal: 1.59ms\tremaining: 3.19s\n[14:44:50] Stopped by overfitting detector  (300 iterations wait)\n[14:44:50] bestTest = 13766.84378\n[14:44:50] bestIteration = 1491\n[14:44:50] Shrink model to first 1492 iterations.\n[14:44:50] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.21163132405513443, 'min_data_in_leaf': 12} scored -13766.843616452992 in 0:00:03.138398\n[14:44:50] 0:\tlearn: 55795.8262936\ttest: 48627.2248759\tbest: 48627.2248759 (0)\ttotal: 2.14ms\tremaining: 4.28s\n[14:44:52] Stopped by overfitting detector  (300 iterations wait)\n[14:44:52] bestTest = 13941.25075\n[14:44:52] bestIteration = 690\n[14:44:52] Shrink model to first 691 iterations.\n[14:44:52] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.8479571496488937, 'min_data_in_leaf': 13} scored -13942.543836805555 in 0:00:02.152895\n[14:44:53] 0:\tlearn: 55891.5468511\ttest: 48819.9946483\tbest: 48819.9946483 (0)\ttotal: 3.11ms\tremaining: 6.22s\n[14:44:57] Stopped by overfitting detector  (300 iterations wait)\n[14:44:57] bestTest = 13703.00197\n[14:44:57] bestIteration = 1443\n[14:44:57] Shrink model to first 1444 iterations.\n[14:44:57] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.4615380284656774, 'min_data_in_leaf': 8} scored -13703.002236912393 in 0:00:04.845706\n[14:44:58] 0:\tlearn: 55830.7900385\ttest: 48668.4323480\tbest: 48668.4323480 (0)\ttotal: 3.05ms\tremaining: 6.1s\n[14:45:03] Stopped by overfitting detector  (300 iterations wait)\n[14:45:03] bestTest = 13483.03264\n[14:45:03] bestIteration = 1620\n[14:45:03] Shrink model to first 1621 iterations.\n[14:45:03] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.4670819546163165, 'min_data_in_leaf': 1} scored -13483.03295272436 in 0:00:05.339701\n[14:45:03] 0:\tlearn: 55889.8649846\ttest: 48818.4668476\tbest: 48818.4668476 (0)\ttotal: 3.05ms\tremaining: 6.09s\n[14:45:06] Stopped by overfitting detector  (300 iterations wait)\n[14:45:06] bestTest = 13812.67198\n[14:45:06] bestIteration = 807\n[14:45:06] Shrink model to first 808 iterations.\n[14:45:06] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.4280822175767867, 'min_data_in_leaf': 1} scored -13812.671975160256 in 0:00:03.141906\n[14:45:06] 0:\tlearn: 55836.4616385\ttest: 48671.1580028\tbest: 48671.1580028 (0)\ttotal: 2.86ms\tremaining: 5.72s\n[14:45:09] Stopped by overfitting detector  (300 iterations wait)\n[14:45:09] bestTest = 13582.14286\n[14:45:09] bestIteration = 907\n[14:45:09] Shrink model to first 908 iterations.\n[14:45:09] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5724860834221164, 'min_data_in_leaf': 4} scored -13582.142427884615 in 0:00:03.415132\n[14:45:09] 0:\tlearn: 55830.3506384\ttest: 48668.2225667\tbest: 48668.2225667 (0)\ttotal: 2.84ms\tremaining: 5.69s\n[14:45:15] bestTest = 13363.23095\n[14:45:15] bestIteration = 1886\n[14:45:15] Shrink model to first 1887 iterations.\n[14:45:15] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.4590005918163609, 'min_data_in_leaf': 4} scored -13363.231103098291 in 0:00:05.574716\n[14:45:15] 0:\tlearn: 55766.4809247\ttest: 48657.4708829\tbest: 48657.4708829 (0)\ttotal: 3.36ms\tremaining: 6.71s\n[14:45:18] Stopped by overfitting detector  (300 iterations wait)\n[14:45:18] bestTest = 13614.89789\n[14:45:18] bestIteration = 875\n[14:45:18] Shrink model to first 876 iterations.\n[14:45:18] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.15221493100921366, 'min_data_in_leaf': 3} scored -13614.89813701923 in 0:00:03.338795\n[14:45:18] 0:\tlearn: 55812.3878939\ttest: 48659.8164802\tbest: 48659.8164802 (0)\ttotal: 2.85ms\tremaining: 5.69s\n[14:45:24] bestTest = 13575.41184\n[14:45:24] bestIteration = 1849\n[14:45:24] Shrink model to first 1850 iterations.\n[14:45:24] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1389208237449608, 'min_data_in_leaf': 2} scored -13575.411458333334 in 0:00:06.113918\n[14:45:25] 0:\tlearn: 55782.6553092\ttest: 48646.7330508\tbest: 48646.7330508 (0)\ttotal: 3.02ms\tremaining: 6.03s\n[14:45:30] bestTest = 13936.06535\n[14:45:30] bestIteration = 1998\n[14:45:30] Shrink model to first 1999 iterations.\n[14:45:30] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.6560027250861861, 'min_data_in_leaf': 2} scored -13936.06530448718 in 0:00:05.580790\n[14:45:30] 0:\tlearn: 56146.8953901\ttest: 49013.8461667\tbest: 49013.8461667 (0)\ttotal: 4.89ms\tremaining: 9.78s\n[14:45:34] Stopped by overfitting detector  (300 iterations wait)\n[14:45:34] bestTest = 14403.68094\n[14:45:34] bestIteration = 687\n[14:45:34] Shrink model to first 688 iterations.\n[14:45:34] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 5.916890243569614, 'min_data_in_leaf': 5} scored -14403.680422008547 in 0:00:04.311851\n[14:45:34] 0:\tlearn: 55881.1346618\ttest: 48693.7057394\tbest: 48693.7057394 (0)\ttotal: 3.03ms\tremaining: 6.06s\n[14:45:39] Stopped by overfitting detector  (300 iterations wait)\n[14:45:39] bestTest = 13511.17259\n[14:45:39] bestIteration = 1544\n[14:45:39] Shrink model to first 1545 iterations.\n[14:45:39] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.472189982495428, 'min_data_in_leaf': 3} scored -13511.172843215812 in 0:00:05.105442\n[14:45:40] 0:\tlearn: 55874.9395037\ttest: 48664.4999614\tbest: 48664.4999614 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[14:45:42] Stopped by overfitting detector  (300 iterations wait)\n[14:45:42] bestTest = 13476.20377\n[14:45:42] bestIteration = 980\n[14:45:42] Shrink model to first 981 iterations.\n[14:45:42] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.7626385079727003, 'min_data_in_leaf': 2} scored -13476.203759348291 in 0:00:02.675706\n[14:45:42] 0:\tlearn: 55782.9279583\ttest: 48622.0096601\tbest: 48622.0096601 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[14:45:44] Stopped by overfitting detector  (300 iterations wait)\n[14:45:44] bestTest = 13816.96587\n[14:45:44] bestIteration = 827\n[14:45:44] Shrink model to first 828 iterations.\n[14:45:44] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5876989602882933, 'min_data_in_leaf': 2} scored -13816.965678418803 in 0:00:02.356229\n[14:45:45] 0:\tlearn: 55839.8571518\ttest: 48646.9642041\tbest: 48646.9642041 (0)\ttotal: 2.29ms\tremaining: 4.58s\n[14:45:47] Stopped by overfitting detector  (300 iterations wait)\n[14:45:47] bestTest = 13510.41298\n[14:45:47] bestIteration = 996\n[14:45:47] Shrink model to first 997 iterations.\n[14:45:47] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.8470661159682626, 'min_data_in_leaf': 3} scored -13510.412393162393 in 0:00:02.707520\n[14:45:47] 0:\tlearn: 55761.8669152\ttest: 48614.1804354\tbest: 48614.1804354 (0)\ttotal: 2.09ms\tremaining: 4.18s\n[14:45:50] Stopped by overfitting detector  (300 iterations wait)\n[14:45:50] bestTest = 14174.48216\n[14:45:50] bestIteration = 1246\n[14:45:50] Shrink model to first 1247 iterations.\n[14:45:50] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.19541822461767716, 'min_data_in_leaf': 1} scored -14174.482572115385 in 0:00:03.196708\n[14:45:51] 0:\tlearn: 56027.2570398\ttest: 48880.9384920\tbest: 48880.9384920 (0)\ttotal: 2.53ms\tremaining: 5.05s\n[14:45:54] Stopped by overfitting detector  (300 iterations wait)\n[14:45:54] bestTest = 13708.51297\n[14:45:54] bestIteration = 1296\n[14:45:54] Shrink model to first 1297 iterations.\n[14:45:54] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.880749374240542, 'min_data_in_leaf': 3} scored -13708.513454861111 in 0:00:03.739332\n[14:45:54] 0:\tlearn: 55796.7245356\ttest: 48627.5986295\tbest: 48627.5986295 (0)\ttotal: 2.55ms\tremaining: 5.1s\n[14:45:58] bestTest = 13528.79189\n[14:45:58] bestIteration = 1883\n[14:45:58] Shrink model to first 1884 iterations.\n[14:45:58] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.8666375530061483, 'min_data_in_leaf': 4} scored -13528.79156650641 in 0:00:04.114682\n[14:45:58] 0:\tlearn: 55860.7617195\ttest: 48657.2385096\tbest: 48657.2385096 (0)\ttotal: 2.31ms\tremaining: 4.62s\n[14:46:02] Stopped by overfitting detector  (300 iterations wait)\n[14:46:02] bestTest = 13572.98744\n[14:46:02] bestIteration = 1584\n[14:46:02] Shrink model to first 1585 iterations.\n[14:46:02] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.3800179701110977, 'min_data_in_leaf': 1} scored -13572.987313034188 in 0:00:03.868922\n[14:46:02] 0:\tlearn: 55750.4350689\ttest: 48610.3653929\tbest: 48610.3653929 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[14:46:05] Stopped by overfitting detector  (300 iterations wait)\n[14:46:05] bestTest = 13778.99705\n[14:46:05] bestIteration = 1005\n[14:46:05] Shrink model to first 1006 iterations.\n[14:46:05] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.840796733366603e-08, 'min_data_in_leaf': 5} scored -13778.996761485043 in 0:00:02.706607\n[14:46:05] 0:\tlearn: 55774.2338940\ttest: 48618.6660506\tbest: 48618.6660506 (0)\ttotal: 2.14ms\tremaining: 4.29s\n[14:46:08] Stopped by overfitting detector  (300 iterations wait)\n[14:46:08] bestTest = 13983.29767\n[14:46:08] bestIteration = 1441\n[14:46:08] Shrink model to first 1442 iterations.\n[14:46:08] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.42078865925143516, 'min_data_in_leaf': 2} scored -13983.298043536324 in 0:00:03.555551\n[14:46:09] 0:\tlearn: 55755.2760790\ttest: 48611.9377186\tbest: 48611.9377186 (0)\ttotal: 2.13ms\tremaining: 4.26s\n[14:46:12] Stopped by overfitting detector  (300 iterations wait)\n[14:46:12] bestTest = 13705.23433\n[14:46:12] bestIteration = 1541\n[14:46:12] Shrink model to first 1542 iterations.\n[14:46:12] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.08121217213740116, 'min_data_in_leaf': 6} scored -13705.234341613248 in 0:00:03.841331\n[14:46:12] 0:\tlearn: 56104.9028174\ttest: 48892.0381061\tbest: 48892.0381061 (0)\ttotal: 2.27ms\tremaining: 4.53s\n[14:46:15] Stopped by overfitting detector  (300 iterations wait)\n[14:46:15] bestTest = 13629.75796\n[14:46:15] bestIteration = 1131\n[14:46:15] Shrink model to first 1132 iterations.\n[14:46:15] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.995728622397872, 'min_data_in_leaf': 4} scored -13629.757745726496 in 0:00:02.939878\n[14:46:15] 0:\tlearn: 56221.9331498\ttest: 48988.6207886\tbest: 48988.6207886 (0)\ttotal: 2.31ms\tremaining: 4.63s\n[14:46:19] Stopped by overfitting detector  (300 iterations wait)\n[14:46:19] bestTest = 13612.86006\n[14:46:19] bestIteration = 1355\n[14:46:19] Shrink model to first 1356 iterations.\n[14:46:19] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 9.90980911490202, 'min_data_in_leaf': 17} scored -13612.860209668803 in 0:00:03.390062\n[14:46:19] 0:\tlearn: 55870.2619848\ttest: 48688.0510702\tbest: 48688.0510702 (0)\ttotal: 2.91ms\tremaining: 5.82s\n[14:46:22] Stopped by overfitting detector  (300 iterations wait)\n[14:46:22] bestTest = 13528.3065\n[14:46:22] bestIteration = 977\n[14:46:22] Shrink model to first 978 iterations.\n[14:46:22] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.2420227892812097, 'min_data_in_leaf': 3} scored -13528.307091346154 in 0:00:03.633805\n[14:46:22] 0:\tlearn: 55858.1542485\ttest: 48681.8768192\tbest: 48681.8768192 (0)\ttotal: 2.81ms\tremaining: 5.62s\n[14:46:27] Stopped by overfitting detector  (300 iterations wait)\n[14:46:27] bestTest = 13094.10916\n[14:46:27] bestIteration = 1091\n[14:46:27] Shrink model to first 1092 iterations.\n[14:46:27] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9941279817590767, 'min_data_in_leaf': 3} scored -13094.109041132479 in 0:00:04.349475\n[14:46:27] 0:\tlearn: 55808.2326580\ttest: 48657.9229998\tbest: 48657.9229998 (0)\ttotal: 2.96ms\tremaining: 5.92s\n[14:46:30] Stopped by overfitting detector  (300 iterations wait)\n[14:46:30] bestTest = 13844.31993\n[14:46:30] bestIteration = 925\n[14:46:30] Shrink model to first 926 iterations.\n[14:46:30] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0678526883794393, 'min_data_in_leaf': 15} scored -13844.319778311965 in 0:00:03.480457\n[14:46:30] 0:\tlearn: 55772.1436613\ttest: 48642.3846815\tbest: 48642.3846815 (0)\ttotal: 2.97ms\tremaining: 5.94s\n[14:46:33] Stopped by overfitting detector  (300 iterations wait)\n[14:46:33] bestTest = 13869.06745\n[14:46:33] bestIteration = 829\n[14:46:33] Shrink model to first 830 iterations.\n[14:46:34] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4999086445673402, 'min_data_in_leaf': 2} scored -13869.067307692309 in 0:00:03.303987\n[14:46:34] 0:\tlearn: 55768.5892272\ttest: 48616.5767808\tbest: 48616.5767808 (0)\ttotal: 2.18ms\tremaining: 4.37s\n[14:46:37] Stopped by overfitting detector  (300 iterations wait)\n[14:46:37] bestTest = 13817.06939\n[14:46:37] bestIteration = 1387\n[14:46:37] Shrink model to first 1388 iterations.\n[14:46:37] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.316149571371825, 'min_data_in_leaf': 1} scored -13817.069110576924 in 0:00:03.454922\n[14:46:37] 0:\tlearn: 55981.4152353\ttest: 48864.4555655\tbest: 48864.4555655 (0)\ttotal: 4.37ms\tremaining: 8.72s\n[14:46:42] Stopped by overfitting detector  (300 iterations wait)\n[14:46:42] bestTest = 14236.4086\n[14:46:42] bestIteration = 1015\n[14:46:42] Shrink model to first 1016 iterations.\n[14:46:42] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 4.047996596610367, 'min_data_in_leaf': 3} scored -14236.408086271367 in 0:00:05.322135\n[14:46:43] 0:\tlearn: 55810.3009433\ttest: 48633.4036374\tbest: 48633.4036374 (0)\ttotal: 2.17ms\tremaining: 4.33s\n[14:46:45] Stopped by overfitting detector  (300 iterations wait)\n[14:46:45] bestTest = 13596.67245\n[14:46:45] bestIteration = 1123\n[14:46:45] Shrink model to first 1124 iterations.\n[14:46:45] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1576968366913294, 'min_data_in_leaf': 2} scored -13598.120125534188 in 0:00:02.968888\n[14:46:46] 0:\tlearn: 55771.9173885\ttest: 48659.3919521\tbest: 48659.3919521 (0)\ttotal: 2.86ms\tremaining: 5.71s\n[14:46:50] Stopped by overfitting detector  (300 iterations wait)\n[14:46:50] bestTest = 13739.8639\n[14:46:50] bestIteration = 1203\n[14:46:50] Shrink model to first 1204 iterations.\n[14:46:50] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.2105187209181598, 'min_data_in_leaf': 13} scored -13739.863882211539 in 0:00:04.193011\n[14:46:50] 0:\tlearn: 55751.3909981\ttest: 48610.6704864\tbest: 48610.6704864 (0)\ttotal: 2.12ms\tremaining: 4.25s\n[14:46:53] Stopped by overfitting detector  (300 iterations wait)\n[14:46:53] bestTest = 14285.59299\n[14:46:53] bestIteration = 1163\n[14:46:53] Shrink model to first 1164 iterations.\n[14:46:53] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.01585512155705738, 'min_data_in_leaf': 4} scored -14285.593215811965 in 0:00:03.106120\n[14:46:53] 0:\tlearn: 55843.3778731\ttest: 48648.6569499\tbest: 48648.6569499 (0)\ttotal: 2.13ms\tremaining: 4.25s\n[14:46:56] Stopped by overfitting detector  (300 iterations wait)\n[14:46:56] bestTest = 13636.7764\n[14:46:56] bestIteration = 1467\n[14:46:56] Shrink model to first 1468 iterations.\n[14:46:56] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.934209904652144, 'min_data_in_leaf': 6} scored -13636.776208600428 in 0:00:03.613002\n[14:46:57] 0:\tlearn: 55880.4113903\ttest: 48693.3264300\tbest: 48693.3264300 (0)\ttotal: 2.86ms\tremaining: 5.72s\n[14:47:02] Stopped by overfitting detector  (300 iterations wait)\n[14:47:02] bestTest = 13503.75002\n[14:47:02] bestIteration = 1506\n[14:47:02] Shrink model to first 1507 iterations.\n[14:47:02] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.4566579042878014, 'min_data_in_leaf': 3} scored -13503.749599358975 in 0:00:05.585590\n[14:47:02] 0:\tlearn: 55931.5495835\ttest: 48856.1535651\tbest: 48856.1535651 (0)\ttotal: 2.91ms\tremaining: 5.81s\n[14:47:07] Stopped by overfitting detector  (300 iterations wait)\n[14:47:07] bestTest = 13949.35218\n[14:47:07] bestIteration = 1678\n[14:47:07] Shrink model to first 1679 iterations.\n[14:47:08] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 4.2910417217602745, 'min_data_in_leaf': 14} scored -13949.351996527777 in 0:00:05.507311\n[14:47:08] 0:\tlearn: 55751.2470436\ttest: 48652.4185502\tbest: 48652.4185502 (0)\ttotal: 2.83ms\tremaining: 5.66s\n[14:47:11] Stopped by overfitting detector  (300 iterations wait)\n[14:47:11] bestTest = 13880.51205\n[14:47:11] bestIteration = 978\n[14:47:11] Shrink model to first 979 iterations.\n[14:47:11] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000664951326921748, 'min_data_in_leaf': 3} scored -13880.51218616453 in 0:00:03.612633\n[14:47:11] 0:\tlearn: 55788.1244164\ttest: 48649.0551415\tbest: 48649.0551415 (0)\ttotal: 4.8ms\tremaining: 9.59s\n[14:47:17] Stopped by overfitting detector  (300 iterations wait)\n[14:47:17] bestTest = 13682.39534\n[14:47:17] bestIteration = 1664\n[14:47:17] Shrink model to first 1665 iterations.\n[14:47:17] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.7402889677570123, 'min_data_in_leaf': 5} scored -13682.394965277777 in 0:00:05.496360\n[14:47:17] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[14:47:17] The set of hyperparameters \u001b[1m{'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9941279817590767, 'min_data_in_leaf': 3}\u001b[0m\n achieve -13094.1090 mae\n[14:47:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[14:47:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:47:17] 0:\tlearn: 56749.2127023\ttest: 49449.2057814\tbest: 49449.2057814 (0)\ttotal: 2.83ms\tremaining: 8.5s\n[14:47:22] Stopped by overfitting detector  (100 iterations wait)\n[14:47:22] bestTest = 13536.43338\n[14:47:22] bestIteration = 1915\n[14:47:22] Shrink model to first 1916 iterations.\n[14:47:22] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:47:22] 0:\tlearn: 54017.6495993\ttest: 57933.8010153\tbest: 57933.8010153 (0)\ttotal: 2.89ms\tremaining: 8.66s\n[14:47:27] Stopped by overfitting detector  (100 iterations wait)\n[14:47:27] bestTest = 15900.1628\n[14:47:27] bestIteration = 1604\n[14:47:27] Shrink model to first 1605 iterations.\n[14:47:27] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:47:27] 0:\tlearn: 55767.9622833\ttest: 53715.1317576\tbest: 53715.1317576 (0)\ttotal: 3.44ms\tremaining: 10.3s\n[14:47:29] Stopped by overfitting detector  (100 iterations wait)\n[14:47:29] bestTest = 15885.16221\n[14:47:29] bestIteration = 555\n[14:47:29] Shrink model to first 556 iterations.\n[14:47:29] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:47:29] 0:\tlearn: 54132.3857247\ttest: 58501.0468150\tbest: 58501.0468150 (0)\ttotal: 3.17ms\tremaining: 9.51s\n[14:47:31] Stopped by overfitting detector  (100 iterations wait)\n[14:47:31] bestTest = 14393.96218\n[14:47:31] bestIteration = 757\n[14:47:31] Shrink model to first 758 iterations.\n[14:47:31] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:47:32] 0:\tlearn: 54702.9175240\ttest: 56531.0799361\tbest: 56531.0799361 (0)\ttotal: 3.99ms\tremaining: 12s\n[14:47:36] Stopped by overfitting detector  (100 iterations wait)\n[14:47:36] bestTest = 14451.28432\n[14:47:36] bestIteration = 1529\n[14:47:36] Shrink model to first 1530 iterations.\n[14:47:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14834.104378478169\u001b[0m\n[14:47:36] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[14:47:36] Time left 4280.30 secs\n\n[14:47:36] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[14:47:36] Blending: optimization starts with equal weights and score \u001b[1m-14622.994274400686\u001b[0m\n[14:47:36] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14559.153617963399\u001b[0m, weights = \u001b[1m[0.17300273 0.09875663 0.07599268 0.27028197 0.38196602]\u001b[0m\n[14:47:36] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14548.976729719607\u001b[0m, weights = \u001b[1m[0.18771666 0.15560193 0.         0.2887626  0.36791885]\u001b[0m\n[14:47:36] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14546.803988522046\u001b[0m, weights = \u001b[1m[0.18447626 0.18496788 0.         0.25611317 0.3744427 ]\u001b[0m\n[14:47:36] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14546.748010086687\u001b[0m, weights = \u001b[1m[0.18585072 0.18391132 0.         0.2574051  0.37283286]\u001b[0m\n[14:47:36] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14546.744622217466\u001b[0m, weights = \u001b[1m[0.18597044 0.1838827  0.         0.25757092 0.37257594]\u001b[0m\n[14:47:36] \u001b[1mAutoml preset training completed in 672.22 seconds\u001b[0m\n\n[14:47:36] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.18597 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.18388 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.25757 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.37258 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[14:47:36] ==================================================\n[14:47:36] Start 3 automl preset configuration:\n[14:47:36] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n[14:47:36] Found reader_params in kwargs, need to combine\n[14:47:36] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 45, 'cv': 5}\n[14:47:36] Stdout logging level is INFO3.\n[14:47:36] Task: reg\n\n[14:47:36] Start automl preset with listed constraints:\n[14:47:36] - time: 4280.14 seconds\n[14:47:36] - CPU: 4 cores\n[14:47:36] - memory: 16 GB\n\n[14:47:36] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[14:47:43] Feats was rejected during automatic roles guess: []\n[14:47:43] Layer \u001b[1m1\u001b[0m train process start. Time left 4273.06 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:47:44] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[14:47:44] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:47:44] Linear model: C = 1e-05 score = -37252.40898771367\n[14:47:44] Linear model: C = 5e-05 score = -24245.89398036859\n[14:47:44] Linear model: C = 0.0001 score = -21857.56587623531\n[14:47:44] Linear model: C = 0.0005 score = -19910.238895774906\n[14:47:44] Linear model: C = 0.001 score = -19780.33169738248\n[14:47:45] Linear model: C = 0.005 score = -20085.099793002137\n[14:47:45] Linear model: C = 0.01 score = -20085.099793002137\n[14:47:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:47:45] Linear model: C = 1e-05 score = -36241.4312900641\n[14:47:45] Linear model: C = 5e-05 score = -22942.45282451923\n[14:47:45] Linear model: C = 0.0001 score = -20386.186298076922\n[14:47:45] Linear model: C = 0.0005 score = -17261.72345753205\n[14:47:45] Linear model: C = 0.001 score = -17261.722339075855\n[14:47:46] Linear model: C = 0.005 score = -16722.847556089742\n[14:47:46] Linear model: C = 0.01 score = -16918.9691005609\n[14:47:46] Linear model: C = 0.05 score = -17777.437908987715\n[14:47:46] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:47:46] Linear model: C = 1e-05 score = -38008.12817174145\n[14:47:47] Linear model: C = 5e-05 score = -25456.0031383547\n[14:47:47] Linear model: C = 0.0001 score = -22533.254306891027\n[14:47:47] Linear model: C = 0.0005 score = -19216.011952457266\n[14:47:47] Linear model: C = 0.001 score = -18669.995910122863\n[14:47:47] Linear model: C = 0.005 score = -18669.99824719551\n[14:47:47] Linear model: C = 0.01 score = -18509.583617120727\n[14:47:48] Linear model: C = 0.05 score = -19701.68414463141\n[14:47:48] Linear model: C = 0.1 score = -20207.099893162394\n[14:47:48] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:47:48] Linear model: C = 1e-05 score = -35214.91154774678\n[14:47:48] Linear model: C = 5e-05 score = -22084.605150214593\n[14:47:48] Linear model: C = 0.0001 score = -19596.120238733907\n[14:47:49] Linear model: C = 0.0005 score = -17497.803111587982\n[14:47:49] Linear model: C = 0.001 score = -17497.80368159871\n[14:47:49] Linear model: C = 0.005 score = -18155.010679318668\n[14:47:49] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:47:49] Linear model: C = 1e-05 score = -34659.04838385193\n[14:47:49] Linear model: C = 5e-05 score = -22735.68874061159\n[14:47:49] Linear model: C = 0.0001 score = -20013.34732094957\n[14:47:50] Linear model: C = 0.0005 score = -16797.48159200644\n[14:47:50] Linear model: C = 0.001 score = -16203.557504023605\n[14:47:50] Linear model: C = 0.005 score = -16203.557504023605\n[14:47:50] Linear model: C = 0.01 score = -16203.558794930257\n[14:47:50] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17744.352341743364\u001b[0m\n[14:47:50] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[14:47:50] Time left 4266.23 secs\n\n[14:47:50] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:47:54] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[14:47:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[14:47:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:47:55] Training until validation scores don't improve for 200 rounds\n[14:47:59] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:47:59] Training until validation scores don't improve for 200 rounds\n[14:48:01] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:48:01] Training until validation scores don't improve for 200 rounds\n[14:48:05] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:48:05] Training until validation scores don't improve for 200 rounds\n[14:48:06] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:48:06] Training until validation scores don't improve for 200 rounds\n[14:48:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15328.272290373501\u001b[0m\n[14:48:08] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[14:48:08] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[14:48:08] Training until validation scores don't improve for 200 rounds\n[14:48:15] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -17487.472973424145 in 0:00:06.580728\n[14:48:15] Training until validation scores don't improve for 200 rounds\n[14:48:22] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -17192.519564636754 in 0:00:06.995133\n[14:48:22] Training until validation scores don't improve for 200 rounds\n[14:48:26] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -17582.936531784188 in 0:00:04.358933\n[14:48:26] Training until validation scores don't improve for 200 rounds\n[14:48:35] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -17251.521000267094 in 0:00:08.405568\n[14:48:35] Training until validation scores don't improve for 200 rounds\n[14:48:42] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -17218.764189369656 in 0:00:07.593640\n[14:48:42] Training until validation scores don't improve for 200 rounds\n[14:48:45] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -17341.927717681625 in 0:00:03.082760\n[14:48:45] Training until validation scores don't improve for 200 rounds\n[14:48:53] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -17274.755825988246 in 0:00:08.251116\n[14:48:54] Training until validation scores don't improve for 200 rounds\n[14:49:00] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -16914.025674412394 in 0:00:06.666775\n[14:49:00] Training until validation scores don't improve for 200 rounds\n[14:49:14] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -17588.21182224893 in 0:00:13.696176\n[14:49:14] Training until validation scores don't improve for 200 rounds\n[14:49:18] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -17580.04096554487 in 0:00:04.252892\n[14:49:18] Training until validation scores don't improve for 200 rounds\n[14:49:24] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527} scored -16913.956964476496 in 0:00:05.519780\n[14:49:24] Training until validation scores don't improve for 200 rounds\n[14:49:29] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5075634079566923, 'num_leaves': 165, 'bagging_fraction': 0.6795146156302498, 'min_sum_hessian_in_leaf': 0.026738277166992196, 'reg_alpha': 0.0015258645761591619, 'reg_lambda': 0.01881061891210943} scored -16939.545956864316 in 0:00:05.347093\n[14:49:29] Training until validation scores don't improve for 200 rounds\n[14:49:35] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 129, 'bagging_fraction': 0.6794216628122437, 'min_sum_hessian_in_leaf': 0.01875620628228737, 'reg_alpha': 0.0437281057923299, 'reg_lambda': 0.008452229729634516} scored -16768.266276041668 in 0:00:05.544933\n[14:49:35] Training until validation scores don't improve for 200 rounds\n[14:49:44] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.6058804861017528, 'num_leaves': 115, 'bagging_fraction': 0.7066937151944584, 'min_sum_hessian_in_leaf': 0.019367283524941672, 'reg_alpha': 0.0558999100564544, 'reg_lambda': 0.017638528224983765} scored -16794.947799813035 in 0:00:09.666801\n[14:49:44] Training until validation scores don't improve for 200 rounds\n[14:49:52] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5930920176627791, 'num_leaves': 115, 'bagging_fraction': 0.7255100989928714, 'min_sum_hessian_in_leaf': 0.001393848475707784, 'reg_alpha': 0.4189488919094205, 'reg_lambda': 0.010120698664942722} scored -16967.539596688035 in 0:00:07.663056\n[14:49:52] Training until validation scores don't improve for 200 rounds\n[14:49:56] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.6101568156086703, 'num_leaves': 116, 'bagging_fraction': 0.7484483315394532, 'min_sum_hessian_in_leaf': 0.019739906571425634, 'reg_alpha': 0.060441831976246564, 'reg_lambda': 0.24810363711510008} scored -17159.365384615383 in 0:00:04.348771\n[14:49:56] Training until validation scores don't improve for 200 rounds\n[14:50:03] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5856447256058857, 'num_leaves': 173, 'bagging_fraction': 0.9270627421637063, 'min_sum_hessian_in_leaf': 0.0010628817945484137, 'reg_alpha': 0.05254817680498775, 'reg_lambda': 0.004282730650937127} scored -17120.158336672008 in 0:00:06.571159\n[14:50:03] Training until validation scores don't improve for 200 rounds\n[14:50:13] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.9264342202471387, 'num_leaves': 103, 'bagging_fraction': 0.6704560197555285, 'min_sum_hessian_in_leaf': 0.09821084629857695, 'reg_alpha': 0.03755796889727139, 'reg_lambda': 0.14184312049385903} scored -17498.723490918805 in 0:00:10.381600\n[14:50:13] Training until validation scores don't improve for 200 rounds\n[14:50:18] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.6584990961107574, 'num_leaves': 132, 'bagging_fraction': 0.7251840664175886, 'min_sum_hessian_in_leaf': 0.01305852272078039, 'reg_alpha': 0.00013159344585020446, 'reg_lambda': 3.2178954676475564e-05} scored -17280.88341346154 in 0:00:04.638263\n[14:50:18] Training until validation scores don't improve for 200 rounds\n[14:50:20] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8529694011819124, 'num_leaves': 21, 'bagging_fraction': 0.5015508071559405, 'min_sum_hessian_in_leaf': 0.055191805483702804, 'reg_alpha': 0.36714255469878165, 'reg_lambda': 0.0015579107174789602} scored -17800.268830128207 in 0:00:01.783862\n[14:50:20] Training until validation scores don't improve for 200 rounds\n[14:50:30] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.9821265326466516, 'num_leaves': 190, 'bagging_fraction': 0.7866817475027436, 'min_sum_hessian_in_leaf': 0.008796630628268033, 'reg_alpha': 8.56955050599394e-05, 'reg_lambda': 0.06025994607208242} scored -17759.454794337606 in 0:00:10.258709\n[14:50:30] Training until validation scores don't improve for 200 rounds\n[14:50:36] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5621243005829862, 'num_leaves': 151, 'bagging_fraction': 0.679686043070895, 'min_sum_hessian_in_leaf': 0.038167398923061445, 'reg_alpha': 0.004543374948239353, 'reg_lambda': 0.017716235418486447} scored -16842.59157986111 in 0:00:05.837172\n[14:50:36] Training until validation scores don't improve for 200 rounds\n[14:50:41] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.5689726180411, 'num_leaves': 143, 'bagging_fraction': 0.6500267664497343, 'min_sum_hessian_in_leaf': 0.03774650862396374, 'reg_alpha': 0.009354794926487222, 'reg_lambda': 1.2356171248651227} scored -16876.2301181891 in 0:00:05.543801\n[14:50:41] Training until validation scores don't improve for 200 rounds\n[14:50:50] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.6373771568502484, 'num_leaves': 92, 'bagging_fraction': 0.7095070561904049, 'min_sum_hessian_in_leaf': 0.0032840319393065147, 'reg_alpha': 0.6318258005764534, 'reg_lambda': 0.00011492780072274876} scored -16845.755191639957 in 0:00:09.064736\n[14:50:50] Training until validation scores don't improve for 200 rounds\n[14:50:54] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5593569555106337, 'num_leaves': 132, 'bagging_fraction': 0.6174682491436476, 'min_sum_hessian_in_leaf': 0.19693025105060893, 'reg_alpha': 0.012447999643121283, 'reg_lambda': 0.004973808192429202} scored -16824.730836004273 in 0:00:03.831670\n[14:50:54] Training until validation scores don't improve for 200 rounds\n[14:51:00] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6224350026172961, 'num_leaves': 131, 'bagging_fraction': 0.5826508521669772, 'min_sum_hessian_in_leaf': 0.18151879929332426, 'reg_alpha': 0.0004530781170200388, 'reg_lambda': 0.0020147900392844826} scored -17187.88055889423 in 0:00:05.963316\n[14:51:00] Training until validation scores don't improve for 200 rounds\n[14:51:03] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.5542601263212912, 'num_leaves': 82, 'bagging_fraction': 0.6165403917047048, 'min_sum_hessian_in_leaf': 2.9927990921913863, 'reg_alpha': 0.014504522003258998, 'reg_lambda': 1.7269547587376765e-06} scored -16932.79670806624 in 0:00:02.552778\n[14:51:03] Training until validation scores don't improve for 200 rounds\n[14:51:11] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.6811217972538138, 'num_leaves': 119, 'bagging_fraction': 0.7655861314080077, 'min_sum_hessian_in_leaf': 0.10443765321794114, 'reg_alpha': 0.1814593426273075, 'reg_lambda': 0.0021656324683716165} scored -17178.061848958332 in 0:00:07.733270\n[14:51:11] Training until validation scores don't improve for 200 rounds\n[14:51:19] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5541838762955881, 'num_leaves': 177, 'bagging_fraction': 0.5750737460040551, 'min_sum_hessian_in_leaf': 0.012852388340076577, 'reg_alpha': 0.0005924463930155588, 'reg_lambda': 0.08145796813118367} scored -17185.19751602564 in 0:00:08.072339\n[14:51:19] Training until validation scores don't improve for 200 rounds\n[14:51:26] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6917060658154592, 'num_leaves': 102, 'bagging_fraction': 0.906708728779495, 'min_sum_hessian_in_leaf': 0.20434587069222504, 'reg_alpha': 1.2892695473405666, 'reg_lambda': 0.6419033864934268} scored -17309.527794471152 in 0:00:07.670503\n[14:51:26] Training until validation scores don't improve for 200 rounds\n[14:51:31] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5952771786182358, 'num_leaves': 158, 'bagging_fraction': 0.6422287450918825, 'min_sum_hessian_in_leaf': 0.45214416878472535, 'reg_alpha': 0.12528344805109995, 'reg_lambda': 0.00012406340976602655} scored -17122.04211738782 in 0:00:04.838501\n[14:51:31] Training until validation scores don't improve for 200 rounds\n[14:51:37] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5444348617888395, 'num_leaves': 138, 'bagging_fraction': 0.6937854815973666, 'min_sum_hessian_in_leaf': 0.04774080561130361, 'reg_alpha': 0.009546902209183989, 'reg_lambda': 0.029202901034451924} scored -16746.439169337606 in 0:00:05.609834\n[14:51:37] Training until validation scores don't improve for 200 rounds\n[14:51:41] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.538236776913789, 'num_leaves': 133, 'bagging_fraction': 0.7122076784477206, 'min_sum_hessian_in_leaf': 0.0663053469846745, 'reg_alpha': 0.01757562544434877, 'reg_lambda': 0.03437650372294658} scored -16864.246961805555 in 0:00:04.104427\n[14:51:41] Training until validation scores don't improve for 200 rounds\n[14:51:51] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.6236227326237533, 'num_leaves': 121, 'bagging_fraction': 0.7483838185721522, 'min_sum_hessian_in_leaf': 0.014820209278517163, 'reg_alpha': 5.9708266906149754e-05, 'reg_lambda': 4.45650651987144} scored -17293.018396100426 in 0:00:09.682307\n[14:51:51] Training until validation scores don't improve for 200 rounds\n[14:51:59] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.540900139435048, 'num_leaves': 76, 'bagging_fraction': 0.8288532787998741, 'min_sum_hessian_in_leaf': 0.37200808980947453, 'reg_alpha': 0.009695532463258853, 'reg_lambda': 0.004172499552103006} scored -16956.87865584936 in 0:00:08.402493\n[14:51:59] Training until validation scores don't improve for 200 rounds\n[14:52:05] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.6817546010519131, 'num_leaves': 106, 'bagging_fraction': 0.6564408748955931, 'min_sum_hessian_in_leaf': 0.00272808530200678, 'reg_alpha': 0.0012744962893082138, 'reg_lambda': 0.006231231260161612} scored -16910.0597789797 in 0:00:05.979599\n[14:52:05] Training until validation scores don't improve for 200 rounds\n[14:52:12] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.5852422904469187, 'num_leaves': 193, 'bagging_fraction': 0.6197176577931132, 'min_sum_hessian_in_leaf': 0.00853575453731361, 'reg_alpha': 0.11722697095810455, 'reg_lambda': 0.0008849405110042376} scored -16869.939586672008 in 0:00:07.092719\n[14:52:12] Training until validation scores don't improve for 200 rounds\n[14:52:18] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.7212586030523233, 'num_leaves': 215, 'bagging_fraction': 0.7072155962269836, 'min_sum_hessian_in_leaf': 1.1453540131021704, 'reg_alpha': 2.157270881140327e-05, 'reg_lambda': 0.04662164279243233} scored -17009.363147702992 in 0:00:06.070418\n[14:52:18] Training until validation scores don't improve for 200 rounds\n[14:52:27] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.5300046666998826, 'num_leaves': 144, 'bagging_fraction': 0.7754143920498267, 'min_sum_hessian_in_leaf': 0.15997448330705905, 'reg_alpha': 0.03704625190463503, 'reg_lambda': 2.9936787073789606e-08} scored -16654.63438167735 in 0:00:09.096094\n[14:52:27] Training until validation scores don't improve for 200 rounds\n[14:52:36] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.526956995236743, 'num_leaves': 143, 'bagging_fraction': 0.8086262212779747, 'min_sum_hessian_in_leaf': 0.039981224620847446, 'reg_alpha': 1.1256212903330673, 'reg_lambda': 1.2040784157143494e-08} scored -17011.58153044872 in 0:00:08.453754\n[14:52:36] Training until validation scores don't improve for 200 rounds\n[14:52:48] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.5015568508201073, 'num_leaves': 92, 'bagging_fraction': 0.8681473671732493, 'min_sum_hessian_in_leaf': 0.08685311870925168, 'reg_alpha': 0.038475026946438236, 'reg_lambda': 7.577262984869785e-08} scored -16793.712022569445 in 0:00:12.225955\n[14:52:48] Training until validation scores don't improve for 200 rounds\n[14:52:58] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5021087442153892, 'num_leaves': 92, 'bagging_fraction': 0.8578726687141883, 'min_sum_hessian_in_leaf': 0.1278325051000239, 'reg_alpha': 0.03451772479612021, 'reg_lambda': 7.802093892438156e-08} scored -16719.71594551282 in 0:00:10.165765\n[14:52:58] Training until validation scores don't improve for 200 rounds\n[14:53:05] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5054055447722539, 'num_leaves': 69, 'bagging_fraction': 0.8800168388559055, 'min_sum_hessian_in_leaf': 0.08491177054182329, 'reg_alpha': 0.004332200791544349, 'reg_lambda': 1.399377171359152e-07} scored -16876.245976896367 in 0:00:06.420762\n[14:53:05] Training until validation scores don't improve for 200 rounds\n[14:53:12] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5030642866998165, 'num_leaves': 48, 'bagging_fraction': 0.8595793887989143, 'min_sum_hessian_in_leaf': 0.15172892971020907, 'reg_alpha': 0.026686135181454133, 'reg_lambda': 9.206645964395513e-08} scored -16767.331797542734 in 0:00:07.546804\n[14:53:12] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[14:53:12] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5300046666998826, 'num_leaves': 144, 'bagging_fraction': 0.7754143920498267, 'min_sum_hessian_in_leaf': 0.15997448330705905, 'reg_alpha': 0.03704625190463503, 'reg_lambda': 2.9936787073789606e-08}\u001b[0m\n achieve -16654.6344 mae\n[14:53:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[14:53:12] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:53:12] Training until validation scores don't improve for 100 rounds\n[14:53:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:53:14] Training until validation scores don't improve for 100 rounds\n[14:53:15] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:53:15] Training until validation scores don't improve for 100 rounds\n[14:53:16] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:53:16] Training until validation scores don't improve for 100 rounds\n[14:53:16] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[14:53:16] Training until validation scores don't improve for 100 rounds\n[14:53:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15585.1851221372\u001b[0m\n[14:53:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[14:53:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[14:53:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:53:17] 0:\tlearn: 53896.6927615\ttest: 55236.7293788\tbest: 55236.7293788 (0)\ttotal: 2.58ms\tremaining: 5.16s\n[14:53:21] bestTest = 16871.5917\n[14:53:21] bestIteration = 1861\n[14:53:21] Shrink model to first 1862 iterations.\n[14:53:21] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:53:21] 0:\tlearn: 54704.4220733\ttest: 54086.6154489\tbest: 54086.6154489 (0)\ttotal: 2.84ms\tremaining: 5.67s\n[14:53:24] Stopped by overfitting detector  (300 iterations wait)\n[14:53:24] bestTest = 13679.68016\n[14:53:24] bestIteration = 1208\n[14:53:24] Shrink model to first 1209 iterations.\n[14:53:24] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:53:24] 0:\tlearn: 53957.6314965\ttest: 54908.7136078\tbest: 54908.7136078 (0)\ttotal: 3.24ms\tremaining: 6.48s\n[14:53:26] Stopped by overfitting detector  (300 iterations wait)\n[14:53:26] bestTest = 15576.61185\n[14:53:26] bestIteration = 536\n[14:53:26] Shrink model to first 537 iterations.\n[14:53:26] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:53:26] 0:\tlearn: 53723.4569354\ttest: 54790.2936945\tbest: 54790.2936945 (0)\ttotal: 2.24ms\tremaining: 4.48s\n[14:53:28] Stopped by overfitting detector  (300 iterations wait)\n[14:53:28] bestTest = 15571.86073\n[14:53:28] bestIteration = 665\n[14:53:28] Shrink model to first 666 iterations.\n[14:53:28] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[14:53:28] 0:\tlearn: 54668.2496692\ttest: 52241.4376730\tbest: 52241.4376730 (0)\ttotal: 2.44ms\tremaining: 4.87s\n[14:53:31] Stopped by overfitting detector  (300 iterations wait)\n[14:53:31] bestTest = 13876.52232\n[14:53:31] bestIteration = 1334\n[14:53:31] Shrink model to first 1335 iterations.\n[14:53:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15115.922854906892\u001b[0m\n[14:53:31] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[14:53:31] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[14:53:31] 0:\tlearn: 54030.2947719\ttest: 55426.3063005\tbest: 55426.3063005 (0)\ttotal: 2.45ms\tremaining: 4.9s\n[14:53:34] Stopped by overfitting detector  (300 iterations wait)\n[14:53:34] bestTest = 16499.17931\n[14:53:34] bestIteration = 1611\n[14:53:34] Shrink model to first 1612 iterations.\n[14:53:34] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -16508.99699519231 in 0:00:02.926020\n[14:53:34] 0:\tlearn: 54242.2609215\ttest: 55473.2586540\tbest: 55473.2586540 (0)\ttotal: 1.5ms\tremaining: 3s\n[14:53:36] bestTest = 17385.73335\n[14:53:36] bestIteration = 1991\n[14:53:36] Shrink model to first 1992 iterations.\n[14:53:36] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -17385.73322315705 in 0:00:02.253599\n[14:53:36] 0:\tlearn: 54248.4312291\ttest: 55551.3076330\tbest: 55551.3076330 (0)\ttotal: 1.23ms\tremaining: 2.46s\n[14:53:38] bestTest = 17377.34541\n[14:53:38] bestIteration = 1982\n[14:53:38] Shrink model to first 1983 iterations.\n[14:53:39] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -17377.34480168269 in 0:00:02.259531\n[14:53:39] 0:\tlearn: 54242.2186139\ttest: 55473.2177495\tbest: 55473.2177495 (0)\ttotal: 1.2ms\tremaining: 2.39s\n[14:53:41] bestTest = 17439.81005\n[14:53:41] bestIteration = 1852\n[14:53:41] Shrink model to first 1853 iterations.\n[14:53:41] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -17439.80991252671 in 0:00:02.257546\n[14:53:41] 0:\tlearn: 53824.8674926\ttest: 55195.6651923\tbest: 55195.6651923 (0)\ttotal: 3.66ms\tremaining: 7.32s\n[14:53:44] Stopped by overfitting detector  (300 iterations wait)\n[14:53:44] bestTest = 16776.23723\n[14:53:44] bestIteration = 868\n[14:53:44] Shrink model to first 869 iterations.\n[14:53:44] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -16776.237613514957 in 0:00:03.292060\n[14:53:44] 0:\tlearn: 53825.1448471\ttest: 55195.7968779\tbest: 55195.7968779 (0)\ttotal: 3.97ms\tremaining: 7.94s\n[14:53:47] Stopped by overfitting detector  (300 iterations wait)\n[14:53:47] bestTest = 16910.95098\n[14:53:47] bestIteration = 655\n[14:53:47] Shrink model to first 656 iterations.\n[14:53:47] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -16910.95067107372 in 0:00:02.666675\n[14:53:47] 0:\tlearn: 54008.3155391\ttest: 55495.9450970\tbest: 55495.9450970 (0)\ttotal: 3.29ms\tremaining: 6.58s\n[14:53:50] Stopped by overfitting detector  (300 iterations wait)\n[14:53:50] bestTest = 16727.55444\n[14:53:50] bestIteration = 1055\n[14:53:50] Shrink model to first 1056 iterations.\n[14:53:50] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -16727.554003071582 in 0:00:03.720337\n[14:53:51] 0:\tlearn: 53638.4267903\ttest: 55224.1455336\tbest: 55224.1455336 (0)\ttotal: 5.72ms\tremaining: 11.4s\n[14:53:54] Stopped by overfitting detector  (300 iterations wait)\n[14:53:54] bestTest = 17512.08259\n[14:53:54] bestIteration = 549\n[14:53:54] Shrink model to first 550 iterations.\n[14:53:54] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -17512.082098023504 in 0:00:03.468435\n[14:53:54] 0:\tlearn: 54276.3447694\ttest: 55579.8026095\tbest: 55579.8026095 (0)\ttotal: 1.22ms\tremaining: 2.44s\n[14:53:56] bestTest = 17573.12879\n[14:53:56] bestIteration = 1960\n[14:53:56] Shrink model to first 1961 iterations.\n[14:53:57] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -17573.128639155984 in 0:00:02.574503\n[14:53:57] 0:\tlearn: 53824.9735396\ttest: 55195.7155232\tbest: 55195.7155232 (0)\ttotal: 3.82ms\tremaining: 7.64s\n[14:54:00] Stopped by overfitting detector  (300 iterations wait)\n[14:54:00] bestTest = 16948.92474\n[14:54:00] bestIteration = 971\n[14:54:00] Shrink model to first 972 iterations.\n[14:54:00] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -16948.92506343483 in 0:00:03.647786\n[14:54:00] 0:\tlearn: 54030.1858952\ttest: 55426.1715761\tbest: 55426.1715761 (0)\ttotal: 1.61ms\tremaining: 3.23s\n[14:54:03] Stopped by overfitting detector  (300 iterations wait)\n[14:54:03] bestTest = 16631.52867\n[14:54:03] bestIteration = 1397\n[14:54:03] Shrink model to first 1398 iterations.\n[14:54:03] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 14} scored -16639.592497996793 in 0:00:02.620132\n[14:54:03] 0:\tlearn: 54030.1858953\ttest: 55426.1715763\tbest: 55426.1715763 (0)\ttotal: 1.66ms\tremaining: 3.32s\n[14:54:05] Stopped by overfitting detector  (300 iterations wait)\n[14:54:05] bestTest = 16618.4069\n[14:54:05] bestIteration = 1418\n[14:54:05] Shrink model to first 1419 iterations.\n[14:54:05] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3815073407783029e-08, 'min_data_in_leaf': 16} scored -16626.470419337606 in 0:00:02.630126\n[14:54:06] 0:\tlearn: 54030.1858953\ttest: 55426.1715763\tbest: 55426.1715763 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[14:54:08] Stopped by overfitting detector  (300 iterations wait)\n[14:54:08] bestTest = 16631.52867\n[14:54:08] bestIteration = 1397\n[14:54:08] Shrink model to first 1398 iterations.\n[14:54:08] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3858728884475828e-08, 'min_data_in_leaf': 16} scored -16639.592497996793 in 0:00:02.577752\n[14:54:08] 0:\tlearn: 54035.3886407\ttest: 55432.5985387\tbest: 55432.5985387 (0)\ttotal: 1.54ms\tremaining: 3.08s\n[14:54:11] bestTest = 16590.30685\n[14:54:11] bestIteration = 1988\n[14:54:11] Shrink model to first 1989 iterations.\n[14:54:11] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.12015191102286037, 'min_data_in_leaf': 19} scored -16598.443926949785 in 0:00:03.345878\n[14:54:12] 0:\tlearn: 53874.7522328\ttest: 55318.3041385\tbest: 55318.3041385 (0)\ttotal: 2.25ms\tremaining: 4.49s\n[14:54:15] Stopped by overfitting detector  (300 iterations wait)\n[14:54:15] bestTest = 17042.72873\n[14:54:15] bestIteration = 1643\n[14:54:15] Shrink model to first 1644 iterations.\n[14:54:15] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.12161726393099143, 'min_data_in_leaf': 19} scored -17042.71718082265 in 0:00:03.917164\n[14:54:15] 0:\tlearn: 53873.4845627\ttest: 55317.0565529\tbest: 55317.0565529 (0)\ttotal: 2.24ms\tremaining: 4.49s\n[14:54:19] Stopped by overfitting detector  (300 iterations wait)\n[14:54:19] bestTest = 16834.63374\n[14:54:19] bestIteration = 1399\n[14:54:19] Shrink model to first 1400 iterations.\n[14:54:19] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10130492013778519, 'min_data_in_leaf': 12} scored -16833.403161725426 in 0:00:03.442512\n[14:54:19] 0:\tlearn: 54036.0565273\ttest: 55433.4214905\tbest: 55433.4214905 (0)\ttotal: 1.57ms\tremaining: 3.15s\n[14:54:22] bestTest = 16616.4168\n[14:54:22] bestIteration = 1999\n[14:54:22] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.13607520246444538, 'min_data_in_leaf': 7} scored -16625.63651842949 in 0:00:03.101613\n[14:54:22] 0:\tlearn: 54184.6486217\ttest: 55610.6714762\tbest: 55610.6714762 (0)\ttotal: 2.16ms\tremaining: 4.33s\n[14:54:26] bestTest = 16848.4108\n[14:54:26] bestIteration = 1850\n[14:54:26] Shrink model to first 1851 iterations.\n[14:54:26] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 9.86874546485378, 'min_data_in_leaf': 1} scored -16843.52904647436 in 0:00:03.969804\n[14:54:26] 0:\tlearn: 54030.1861827\ttest: 55426.1719319\tbest: 55426.1719319 (0)\ttotal: 1.59ms\tremaining: 3.17s\n[14:54:29] Stopped by overfitting detector  (300 iterations wait)\n[14:54:29] bestTest = 16618.4059\n[14:54:29] bestIteration = 1418\n[14:54:29] Shrink model to first 1419 iterations.\n[14:54:29] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 6.458243615671733e-06, 'min_data_in_leaf': 18} scored -16626.469501201922 in 0:00:02.819747\n[14:54:29] 0:\tlearn: 54031.5740331\ttest: 55427.8886826\tbest: 55427.8886826 (0)\ttotal: 1.91ms\tremaining: 3.82s\n[14:54:31] Stopped by overfitting detector  (300 iterations wait)\n[14:54:31] bestTest = 16587.26481\n[14:54:31] bestIteration = 854\n[14:54:31] Shrink model to first 855 iterations.\n[14:54:31] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.03137765288928345, 'min_data_in_leaf': 13} scored -16593.686197916668 in 0:00:01.953647\n[14:54:31] 0:\tlearn: 53867.5402669\ttest: 55311.2163228\tbest: 55311.2163228 (0)\ttotal: 2.26ms\tremaining: 4.51s\n[14:54:35] bestTest = 17036.54994\n[14:54:35] bestIteration = 1802\n[14:54:35] Shrink model to first 1803 iterations.\n[14:54:35] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.008660691775131988, 'min_data_in_leaf': 13} scored -17006.22818175748 in 0:00:04.028686\n[14:54:35] 0:\tlearn: 54046.5750220\ttest: 55446.2883230\tbest: 55446.2883230 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[14:54:38] bestTest = 16629.33841\n[14:54:38] bestIteration = 1925\n[14:54:38] Shrink model to first 1926 iterations.\n[14:54:38] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.4013385162639634, 'min_data_in_leaf': 17} scored -16632.56946113782 in 0:00:02.984724\n[14:54:38] 0:\tlearn: 54031.0508323\ttest: 55427.2416470\tbest: 55427.2416470 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:54:41] bestTest = 16402.41092\n[14:54:41] bestIteration = 1729\n[14:54:41] Shrink model to first 1730 iterations.\n[14:54:41] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.019492571859171148, 'min_data_in_leaf': 11} scored -16403.881560496793 in 0:00:03.052918\n[14:54:41] 0:\tlearn: 54248.7855691\ttest: 55551.6697414\tbest: 55551.6697414 (0)\ttotal: 1.26ms\tremaining: 2.52s\n[14:54:43] bestTest = 17160.02951\n[14:54:43] bestIteration = 1960\n[14:54:43] Shrink model to first 1961 iterations.\n[14:54:43] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.018463101064529138, 'min_data_in_leaf': 11} scored -17160.029397035258 in 0:00:02.295755\n[14:54:43] 0:\tlearn: 54030.1955367\ttest: 55426.1835068\tbest: 55426.1835068 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:54:46] bestTest = 16585.36607\n[14:54:46] bestIteration = 1995\n[14:54:46] Shrink model to first 1996 iterations.\n[14:54:46] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00021622570981589992, 'min_data_in_leaf': 9} scored -16593.429370325855 in 0:00:03.017078\n[14:54:46] 0:\tlearn: 53866.9845298\ttest: 55310.6713075\tbest: 55310.6713075 (0)\ttotal: 2.15ms\tremaining: 4.31s\n[14:54:50] Stopped by overfitting detector  (300 iterations wait)\n[14:54:50] bestTest = 16849.60025\n[14:54:50] bestIteration = 1652\n[14:54:50] Shrink model to first 1653 iterations.\n[14:54:50] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0002191086505239917, 'min_data_in_leaf': 8} scored -16806.940421340812 in 0:00:03.965507\n[14:54:50] 0:\tlearn: 54227.8017361\ttest: 55582.8533364\tbest: 55582.8533364 (0)\ttotal: 1.6ms\tremaining: 3.19s\n[14:54:53] bestTest = 17091.1018\n[14:54:53] bestIteration = 1998\n[14:54:53] Shrink model to first 1999 iterations.\n[14:54:53] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0002654849800667137, 'min_data_in_leaf': 4} scored -17091.10216346154 in 0:00:03.082096\n[14:54:53] 0:\tlearn: 54248.4312527\ttest: 55551.3076572\tbest: 55551.3076572 (0)\ttotal: 1.23ms\tremaining: 2.47s\n[14:54:55] bestTest = 17377.44467\n[14:54:55] bestIteration = 1982\n[14:54:55] Shrink model to first 1983 iterations.\n[14:54:55] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.043442636576258e-06, 'min_data_in_leaf': 10} scored -17377.44484508547 in 0:00:02.267130\n[14:54:56] 0:\tlearn: 53866.9717030\ttest: 55310.6587305\tbest: 55310.6587305 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[14:54:59] Stopped by overfitting detector  (300 iterations wait)\n[14:54:59] bestTest = 16874.59688\n[14:54:59] bestIteration = 1263\n[14:54:59] Shrink model to first 1264 iterations.\n[14:54:59] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.471517767435941e-05, 'min_data_in_leaf': 3} scored -16831.93169070513 in 0:00:03.184295\n[14:54:59] 0:\tlearn: 54242.2656761\ttest: 55473.2632510\tbest: 55473.2632510 (0)\ttotal: 1.23ms\tremaining: 2.45s\n[14:55:01] bestTest = 17406.14675\n[14:55:01] bestIteration = 1996\n[14:55:01] Shrink model to first 1997 iterations.\n[14:55:01] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002850842067850182, 'min_data_in_leaf': 8} scored -17406.14626736111 in 0:00:02.529186\n[14:55:02] 0:\tlearn: 54030.2199768\ttest: 55426.2137496\tbest: 55426.2137496 (0)\ttotal: 1.89ms\tremaining: 3.78s\n[14:55:04] bestTest = 16472.16448\n[14:55:04] bestIteration = 1995\n[14:55:04] Shrink model to first 1996 iterations.\n[14:55:04] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0007644129768042402, 'min_data_in_leaf': 11} scored -16480.18244190705 in 0:00:03.376018\n[14:55:05] 0:\tlearn: 54030.2373429\ttest: 55426.2352386\tbest: 55426.2352386 (0)\ttotal: 1.61ms\tremaining: 3.21s\n[14:55:07] bestTest = 16147.30501\n[14:55:07] bestIteration = 1914\n[14:55:07] Shrink model to first 1915 iterations.\n[14:55:08] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0011540257706334474, 'min_data_in_leaf': 11} scored -16150.624599358975 in 0:00:03.014314\n[14:55:08] 0:\tlearn: 54030.2863002\ttest: 55426.2958179\tbest: 55426.2958179 (0)\ttotal: 1.61ms\tremaining: 3.23s\n[14:55:10] Stopped by overfitting detector  (300 iterations wait)\n[14:55:10] bestTest = 16409.08548\n[14:55:10] bestIteration = 1578\n[14:55:10] Shrink model to first 1579 iterations.\n[14:55:10] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0022528158897944755, 'min_data_in_leaf': 11} scored -16418.856904380344 in 0:00:02.882908\n[14:55:11] 0:\tlearn: 54030.2372657\ttest: 55426.2351430\tbest: 55426.2351430 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[14:55:13] bestTest = 16147.30531\n[14:55:13] bestIteration = 1914\n[14:55:13] Shrink model to first 1915 iterations.\n[14:55:13] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0011522921911217873, 'min_data_in_leaf': 12} scored -16150.624716212607 in 0:00:03.064391\n[14:55:14] 0:\tlearn: 54248.4941640\ttest: 55551.3719475\tbest: 55551.3719475 (0)\ttotal: 1.22ms\tremaining: 2.45s\n[14:55:16] bestTest = 17310.07702\n[14:55:16] bestIteration = 1994\n[14:55:16] Shrink model to first 1995 iterations.\n[14:55:16] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0032781828488049917, 'min_data_in_leaf': 13} scored -17310.077006543805 in 0:00:02.269917\n[14:55:16] 0:\tlearn: 54248.4324002\ttest: 55551.3088299\tbest: 55551.3088299 (0)\ttotal: 1.24ms\tremaining: 2.47s\n[14:55:18] bestTest = 17377.33875\n[14:55:18] bestIteration = 1982\n[14:55:18] Shrink model to first 1983 iterations.\n[14:55:18] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 6.179631397123778e-05, 'min_data_in_leaf': 12} scored -17377.339393028848 in 0:00:02.267827\n[14:55:18] 0:\tlearn: 53896.3663196\ttest: 55236.5687060\tbest: 55236.5687060 (0)\ttotal: 2.05ms\tremaining: 4.09s\n[14:55:22] bestTest = 16653.15298\n[14:55:22] bestIteration = 1995\n[14:55:22] Shrink model to first 1996 iterations.\n[14:55:22] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.005694843069242804, 'min_data_in_leaf': 15} scored -16653.15324519231 in 0:00:04.024299\n[14:55:22] 0:\tlearn: 54030.2285293\ttest: 55426.2243325\tbest: 55426.2243325 (0)\ttotal: 1.72ms\tremaining: 3.44s\n[14:55:25] bestTest = 16472.12881\n[14:55:25] bestIteration = 1995\n[14:55:25] Shrink model to first 1996 iterations.\n[14:55:25] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0009562797261249352, 'min_data_in_leaf': 12} scored -16480.14788661859 in 0:00:03.027802\n[14:55:25] 0:\tlearn: 53641.9161821\ttest: 55227.2308321\tbest: 55227.2308321 (0)\ttotal: 5.1ms\tremaining: 10.2s\n[14:55:31] Stopped by overfitting detector  (300 iterations wait)\n[14:55:31] bestTest = 17654.13625\n[14:55:31] bestIteration = 1104\n[14:55:31] Shrink model to first 1105 iterations.\n[14:55:31] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0324940112903956, 'min_data_in_leaf': 10} scored -17654.13611778846 in 0:00:05.569157\n[14:55:31] 0:\tlearn: 54242.2186752\ttest: 55473.2178087\tbest: 55473.2178087 (0)\ttotal: 1.21ms\tremaining: 2.42s\n[14:55:33] bestTest = 17439.80987\n[14:55:33] bestIteration = 1852\n[14:55:33] Shrink model to first 1853 iterations.\n[14:55:33] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 8.079160527532204e-05, 'min_data_in_leaf': 14} scored -17439.809795673078 in 0:00:02.568533\n[14:55:33] 0:\tlearn: 54030.2497442\ttest: 55426.2505840\tbest: 55426.2505840 (0)\ttotal: 1.87ms\tremaining: 3.73s\n[14:55:36] bestTest = 16355.91348\n[14:55:36] bestIteration = 1774\n[14:55:36] Shrink model to first 1775 iterations.\n[14:55:36] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0014322994820565986, 'min_data_in_leaf': 9} scored -16363.976929754273 in 0:00:03.182482\n[14:55:37] 0:\tlearn: 54030.2403040\ttest: 55426.2389026\tbest: 55426.2389026 (0)\ttotal: 1.62ms\tremaining: 3.23s\n[14:55:39] Stopped by overfitting detector  (300 iterations wait)\n[14:55:39] bestTest = 16382.73186\n[14:55:39] bestIteration = 1537\n[14:55:39] Shrink model to first 1538 iterations.\n[14:55:39] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.001220465366796973, 'min_data_in_leaf': 9} scored -16388.90209334936 in 0:00:02.803680\n[14:55:39] 0:\tlearn: 54030.2413607\ttest: 55426.2402103\tbest: 55426.2402103 (0)\ttotal: 1.65ms\tremaining: 3.29s\n[14:55:42] Stopped by overfitting detector  (300 iterations wait)\n[14:55:42] bestTest = 16417.91242\n[14:55:42] bestIteration = 1568\n[14:55:42] Shrink model to first 1569 iterations.\n[14:55:42] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00124417738080454, 'min_data_in_leaf': 9} scored -16420.684511885684 in 0:00:02.888982\n[14:55:42] 0:\tlearn: 54030.2057928\ttest: 55426.1961980\tbest: 55426.1961980 (0)\ttotal: 1.67ms\tremaining: 3.33s\n[14:55:45] bestTest = 16548.87249\n[14:55:45] bestIteration = 1811\n[14:55:45] Shrink model to first 1812 iterations.\n[14:55:45] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00044624882647332223, 'min_data_in_leaf': 6} scored -16556.93576388889 in 0:00:03.006518\n[14:55:45] 0:\tlearn: 54030.5486369\ttest: 55426.6204063\tbest: 55426.6204063 (0)\ttotal: 1.6ms\tremaining: 3.21s\n[14:55:48] Stopped by overfitting detector  (300 iterations wait)\n[14:55:48] bestTest = 16510.62231\n[14:55:48] bestIteration = 1641\n[14:55:48] Shrink model to first 1642 iterations.\n[14:55:48] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.008151272732444044, 'min_data_in_leaf': 8} scored -16517.016743456195 in 0:00:02.933694\n[14:55:48] 0:\tlearn: 53866.9773613\ttest: 55310.6642786\tbest: 55310.6642786 (0)\ttotal: 2.28ms\tremaining: 4.55s\n[14:55:52] Stopped by overfitting detector  (300 iterations wait)\n[14:55:52] bestTest = 16849.61016\n[14:55:52] bestIteration = 1652\n[14:55:52] Shrink model to first 1653 iterations.\n[14:55:52] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00011046589587353598, 'min_data_in_leaf': 9} scored -16806.946864983973 in 0:00:03.940247\n[14:55:52] 0:\tlearn: 54248.4318937\ttest: 55551.3083123\tbest: 55551.3083123 (0)\ttotal: 1.21ms\tremaining: 2.42s\n[14:55:54] bestTest = 17371.84095\n[14:55:54] bestIteration = 1997\n[14:55:54] Shrink model to first 1998 iterations.\n[14:55:54] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 3.542236289442737e-05, 'min_data_in_leaf': 7} scored -17371.84074519231 in 0:00:02.268542\n[14:55:55] 0:\tlearn: 54227.7872042\ttest: 55582.8653084\tbest: 55582.8653084 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[14:55:58] bestTest = 17100.79327\n[14:55:58] bestIteration = 1878\n[14:55:58] Shrink model to first 1879 iterations.\n[14:55:58] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.376271778223028e-07, 'min_data_in_leaf': 10} scored -17100.79296875 in 0:00:03.273663\n[14:55:58] 0:\tlearn: 53870.0804409\ttest: 55313.7098083\tbest: 55313.7098083 (0)\ttotal: 2.21ms\tremaining: 4.42s\n[14:56:01] Stopped by overfitting detector  (300 iterations wait)\n[14:56:01] bestTest = 16835.57947\n[14:56:01] bestIteration = 1171\n[14:56:01] Shrink model to first 1172 iterations.\n[14:56:01] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.04772454692524453, 'min_data_in_leaf': 14} scored -16819.810446714742 in 0:00:02.976004\n[14:56:01] 0:\tlearn: 53766.9757727\ttest: 55279.3428992\tbest: 55279.3428992 (0)\ttotal: 3.38ms\tremaining: 6.76s\n[14:56:04] Stopped by overfitting detector  (300 iterations wait)\n[14:56:04] bestTest = 17157.53689\n[14:56:04] bestIteration = 719\n[14:56:04] Shrink model to first 720 iterations.\n[14:56:04] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.005003722137478766, 'min_data_in_leaf': 12} scored -17157.536291399574 in 0:00:02.894310\n[14:56:04] 0:\tlearn: 54045.3244928\ttest: 55444.7692489\tbest: 55444.7692489 (0)\ttotal: 1.63ms\tremaining: 3.27s\n[14:56:07] Stopped by overfitting detector  (300 iterations wait)\n[14:56:07] bestTest = 16304.57557\n[14:56:07] bestIteration = 1578\n[14:56:07] Shrink model to first 1579 iterations.\n[14:56:07] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.3684047878156692, 'min_data_in_leaf': 7} scored -16307.725510817309 in 0:00:03.388607\n[14:56:07] 0:\tlearn: 54051.9485232\ttest: 55452.7780664\tbest: 55452.7780664 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[14:56:10] bestTest = 16326.5586\n[14:56:10] bestIteration = 1994\n[14:56:10] Shrink model to first 1995 iterations.\n[14:56:10] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5469924064743259, 'min_data_in_leaf': 5} scored -16332.740651709402 in 0:00:03.012381\n[14:56:10] 0:\tlearn: 54038.9916520\ttest: 55437.0307435\tbest: 55437.0307435 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:56:13] Stopped by overfitting detector  (300 iterations wait)\n[14:56:13] bestTest = 16625.19824\n[14:56:13] bestIteration = 1460\n[14:56:13] Shrink model to first 1461 iterations.\n[14:56:13] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.20737536609880286, 'min_data_in_leaf': 5} scored -16631.76191907051 in 0:00:02.722500\n[14:56:13] 0:\tlearn: 54097.9232740\ttest: 55505.5960668\tbest: 55505.5960668 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[14:56:16] bestTest = 16263.26313\n[14:56:16] bestIteration = 1999\n[14:56:16] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.034641376892043, 'min_data_in_leaf': 5} scored -16264.240100827992 in 0:00:02.999525\n[14:56:16] 0:\tlearn: 54066.6719896\ttest: 55470.2202085\tbest: 55470.2202085 (0)\ttotal: 1.57ms\tremaining: 3.15s\n[14:56:19] Stopped by overfitting detector  (300 iterations wait)\n[14:56:19] bestTest = 16122.69595\n[14:56:19] bestIteration = 1598\n[14:56:19] Shrink model to first 1599 iterations.\n[14:56:19] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.9787564079368203, 'min_data_in_leaf': 3} scored -16129.402744391025 in 0:00:02.843280\n[14:56:19] 0:\tlearn: 53926.7834384\ttest: 55369.5436557\tbest: 55369.5436557 (0)\ttotal: 2.14ms\tremaining: 4.28s\n[14:56:22] Stopped by overfitting detector  (300 iterations wait)\n[14:56:22] bestTest = 16460.2842\n[14:56:22] bestIteration = 1320\n[14:56:22] Shrink model to first 1321 iterations.\n[14:56:22] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1191299674604964, 'min_data_in_leaf': 2} scored -16460.28400440705 in 0:00:03.326977\n[14:56:22] 0:\tlearn: 54159.5391897\ttest: 55570.4603569\tbest: 55570.4603569 (0)\ttotal: 1.55ms\tremaining: 3.09s\n[14:56:25] bestTest = 16942.24117\n[14:56:25] bestIteration = 1999\n[14:56:25] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 4.553949987603766, 'min_data_in_leaf': 5} scored -16949.274255475426 in 0:00:02.988191\n[14:56:25] 0:\tlearn: 54061.5082828\ttest: 55464.1614490\tbest: 55464.1614490 (0)\ttotal: 1.59ms\tremaining: 3.19s\n[14:56:28] Stopped by overfitting detector  (300 iterations wait)\n[14:56:28] bestTest = 16410.00108\n[14:56:28] bestIteration = 1436\n[14:56:28] Shrink model to first 1437 iterations.\n[14:56:28] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.8220826552930509, 'min_data_in_leaf': 3} scored -16420.465578258547 in 0:00:02.641944\n[14:56:28] 0:\tlearn: 54294.4140730\ttest: 55598.1740490\tbest: 55598.1740490 (0)\ttotal: 1.26ms\tremaining: 2.52s\n[14:56:30] bestTest = 17137.69922\n[14:56:30] bestIteration = 1999\n[14:56:30] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.5943785724645765, 'min_data_in_leaf': 5} scored -17137.699101896367 in 0:00:02.289268\n[14:56:30] 0:\tlearn: 54243.7713142\ttest: 55653.5252479\tbest: 55653.5252479 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[14:56:33] Stopped by overfitting detector  (300 iterations wait)\n[14:56:33] bestTest = 16565.14462\n[14:56:33] bestIteration = 1467\n[14:56:33] Shrink model to first 1468 iterations.\n[14:56:33] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 8.740753832273379, 'min_data_in_leaf': 3} scored -16571.020315838676 in 0:00:02.682819\n[14:56:33] 0:\tlearn: 54248.1486279\ttest: 55571.4342872\tbest: 55571.4342872 (0)\ttotal: 1.6ms\tremaining: 3.19s\n[14:56:36] bestTest = 16853.76937\n[14:56:36] bestIteration = 1980\n[14:56:36] Shrink model to first 1981 iterations.\n[14:56:36] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.43430256392184063, 'min_data_in_leaf': 2} scored -16853.76948116987 in 0:00:02.977499\n[14:56:36] 0:\tlearn: 54043.3594644\ttest: 55442.3759540\tbest: 55442.3759540 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[14:56:39] Stopped by overfitting detector  (300 iterations wait)\n[14:56:39] bestTest = 16599.90915\n[14:56:39] bestIteration = 1593\n[14:56:39] Shrink model to first 1594 iterations.\n[14:56:39] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.31740343849977, 'min_data_in_leaf': 6} scored -16603.054370325855 in 0:00:03.253840\n[14:56:39] 0:\tlearn: 54106.1936340\ttest: 55514.6261496\tbest: 55514.6261496 (0)\ttotal: 1.87ms\tremaining: 3.73s\n[14:56:42] bestTest = 16231.81224\n[14:56:42] bestIteration = 1778\n[14:56:42] Shrink model to first 1779 iterations.\n[14:56:42] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.3417633443974344, 'min_data_in_leaf': 6} scored -16231.726796207266 in 0:00:03.055357\n[14:56:42] 0:\tlearn: 54110.3973059\ttest: 55519.1700575\tbest: 55519.1700575 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[14:56:43] Stopped by overfitting detector  (300 iterations wait)\n[14:56:44] bestTest = 16678.69346\n[14:56:44] bestIteration = 721\n[14:56:44] Shrink model to first 722 iterations.\n[14:56:44] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.501881941410665, 'min_data_in_leaf': 4} scored -16690.068977029914 in 0:00:01.632321\n[14:56:44] 0:\tlearn: 54063.0572503\ttest: 55465.9855831\tbest: 55465.9855831 (0)\ttotal: 1.59ms\tremaining: 3.17s\n[14:56:46] Stopped by overfitting detector  (300 iterations wait)\n[14:56:46] bestTest = 16220.60608\n[14:56:46] bestIteration = 1419\n[14:56:46] Shrink model to first 1420 iterations.\n[14:56:46] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.868501877772144, 'min_data_in_leaf': 7} scored -16224.71390892094 in 0:00:02.631068\n[14:56:47] 0:\tlearn: 54095.4424101\ttest: 55502.8626531\tbest: 55502.8626531 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[14:56:49] bestTest = 16463.32462\n[14:56:49] bestIteration = 1995\n[14:56:49] Shrink model to first 1996 iterations.\n[14:56:49] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.9446217758074174, 'min_data_in_leaf': 7} scored -16474.01732772436 in 0:00:03.251149\n[14:56:50] 0:\tlearn: 54335.8233283\ttest: 55639.9675340\tbest: 55639.9675340 (0)\ttotal: 1.2ms\tremaining: 2.39s\n[14:56:52] bestTest = 17572.50849\n[14:56:52] bestIteration = 1990\n[14:56:52] Shrink model to first 1991 iterations.\n[14:56:52] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 5.2780588785123, 'min_data_in_leaf': 7} scored -17572.50883079594 in 0:00:02.307555\n[14:56:52] 0:\tlearn: 53871.7821697\ttest: 55315.3821808\tbest: 55315.3821808 (0)\ttotal: 2.13ms\tremaining: 4.25s\n[14:56:56] Stopped by overfitting detector  (300 iterations wait)\n[14:56:56] bestTest = 17043.46327\n[14:56:56] bestIteration = 1687\n[14:56:56] Shrink model to first 1688 iterations.\n[14:56:56] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.07433354619547114, 'min_data_in_leaf': 4} scored -17041.896217280984 in 0:00:03.969850\n[14:56:56] 0:\tlearn: 54076.1079233\ttest: 55481.1289321\tbest: 55481.1289321 (0)\ttotal: 1.6ms\tremaining: 3.19s\n[14:56:59] bestTest = 16289.42976\n[14:56:59] bestIteration = 1888\n[14:56:59] Shrink model to first 1889 iterations.\n[14:56:59] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2788173981263902, 'min_data_in_leaf': 6} scored -16295.868222489316 in 0:00:02.983349\n[14:56:59] 0:\tlearn: 53945.3644270\ttest: 55387.6693466\tbest: 55387.6693466 (0)\ttotal: 2.08ms\tremaining: 4.17s\n[14:57:02] Stopped by overfitting detector  (300 iterations wait)\n[14:57:02] bestTest = 16690.44182\n[14:57:02] bestIteration = 1304\n[14:57:02] Shrink model to first 1305 iterations.\n[14:57:02] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.5490112376985394, 'min_data_in_leaf': 2} scored -16682.822749732906 in 0:00:03.288155\n[14:57:02] 0:\tlearn: 54063.7441893\ttest: 55466.7927216\tbest: 55466.7927216 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[14:57:05] bestTest = 16593.18918\n[14:57:05] bestIteration = 1928\n[14:57:05] Shrink model to first 1929 iterations.\n[14:57:05] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.889247887495479, 'min_data_in_leaf': 6} scored -16605.37049278846 in 0:00:03.010261\n[14:57:05] 0:\tlearn: 54041.8846978\ttest: 55440.5749434\tbest: 55440.5749434 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[14:57:08] Stopped by overfitting detector  (300 iterations wait)\n[14:57:08] bestTest = 16838.83529\n[14:57:08] bestIteration = 1507\n[14:57:08] Shrink model to first 1508 iterations.\n[14:57:08] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.27973457202062174, 'min_data_in_leaf': 6} scored -16852.88361378205 in 0:00:02.717736\n[14:57:08] 0:\tlearn: 54056.5153564\ttest: 55458.2427461\tbest: 55458.2427461 (0)\ttotal: 1.63ms\tremaining: 3.27s\n[14:57:11] Stopped by overfitting detector  (300 iterations wait)\n[14:57:11] bestTest = 16420.96532\n[14:57:11] bestIteration = 1459\n[14:57:11] Shrink model to first 1460 iterations.\n[14:57:11] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.6759193998482723, 'min_data_in_leaf': 8} scored -16424.11204594017 in 0:00:02.979011\n[14:57:11] 0:\tlearn: 54226.1030056\ttest: 55636.4325845\tbest: 55636.4325845 (0)\ttotal: 1.88ms\tremaining: 3.75s\n[14:57:14] bestTest = 16915.85367\n[14:57:14] bestIteration = 1991\n[14:57:14] Shrink model to first 1992 iterations.\n[14:57:14] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.79713616723855, 'min_data_in_leaf': 5} scored -16927.55498798077 in 0:00:03.158940\n[14:57:14] 0:\tlearn: 54131.3989921\ttest: 55541.4626682\tbest: 55541.4626682 (0)\ttotal: 1.56ms\tremaining: 3.13s\n[14:57:17] Stopped by overfitting detector  (300 iterations wait)\n[14:57:17] bestTest = 16656.86415\n[14:57:17] bestIteration = 1695\n[14:57:17] Shrink model to first 1696 iterations.\n[14:57:17] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.339840482466172, 'min_data_in_leaf': 7} scored -16660.205745860043 in 0:00:03.016607\n[14:57:17] 0:\tlearn: 54036.7287533\ttest: 55434.2491978\tbest: 55434.2491978 (0)\ttotal: 1.56ms\tremaining: 3.13s\n[14:57:19] Stopped by overfitting detector  (300 iterations wait)\n[14:57:19] bestTest = 16563.12925\n[14:57:19] bestIteration = 836\n[14:57:19] Shrink model to first 837 iterations.\n[14:57:19] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1522151515855865, 'min_data_in_leaf': 3} scored -16575.72465945513 in 0:00:01.772486\n[14:57:19] 0:\tlearn: 54076.2916306\ttest: 55481.3392627\tbest: 55481.3392627 (0)\ttotal: 1.58ms\tremaining: 3.15s\n[14:57:22] bestTest = 16243.09676\n[14:57:22] bestIteration = 1916\n[14:57:22] Shrink model to first 1917 iterations.\n[14:57:22] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2848291394283422, 'min_data_in_leaf': 6} scored -16246.317040598291 in 0:00:03.030225\n[14:57:22] 0:\tlearn: 54242.2174629\ttest: 55473.2166367\tbest: 55473.2166367 (0)\ttotal: 1.21ms\tremaining: 2.41s\n[14:57:24] bestTest = 17489.04017\n[14:57:24] bestIteration = 1852\n[14:57:24] Shrink model to first 1853 iterations.\n[14:57:24] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 9.351658837848487e-06, 'min_data_in_leaf': 4} scored -17489.040448050215 in 0:00:02.299891\n[14:57:24] 0:\tlearn: 53885.9926567\ttest: 55389.5795205\tbest: 55389.5795205 (0)\ttotal: 2.99ms\tremaining: 5.98s\n[14:57:28] Stopped by overfitting detector  (300 iterations wait)\n[14:57:28] bestTest = 16685.69866\n[14:57:28] bestIteration = 1189\n[14:57:28] Shrink model to first 1190 iterations.\n[14:57:28] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3827237053348003, 'min_data_in_leaf': 5} scored -16685.698734642094 in 0:00:04.077081\n[14:57:28] 0:\tlearn: 54171.6042374\ttest: 55582.6518875\tbest: 55582.6518875 (0)\ttotal: 1.56ms\tremaining: 3.12s\n[14:57:31] Stopped by overfitting detector  (300 iterations wait)\n[14:57:31] bestTest = 16751.66338\n[14:57:31] bestIteration = 1607\n[14:57:31] Shrink model to first 1608 iterations.\n[14:57:31] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.104207517424197, 'min_data_in_leaf': 8} scored -16758.101145165598 in 0:00:02.858972\n[14:57:31] 0:\tlearn: 54083.3257042\ttest: 55489.3357341\tbest: 55489.3357341 (0)\ttotal: 1.56ms\tremaining: 3.13s\n[14:57:34] Stopped by overfitting detector  (300 iterations wait)\n[14:57:34] bestTest = 16313.37038\n[14:57:34] bestIteration = 1459\n[14:57:34] Shrink model to first 1460 iterations.\n[14:57:34] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.5196904653982717, 'min_data_in_leaf': 6} scored -16320.690120860043 in 0:00:02.707203\n[14:57:34] 0:\tlearn: 54038.4628506\ttest: 55436.3814322\tbest: 55436.3814322 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[14:57:37] Stopped by overfitting detector  (300 iterations wait)\n[14:57:37] bestTest = 16730.83315\n[14:57:37] bestIteration = 1608\n[14:57:37] Shrink model to first 1609 iterations.\n[14:57:37] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1943715116021663, 'min_data_in_leaf': 7} scored -16734.114149305555 in 0:00:02.878527\n[14:57:37] 0:\tlearn: 54049.4804383\ttest: 55449.8050690\tbest: 55449.8050690 (0)\ttotal: 1.57ms\tremaining: 3.15s\n[14:57:40] bestTest = 16503.07098\n[14:57:40] bestIteration = 1998\n[14:57:40] Shrink model to first 1999 iterations.\n[14:57:40] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.4792670548920583, 'min_data_in_leaf': 13} scored -16505.69314236111 in 0:00:03.000247\n[14:57:40] 0:\tlearn: 54034.5467028\ttest: 55431.5603401\tbest: 55431.5603401 (0)\ttotal: 1.57ms\tremaining: 3.15s\n[14:57:43] bestTest = 16521.64857\n[14:57:43] bestIteration = 1889\n[14:57:43] Shrink model to first 1890 iterations.\n[14:57:43] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10023947935304714, 'min_data_in_leaf': 6} scored -16527.819878472223 in 0:00:03.282993\n[14:57:43] 0:\tlearn: 54030.2077006\ttest: 55426.1985587\tbest: 55426.1985587 (0)\ttotal: 1.99ms\tremaining: 3.99s\n[14:57:46] bestTest = 16492.90401\n[14:57:46] bestIteration = 1998\n[14:57:46] Shrink model to first 1999 iterations.\n[14:57:46] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0004890395955247634, 'min_data_in_leaf': 1} scored -16500.575737847223 in 0:00:03.341670\n[14:57:47] 0:\tlearn: 54124.2577226\ttest: 55533.9536850\tbest: 55533.9536850 (0)\ttotal: 1.7ms\tremaining: 3.4s\n[14:57:49] Stopped by overfitting detector  (300 iterations wait)\n[14:57:49] bestTest = 16235.53767\n[14:57:49] bestIteration = 1473\n[14:57:49] Shrink model to first 1474 iterations.\n[14:57:49] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.04802665676445, 'min_data_in_leaf': 10} scored -16239.418953659188 in 0:00:02.664637\n[14:57:49] 0:\tlearn: 54101.2383101\ttest: 55509.2304973\tbest: 55509.2304973 (0)\ttotal: 1.59ms\tremaining: 3.17s\n[14:57:52] Stopped by overfitting detector  (300 iterations wait)\n[14:57:52] bestTest = 16455.42424\n[14:57:52] bestIteration = 1376\n[14:57:52] Shrink model to first 1377 iterations.\n[14:57:52] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.1564640375870967, 'min_data_in_leaf': 10} scored -16456.89958934295 in 0:00:02.574110\n[14:57:52] 0:\tlearn: 54134.1637691\ttest: 55544.3518607\tbest: 55544.3518607 (0)\ttotal: 1.57ms\tremaining: 3.13s\n[14:57:54] Stopped by overfitting detector  (300 iterations wait)\n[14:57:54] bestTest = 16737.44994\n[14:57:54] bestIteration = 1474\n[14:57:54] Shrink model to first 1475 iterations.\n[14:57:54] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4546495507285044, 'min_data_in_leaf': 12} scored -16741.29109909188 in 0:00:02.673528\n[14:57:55] 0:\tlearn: 53778.8261247\ttest: 55349.6245584\tbest: 55349.6245584 (0)\ttotal: 4.71ms\tremaining: 9.41s\n[14:57:57] Stopped by overfitting detector  (300 iterations wait)\n[14:57:57] bestTest = 17259.41614\n[14:57:57] bestIteration = 350\n[14:57:57] Shrink model to first 351 iterations.\n[14:57:57] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.9768953701112884, 'min_data_in_leaf': 11} scored -17259.41579861111 in 0:00:02.639292\n[14:57:57] 0:\tlearn: 54218.0010409\ttest: 55476.6447729\tbest: 55476.6447729 (0)\ttotal: 2.04ms\tremaining: 4.07s\n[14:58:01] Stopped by overfitting detector  (300 iterations wait)\n[14:58:01] bestTest = 16866.31952\n[14:58:01] bestIteration = 1586\n[14:58:01] Shrink model to first 1587 iterations.\n[14:58:01] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 9.886580636702957, 'min_data_in_leaf': 13} scored -16866.31959468483 in 0:00:03.728307\n[14:58:01] 0:\tlearn: 54248.4312143\ttest: 55551.3076179\tbest: 55551.3076179 (0)\ttotal: 1.22ms\tremaining: 2.43s\n[14:58:03] bestTest = 17377.3455\n[14:58:03] bestIteration = 1982\n[14:58:03] Shrink model to first 1983 iterations.\n[14:58:03] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 4.42879718143743e-08, 'min_data_in_leaf': 11} scored -17377.34536925748 in 0:00:02.301549\n[14:58:03] 0:\tlearn: 54053.4577513\ttest: 55454.5893144\tbest: 55454.5893144 (0)\ttotal: 1.56ms\tremaining: 3.12s\n[14:58:06] bestTest = 16223.47096\n[14:58:06] bestIteration = 1817\n[14:58:06] Shrink model to first 1818 iterations.\n[14:58:06] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5890860683715836, 'min_data_in_leaf': 7} scored -16230.066690037393 in 0:00:03.004234\n[14:58:06] 0:\tlearn: 54058.7585754\ttest: 55460.9091989\tbest: 55460.9091989 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[14:58:09] Stopped by overfitting detector  (300 iterations wait)\n[14:58:09] bestTest = 16449.08916\n[14:58:09] bestIteration = 1431\n[14:58:09] Shrink model to first 1432 iterations.\n[14:58:09] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.7409261287931915, 'min_data_in_leaf': 8} scored -16459.826739449785 in 0:00:02.640374\n[14:58:09] 0:\tlearn: 54195.1289834\ttest: 55606.0947181\tbest: 55606.0947181 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[14:58:12] bestTest = 17081.96724\n[14:58:12] bestIteration = 1929\n[14:58:12] Shrink model to first 1930 iterations.\n[14:58:12] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 6.225724866914116, 'min_data_in_leaf': 5} scored -17088.905265090812 in 0:00:03.050328\n[14:58:12] 0:\tlearn: 54030.1859261\ttest: 55426.1716144\tbest: 55426.1716144 (0)\ttotal: 1.66ms\tremaining: 3.33s\n[14:58:14] Stopped by overfitting detector  (300 iterations wait)\n[14:58:14] bestTest = 16618.40679\n[14:58:14] bestIteration = 1418\n[14:58:14] Shrink model to first 1419 iterations.\n[14:58:15] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.047366195470366e-07, 'min_data_in_leaf': 6} scored -16626.47020232372 in 0:00:02.695482\n[14:58:15] 0:\tlearn: 54133.6880714\ttest: 55543.8554440\tbest: 55543.8554440 (0)\ttotal: 1.9ms\tremaining: 3.8s\n[14:58:18] bestTest = 16761.90564\n[14:58:18] bestIteration = 1991\n[14:58:18] Shrink model to first 1992 iterations.\n[14:58:18] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.43482391622008, 'min_data_in_leaf': 4} scored -16765.707047943375 in 0:00:03.453595\n[14:58:18] 0:\tlearn: 54077.5235617\ttest: 55482.7477443\tbest: 55482.7477443 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[14:58:21] bestTest = 16240.3731\n[14:58:21] bestIteration = 1999\n[14:58:21] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3253064179436045, 'min_data_in_leaf': 9} scored -16248.401625934828 in 0:00:02.984997\n[14:58:21] 0:\tlearn: 54032.5411110\ttest: 55429.0840791\tbest: 55429.0840791 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[14:58:24] Stopped by overfitting detector  (300 iterations wait)\n[14:58:24] bestTest = 16567.39999\n[14:58:24] bestIteration = 1554\n[14:58:24] Shrink model to first 1555 iterations.\n[14:58:24] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.053531649261249925, 'min_data_in_leaf': 10} scored -16573.58143028846 in 0:00:02.855024\n[14:58:24] 0:\tlearn: 54042.3114257\ttest: 55441.0964830\tbest: 55441.0964830 (0)\ttotal: 1.59ms\tremaining: 3.19s\n[14:58:27] bestTest = 16766.04861\n[14:58:27] bestIteration = 1899\n[14:58:27] Shrink model to first 1900 iterations.\n[14:58:27] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.2905802109163183, 'min_data_in_leaf': 10} scored -16775.84039463141 in 0:00:03.045553\n[14:58:27] 0:\tlearn: 54030.7879930\ttest: 55426.9165228\tbest: 55426.9165228 (0)\ttotal: 1.6ms\tremaining: 3.21s\n[14:58:30] bestTest = 16360.64582\n[14:58:30] bestIteration = 1946\n[14:58:30] Shrink model to first 1947 iterations.\n[14:58:30] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.013548606178167551, 'min_data_in_leaf': 9} scored -16369.086371527777 in 0:00:03.050182\n[14:58:30] 0:\tlearn: 54053.8610827\ttest: 55455.0724790\tbest: 55455.0724790 (0)\ttotal: 1.66ms\tremaining: 3.32s\n[14:58:33] bestTest = 16348.61588\n[14:58:33] bestIteration = 1985\n[14:58:33] Shrink model to first 1986 iterations.\n[14:58:33] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.6004217365861487, 'min_data_in_leaf': 8} scored -16354.898571047008 in 0:00:03.106530\n[14:58:33] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[14:58:33] The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.9787564079368203, 'min_data_in_leaf': 3}\u001b[0m\n achieve -16129.4027 mae\n[14:58:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[14:58:33] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:58:33] 0:\tlearn: 54792.8736014\ttest: 56144.1590853\tbest: 56144.1590853 (0)\ttotal: 1.58ms\tremaining: 4.74s\n[14:58:36] Stopped by overfitting detector  (100 iterations wait)\n[14:58:36] bestTest = 16991.837\n[14:58:36] bestIteration = 1637\n[14:58:36] Shrink model to first 1638 iterations.\n[14:58:36] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:58:36] 0:\tlearn: 55681.9330981\ttest: 55195.7666752\tbest: 55195.7666752 (0)\ttotal: 1.54ms\tremaining: 4.62s\n[14:58:37] Stopped by overfitting detector  (100 iterations wait)\n[14:58:37] bestTest = 13199.68244\n[14:58:37] bestIteration = 618\n[14:58:37] Shrink model to first 619 iterations.\n[14:58:37] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:58:37] 0:\tlearn: 54790.8916351\ttest: 55811.2969673\tbest: 55811.2969673 (0)\ttotal: 1.57ms\tremaining: 4.71s\n[14:58:39] Stopped by overfitting detector  (100 iterations wait)\n[14:58:39] bestTest = 15448.59481\n[14:58:39] bestIteration = 1019\n[14:58:39] Shrink model to first 1020 iterations.\n[14:58:39] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:58:39] 0:\tlearn: 54821.5820922\ttest: 55949.6622707\tbest: 55949.6622707 (0)\ttotal: 1.58ms\tremaining: 4.73s\n[14:58:40] Stopped by overfitting detector  (100 iterations wait)\n[14:58:40] bestTest = 14686.49327\n[14:58:40] bestIteration = 925\n[14:58:40] Shrink model to first 926 iterations.\n[14:58:40] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[14:58:40] 0:\tlearn: 55888.8189717\ttest: 53430.5453610\tbest: 53430.5453610 (0)\ttotal: 1.56ms\tremaining: 4.69s\n[14:58:42] Stopped by overfitting detector  (100 iterations wait)\n[14:58:42] bestTest = 14033.43528\n[14:58:42] bestIteration = 1482\n[14:58:42] Shrink model to first 1483 iterations.\n[14:58:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14880.14538406999\u001b[0m\n[14:58:42] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[14:58:42] Time left 3613.66 secs\n\n[14:58:42] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[14:58:42] Blending: optimization starts with equal weights and score \u001b[1m-14578.067239003638\u001b[0m\n[14:58:43] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14545.209843883777\u001b[0m, weights = \u001b[1m[0.16294904 0.2915355  0.08521949 0.17030375 0.28999224]\u001b[0m\n[14:58:43] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14541.304617267766\u001b[0m, weights = \u001b[1m[0.1417729  0.32964262 0.06314814 0.18446611 0.28097022]\u001b[0m\n[14:58:43] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14540.889099957192\u001b[0m, weights = \u001b[1m[0.13654819 0.33254027 0.06239028 0.18162008 0.28690127]\u001b[0m\n[14:58:43] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14540.872347897046\u001b[0m, weights = \u001b[1m[0.13539743 0.33257347 0.06186449 0.18008949 0.29007512]\u001b[0m\n[14:58:43] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14540.869324566567\u001b[0m, weights = \u001b[1m[0.13508081 0.3317958  0.06171982 0.18070637 0.29069716]\u001b[0m\n[14:58:43] \u001b[1mAutoml preset training completed in 666.60 seconds\u001b[0m\n\n[14:58:43] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.13508 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.33180 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.06172 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.18071 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.29070 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[14:58:43] ==================================================\n[14:58:43] Start 4 automl preset configuration:\n[14:58:43] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n[14:58:43] Found reader_params in kwargs, need to combine\n[14:58:43] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 46, 'cv': 5}\n[14:58:43] Stdout logging level is INFO3.\n[14:58:43] Task: reg\n\n[14:58:43] Start automl preset with listed constraints:\n[14:58:43] - time: 3613.50 seconds\n[14:58:43] - CPU: 4 cores\n[14:58:43] - memory: 16 GB\n\n[14:58:43] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[14:58:49] Feats was rejected during automatic roles guess: []\n[14:58:49] Layer \u001b[1m1\u001b[0m train process start. Time left 3606.76 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:58:50] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[14:58:50] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:58:50] Linear model: C = 1e-05 score = -38195.90458066239\n[14:58:50] Linear model: C = 5e-05 score = -24382.960353231836\n[14:58:50] Linear model: C = 0.0001 score = -21628.666708400106\n[14:58:51] Linear model: C = 0.0005 score = -19300.476323576055\n[14:58:51] Linear model: C = 0.001 score = -19300.476323576055\n[14:58:51] Linear model: C = 0.005 score = -19477.785913711938\n[14:58:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:58:51] Linear model: C = 1e-05 score = -38847.46447649573\n[14:58:51] Linear model: C = 5e-05 score = -24577.829126602563\n[14:58:51] Linear model: C = 0.0001 score = -21945.577590811965\n[14:58:52] Linear model: C = 0.0005 score = -19634.14266159188\n[14:58:52] Linear model: C = 0.001 score = -19410.40336204594\n[14:58:52] Linear model: C = 0.005 score = -19415.18144030449\n[14:58:52] Linear model: C = 0.01 score = -19415.18299278846\n[14:58:52] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:58:53] Linear model: C = 1e-05 score = -38532.61538461538\n[14:58:53] Linear model: C = 5e-05 score = -25575.182091346152\n[14:58:53] Linear model: C = 0.0001 score = -22429.961037660258\n[14:58:53] Linear model: C = 0.0005 score = -18302.24589342949\n[14:58:53] Linear model: C = 0.001 score = -17473.53617454594\n[14:58:54] Linear model: C = 0.005 score = -16569.948567708332\n[14:58:54] Linear model: C = 0.01 score = -16569.948267227563\n[14:58:54] Linear model: C = 0.05 score = -17725.447332398504\n[14:58:54] Linear model: C = 0.1 score = -17897.9718883547\n[14:58:54] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:58:55] Linear model: C = 1e-05 score = -33403.933409334764\n[14:58:55] Linear model: C = 5e-05 score = -20416.522029238196\n[14:58:55] Linear model: C = 0.0001 score = -18080.950409066525\n[14:58:55] Linear model: C = 0.0005 score = -15751.470191791845\n[14:58:55] Linear model: C = 0.001 score = -15651.803731893777\n[14:58:56] Linear model: C = 0.005 score = -16055.512020520386\n[14:58:56] Linear model: C = 0.01 score = -16528.94643575644\n[14:58:56] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[14:58:56] Linear model: C = 1e-05 score = -36682.17623390558\n[14:58:56] Linear model: C = 5e-05 score = -22937.198229613732\n[14:58:56] Linear model: C = 0.0001 score = -19914.988599785407\n[14:58:56] Linear model: C = 0.0005 score = -16734.768994769314\n[14:58:57] Linear model: C = 0.001 score = -16734.76642972103\n[14:58:57] Linear model: C = 0.005 score = -16892.31192998927\n[14:58:57] Linear model: C = 0.01 score = -17391.488113599786\n[14:58:57] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17535.77447656083\u001b[0m\n[14:58:57] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[14:58:57] Time left 3599.12 secs\n\n[14:58:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[14:58:57] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:58:57] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[14:59:00] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:59:00] Training until validation scores don't improve for 200 rounds\n[14:59:04] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:59:04] Training until validation scores don't improve for 200 rounds\n[14:59:06] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:59:06] Training until validation scores don't improve for 200 rounds\n[14:59:08] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[14:59:08] Training until validation scores don't improve for 200 rounds\n[14:59:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15512.287507357663\u001b[0m\n[14:59:10] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[14:59:10] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[14:59:10] Training until validation scores don't improve for 200 rounds\n[14:59:13] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -17379.544270833332 in 0:00:03.488138\n[14:59:13] Training until validation scores don't improve for 200 rounds\n[14:59:17] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -17043.109007745727 in 0:00:03.416699\n[14:59:17] Training until validation scores don't improve for 200 rounds\n[14:59:22] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -16950.278879540598 in 0:00:05.316321\n[14:59:22] Training until validation scores don't improve for 200 rounds\n[14:59:25] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -17330.297843215812 in 0:00:02.836322\n[14:59:25] Training until validation scores don't improve for 200 rounds\n[14:59:28] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -16901.776375534188 in 0:00:03.582915\n[14:59:28] Training until validation scores don't improve for 200 rounds\n[14:59:31] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -17391.39623397436 in 0:00:02.698525\n[14:59:31] Training until validation scores don't improve for 200 rounds\n[14:59:35] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -17210.212773771367 in 0:00:04.095814\n[14:59:35] Training until validation scores don't improve for 200 rounds\n[14:59:38] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -16907.739416399574 in 0:00:02.517692\n[14:59:38] Training until validation scores don't improve for 200 rounds\n[14:59:41] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -17573.70579594017 in 0:00:03.604470\n[14:59:41] Training until validation scores don't improve for 200 rounds\n[14:59:44] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -17123.317708333332 in 0:00:02.854711\n[14:59:44] Training until validation scores don't improve for 200 rounds\n[14:59:48] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 177, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.050888616200595385, 'reg_alpha': 0.010510985525196167, 'reg_lambda': 2.2311398834761413e-08} scored -17169.6500400641 in 0:00:04.003553\n[14:59:48] Training until validation scores don't improve for 200 rounds\n[14:59:51] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.507797399829228, 'num_leaves': 179, 'bagging_fraction': 0.6673975881116181, 'min_sum_hessian_in_leaf': 0.1610128003061733, 'reg_alpha': 0.001079801017138211, 'reg_lambda': 0.01881061891210943} scored -16969.79316907051 in 0:00:02.825242\n[14:59:52] Training until validation scores don't improve for 200 rounds\n[14:59:57] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5978132755554657, 'num_leaves': 189, 'bagging_fraction': 0.6417907414923303, 'min_sum_hessian_in_leaf': 0.01875620628228737, 'reg_alpha': 0.022017949493573677, 'reg_lambda': 0.003610116265596713} scored -16982.934762286324 in 0:00:06.291309\n[14:59:57] Training until validation scores don't improve for 200 rounds\n[15:00:01] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.8785841377478474, 'num_leaves': 127, 'bagging_fraction': 0.722308544990837, 'min_sum_hessian_in_leaf': 1.7282108375668734, 'reg_alpha': 4.548670779377984e-05, 'reg_lambda': 2.9536889586486034e-06} scored -17060.82792467949 in 0:00:03.618267\n[15:00:01] Training until validation scores don't improve for 200 rounds\n[15:00:03] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5566688186333628, 'num_leaves': 203, 'bagging_fraction': 0.6040480561972923, 'min_sum_hessian_in_leaf': 0.37947060877945143, 'reg_alpha': 0.00042462573201201744, 'reg_lambda': 1.063082707940129e-08} scored -17051.07842548077 in 0:00:02.452406\n[15:00:04] Training until validation scores don't improve for 200 rounds\n[15:00:06] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.615626318320349, 'num_leaves': 134, 'bagging_fraction': 0.5127747474052715, 'min_sum_hessian_in_leaf': 6.571634539290906, 'reg_alpha': 0.07208603147883481, 'reg_lambda': 0.00014211618981379645} scored -17280.602096688035 in 0:00:02.143391\n[15:00:06] Training until validation scores don't improve for 200 rounds\n[15:00:10] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.8621859258366549, 'num_leaves': 161, 'bagging_fraction': 0.7325956233926898, 'min_sum_hessian_in_leaf': 0.027731163081551317, 'reg_alpha': 2.0249298616973216e-05, 'reg_lambda': 3.8568923410717157e-07} scored -17327.661658653848 in 0:00:04.131856\n[15:00:10] Training until validation scores don't improve for 200 rounds\n[15:00:14] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.7299820798583574, 'num_leaves': 254, 'bagging_fraction': 0.6088129728103225, 'min_sum_hessian_in_leaf': 0.144868987635027, 'reg_alpha': 0.00202482044166596, 'reg_lambda': 0.0018125999369080772} scored -16979.411124465812 in 0:00:03.808561\n[15:00:14] Training until validation scores don't improve for 200 rounds\n[15:00:17] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.5998659891438878, 'num_leaves': 215, 'bagging_fraction': 0.5693086613243123, 'min_sum_hessian_in_leaf': 1.8655654346846529, 'reg_alpha': 0.27410262472733804, 'reg_lambda': 0.018435554894550506} scored -16824.465277777777 in 0:00:03.491626\n[15:00:17] Training until validation scores don't improve for 200 rounds\n[15:00:21] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.6599362867984437, 'num_leaves': 213, 'bagging_fraction': 0.5700960822481722, 'min_sum_hessian_in_leaf': 2.2094860255768376, 'reg_alpha': 0.36714255469878165, 'reg_lambda': 0.05740835784199981} scored -16740.151008279914 in 0:00:03.552818\n[15:00:21] Training until validation scores don't improve for 200 rounds\n[15:00:26] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.654850389858358, 'num_leaves': 109, 'bagging_fraction': 0.5669716875225357, 'min_sum_hessian_in_leaf': 2.5652628836976876, 'reg_alpha': 0.4348329970463301, 'reg_lambda': 0.10351163679178912} scored -16821.004273504273 in 0:00:05.308908\n[15:00:26] Training until validation scores don't improve for 200 rounds\n[15:00:29] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.6481166160038659, 'num_leaves': 107, 'bagging_fraction': 0.5655735420675556, 'min_sum_hessian_in_leaf': 2.6590271075927987, 'reg_alpha': 0.51899184599321, 'reg_lambda': 0.06576899283984078} scored -16726.62950721154 in 0:00:02.793032\n[15:00:29] Training until validation scores don't improve for 200 rounds\n[15:00:32] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.6739935514376999, 'num_leaves': 102, 'bagging_fraction': 0.5407903592556691, 'min_sum_hessian_in_leaf': 3.876048510090418, 'reg_alpha': 0.6118745226794134, 'reg_lambda': 0.16415499439521303} scored -17090.40995592949 in 0:00:02.801128\n[15:00:32] Training until validation scores don't improve for 200 rounds\n[15:00:34] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.6428924987963969, 'num_leaves': 106, 'bagging_fraction': 0.5095443971649275, 'min_sum_hessian_in_leaf': 9.562402056861744, 'reg_alpha': 0.2792540478583079, 'reg_lambda': 0.09551586111942274} scored -17260.90217681624 in 0:00:02.122734\n[15:00:34] Training until validation scores don't improve for 200 rounds\n[15:00:37] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5629392891959613, 'num_leaves': 151, 'bagging_fraction': 0.6878283490656888, 'min_sum_hessian_in_leaf': 3.0069031155459154, 'reg_alpha': 9.762069055774612, 'reg_lambda': 0.8910062386573254} scored -17066.937900641027 in 0:00:03.186205\n[15:00:37] Training until validation scores don't improve for 200 rounds\n[15:00:40] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6922105340953233, 'num_leaves': 115, 'bagging_fraction': 0.5673861611398618, 'min_sum_hessian_in_leaf': 0.8131095290595362, 'reg_alpha': 1.5292854660968869, 'reg_lambda': 0.018406742016191892} scored -16675.23607772436 in 0:00:03.569848\n[15:00:41] Training until validation scores don't improve for 200 rounds\n[15:00:43] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.6895275318198413, 'num_leaves': 18, 'bagging_fraction': 0.6477126892772116, 'min_sum_hessian_in_leaf': 0.7445868429130833, 'reg_alpha': 0.03887666836269384, 'reg_lambda': 0.012346572608100164} scored -16877.0867053953 in 0:00:02.619924\n[15:00:43] Training until validation scores don't improve for 200 rounds\n[15:00:48] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.624664712174408, 'num_leaves': 84, 'bagging_fraction': 0.925308566320651, 'min_sum_hessian_in_leaf': 0.8288075176264152, 'reg_alpha': 1.5419882983290665, 'reg_lambda': 7.43881031955266} scored -17334.229033119656 in 0:00:04.690125\n[15:00:48] Training until validation scores don't improve for 200 rounds\n[15:00:51] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5727830662228991, 'num_leaves': 145, 'bagging_fraction': 0.5750737460040551, 'min_sum_hessian_in_leaf': 1.1818041864638515, 'reg_alpha': 0.10716752915105912, 'reg_lambda': 1.0014963289692012} scored -16912.3030849359 in 0:00:03.157154\n[15:00:51] Training until validation scores don't improve for 200 rounds\n[15:00:54] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6916772660554301, 'num_leaves': 122, 'bagging_fraction': 0.7066524668916468, 'min_sum_hessian_in_leaf': 0.0013030133773607152, 'reg_alpha': 0.007356649670135036, 'reg_lambda': 0.0066242126246542025} scored -17111.541499732906 in 0:00:03.003219\n[15:00:54] Training until validation scores don't improve for 200 rounds\n[15:00:58] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.7550748975922577, 'num_leaves': 159, 'bagging_fraction': 0.7463367214037203, 'min_sum_hessian_in_leaf': 4.387636133047436, 'reg_alpha': 2.230100874180154, 'reg_lambda': 0.043944095345813096} scored -17106.936531784188 in 0:00:04.449322\n[15:00:58] Training until validation scores don't improve for 200 rounds\n[15:01:02] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.6671125819441834, 'num_leaves': 110, 'bagging_fraction': 0.5590642142678967, 'min_sum_hessian_in_leaf': 2.2849203335985484, 'reg_alpha': 0.6239959414606467, 'reg_lambda': 0.3662722711508977} scored -16872.988982371793 in 0:00:03.351791\n[15:01:02] Training until validation scores don't improve for 200 rounds\n[15:01:04] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.710419861245253, 'num_leaves': 80, 'bagging_fraction': 0.5090209201695644, 'min_sum_hessian_in_leaf': 0.2706520293673624, 'reg_alpha': 0.3025395676030099, 'reg_lambda': 0.057695707946742975} scored -17206.921741452992 in 0:00:02.252670\n[15:01:04] Training until validation scores don't improve for 200 rounds\n[15:01:08] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.6403597613660198, 'num_leaves': 95, 'bagging_fraction': 0.6206970822977423, 'min_sum_hessian_in_leaf': 3.8604601250936246, 'reg_alpha': 0.11292927839341119, 'reg_lambda': 0.0015398736030409984} scored -16929.741920405984 in 0:00:03.518125\n[15:01:08] Training until validation scores don't improve for 200 rounds\n[15:01:11] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.6878778907079554, 'num_leaves': 119, 'bagging_fraction': 0.5800953029635283, 'min_sum_hessian_in_leaf': 0.6937256876009805, 'reg_alpha': 1.315951277724236, 'reg_lambda': 2.542525311198235} scored -16758.95723157051 in 0:00:03.749635\n[15:01:11] Training until validation scores don't improve for 200 rounds\n[15:01:15] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.75445598111558, 'num_leaves': 119, 'bagging_fraction': 0.785299853251502, 'min_sum_hessian_in_leaf': 0.513325279274924, 'reg_alpha': 4.9773422873317905, 'reg_lambda': 4.5216420249792435} scored -16926.65127537393 in 0:00:04.007312\n[15:01:15] Training until validation scores don't improve for 200 rounds\n[15:01:19] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.8041859363210639, 'num_leaves': 138, 'bagging_fraction': 0.5892620663119726, 'min_sum_hessian_in_leaf': 0.9728524676336762, 'reg_alpha': 1.2641184576446336, 'reg_lambda': 1.7276849121147075} scored -16826.13782051282 in 0:00:04.065604\n[15:01:19] Training until validation scores don't improve for 200 rounds\n[15:01:23] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.7011787615060028, 'num_leaves': 73, 'bagging_fraction': 0.653839370780088, 'min_sum_hessian_in_leaf': 0.3280966384779825, 'reg_alpha': 0.007856899544567166, 'reg_lambda': 0.41744126181430313} scored -16843.085970886754 in 0:00:03.902031\n[15:01:23] Training until validation scores don't improve for 200 rounds\n[15:01:26] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.7215514614076, 'num_leaves': 96, 'bagging_fraction': 0.5369700216168577, 'min_sum_hessian_in_leaf': 0.2235308118671907, 'reg_alpha': 8.00366224565974, 'reg_lambda': 3.176040584462055} scored -17168.87954059829 in 0:00:02.691369\n[15:01:26] Training until validation scores don't improve for 200 rounds\n[15:01:31] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.5892633970107368, 'num_leaves': 39, 'bagging_fraction': 0.5830915144184023, 'min_sum_hessian_in_leaf': 1.4333898485730612, 'reg_alpha': 1.1950186121819386, 'reg_lambda': 5.188531211438814e-05} scored -16817.157552083332 in 0:00:04.907895\n[15:01:31] Training until validation scores don't improve for 200 rounds\n[15:01:34] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.5460652213681998, 'num_leaves': 164, 'bagging_fraction': 0.622974836698183, 'min_sum_hessian_in_leaf': 9.093200362087934, 'reg_alpha': 0.0392472885530646, 'reg_lambda': 0.03770089884676986} scored -16884.98203792735 in 0:00:03.349176\n[15:01:34] Training until validation scores don't improve for 200 rounds\n[15:01:37] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5892029725088137, 'num_leaves': 38, 'bagging_fraction': 0.5855218404896813, 'min_sum_hessian_in_leaf': 1.614898498409112, 'reg_alpha': 1.2266350415974658, 'reg_lambda': 9.708933179783323e-05} scored -16873.863982371793 in 0:00:02.648722\n[15:01:37] Training until validation scores don't improve for 200 rounds\n[15:01:41] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.6246229365440377, 'num_leaves': 51, 'bagging_fraction': 0.5496628379670766, 'min_sum_hessian_in_leaf': 0.5527272736995995, 'reg_alpha': 0.1523945354520408, 'reg_lambda': 4.009233925834965e-05} scored -16976.843048878207 in 0:00:03.524436\n[15:01:41] Training until validation scores don't improve for 200 rounds\n[15:01:44] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.6736143484825929, 'num_leaves': 32, 'bagging_fraction': 0.5255791793245765, 'min_sum_hessian_in_leaf': 1.0528981904492911, 'reg_alpha': 3.1142290749415618, 'reg_lambda': 0.0007345564742179176} scored -17221.56577190171 in 0:00:03.632416\n[15:01:44] Training until validation scores don't improve for 200 rounds\n[15:01:48] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.7777544504067093, 'num_leaves': 91, 'bagging_fraction': 0.5983788030586337, 'min_sum_hessian_in_leaf': 5.297536878822918, 'reg_alpha': 4.6114591529469253e-07, 'reg_lambda': 2.464262940489375e-06} scored -16706.421774839742 in 0:00:03.529899\n[15:01:48] Training until validation scores don't improve for 200 rounds\n[15:01:52] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.8159909899618155, 'num_leaves': 91, 'bagging_fraction': 0.6686376040687214, 'min_sum_hessian_in_leaf': 5.456698038771459, 'reg_alpha': 6.145326970254036e-07, 'reg_lambda': 1.29456707650577e-06} scored -17104.055655715812 in 0:00:04.245715\n[15:01:52] Training until validation scores don't improve for 200 rounds\n[15:01:55] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.7512669103365401, 'num_leaves': 117, 'bagging_fraction': 0.7769163235943486, 'min_sum_hessian_in_leaf': 3.0250318990696288, 'reg_alpha': 8.735590084919967e-07, 'reg_lambda': 0.36436042693892756} scored -17152.591312767094 in 0:00:02.877588\n[15:01:55] Training until validation scores don't improve for 200 rounds\n[15:01:58] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.7808877920968509, 'num_leaves': 71, 'bagging_fraction': 0.6020650213462795, 'min_sum_hessian_in_leaf': 6.033988352497147, 'reg_alpha': 3.382254694921008e-08, 'reg_lambda': 0.003808032060566092} scored -16866.639256143164 in 0:00:03.503650\n[15:01:58] Training until validation scores don't improve for 200 rounds\n[15:02:04] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.8311554812252513, 'num_leaves': 136, 'bagging_fraction': 0.5546572599133675, 'min_sum_hessian_in_leaf': 0.06784432363384868, 'reg_alpha': 3.0037713776480864e-05, 'reg_lambda': 0.007004699176434449} scored -17072.105702457266 in 0:00:05.541630\n[15:02:04] Training until validation scores don't improve for 200 rounds\n[15:02:07] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.7327405737342406, 'num_leaves': 128, 'bagging_fraction': 0.832207227143331, 'min_sum_hessian_in_leaf': 0.6470145690213598, 'reg_alpha': 0.00010629767902315757, 'reg_lambda': 9.490192051531244e-08} scored -17194.949252136754 in 0:00:02.904872\n[15:02:07] Training until validation scores don't improve for 200 rounds\n[15:02:12] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.7745710328617593, 'num_leaves': 64, 'bagging_fraction': 0.6356898410373601, 'min_sum_hessian_in_leaf': 1.9640651651051728, 'reg_alpha': 2.125995065750223e-06, 'reg_lambda': 8.961705501360367} scored -16950.00751201923 in 0:00:04.821071\n[15:02:12] Training until validation scores don't improve for 200 rounds\n[15:02:15] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.9902797021594099, 'num_leaves': 53, 'bagging_fraction': 0.5854310042546255, 'min_sum_hessian_in_leaf': 1.6756881239058015, 'reg_alpha': 0.8840038279490852, 'reg_lambda': 5.156521551023074e-06} scored -16956.18309294872 in 0:00:03.543043\n[15:02:15] Training until validation scores don't improve for 200 rounds\n[15:02:19] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.6548386762311622, 'num_leaves': 78, 'bagging_fraction': 0.5270305722432066, 'min_sum_hessian_in_leaf': 1.357820459891672, 'reg_alpha': 3.536242087603098, 'reg_lambda': 1.6990979662336183e-05} scored -17189.05018028846 in 0:00:03.357161\n[15:02:19] Training until validation scores don't improve for 200 rounds\n[15:02:21] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.5321077275012417, 'num_leaves': 192, 'bagging_fraction': 0.6118630278908144, 'min_sum_hessian_in_leaf': 2.9548967928069527, 'reg_alpha': 0.028786596593390015, 'reg_lambda': 4.889417429671245e-07} scored -17044.37282986111 in 0:00:02.546234\n[15:02:21] Training until validation scores don't improve for 200 rounds\n[15:02:25] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.5897096865401765, 'num_leaves': 91, 'bagging_fraction': 0.5006054675591349, 'min_sum_hessian_in_leaf': 7.2175269227769325, 'reg_alpha': 1.045987239438301e-07, 'reg_lambda': 0.00020542246624526546} scored -16901.828125 in 0:00:03.329503\n[15:02:25] Training until validation scores don't improve for 200 rounds\n[15:02:28] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.6354151444194325, 'num_leaves': 113, 'bagging_fraction': 0.5700246087147227, 'min_sum_hessian_in_leaf': 4.610848189222376, 'reg_alpha': 0.15199542595789003, 'reg_lambda': 1.7118953833087333e-06} scored -16621.670038728633 in 0:00:03.600195\n[15:02:28] Training until validation scores don't improve for 200 rounds\n[15:02:31] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.679540634233845, 'num_leaves': 111, 'bagging_fraction': 0.5571285155640782, 'min_sum_hessian_in_leaf': 4.280275334465709, 'reg_alpha': 0.000573223647539819, 'reg_lambda': 6.276894183464499e-08} scored -17015.27140090812 in 0:00:03.253746\n[15:02:31] Training until validation scores don't improve for 200 rounds\n[15:02:36] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.6139286599431688, 'num_leaves': 100, 'bagging_fraction': 0.5324356325994195, 'min_sum_hessian_in_leaf': 2.408366405259297, 'reg_alpha': 1.0191612039916958e-05, 'reg_lambda': 1.7162387588071095e-06} scored -17044.098023504273 in 0:00:04.128233\n[15:02:36] Training until validation scores don't improve for 200 rounds\n[15:02:40] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.9344998297869923, 'num_leaves': 128, 'bagging_fraction': 0.5673931121072195, 'min_sum_hessian_in_leaf': 4.842653847216317, 'reg_alpha': 0.003967952264367221, 'reg_lambda': 0.02465788364222845} scored -17023.927617521367 in 0:00:04.052682\n[15:02:40] Training until validation scores don't improve for 200 rounds\n[15:02:43] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.7049043186908865, 'num_leaves': 228, 'bagging_fraction': 0.986973879508497, 'min_sum_hessian_in_leaf': 7.060024992988583, 'reg_alpha': 0.1982456796238944, 'reg_lambda': 1.0859304538983633e-05} scored -17499.11137820513 in 0:00:03.364679\n[15:02:43] Training until validation scores don't improve for 200 rounds\n[15:02:46] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.6397995016316395, 'num_leaves': 149, 'bagging_fraction': 0.8830839626320754, 'min_sum_hessian_in_leaf': 3.3532718975531166, 'reg_alpha': 0.0002014168001125811, 'reg_lambda': 1.722913991148584e-07} scored -17366.967581463676 in 0:00:02.997574\n[15:02:46] Training until validation scores don't improve for 200 rounds\n[15:02:49] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.6631615963928547, 'num_leaves': 17, 'bagging_fraction': 0.5943011934545223, 'min_sum_hessian_in_leaf': 1.3324108669688794, 'reg_alpha': 0.0651881767736101, 'reg_lambda': 3.4199189046230976e-05} scored -16780.65124198718 in 0:00:02.982453\n[15:02:49] Training until validation scores don't improve for 200 rounds\n[15:02:52] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.6630728392085936, 'num_leaves': 115, 'bagging_fraction': 0.5981006276684128, 'min_sum_hessian_in_leaf': 0.8138422242209573, 'reg_alpha': 0.09033658488368455, 'reg_lambda': 5.947468571887927e-07} scored -16807.91579861111 in 0:00:03.379860\n[15:02:52] Training until validation scores don't improve for 200 rounds\n[15:02:55] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.6877992865223248, 'num_leaves': 16, 'bagging_fraction': 0.630315717404836, 'min_sum_hessian_in_leaf': 2.1744656636699733, 'reg_alpha': 0.4014216776523125, 'reg_lambda': 4.2025629396556955e-06} scored -16929.60216346154 in 0:00:02.998302\n[15:02:55] Training until validation scores don't improve for 200 rounds\n[15:02:59] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.7312988280422003, 'num_leaves': 104, 'bagging_fraction': 0.570816204723596, 'min_sum_hessian_in_leaf': 0.3997728975565209, 'reg_alpha': 0.016605034750172547, 'reg_lambda': 1.7308589290382918e-06} scored -16865.158219818375 in 0:00:03.733683\n[15:02:59] Training until validation scores don't improve for 200 rounds\n[15:03:03] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.6332454869571149, 'num_leaves': 173, 'bagging_fraction': 0.6609977572411594, 'min_sum_hessian_in_leaf': 0.011077915665739672, 'reg_alpha': 0.054354318463583996, 'reg_lambda': 0.1517123510962557} scored -16846.10266426282 in 0:00:03.851363\n[15:03:03] Training until validation scores don't improve for 200 rounds\n[15:03:07] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.6116139637921957, 'num_leaves': 142, 'bagging_fraction': 0.6099620420243416, 'min_sum_hessian_in_leaf': 1.1418533302192038, 'reg_alpha': 0.4215662473946839, 'reg_lambda': 3.0569254370934626e-05} scored -16978.883079594016 in 0:00:04.037389\n[15:03:07] Training until validation scores don't improve for 200 rounds\n[15:03:10] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.6525265296780188, 'num_leaves': 127, 'bagging_fraction': 0.6852399388414824, 'min_sum_hessian_in_leaf': 9.772420035943098, 'reg_alpha': 2.196856638520025, 'reg_lambda': 0.0003579271746859001} scored -17040.596120459402 in 0:00:03.010291\n[15:03:10] Training until validation scores don't improve for 200 rounds\n[15:03:14] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.6957740849250668, 'num_leaves': 87, 'bagging_fraction': 0.5180364301356513, 'min_sum_hessian_in_leaf': 0.16888294558798045, 'reg_alpha': 0.7050244833738089, 'reg_lambda': 0.0008620954404283427} scored -17069.20596287393 in 0:00:03.672763\n[15:03:14] Training until validation scores don't improve for 200 rounds\n[15:03:18] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.716833248419101, 'num_leaves': 243, 'bagging_fraction': 0.544450555249939, 'min_sum_hessian_in_leaf': 2.599153782642758, 'reg_alpha': 0.1640791538586003, 'reg_lambda': 8.34933915035148e-06} scored -17139.15217681624 in 0:00:03.893916\n[15:03:18] Training until validation scores don't improve for 200 rounds\n[15:03:21] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.7407745148473263, 'num_leaves': 210, 'bagging_fraction': 0.5747573342999422, 'min_sum_hessian_in_leaf': 0.9581620488021756, 'reg_alpha': 6.689211902084318, 'reg_lambda': 0.0697726156562056} scored -16839.527577457266 in 0:00:03.504691\n[15:03:21] Training until validation scores don't improve for 200 rounds\n[15:03:25] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.6640789673899604, 'num_leaves': 114, 'bagging_fraction': 0.6001448110593353, 'min_sum_hessian_in_leaf': 0.5457193504952794, 'reg_alpha': 0.08547420656990883, 'reg_lambda': 4.40832755252232e-07} scored -16810.217548076922 in 0:00:03.389245\n[15:03:25] Training until validation scores don't improve for 200 rounds\n[15:03:28] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.6649036265071171, 'num_leaves': 122, 'bagging_fraction': 0.5921587102037335, 'min_sum_hessian_in_leaf': 0.7483956745785274, 'reg_alpha': 0.014017419097230768, 'reg_lambda': 1.091117483477116e-06} scored -16725.574352297008 in 0:00:03.391798\n[15:03:28] Training until validation scores don't improve for 200 rounds\n[15:03:32] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.6326108135344611, 'num_leaves': 122, 'bagging_fraction': 0.6220719762088673, 'min_sum_hessian_in_leaf': 0.6922506328532338, 'reg_alpha': 0.018533433520098053, 'reg_lambda': 9.000838912286132e-07} scored -16791.3030849359 in 0:00:03.771798\n[15:03:32] Training until validation scores don't improve for 200 rounds\n[15:03:36] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.6786491324440077, 'num_leaves': 105, 'bagging_fraction': 0.5591251915275993, 'min_sum_hessian_in_leaf': 0.311573197272561, 'reg_alpha': 0.004617412218621724, 'reg_lambda': 3.342041698130787e-06} scored -16933.85703792735 in 0:00:04.098757\n[15:03:36] Training until validation scores don't improve for 200 rounds\n[15:03:41] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.6475857935547041, 'num_leaves': 135, 'bagging_fraction': 0.5826055293910616, 'min_sum_hessian_in_leaf': 1.504351826358053, 'reg_alpha': 0.0014670710441013592, 'reg_lambda': 7.184781862596867e-05} scored -16734.122529380344 in 0:00:04.666513\n[15:03:41] Training until validation scores don't improve for 200 rounds\n[15:03:44] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.5721097493089384, 'num_leaves': 98, 'bagging_fraction': 0.6434791778341986, 'min_sum_hessian_in_leaf': 1.9319350825373023, 'reg_alpha': 0.001492566918706572, 'reg_lambda': 2.126118128567737} scored -17051.30719150641 in 0:00:02.845830\n[15:03:44] Training until validation scores don't improve for 200 rounds\n[15:03:47] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.6494485289132572, 'num_leaves': 122, 'bagging_fraction': 0.5781448037130974, 'min_sum_hessian_in_leaf': 4.201276266345342, 'reg_alpha': 0.012130583703308377, 'reg_lambda': 0.5245033841699518} scored -16759.673410790598 in 0:00:03.486893\n[15:03:47] Training until validation scores don't improve for 200 rounds\n[15:03:54] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.6037301254189471, 'num_leaves': 153, 'bagging_fraction': 0.5368502357604121, 'min_sum_hessian_in_leaf': 0.20836206820147005, 'reg_alpha': 0.23644140008732178, 'reg_lambda': 0.0001075268521387413} scored -17064.03345352564 in 0:00:06.485930\n[15:03:54] Training until validation scores don't improve for 200 rounds\n[15:03:56] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.6243840829183968, 'num_leaves': 133, 'bagging_fraction': 0.6100465524316065, 'min_sum_hessian_in_leaf': 3.2354172880930423, 'reg_alpha': 1.8804455674686946, 'reg_lambda': 1.7444990959227105e-07} scored -16828.083366720086 in 0:00:02.818972\n[15:03:56] Training until validation scores don't improve for 200 rounds\n[15:04:00] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.7031131303911341, 'num_leaves': 139, 'bagging_fraction': 0.5500684671922816, 'min_sum_hessian_in_leaf': 0.4387919796012228, 'reg_alpha': 0.003650618211525876, 'reg_lambda': 0.005148678199996491} scored -16989.51766159188 in 0:00:03.708987\n[15:04:00] Training until validation scores don't improve for 200 rounds\n[15:04:03] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.6466488800082832, 'num_leaves': 124, 'bagging_fraction': 0.5751951336706322, 'min_sum_hessian_in_leaf': 5.069024449197647, 'reg_alpha': 0.0008819938142164442, 'reg_lambda': 0.49482836288103055} scored -16894.6335803953 in 0:00:03.277632\n[15:04:03] Training until validation scores don't improve for 200 rounds\n[15:04:07] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.6809941406170805, 'num_leaves': 133, 'bagging_fraction': 0.5817217349486846, 'min_sum_hessian_in_leaf': 3.730918150505741, 'reg_alpha': 0.01254742378722591, 'reg_lambda': 0.2551896950408803} scored -16744.39109241453 in 0:00:03.710862\n[15:04:07] Training until validation scores don't improve for 200 rounds\n[15:04:12] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.6868183028004038, 'num_leaves': 110, 'bagging_fraction': 0.5922703162339243, 'min_sum_hessian_in_leaf': 7.65322852555381, 'reg_alpha': 1.2881940657218943e-08, 'reg_lambda': 0.20131261971982922} scored -16802.98878205128 in 0:00:05.190488\n[15:04:12] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[15:04:12] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6354151444194325, 'num_leaves': 113, 'bagging_fraction': 0.5700246087147227, 'min_sum_hessian_in_leaf': 4.610848189222376, 'reg_alpha': 0.15199542595789003, 'reg_lambda': 1.7118953833087333e-06}\u001b[0m\n achieve -16621.6700 mae\n[15:04:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:04:12] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:04:12] Training until validation scores don't improve for 100 rounds\n[15:04:13] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:04:13] Training until validation scores don't improve for 100 rounds\n[15:04:14] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:04:14] Training until validation scores don't improve for 100 rounds\n[15:04:14] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:04:14] Training until validation scores don't improve for 100 rounds\n[15:04:15] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:04:15] Training until validation scores don't improve for 100 rounds\n[15:04:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15725.68378103596\u001b[0m\n[15:04:16] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:04:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[15:04:16] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:04:16] 0:\tlearn: 54493.3605965\ttest: 55295.4153040\tbest: 55295.4153040 (0)\ttotal: 3.05ms\tremaining: 6.09s\n[15:04:18] Stopped by overfitting detector  (300 iterations wait)\n[15:04:18] bestTest = 16188.74037\n[15:04:18] bestIteration = 646\n[15:04:18] Shrink model to first 647 iterations.\n[15:04:18] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:04:18] 0:\tlearn: 53979.4717422\ttest: 56635.3474344\tbest: 56635.3474344 (0)\ttotal: 2.44ms\tremaining: 4.88s\n[15:04:21] Stopped by overfitting detector  (300 iterations wait)\n[15:04:21] bestTest = 16851.12839\n[15:04:21] bestIteration = 1400\n[15:04:21] Shrink model to first 1401 iterations.\n[15:04:21] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:04:21] 0:\tlearn: 53626.6190937\ttest: 54735.2855532\tbest: 54735.2855532 (0)\ttotal: 3.41ms\tremaining: 6.83s\n[15:04:23] Stopped by overfitting detector  (300 iterations wait)\n[15:04:23] bestTest = 14503.01047\n[15:04:23] bestIteration = 713\n[15:04:23] Shrink model to first 714 iterations.\n[15:04:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:04:23] 0:\tlearn: 55364.2388798\ttest: 51525.1032483\tbest: 51525.1032483 (0)\ttotal: 2.34ms\tremaining: 4.67s\n[15:04:25] Stopped by overfitting detector  (300 iterations wait)\n[15:04:25] bestTest = 13373.44512\n[15:04:25] bestIteration = 452\n[15:04:25] Shrink model to first 453 iterations.\n[15:04:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:04:25] 0:\tlearn: 54568.1321216\ttest: 54223.3822752\tbest: 54223.3822752 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:04:29] bestTest = 13227.33188\n[15:04:29] bestIteration = 1999\n[15:04:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-14831.348318439641\u001b[0m\n[15:04:29] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[15:04:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[15:04:29] 0:\tlearn: 54219.7321323\ttest: 55061.4971059\tbest: 55061.4971059 (0)\ttotal: 1.7ms\tremaining: 3.39s\n[15:04:31] Stopped by overfitting detector  (300 iterations wait)\n[15:04:31] bestTest = 16795.06154\n[15:04:31] bestIteration = 533\n[15:04:31] Shrink model to first 534 iterations.\n[15:04:31] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -16795.06159855769 in 0:00:01.429362\n[15:04:31] 0:\tlearn: 54648.8700985\ttest: 55429.9834512\tbest: 55429.9834512 (0)\ttotal: 1.52ms\tremaining: 3.04s\n[15:04:32] Stopped by overfitting detector  (300 iterations wait)\n[15:04:32] bestTest = 16792.03925\n[15:04:32] bestIteration = 844\n[15:04:32] Shrink model to first 845 iterations.\n[15:04:32] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -16792.039346287394 in 0:00:01.526180\n[15:04:32] 0:\tlearn: 54289.9457351\ttest: 55094.6944635\tbest: 55094.6944635 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[15:04:35] bestTest = 16715.90369\n[15:04:35] bestIteration = 1815\n[15:04:35] Shrink model to first 1816 iterations.\n[15:04:35] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -16715.903812767094 in 0:00:02.464039\n[15:04:35] 0:\tlearn: 54648.8261807\ttest: 55429.9318925\tbest: 55429.9318925 (0)\ttotal: 1.28ms\tremaining: 2.56s\n[15:04:37] bestTest = 16647.083\n[15:04:37] bestIteration = 1991\n[15:04:37] Shrink model to first 1992 iterations.\n[15:04:37] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -16647.082465277777 in 0:00:02.437464\n[15:04:38] 0:\tlearn: 54419.3035844\ttest: 55264.3990316\tbest: 55264.3990316 (0)\ttotal: 4.15ms\tremaining: 8.3s\n[15:04:40] Stopped by overfitting detector  (300 iterations wait)\n[15:04:40] bestTest = 17255.83615\n[15:04:40] bestIteration = 519\n[15:04:40] Shrink model to first 520 iterations.\n[15:04:40] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -17255.83563701923 in 0:00:02.855334\n[15:04:40] 0:\tlearn: 54419.4577403\ttest: 55264.5343772\tbest: 55264.5343772 (0)\ttotal: 4.23ms\tremaining: 8.46s\n[15:04:43] Stopped by overfitting detector  (300 iterations wait)\n[15:04:43] bestTest = 17346.91214\n[15:04:43] bestIteration = 483\n[15:04:43] Shrink model to first 484 iterations.\n[15:04:43] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -17346.91282719017 in 0:00:02.868510\n[15:04:43] 0:\tlearn: 54269.6285462\ttest: 55081.6252982\tbest: 55081.6252982 (0)\ttotal: 3.23ms\tremaining: 6.46s\n[15:04:46] Stopped by overfitting detector  (300 iterations wait)\n[15:04:46] bestTest = 17153.63881\n[15:04:46] bestIteration = 760\n[15:04:46] Shrink model to first 761 iterations.\n[15:04:46] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -17151.935830662394 in 0:00:03.146961\n[15:04:46] 0:\tlearn: 54076.3052616\ttest: 55006.7367139\tbest: 55006.7367139 (0)\ttotal: 5.21ms\tremaining: 10.4s\n[15:04:51] Stopped by overfitting detector  (300 iterations wait)\n[15:04:51] bestTest = 17141.89895\n[15:04:51] bestIteration = 779\n[15:04:51] Shrink model to first 780 iterations.\n[15:04:51] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -17131.80892761752 in 0:00:04.615947\n[15:04:51] 0:\tlearn: 54322.1183161\ttest: 55121.9138106\tbest: 55121.9138106 (0)\ttotal: 1.56ms\tremaining: 3.12s\n[15:04:53] bestTest = 16429.23885\n[15:04:53] bestIteration = 1791\n[15:04:53] Shrink model to first 1792 iterations.\n[15:04:53] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -16429.238848824785 in 0:00:02.476428\n[15:04:53] 0:\tlearn: 54419.3625178\ttest: 55264.4507788\tbest: 55264.4507788 (0)\ttotal: 2.91ms\tremaining: 5.81s\n[15:04:55] Stopped by overfitting detector  (300 iterations wait)\n[15:04:55] bestTest = 17248.41819\n[15:04:55] bestIteration = 374\n[15:04:55] Shrink model to first 375 iterations.\n[15:04:55] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -17248.41763488248 in 0:00:02.061020\n[15:04:55] 0:\tlearn: 54439.6134805\ttest: 55291.7684841\tbest: 55291.7684841 (0)\ttotal: 1.74ms\tremaining: 3.47s\n[15:04:58] Stopped by overfitting detector  (300 iterations wait)\n[15:04:58] bestTest = 16163.14714\n[15:04:58] bestIteration = 1317\n[15:04:58] Shrink model to first 1318 iterations.\n[15:04:58] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.31904907294463, 'min_data_in_leaf': 14} scored -16166.118255876068 in 0:00:02.607953\n[15:04:58] 0:\tlearn: 54488.5300997\ttest: 55330.9706972\tbest: 55330.9706972 (0)\ttotal: 1.66ms\tremaining: 3.32s\n[15:05:01] Stopped by overfitting detector  (300 iterations wait)\n[15:05:01] bestTest = 16305.5009\n[15:05:01] bestIteration = 1611\n[15:05:01] Shrink model to first 1612 iterations.\n[15:05:01] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.654538200209698, 'min_data_in_leaf': 15} scored -16305.501201923076 in 0:00:03.037066\n[15:05:01] 0:\tlearn: 54227.3233390\ttest: 55064.5443727\tbest: 55064.5443727 (0)\ttotal: 1.69ms\tremaining: 3.38s\n[15:05:04] Stopped by overfitting detector  (300 iterations wait)\n[15:05:04] bestTest = 16493.90877\n[15:05:04] bestIteration = 1528\n[15:05:04] Shrink model to first 1529 iterations.\n[15:05:04] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.2106831293560533, 'min_data_in_leaf': 15} scored -16493.908787393164 in 0:00:03.006140\n[15:05:04] 0:\tlearn: 54510.9411888\ttest: 55349.3663578\tbest: 55349.3663578 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[15:05:07] bestTest = 16496.75189\n[15:05:07] bestIteration = 1987\n[15:05:07] Shrink model to first 1988 iterations.\n[15:05:07] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 8.83188645291561, 'min_data_in_leaf': 15} scored -16496.751802884617 in 0:00:03.246456\n[15:05:07] 0:\tlearn: 54224.9557460\ttest: 55087.4993884\tbest: 55087.4993884 (0)\ttotal: 2.29ms\tremaining: 4.58s\n[15:05:09] Stopped by overfitting detector  (300 iterations wait)\n[15:05:09] bestTest = 16393.02381\n[15:05:09] bestIteration = 742\n[15:05:09] Shrink model to first 743 iterations.\n[15:05:09] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.25245062801063695, 'min_data_in_leaf': 19} scored -16403.698551014957 in 0:00:02.336560\n[15:05:10] 0:\tlearn: 54214.6863476\ttest: 55085.0608069\tbest: 55085.0608069 (0)\ttotal: 2.25ms\tremaining: 4.51s\n[15:05:12] Stopped by overfitting detector  (300 iterations wait)\n[15:05:12] bestTest = 16291.683\n[15:05:12] bestIteration = 1026\n[15:05:12] Shrink model to first 1027 iterations.\n[15:05:13] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.08810028012678793, 'min_data_in_leaf': 17} scored -16291.683259882479 in 0:00:03.056051\n[15:05:13] 0:\tlearn: 54214.7189715\ttest: 55085.0676861\tbest: 55085.0676861 (0)\ttotal: 2.71ms\tremaining: 5.42s\n[15:05:15] Stopped by overfitting detector  (300 iterations wait)\n[15:05:15] bestTest = 16312.17978\n[15:05:15] bestIteration = 811\n[15:05:15] Shrink model to first 812 iterations.\n[15:05:15] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.08858623697797322, 'min_data_in_leaf': 12} scored -16312.179720886752 in 0:00:02.801264\n[15:05:16] 0:\tlearn: 54208.4984551\ttest: 55083.8553753\tbest: 55083.8553753 (0)\ttotal: 2.24ms\tremaining: 4.47s\n[15:05:17] Stopped by overfitting detector  (300 iterations wait)\n[15:05:17] bestTest = 16666.55701\n[15:05:17] bestIteration = 493\n[15:05:17] Shrink model to first 494 iterations.\n[15:05:17] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 8.265860882114358e-08, 'min_data_in_leaf': 18} scored -16682.125567574785 in 0:00:02.078173\n[15:05:18] 0:\tlearn: 54078.8446810\ttest: 55007.6563159\tbest: 55007.6563159 (0)\ttotal: 4.74ms\tremaining: 9.47s\n[15:05:21] Stopped by overfitting detector  (300 iterations wait)\n[15:05:21] bestTest = 17039.14896\n[15:05:21] bestIteration = 548\n[15:05:21] Shrink model to first 549 iterations.\n[15:05:21] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.03576754794900295, 'min_data_in_leaf': 13} scored -17040.04971287393 in 0:00:03.631034\n[15:05:21] 0:\tlearn: 54236.9378283\ttest: 55069.0252186\tbest: 55069.0252186 (0)\ttotal: 1.82ms\tremaining: 3.65s\n[15:05:24] Stopped by overfitting detector  (300 iterations wait)\n[15:05:24] bestTest = 16533.33146\n[15:05:24] bestIteration = 1634\n[15:05:24] Shrink model to first 1635 iterations.\n[15:05:24] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.48655210851246783, 'min_data_in_leaf': 17} scored -16533.331196581195 in 0:00:03.196557\n[15:05:24] 0:\tlearn: 54209.5051543\ttest: 55084.0380847\tbest: 55084.0380847 (0)\ttotal: 2.36ms\tremaining: 4.73s\n[15:05:27] Stopped by overfitting detector  (300 iterations wait)\n[15:05:27] bestTest = 16402.24805\n[15:05:27] bestIteration = 962\n[15:05:27] Shrink model to first 963 iterations.\n[15:05:27] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.013786375704895552, 'min_data_in_leaf': 12} scored -16402.248030181625 in 0:00:02.811288\n[15:05:27] 0:\tlearn: 54527.2117893\ttest: 55362.9134735\tbest: 55362.9134735 (0)\ttotal: 1.65ms\tremaining: 3.29s\n[15:05:30] bestTest = 16313.0959\n[15:05:30] bestIteration = 1906\n[15:05:30] Shrink model to first 1907 iterations.\n[15:05:30] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 9.73491582823739, 'min_data_in_leaf': 17} scored -16313.096020299145 in 0:00:03.251110\n[15:05:31] 0:\tlearn: 54263.1449523\ttest: 55101.0812207\tbest: 55101.0812207 (0)\ttotal: 2.22ms\tremaining: 4.43s\n[15:05:33] Stopped by overfitting detector  (300 iterations wait)\n[15:05:33] bestTest = 16339.99213\n[15:05:33] bestIteration = 1112\n[15:05:33] Shrink model to first 1113 iterations.\n[15:05:33] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0636412046988564, 'min_data_in_leaf': 14} scored -16335.752771100428 in 0:00:03.128110\n[15:05:34] 0:\tlearn: 54266.1397902\ttest: 55085.0061991\tbest: 55085.0061991 (0)\ttotal: 1.72ms\tremaining: 3.45s\n[15:05:36] Stopped by overfitting detector  (300 iterations wait)\n[15:05:36] bestTest = 16321.26005\n[15:05:36] bestIteration = 1490\n[15:05:36] Shrink model to first 1491 iterations.\n[15:05:36] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3973296691721306, 'min_data_in_leaf': 17} scored -16326.610743856838 in 0:00:02.924223\n[15:05:37] 0:\tlearn: 54222.4066334\ttest: 55062.5082988\tbest: 55062.5082988 (0)\ttotal: 1.85ms\tremaining: 3.7s\n[15:05:39] Stopped by overfitting detector  (300 iterations wait)\n[15:05:39] bestTest = 16321.56338\n[15:05:39] bestIteration = 1189\n[15:05:39] Shrink model to first 1190 iterations.\n[15:05:39] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.07476985772132953, 'min_data_in_leaf': 16} scored -16321.562917334402 in 0:00:02.455257\n[15:05:39] 0:\tlearn: 54304.2672833\ttest: 55108.7163162\tbest: 55108.7163162 (0)\ttotal: 2.26ms\tremaining: 4.52s\n[15:05:42] Stopped by overfitting detector  (300 iterations wait)\n[15:05:42] bestTest = 16088.6171\n[15:05:42] bestIteration = 1315\n[15:05:42] Shrink model to first 1316 iterations.\n[15:05:42] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.0479699319390527, 'min_data_in_leaf': 12} scored -16102.056423611111 in 0:00:03.563083\n[15:05:43] 0:\tlearn: 54513.6792882\ttest: 55315.3930374\tbest: 55315.3930374 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:05:46] Stopped by overfitting detector  (300 iterations wait)\n[15:05:46] bestTest = 15802.18692\n[15:05:46] bestIteration = 1214\n[15:05:46] Shrink model to first 1215 iterations.\n[15:05:46] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.5460381634882061, 'min_data_in_leaf': 9} scored -15802.18703258547 in 0:00:03.544654\n[15:05:46] 0:\tlearn: 54454.7702470\ttest: 55294.9083153\tbest: 55294.9083153 (0)\ttotal: 3.55ms\tremaining: 7.09s\n[15:05:51] Stopped by overfitting detector  (300 iterations wait)\n[15:05:51] bestTest = 16884.30807\n[15:05:51] bestIteration = 1248\n[15:05:51] Shrink model to first 1249 iterations.\n[15:05:51] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.5612521562553971, 'min_data_in_leaf': 8} scored -16884.30779246795 in 0:00:04.610922\n[15:05:51] 0:\tlearn: 54492.9298630\ttest: 55294.9609653\tbest: 55294.9609653 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:05:53] Stopped by overfitting detector  (300 iterations wait)\n[15:05:53] bestTest = 16072.39787\n[15:05:53] bestIteration = 577\n[15:05:53] Shrink model to first 578 iterations.\n[15:05:53] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0218289139830237e-05, 'min_data_in_leaf': 11} scored -16072.398537660256 in 0:00:02.014452\n[15:05:53] 0:\tlearn: 54492.9295471\ttest: 55294.9606314\tbest: 55294.9606314 (0)\ttotal: 2.21ms\tremaining: 4.41s\n[15:05:55] Stopped by overfitting detector  (300 iterations wait)\n[15:05:55] bestTest = 16072.4002\n[15:05:55] bestIteration = 577\n[15:05:55] Shrink model to first 578 iterations.\n[15:05:55] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.9134310706057672e-06, 'min_data_in_leaf': 11} scored -16072.400707799145 in 0:00:01.998831\n[15:05:55] 0:\tlearn: 54419.3026504\ttest: 55264.3982115\tbest: 55264.3982115 (0)\ttotal: 2.9ms\tremaining: 5.79s\n[15:05:57] Stopped by overfitting detector  (300 iterations wait)\n[15:05:57] bestTest = 17255.84001\n[15:05:57] bestIteration = 519\n[15:05:57] Shrink model to first 520 iterations.\n[15:05:57] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 6.950696613120091e-06, 'min_data_in_leaf': 8} scored -17255.840511485043 in 0:00:02.490274\n[15:05:58] 0:\tlearn: 54492.9295199\ttest: 55294.9606027\tbest: 55294.9606027 (0)\ttotal: 2.3ms\tremaining: 4.6s\n[15:05:59] Stopped by overfitting detector  (300 iterations wait)\n[15:05:59] bestTest = 16072.4004\n[15:05:59] bestIteration = 577\n[15:05:59] Shrink model to first 578 iterations.\n[15:05:59] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.285918050110841e-06, 'min_data_in_leaf': 11} scored -16072.401041666666 in 0:00:02.261680\n[15:06:00] 0:\tlearn: 54492.9294356\ttest: 55294.9605136\tbest: 55294.9605136 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:06:01] Stopped by overfitting detector  (300 iterations wait)\n[15:06:01] bestTest = 16072.40102\n[15:06:01] bestIteration = 577\n[15:06:01] Shrink model to first 578 iterations.\n[15:06:01] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.350241583322405e-07, 'min_data_in_leaf': 10} scored -16072.401909722223 in 0:00:02.051069\n[15:06:02] 0:\tlearn: 54492.9297548\ttest: 55294.9608510\tbest: 55294.9608510 (0)\ttotal: 2.29ms\tremaining: 4.57s\n[15:06:03] Stopped by overfitting detector  (300 iterations wait)\n[15:06:03] bestTest = 16072.39867\n[15:06:03] bestIteration = 577\n[15:06:03] Shrink model to first 578 iterations.\n[15:06:03] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 7.717326643088023e-06, 'min_data_in_leaf': 7} scored -16072.399105235043 in 0:00:02.008543\n[15:06:04] 0:\tlearn: 54492.9339240\ttest: 55294.9652576\tbest: 55294.9652576 (0)\ttotal: 2.26ms\tremaining: 4.53s\n[15:06:06] Stopped by overfitting detector  (300 iterations wait)\n[15:06:06] bestTest = 16110.94459\n[15:06:06] bestIteration = 725\n[15:06:06] Shrink model to first 726 iterations.\n[15:06:06] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00010413311631145382, 'min_data_in_leaf': 6} scored -16110.94451121795 in 0:00:02.309620\n[15:06:06] 0:\tlearn: 54419.3026115\ttest: 55264.3981773\tbest: 55264.3981773 (0)\ttotal: 2.98ms\tremaining: 5.96s\n[15:06:08] Stopped by overfitting detector  (300 iterations wait)\n[15:06:08] bestTest = 17255.84017\n[15:06:08] bestIteration = 519\n[15:06:08] Shrink model to first 520 iterations.\n[15:06:08] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 6.414098602509984e-06, 'min_data_in_leaf': 8} scored -17255.84044471154 in 0:00:02.494717\n[15:06:09] 0:\tlearn: 54492.9294217\ttest: 55294.9604989\tbest: 55294.9604989 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[15:06:10] Stopped by overfitting detector  (300 iterations wait)\n[15:06:10] bestTest = 16072.40112\n[15:06:10] bestIteration = 577\n[15:06:10] Shrink model to first 578 iterations.\n[15:06:10] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.4329321655479866e-08, 'min_data_in_leaf': 7} scored -16072.401475694445 in 0:00:01.996619\n[15:06:11] 0:\tlearn: 54419.3046677\ttest: 55264.3999829\tbest: 55264.3999829 (0)\ttotal: 2.95ms\tremaining: 5.89s\n[15:06:13] Stopped by overfitting detector  (300 iterations wait)\n[15:06:13] bestTest = 17255.83168\n[15:06:13] bestIteration = 519\n[15:06:13] Shrink model to first 520 iterations.\n[15:06:13] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.4761658643264604e-05, 'min_data_in_leaf': 9} scored -17255.831931089742 in 0:00:02.544823\n[15:06:13] 0:\tlearn: 54492.9361003\ttest: 55294.9675577\tbest: 55294.9675577 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[15:06:15] Stopped by overfitting detector  (300 iterations wait)\n[15:06:15] bestTest = 16110.9425\n[15:06:15] bestIteration = 725\n[15:06:15] Shrink model to first 726 iterations.\n[15:06:15] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00015446158777906275, 'min_data_in_leaf': 3} scored -16110.943042200855 in 0:00:02.297536\n[15:06:15] 0:\tlearn: 54648.8248320\ttest: 55429.9303093\tbest: 55429.9303093 (0)\ttotal: 1.29ms\tremaining: 2.57s\n[15:06:18] bestTest = 16646.72842\n[15:06:18] bestIteration = 1991\n[15:06:18] Shrink model to first 1992 iterations.\n[15:06:18] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 6.388834119774813e-07, 'min_data_in_leaf': 11} scored -16646.72843215812 in 0:00:02.588068\n[15:06:18] 0:\tlearn: 54419.3298108\ttest: 55264.4220608\tbest: 55264.4220608 (0)\ttotal: 3.43ms\tremaining: 6.87s\n[15:06:20] Stopped by overfitting detector  (300 iterations wait)\n[15:06:20] bestTest = 17246.8278\n[15:06:20] bestIteration = 494\n[15:06:20] Shrink model to first 495 iterations.\n[15:06:20] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0003814374099034744, 'min_data_in_leaf': 5} scored -17246.828158386754 in 0:00:02.624186\n[15:06:21] 0:\tlearn: 54492.9295165\ttest: 55294.9605991\tbest: 55294.9605991 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[15:06:22] Stopped by overfitting detector  (300 iterations wait)\n[15:06:22] bestTest = 16072.40042\n[15:06:22] bestIteration = 577\n[15:06:22] Shrink model to first 578 iterations.\n[15:06:22] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.206058994266878e-06, 'min_data_in_leaf': 10} scored -16072.401175213676 in 0:00:02.049551\n[15:06:23] 0:\tlearn: 54492.9295552\ttest: 55294.9606400\tbest: 55294.9606400 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[15:06:24] Stopped by overfitting detector  (300 iterations wait)\n[15:06:24] bestTest = 16072.40014\n[15:06:24] bestIteration = 577\n[15:06:24] Shrink model to first 578 iterations.\n[15:06:24] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.1009242615595153e-06, 'min_data_in_leaf': 11} scored -16072.400574252137 in 0:00:01.981210\n[15:06:25] 0:\tlearn: 54492.9294313\ttest: 55294.9605090\tbest: 55294.9605090 (0)\ttotal: 2.22ms\tremaining: 4.44s\n[15:06:27] Stopped by overfitting detector  (300 iterations wait)\n[15:06:27] bestTest = 16072.40105\n[15:06:27] bestIteration = 577\n[15:06:27] Shrink model to first 578 iterations.\n[15:06:27] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.3647536652237743e-07, 'min_data_in_leaf': 9} scored -16072.401609241453 in 0:00:02.243218\n[15:06:27] 0:\tlearn: 54419.3037540\ttest: 55264.3991805\tbest: 55264.3991805 (0)\ttotal: 2.94ms\tremaining: 5.87s\n[15:06:29] Stopped by overfitting detector  (300 iterations wait)\n[15:06:29] bestTest = 17255.83545\n[15:06:29] bestIteration = 519\n[15:06:29] Shrink model to first 520 iterations.\n[15:06:29] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.2164152752132e-05, 'min_data_in_leaf': 7} scored -17255.83530315171 in 0:00:02.468411\n[15:06:29] 0:\tlearn: 54492.9295719\ttest: 55294.9606577\tbest: 55294.9606577 (0)\ttotal: 2.17ms\tremaining: 4.35s\n[15:06:31] Stopped by overfitting detector  (300 iterations wait)\n[15:06:31] bestTest = 16072.40002\n[15:06:31] bestIteration = 577\n[15:06:31] Shrink model to first 578 iterations.\n[15:06:31] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.488383131670746e-06, 'min_data_in_leaf': 13} scored -16072.400273771367 in 0:00:01.977078\n[15:06:31] 0:\tlearn: 54492.9297389\ttest: 55294.9608342\tbest: 55294.9608342 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[15:06:33] Stopped by overfitting detector  (300 iterations wait)\n[15:06:33] bestTest = 16072.39878\n[15:06:33] bestIteration = 577\n[15:06:33] Shrink model to first 578 iterations.\n[15:06:33] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 7.349577218199128e-06, 'min_data_in_leaf': 13} scored -16072.398938301281 in 0:00:02.019958\n[15:06:33] 0:\tlearn: 54492.9298813\ttest: 55294.9609847\tbest: 55294.9609847 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[15:06:35] Stopped by overfitting detector  (300 iterations wait)\n[15:06:35] bestTest = 16072.39773\n[15:06:35] bestIteration = 577\n[15:06:35] Shrink model to first 578 iterations.\n[15:06:35] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0642574013896496e-05, 'min_data_in_leaf': 13} scored -16072.39813701923 in 0:00:01.973919\n[15:06:35] 0:\tlearn: 54493.8945978\ttest: 55292.3970416\tbest: 55292.3970416 (0)\ttotal: 1.68ms\tremaining: 3.37s\n[15:06:38] Stopped by overfitting detector  (300 iterations wait)\n[15:06:38] bestTest = 16587.56876\n[15:06:38] bestIteration = 1490\n[15:06:38] Shrink model to first 1491 iterations.\n[15:06:38] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 3.72764164462263e-05, 'min_data_in_leaf': 14} scored -16587.569277510684 in 0:00:02.900206\n[15:06:38] 0:\tlearn: 54419.3028527\ttest: 55264.3983891\tbest: 55264.3983891 (0)\ttotal: 2.8ms\tremaining: 5.61s\n[15:06:41] Stopped by overfitting detector  (300 iterations wait)\n[15:06:41] bestTest = 17255.83917\n[15:06:41] bestIteration = 519\n[15:06:41] Shrink model to first 520 iterations.\n[15:06:41] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 9.739014179218929e-06, 'min_data_in_leaf': 13} scored -17255.83904246795 in 0:00:02.465223\n[15:06:41] 0:\tlearn: 54492.9709076\ttest: 55295.0043395\tbest: 55295.0043395 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:06:43] Stopped by overfitting detector  (300 iterations wait)\n[15:06:43] bestTest = 16004.97119\n[15:06:43] bestIteration = 688\n[15:06:43] Shrink model to first 689 iterations.\n[15:06:43] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0009596367036655979, 'min_data_in_leaf': 2} scored -16004.971654647436 in 0:00:02.255725\n[15:06:43] 0:\tlearn: 54492.9888175\ttest: 55295.0232606\tbest: 55295.0232606 (0)\ttotal: 2.19ms\tremaining: 4.39s\n[15:06:45] Stopped by overfitting detector  (300 iterations wait)\n[15:06:45] bestTest = 15940.00508\n[15:06:45] bestIteration = 707\n[15:06:45] Shrink model to first 708 iterations.\n[15:06:45] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0013740831539666809, 'min_data_in_leaf': 1} scored -15940.005208333334 in 0:00:02.235281\n[15:06:45] 0:\tlearn: 54493.0127740\ttest: 55295.0485647\tbest: 55295.0485647 (0)\ttotal: 2.3ms\tremaining: 4.59s\n[15:06:48] Stopped by overfitting detector  (300 iterations wait)\n[15:06:48] bestTest = 16040.96468\n[15:06:48] bestIteration = 852\n[15:06:48] Shrink model to first 853 iterations.\n[15:06:48] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001928609636393231, 'min_data_in_leaf': 1} scored -16040.964309561965 in 0:00:02.573948\n[15:06:48] 0:\tlearn: 54493.0887510\ttest: 55295.1287771\tbest: 55295.1287771 (0)\ttotal: 2.26ms\tremaining: 4.52s\n[15:06:50] Stopped by overfitting detector  (300 iterations wait)\n[15:06:50] bestTest = 15992.772\n[15:06:50] bestIteration = 691\n[15:06:50] Shrink model to first 692 iterations.\n[15:06:50] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.003688453782475371, 'min_data_in_leaf': 1} scored -15992.772102029914 in 0:00:02.361341\n[15:06:50] 0:\tlearn: 54493.1156260\ttest: 55295.1571364\tbest: 55295.1571364 (0)\ttotal: 2.65ms\tremaining: 5.3s\n[15:06:53] Stopped by overfitting detector  (300 iterations wait)\n[15:06:53] bestTest = 16079.06873\n[15:06:53] bestIteration = 709\n[15:06:53] Shrink model to first 710 iterations.\n[15:06:53] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00431139068876943, 'min_data_in_leaf': 1} scored -16079.06874332265 in 0:00:02.562718\n[15:06:53] 0:\tlearn: 54493.9158430\ttest: 55292.4276450\tbest: 55292.4276450 (0)\ttotal: 1.68ms\tremaining: 3.37s\n[15:06:56] Stopped by overfitting detector  (300 iterations wait)\n[15:06:56] bestTest = 16627.33894\n[15:06:56] bestIteration = 1531\n[15:06:56] Shrink model to first 1532 iterations.\n[15:06:56] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000707377984025565, 'min_data_in_leaf': 2} scored -16627.33827457265 in 0:00:03.302986\n[15:06:56] 0:\tlearn: 54493.0513253\ttest: 55295.0892724\tbest: 55295.0892724 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:06:58] Stopped by overfitting detector  (300 iterations wait)\n[15:06:58] bestTest = 16085.04913\n[15:06:58] bestIteration = 450\n[15:06:58] Shrink model to first 451 iterations.\n[15:06:58] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0028213430994573387, 'min_data_in_leaf': 2} scored -16085.049646100428 in 0:00:01.758041\n[15:06:58] 0:\tlearn: 54493.3275716\ttest: 55295.3805348\tbest: 55295.3805348 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[15:07:00] Stopped by overfitting detector  (300 iterations wait)\n[15:07:00] bestTest = 16206.34919\n[15:07:00] bestIteration = 767\n[15:07:00] Shrink model to first 768 iterations.\n[15:07:00] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.009232011538106714, 'min_data_in_leaf': 2} scored -16206.34952590812 in 0:00:02.391020\n[15:07:00] 0:\tlearn: 54493.9332421\ttest: 55292.4526995\tbest: 55292.4526995 (0)\ttotal: 1.64ms\tremaining: 3.29s\n[15:07:02] Stopped by overfitting detector  (300 iterations wait)\n[15:07:02] bestTest = 16689.244\n[15:07:02] bestIteration = 1058\n[15:07:02] Shrink model to first 1059 iterations.\n[15:07:02] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0012563145432954211, 'min_data_in_leaf': 1} scored -16689.243222489316 in 0:00:02.329491\n[15:07:03] 0:\tlearn: 54492.9430899\ttest: 55294.9749448\tbest: 55294.9749448 (0)\ttotal: 2.22ms\tremaining: 4.43s\n[15:07:05] Stopped by overfitting detector  (300 iterations wait)\n[15:07:05] bestTest = 16110.93576\n[15:07:05] bestIteration = 725\n[15:07:05] Shrink model to first 726 iterations.\n[15:07:05] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00031611758929572646, 'min_data_in_leaf': 3} scored -16110.936298076924 in 0:00:02.309582\n[15:07:05] 0:\tlearn: 54419.7317780\ttest: 55264.7748724\tbest: 55264.7748724 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[15:07:07] Stopped by overfitting detector  (300 iterations wait)\n[15:07:07] bestTest = 17376.0332\n[15:07:07] bestIteration = 449\n[15:07:07] Shrink model to first 450 iterations.\n[15:07:07] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0059339637325433285, 'min_data_in_leaf': 4} scored -17376.032618856836 in 0:00:02.267039\n[15:07:07] 0:\tlearn: 54494.0346549\ttest: 55296.1226391\tbest: 55296.1226391 (0)\ttotal: 2.18ms\tremaining: 4.35s\n[15:07:10] Stopped by overfitting detector  (300 iterations wait)\n[15:07:10] bestTest = 16208.81749\n[15:07:10] bestIteration = 991\n[15:07:10] Shrink model to first 992 iterations.\n[15:07:10] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.02574975199212661, 'min_data_in_leaf': 1} scored -16208.817240918803 in 0:00:02.834809\n[15:07:10] 0:\tlearn: 54492.9396642\ttest: 55294.9713244\tbest: 55294.9713244 (0)\ttotal: 2.21ms\tremaining: 4.41s\n[15:07:12] Stopped by overfitting detector  (300 iterations wait)\n[15:07:12] bestTest = 16110.93906\n[15:07:12] bestIteration = 725\n[15:07:12] Shrink model to first 726 iterations.\n[15:07:12] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00023688733982777323, 'min_data_in_leaf': 3} scored -16110.938635149572 in 0:00:02.389209\n[15:07:13] 0:\tlearn: 54492.9330871\ttest: 55294.9643731\tbest: 55294.9643731 (0)\ttotal: 2.18ms\tremaining: 4.37s\n[15:07:14] Stopped by overfitting detector  (300 iterations wait)\n[15:07:14] bestTest = 16072.3741\n[15:07:14] bestIteration = 577\n[15:07:14] Shrink model to first 578 iterations.\n[15:07:14] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 8.477894355275811e-05, 'min_data_in_leaf': 2} scored -16072.373530982906 in 0:00:01.992262\n[15:07:15] 0:\tlearn: 54492.9806417\ttest: 55295.0146237\tbest: 55295.0146237 (0)\ttotal: 2.25ms\tremaining: 4.49s\n[15:07:17] Stopped by overfitting detector  (300 iterations wait)\n[15:07:17] bestTest = 16004.8893\n[15:07:17] bestIteration = 688\n[15:07:17] Shrink model to first 689 iterations.\n[15:07:17] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0011848781309893423, 'min_data_in_leaf': 2} scored -16004.890024038461 in 0:00:02.204141\n[15:07:17] 0:\tlearn: 54492.9881219\ttest: 55295.0225258\tbest: 55295.0225258 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[15:07:19] Stopped by overfitting detector  (300 iterations wait)\n[15:07:19] bestTest = 15940.01095\n[15:07:19] bestIteration = 707\n[15:07:19] Shrink model to first 708 iterations.\n[15:07:19] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0013579845873043165, 'min_data_in_leaf': 2} scored -15940.01155181624 in 0:00:02.243881\n[15:07:19] 0:\tlearn: 54493.0040168\ttest: 55295.0393156\tbest: 55295.0393156 (0)\ttotal: 2.22ms\tremaining: 4.43s\n[15:07:21] Stopped by overfitting detector  (300 iterations wait)\n[15:07:21] bestTest = 15990.42546\n[15:07:21] bestIteration = 716\n[15:07:21] Shrink model to first 717 iterations.\n[15:07:21] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0017258849462186343, 'min_data_in_leaf': 5} scored -15990.425547542734 in 0:00:02.282865\n[15:07:21] 0:\tlearn: 54493.9186407\ttest: 55292.4316743\tbest: 55292.4316743 (0)\ttotal: 1.71ms\tremaining: 3.42s\n[15:07:25] Stopped by overfitting detector  (300 iterations wait)\n[15:07:25] bestTest = 16618.44396\n[15:07:25] bestIteration = 1653\n[15:07:25] Shrink model to first 1654 iterations.\n[15:07:25] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0007956382791549648, 'min_data_in_leaf': 5} scored -16618.444143963676 in 0:00:03.623237\n[15:07:25] 0:\tlearn: 54494.2179978\ttest: 55296.3142789\tbest: 55296.3142789 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:07:27] Stopped by overfitting detector  (300 iterations wait)\n[15:07:27] bestTest = 16214.6603\n[15:07:27] bestIteration = 486\n[15:07:27] Shrink model to first 487 iterations.\n[15:07:27] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.030058261745192758, 'min_data_in_leaf': 4} scored -16214.660223023504 in 0:00:02.050988\n[15:07:27] 0:\tlearn: 54493.0056709\ttest: 55295.0410627\tbest: 55295.0410627 (0)\ttotal: 2.17ms\tremaining: 4.35s\n[15:07:29] Stopped by overfitting detector  (300 iterations wait)\n[15:07:29] bestTest = 15990.4129\n[15:07:29] bestIteration = 716\n[15:07:29] Shrink model to first 717 iterations.\n[15:07:29] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0017641751020261811, 'min_data_in_leaf': 3} scored -15990.412526709402 in 0:00:02.258344\n[15:07:29] 0:\tlearn: 54369.6178516\ttest: 55194.0952012\tbest: 55194.0952012 (0)\ttotal: 4.67ms\tremaining: 9.34s\n[15:07:32] Stopped by overfitting detector  (300 iterations wait)\n[15:07:32] bestTest = 16521.83975\n[15:07:32] bestIteration = 415\n[15:07:32] Shrink model to first 416 iterations.\n[15:07:32] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0027581860838518674, 'min_data_in_leaf': 3} scored -16521.839877136754 in 0:00:03.133533\n[15:07:32] 0:\tlearn: 54492.9558879\ttest: 55294.9884693\tbest: 55294.9884693 (0)\ttotal: 2.19ms\tremaining: 4.39s\n[15:07:35] Stopped by overfitting detector  (300 iterations wait)\n[15:07:35] bestTest = 16036.36234\n[15:07:35] bestIteration = 1160\n[15:07:35] Shrink model to first 1161 iterations.\n[15:07:35] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0006121496593029671, 'min_data_in_leaf': 5} scored -16036.362613514957 in 0:00:03.149901\n[15:07:36] 0:\tlearn: 54492.9853182\ttest: 55295.0195640\tbest: 55295.0195640 (0)\ttotal: 2.14ms\tremaining: 4.29s\n[15:07:38] Stopped by overfitting detector  (300 iterations wait)\n[15:07:38] bestTest = 16004.84997\n[15:07:38] bestIteration = 688\n[15:07:38] Shrink model to first 689 iterations.\n[15:07:38] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001293098890830249, 'min_data_in_leaf': 2} scored -16004.850060096154 in 0:00:02.210754\n[15:07:38] 0:\tlearn: 54493.2524762\ttest: 55295.3014326\tbest: 55295.3014326 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:07:39] Stopped by overfitting detector  (300 iterations wait)\n[15:07:39] bestTest = 16139.74158\n[15:07:39] bestIteration = 516\n[15:07:39] Shrink model to first 517 iterations.\n[15:07:39] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.007486953053561617, 'min_data_in_leaf': 3} scored -16139.741519764957 in 0:00:01.840282\n[15:07:40] 0:\tlearn: 54493.0065415\ttest: 55295.0419822\tbest: 55295.0419822 (0)\ttotal: 2.17ms\tremaining: 4.35s\n[15:07:42] Stopped by overfitting detector  (300 iterations wait)\n[15:07:42] bestTest = 16041.02096\n[15:07:42] bestIteration = 852\n[15:07:42] Shrink model to first 853 iterations.\n[15:07:42] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0017843274890108143, 'min_data_in_leaf': 1} scored -16041.02063301282 in 0:00:02.562929\n[15:07:42] 0:\tlearn: 54493.5183437\ttest: 55295.5812349\tbest: 55295.5812349 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:07:44] Stopped by overfitting detector  (300 iterations wait)\n[15:07:44] bestTest = 16256.28001\n[15:07:44] bestIteration = 583\n[15:07:44] Shrink model to first 584 iterations.\n[15:07:44] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.013673098207468662, 'min_data_in_leaf': 4} scored -16256.280081463676 in 0:00:02.021356\n[15:07:44] 0:\tlearn: 54493.9077488\ttest: 55292.4159868\tbest: 55292.4159868 (0)\ttotal: 1.64ms\tremaining: 3.29s\n[15:07:47] Stopped by overfitting detector  (300 iterations wait)\n[15:07:47] bestTest = 16620.66737\n[15:07:47] bestIteration = 1576\n[15:07:47] Shrink model to first 1577 iterations.\n[15:07:47] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00045205359070365743, 'min_data_in_leaf': 2} scored -16620.667301014957 in 0:00:03.034298\n[15:07:47] 0:\tlearn: 54419.5756973\ttest: 55264.6379123\tbest: 55264.6379123 (0)\ttotal: 2.82ms\tremaining: 5.64s\n[15:07:50] Stopped by overfitting detector  (300 iterations wait)\n[15:07:50] bestTest = 17102.57384\n[15:07:50] bestIteration = 778\n[15:07:50] Shrink model to first 779 iterations.\n[15:07:50] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.003775689347111145, 'min_data_in_leaf': 3} scored -17102.574318910258 in 0:00:03.161447\n[15:07:50] 0:\tlearn: 54492.9386176\ttest: 55294.9702183\tbest: 55294.9702183 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[15:07:53] Stopped by overfitting detector  (300 iterations wait)\n[15:07:53] bestTest = 16110.94007\n[15:07:53] bestIteration = 725\n[15:07:53] Shrink model to first 726 iterations.\n[15:07:53] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00021268111058103393, 'min_data_in_leaf': 1} scored -16110.940137553418 in 0:00:02.337140\n[15:07:53] 0:\tlearn: 54492.9901883\ttest: 55295.0247088\tbest: 55295.0247088 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:07:55] Stopped by overfitting detector  (300 iterations wait)\n[15:07:55] bestTest = 15939.99351\n[15:07:55] bestIteration = 707\n[15:07:55] Shrink model to first 708 iterations.\n[15:07:55] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0014058096877311882, 'min_data_in_leaf': 2} scored -15939.993088942309 in 0:00:02.396458\n[15:07:55] 0:\tlearn: 54495.7533806\ttest: 55297.9070526\tbest: 55297.9070526 (0)\ttotal: 2.64ms\tremaining: 5.28s\n[15:07:57] Stopped by overfitting detector  (300 iterations wait)\n[15:07:57] bestTest = 16063.53382\n[15:07:57] bestIteration = 544\n[15:07:57] Shrink model to first 545 iterations.\n[15:07:57] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.06655143906250226, 'min_data_in_leaf': 4} scored -16063.533653846154 in 0:00:02.120290\n[15:07:57] 0:\tlearn: 54492.9851528\ttest: 55295.0193893\tbest: 55295.0193893 (0)\ttotal: 2.21ms\tremaining: 4.42s\n[15:07:59] Stopped by overfitting detector  (300 iterations wait)\n[15:07:59] bestTest = 16004.85136\n[15:07:59] bestIteration = 688\n[15:07:59] Shrink model to first 689 iterations.\n[15:07:59] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0012892726494161215, 'min_data_in_leaf': 2} scored -16004.85109508547 in 0:00:02.226572\n[15:08:00] 0:\tlearn: 54493.0171887\ttest: 55295.0532270\tbest: 55295.0532270 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:08:02] Stopped by overfitting detector  (300 iterations wait)\n[15:08:02] bestTest = 16044.16667\n[15:08:02] bestIteration = 496\n[15:08:02] Shrink model to first 497 iterations.\n[15:08:02] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0020308161296433477, 'min_data_in_leaf': 2} scored -16044.166800213676 in 0:00:02.137835\n[15:08:02] 0:\tlearn: 54493.6127942\ttest: 55295.6804686\tbest: 55295.6804686 (0)\ttotal: 2.15ms\tremaining: 4.29s\n[15:08:05] Stopped by overfitting detector  (300 iterations wait)\n[15:08:05] bestTest = 16240.37012\n[15:08:05] bestIteration = 1110\n[15:08:05] Shrink model to first 1111 iterations.\n[15:08:05] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.015876082037276903, 'min_data_in_leaf': 3} scored -16240.369925213676 in 0:00:03.106591\n[15:08:05] 0:\tlearn: 54492.9366838\ttest: 55294.9681745\tbest: 55294.9681745 (0)\ttotal: 2.49ms\tremaining: 4.97s\n[15:08:07] Stopped by overfitting detector  (300 iterations wait)\n[15:08:07] bestTest = 16110.94193\n[15:08:07] bestIteration = 725\n[15:08:07] Shrink model to first 726 iterations.\n[15:08:07] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00016795740386429592, 'min_data_in_leaf': 5} scored -16110.942040598291 in 0:00:02.305337\n[15:08:07] 0:\tlearn: 54492.9890599\ttest: 55295.0235168\tbest: 55295.0235168 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:08:09] Stopped by overfitting detector  (300 iterations wait)\n[15:08:09] bestTest = 15940.00304\n[15:08:09] bestIteration = 707\n[15:08:09] Shrink model to first 708 iterations.\n[15:08:09] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0013796944725148746, 'min_data_in_leaf': 1} scored -15940.002904647436 in 0:00:02.275910\n[15:08:10] 0:\tlearn: 54492.9491054\ttest: 55294.9813020\tbest: 55294.9813020 (0)\ttotal: 2.23ms\tremaining: 4.46s\n[15:08:12] Stopped by overfitting detector  (300 iterations wait)\n[15:08:12] bestTest = 16110.92997\n[15:08:12] bestIteration = 725\n[15:08:12] Shrink model to first 726 iterations.\n[15:08:12] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0004552565974787241, 'min_data_in_leaf': 1} scored -16110.930288461539 in 0:00:02.369371\n[15:08:12] 0:\tlearn: 54498.6693805\ttest: 55300.8776854\tbest: 55300.8776854 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:08:14] Stopped by overfitting detector  (300 iterations wait)\n[15:08:14] bestTest = 16088.57958\n[15:08:14] bestIteration = 683\n[15:08:14] Shrink model to first 684 iterations.\n[15:08:14] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.13787789950843846, 'min_data_in_leaf': 6} scored -16088.579560630342 in 0:00:02.227339\n[15:08:14] 0:\tlearn: 54493.1337986\ttest: 55295.1763085\tbest: 55295.1763085 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[15:08:16] Stopped by overfitting detector  (300 iterations wait)\n[15:08:16] bestTest = 16010.63296\n[15:08:16] bestIteration = 567\n[15:08:16] Shrink model to first 568 iterations.\n[15:08:16] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.004732741502401756, 'min_data_in_leaf': 1} scored -16010.63297943376 in 0:00:01.984164\n[15:08:16] 0:\tlearn: 54419.8796221\ttest: 55264.9045656\tbest: 55264.9045656 (0)\ttotal: 2.95ms\tremaining: 5.91s\n[15:08:19] Stopped by overfitting detector  (300 iterations wait)\n[15:08:19] bestTest = 17225.31624\n[15:08:19] bestIteration = 640\n[15:08:19] Shrink model to first 641 iterations.\n[15:08:19] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00798100343016187, 'min_data_in_leaf': 3} scored -17225.31610576923 in 0:00:02.833343\n[15:08:19] 0:\tlearn: 54208.7361713\ttest: 55083.8980528\tbest: 55083.8980528 (0)\ttotal: 2.24ms\tremaining: 4.49s\n[15:08:21] Stopped by overfitting detector  (300 iterations wait)\n[15:08:21] bestTest = 16436.39734\n[15:08:21] bestIteration = 544\n[15:08:21] Shrink model to first 545 iterations.\n[15:08:21] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0032365744331213486, 'min_data_in_leaf': 4} scored -16436.39703525641 in 0:00:01.955858\n[15:08:21] 0:\tlearn: 54492.9932020\ttest: 55295.0278923\tbest: 55295.0278923 (0)\ttotal: 2.25ms\tremaining: 4.49s\n[15:08:23] Stopped by overfitting detector  (300 iterations wait)\n[15:08:23] bestTest = 15926.36599\n[15:08:23] bestIteration = 892\n[15:08:23] Shrink model to first 893 iterations.\n[15:08:23] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0014755602994562334, 'min_data_in_leaf': 2} scored -15926.366352831197 in 0:00:02.686265\n[15:08:24] 0:\tlearn: 54493.0031500\ttest: 55295.0384000\tbest: 55295.0384000 (0)\ttotal: 2.22ms\tremaining: 4.44s\n[15:08:26] Stopped by overfitting detector  (300 iterations wait)\n[15:08:26] bestTest = 15990.43205\n[15:08:26] bestIteration = 716\n[15:08:26] Shrink model to first 717 iterations.\n[15:08:26] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0017058188416824787, 'min_data_in_leaf': 1} scored -15990.432224893162 in 0:00:02.294317\n[15:08:26] 0:\tlearn: 54492.9569087\ttest: 55294.9895480\tbest: 55294.9895480 (0)\ttotal: 2.29ms\tremaining: 4.58s\n[15:08:28] Stopped by overfitting detector  (300 iterations wait)\n[15:08:28] bestTest = 16045.82699\n[15:08:28] bestIteration = 441\n[15:08:28] Shrink model to first 442 iterations.\n[15:08:28] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000635764252721072, 'min_data_in_leaf': 1} scored -16045.827223557691 in 0:00:02.024904\n[15:08:28] 0:\tlearn: 54492.9350618\ttest: 55294.9664601\tbest: 55294.9664601 (0)\ttotal: 2.63ms\tremaining: 5.26s\n[15:08:30] Stopped by overfitting detector  (300 iterations wait)\n[15:08:30] bestTest = 16110.9435\n[15:08:30] bestIteration = 725\n[15:08:30] Shrink model to first 726 iterations.\n[15:08:30] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00013044452259913466, 'min_data_in_leaf': 1} scored -16110.942741720086 in 0:00:02.431904\n[15:08:30] 0:\tlearn: 54492.9316973\ttest: 55294.9629041\tbest: 55294.9629041 (0)\ttotal: 2.2ms\tremaining: 4.39s\n[15:08:32] Stopped by overfitting detector  (300 iterations wait)\n[15:08:32] bestTest = 16072.38434\n[15:08:32] bestIteration = 577\n[15:08:32] Shrink model to first 578 iterations.\n[15:08:32] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.263679816742172e-05, 'min_data_in_leaf': 2} scored -16072.384815705129 in 0:00:02.052998\n[15:08:33] 0:\tlearn: 54492.9413872\ttest: 55294.9731453\tbest: 55294.9731453 (0)\ttotal: 2.26ms\tremaining: 4.51s\n[15:08:35] Stopped by overfitting detector  (300 iterations wait)\n[15:08:35] bestTest = 16110.9374\n[15:08:35] bestIteration = 725\n[15:08:35] Shrink model to first 726 iterations.\n[15:08:35] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00027673568389392094, 'min_data_in_leaf': 1} scored -16110.937934027777 in 0:00:02.585297\n[15:08:35] 0:\tlearn: 54493.0114933\ttest: 55295.0472122\tbest: 55295.0472122 (0)\ttotal: 2.19ms\tremaining: 4.39s\n[15:08:37] Stopped by overfitting detector  (300 iterations wait)\n[15:08:37] bestTest = 16040.97624\n[15:08:37] bestIteration = 852\n[15:08:37] Shrink model to first 853 iterations.\n[15:08:38] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0018989614669927724, 'min_data_in_leaf': 3} scored -16040.976228632479 in 0:00:02.557150\n[15:08:38] 0:\tlearn: 54493.3823760\ttest: 55295.4382280\tbest: 55295.4382280 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:08:41] Stopped by overfitting detector  (300 iterations wait)\n[15:08:41] bestTest = 16171.30482\n[15:08:41] bestIteration = 1081\n[15:08:41] Shrink model to first 1082 iterations.\n[15:08:41] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.010506665603985074, 'min_data_in_leaf': 2} scored -16171.305588942309 in 0:00:03.023598\n[15:08:41] 0:\tlearn: 54495.0829232\ttest: 55297.2141372\tbest: 55297.2141372 (0)\ttotal: 2.27ms\tremaining: 4.53s\n[15:08:42] Stopped by overfitting detector  (300 iterations wait)\n[15:08:42] bestTest = 16381.20884\n[15:08:42] bestIteration = 382\n[15:08:42] Shrink model to first 383 iterations.\n[15:08:42] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.05052544399743553, 'min_data_in_leaf': 1} scored -16381.209101228633 in 0:00:01.629425\n[15:08:42] 0:\tlearn: 54494.5239679\ttest: 55293.2987499\tbest: 55293.2987499 (0)\ttotal: 2.11ms\tremaining: 4.21s\n[15:08:45] Stopped by overfitting detector  (300 iterations wait)\n[15:08:45] bestTest = 16486.39143\n[15:08:45] bestIteration = 1342\n[15:08:45] Shrink model to first 1343 iterations.\n[15:08:45] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.019969994157608518, 'min_data_in_leaf': 4} scored -16486.391459668805 in 0:00:02.685753\n[15:08:45] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[15:08:45] The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.5460381634882061, 'min_data_in_leaf': 9}\u001b[0m\n achieve -15802.1870 mae\n[15:08:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:08:45] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:08:45] 0:\tlearn: 55163.3087716\ttest: 55934.0827528\tbest: 55934.0827528 (0)\ttotal: 2.2ms\tremaining: 6.61s\n[15:08:47] Stopped by overfitting detector  (100 iterations wait)\n[15:08:47] bestTest = 16327.63832\n[15:08:47] bestIteration = 837\n[15:08:47] Shrink model to first 838 iterations.\n[15:08:47] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:08:47] 0:\tlearn: 54710.7322261\ttest: 57366.5948969\tbest: 57366.5948969 (0)\ttotal: 2.3ms\tremaining: 6.91s\n[15:08:48] Stopped by overfitting detector  (100 iterations wait)\n[15:08:48] bestTest = 16629.82057\n[15:08:48] bestIteration = 614\n[15:08:48] Shrink model to first 615 iterations.\n[15:08:48] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:08:49] 0:\tlearn: 54506.4900440\ttest: 55589.0128732\tbest: 55589.0128732 (0)\ttotal: 2.37ms\tremaining: 7.09s\n[15:08:50] Stopped by overfitting detector  (100 iterations wait)\n[15:08:50] bestTest = 14157.80038\n[15:08:50] bestIteration = 776\n[15:08:50] Shrink model to first 777 iterations.\n[15:08:50] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:08:50] 0:\tlearn: 56149.7201426\ttest: 52294.2726165\tbest: 52294.2726165 (0)\ttotal: 2.31ms\tremaining: 6.91s\n[15:08:53] Stopped by overfitting detector  (100 iterations wait)\n[15:08:53] bestTest = 12972.09803\n[15:08:53] bestIteration = 931\n[15:08:53] Shrink model to first 932 iterations.\n[15:08:53] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:08:53] 0:\tlearn: 55345.3930496\ttest: 54953.7406057\tbest: 54953.7406057 (0)\ttotal: 2.24ms\tremaining: 6.71s\n[15:08:56] Stopped by overfitting detector  (100 iterations wait)\n[15:08:56] bestTest = 13442.34191\n[15:08:56] bestIteration = 1321\n[15:08:56] Shrink model to first 1322 iterations.\n[15:08:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14708.506050005351\u001b[0m\n[15:08:56] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:08:56] Time left 3000.58 secs\n\n[15:08:56] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[15:08:56] Blending: optimization starts with equal weights and score \u001b[1m-14603.28569135274\u001b[0m\n[15:08:56] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14535.7880859375\u001b[0m, weights = \u001b[1m[0.13390236 0.1330987  0.         0.3233535  0.40964538]\u001b[0m\n[15:08:56] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14506.692626953125\u001b[0m, weights = \u001b[1m[0.0755056  0.23829085 0.         0.26410162 0.4221019 ]\u001b[0m\n[15:08:56] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14505.50026755137\u001b[0m, weights = \u001b[1m[0.09110842 0.24575347 0.         0.24971028 0.41342786]\u001b[0m\n[15:08:56] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14505.491083850598\u001b[0m, weights = \u001b[1m[0.09102996 0.24554184 0.         0.24906035 0.41436785]\u001b[0m\n[15:08:56] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14505.491083850598\u001b[0m, weights = \u001b[1m[0.09102996 0.24554184 0.         0.24906035 0.41436785]\u001b[0m\n[15:08:56] Blending: no score update. Terminated\n\n[15:08:56] \u001b[1mAutoml preset training completed in 613.04 seconds\u001b[0m\n\n[15:08:56] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.09103 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.24554 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.24906 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.41437 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[15:08:56] ==================================================\n[15:08:56] Start 5 automl preset configuration:\n[15:08:56] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 47}, 'nn_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n[15:08:56] Found reader_params in kwargs, need to combine\n[15:08:56] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 47, 'cv': 5}\n[15:08:56] Stdout logging level is INFO3.\n[15:08:56] Task: reg\n\n[15:08:56] Start automl preset with listed constraints:\n[15:08:56] - time: 3000.42 seconds\n[15:08:56] - CPU: 4 cores\n[15:08:56] - memory: 16 GB\n\n[15:08:56] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[15:09:03] Feats was rejected during automatic roles guess: []\n[15:09:03] Layer \u001b[1m1\u001b[0m train process start. Time left 2993.52 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:09:03] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[15:09:03] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:09:03] Linear model: C = 1e-05 score = -36791.722956730766\n[15:09:04] Linear model: C = 5e-05 score = -23617.91736778846\n[15:09:04] Linear model: C = 0.0001 score = -20481.347422542734\n[15:09:04] Linear model: C = 0.0005 score = -16586.26133480235\n[15:09:04] Linear model: C = 0.001 score = -16586.26133480235\n[15:09:04] Linear model: C = 0.005 score = -16586.26133480235\n[15:09:04] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:09:04] Linear model: C = 1e-05 score = -38810.874098557695\n[15:09:04] Linear model: C = 5e-05 score = -26772.133380074785\n[15:09:04] Linear model: C = 0.0001 score = -23885.80625667735\n[15:09:05] Linear model: C = 0.0005 score = -21240.716212606836\n[15:09:05] Linear model: C = 0.001 score = -20978.161992521367\n[15:09:05] Linear model: C = 0.005 score = -20618.442107371793\n[15:09:05] Linear model: C = 0.01 score = -20618.44050480769\n[15:09:05] Linear model: C = 0.05 score = -20561.750133547008\n[15:09:06] Linear model: C = 0.1 score = -20561.749866452992\n[15:09:06] Linear model: C = 0.5 score = -20561.750751201922\n[15:09:06] Linear model: C = 1 score = -22146.839192708332\n[15:09:06] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:09:06] Linear model: C = 1e-05 score = -36419.819010416664\n[15:09:06] Linear model: C = 5e-05 score = -23511.499899839742\n[15:09:06] Linear model: C = 0.0001 score = -20552.23066907051\n[15:09:07] Linear model: C = 0.0005 score = -16963.83780715812\n[15:09:07] Linear model: C = 0.001 score = -16963.83849158654\n[15:09:07] Linear model: C = 0.005 score = -16562.996410924145\n[15:09:07] Linear model: C = 0.01 score = -16562.996410924145\n[15:09:07] Linear model: C = 0.05 score = -16562.996410924145\n[15:09:07] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:09:07] Linear model: C = 1e-05 score = -33643.077722639486\n[15:09:07] Linear model: C = 5e-05 score = -21316.295466738196\n[15:09:07] Linear model: C = 0.0001 score = -19495.58860313841\n[15:09:08] Linear model: C = 0.0005 score = -18623.989337446354\n[15:09:08] Linear model: C = 0.001 score = -18623.99207014485\n[15:09:08] Linear model: C = 0.005 score = -18590.907239136268\n[15:09:08] Linear model: C = 0.01 score = -18590.907239136268\n[15:09:08] Linear model: C = 0.05 score = -18590.907658261804\n[15:09:08] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:09:08] Linear model: C = 1e-05 score = -36284.39997988197\n[15:09:08] Linear model: C = 5e-05 score = -22772.251743562232\n[15:09:09] Linear model: C = 0.0001 score = -20935.705614605686\n[15:09:09] Linear model: C = 0.0005 score = -18050.10649979882\n[15:09:09] Linear model: C = 0.001 score = -17444.93946150751\n[15:09:09] Linear model: C = 0.005 score = -16552.822722471836\n[15:09:10] Linear model: C = 0.01 score = -16806.92223544796\n[15:09:10] Linear model: C = 0.05 score = -18818.846130633046\n[15:09:10] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17771.288409507437\u001b[0m\n[15:09:10] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[15:09:10] Time left 2986.16 secs\n\n[15:09:10] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:09:12] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[15:09:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[15:09:12] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:09:12] Training until validation scores don't improve for 200 rounds\n[15:09:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:09:14] Training until validation scores don't improve for 200 rounds\n[15:09:17] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:09:17] Training until validation scores don't improve for 200 rounds\n[15:09:19] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:09:19] Training until validation scores don't improve for 200 rounds\n[15:09:21] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:09:21] Training until validation scores don't improve for 200 rounds\n[15:09:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15623.98868926584\u001b[0m\n[15:09:23] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[15:09:23] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[15:09:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:09:23] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:23] Training until validation scores don't improve for 200 rounds\n[15:09:26] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:26] Training until validation scores don't improve for 200 rounds\n[15:09:29] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:29] Training until validation scores don't improve for 200 rounds\n[15:09:32] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:32] Training until validation scores don't improve for 200 rounds\n[15:09:35] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:35] Training until validation scores don't improve for 200 rounds\n[15:09:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15633.400892283818\u001b[0m\n[15:09:38] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:09:38] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15633.400892283818 in 0:00:14.251413\n[15:09:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:09:38] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:38] Training until validation scores don't improve for 200 rounds\n[15:09:40] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:40] Training until validation scores don't improve for 200 rounds\n[15:09:43] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:43] Training until validation scores don't improve for 200 rounds\n[15:09:46] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:46] Training until validation scores don't improve for 200 rounds\n[15:09:48] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:48] Training until validation scores don't improve for 200 rounds\n[15:09:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15396.467546018835\u001b[0m\n[15:09:50] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:09:50] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -15396.467546018835 in 0:00:12.132568\n[15:09:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:09:50] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:50] Training until validation scores don't improve for 200 rounds\n[15:09:52] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:52] Training until validation scores don't improve for 200 rounds\n[15:09:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:54] Training until validation scores don't improve for 200 rounds\n[15:09:57] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:57] Training until validation scores don't improve for 200 rounds\n[15:09:59] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:09:59] Training until validation scores don't improve for 200 rounds\n[15:10:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15520.19083770334\u001b[0m\n[15:10:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:10:00] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -15520.19083770334 in 0:00:10.684974\n[15:10:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:10:00] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:00] Training until validation scores don't improve for 200 rounds\n[15:10:03] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:03] Training until validation scores don't improve for 200 rounds\n[15:10:08] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:08] Training until validation scores don't improve for 200 rounds\n[15:10:10] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:10] Training until validation scores don't improve for 200 rounds\n[15:10:13] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:13] Training until validation scores don't improve for 200 rounds\n[15:10:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15616.692867749358\u001b[0m\n[15:10:15] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:10:15] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -15616.692867749358 in 0:00:14.539982\n[15:10:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:10:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:15] Training until validation scores don't improve for 200 rounds\n[15:10:17] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:17] Training until validation scores don't improve for 200 rounds\n[15:10:21] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:21] Training until validation scores don't improve for 200 rounds\n[15:10:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:23] Training until validation scores don't improve for 200 rounds\n[15:10:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:25] Training until validation scores don't improve for 200 rounds\n[15:10:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15396.232682737585\u001b[0m\n[15:10:26] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:10:26] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -15396.232682737585 in 0:00:11.317199\n[15:10:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:10:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:26] Training until validation scores don't improve for 200 rounds\n[15:10:28] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:28] Training until validation scores don't improve for 200 rounds\n[15:10:30] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:30] Training until validation scores don't improve for 200 rounds\n[15:10:32] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:32] Training until validation scores don't improve for 200 rounds\n[15:10:34] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:34] Training until validation scores don't improve for 200 rounds\n[15:10:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15547.921674336472\u001b[0m\n[15:10:36] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:10:36] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -15547.921674336472 in 0:00:09.578933\n[15:10:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:10:36] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:36] Training until validation scores don't improve for 200 rounds\n[15:10:40] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:40] Training until validation scores don't improve for 200 rounds\n[15:10:43] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:43] Training until validation scores don't improve for 200 rounds\n[15:10:46] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:46] Training until validation scores don't improve for 200 rounds\n[15:10:48] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:48] Training until validation scores don't improve for 200 rounds\n[15:10:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15634.037841796875\u001b[0m\n[15:10:50] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:10:50] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15634.037841796875 in 0:00:14.332654\n[15:10:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:10:50] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:50] Training until validation scores don't improve for 200 rounds\n[15:10:52] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:52] Training until validation scores don't improve for 200 rounds\n[15:10:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:54] Training until validation scores don't improve for 200 rounds\n[15:10:56] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:56] Training until validation scores don't improve for 200 rounds\n[15:10:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:58] Training until validation scores don't improve for 200 rounds\n[15:10:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15245.91278494221\u001b[0m\n[15:10:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:10:59] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -15245.91278494221 in 0:00:08.826731\n[15:10:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:10:59] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:10:59] Training until validation scores don't improve for 200 rounds\n[15:11:02] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:02] Training until validation scores don't improve for 200 rounds\n[15:11:06] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:06] Training until validation scores don't improve for 200 rounds\n[15:11:10] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:10] Training until validation scores don't improve for 200 rounds\n[15:11:12] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:13] Training until validation scores don't improve for 200 rounds\n[15:11:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15930.504193867722\u001b[0m\n[15:11:16] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:11:16] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15930.504193867722 in 0:00:17.037280\n[15:11:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:11:16] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:16] Training until validation scores don't improve for 200 rounds\n[15:11:18] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:18] Training until validation scores don't improve for 200 rounds\n[15:11:21] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:21] Training until validation scores don't improve for 200 rounds\n[15:11:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:23] Training until validation scores don't improve for 200 rounds\n[15:11:24] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:24] Training until validation scores don't improve for 200 rounds\n[15:11:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15486.737431774402\u001b[0m\n[15:11:26] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:11:26] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -15486.737431774402 in 0:00:10.170633\n[15:11:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:11:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:26] Training until validation scores don't improve for 200 rounds\n[15:11:28] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:28] Training until validation scores don't improve for 200 rounds\n[15:11:31] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:31] Training until validation scores don't improve for 200 rounds\n[15:11:34] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:34] Training until validation scores don't improve for 200 rounds\n[15:11:35] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:35] Training until validation scores don't improve for 200 rounds\n[15:11:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15422.660326813999\u001b[0m\n[15:11:37] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:11:37] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527} scored -15422.660326813999 in 0:00:10.321925\n[15:11:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:11:37] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:37] Training until validation scores don't improve for 200 rounds\n[15:11:38] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:38] Training until validation scores don't improve for 200 rounds\n[15:11:43] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:43] Training until validation scores don't improve for 200 rounds\n[15:11:45] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:45] Training until validation scores don't improve for 200 rounds\n[15:11:46] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:46] Training until validation scores don't improve for 200 rounds\n[15:11:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15450.65309958262\u001b[0m\n[15:11:48] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:11:48] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.6002236728672344, 'num_leaves': 179, 'bagging_fraction': 0.6673975881116181, 'min_sum_hessian_in_leaf': 0.17774668597138318, 'reg_alpha': 0.001079801017138211, 'reg_lambda': 1.197220994321415e-08} scored -15450.65309958262 in 0:00:11.285237\n[15:11:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:11:48] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:48] Training until validation scores don't improve for 200 rounds\n[15:11:50] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:50] Training until validation scores don't improve for 200 rounds\n[15:11:53] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:53] Training until validation scores don't improve for 200 rounds\n[15:11:56] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:56] Training until validation scores don't improve for 200 rounds\n[15:11:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:11:57] Training until validation scores don't improve for 200 rounds\n[15:12:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15468.05043343322\u001b[0m\n[15:12:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:12:00] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.9093992044188224, 'num_leaves': 196, 'bagging_fraction': 0.6417907414923303, 'min_sum_hessian_in_leaf': 1.67050909673135, 'reg_alpha': 0.022017949493573677, 'reg_lambda': 0.003610116265596713} scored -15468.05043343322 in 0:00:11.617527\n[15:12:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:12:00] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:00] Training until validation scores don't improve for 200 rounds\n[15:12:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:01] Training until validation scores don't improve for 200 rounds\n[15:12:04] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:04] Training until validation scores don't improve for 200 rounds\n[15:12:06] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:06] Training until validation scores don't improve for 200 rounds\n[15:12:08] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:08] Training until validation scores don't improve for 200 rounds\n[15:12:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15472.408463987585\u001b[0m\n[15:12:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:12:10] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.6038502363408119, 'num_leaves': 121, 'bagging_fraction': 0.722308544990837, 'min_sum_hessian_in_leaf': 0.02764489285232723, 'reg_alpha': 3.666548287829631e-05, 'reg_lambda': 2.9536889586486034e-06} scored -15472.408463987585 in 0:00:10.395192\n[15:12:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:12:10] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:10] Training until validation scores don't improve for 200 rounds\n[15:12:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:14] Training until validation scores don't improve for 200 rounds\n[15:12:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:16] Training until validation scores don't improve for 200 rounds\n[15:12:19] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:19] Training until validation scores don't improve for 200 rounds\n[15:12:21] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:21] Training until validation scores don't improve for 200 rounds\n[15:12:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15389.1181640625\u001b[0m\n[15:12:23] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:12:23] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.9734159823252648, 'num_leaves': 200, 'bagging_fraction': 0.6040480561972923, 'min_sum_hessian_in_leaf': 0.37947060877945143, 'reg_alpha': 0.12307258184704516, 'reg_lambda': 1.063082707940129e-08} scored -15389.1181640625 in 0:00:13.405174\n[15:12:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:12:23] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:23] Training until validation scores don't improve for 200 rounds\n[15:12:25] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:25] Training until validation scores don't improve for 200 rounds\n[15:12:28] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:28] Training until validation scores don't improve for 200 rounds\n[15:12:30] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:30] Training until validation scores don't improve for 200 rounds\n[15:12:32] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:32] Training until validation scores don't improve for 200 rounds\n[15:12:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15448.388551476884\u001b[0m\n[15:12:34] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:12:34] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 163, 'bagging_fraction': 0.5127747474052715, 'min_sum_hessian_in_leaf': 9.280240491544411, 'reg_alpha': 0.15203858593612088, 'reg_lambda': 0.00014211618981379645} scored -15448.388551476884 in 0:00:10.976495\n[15:12:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:12:34] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:34] Training until validation scores don't improve for 200 rounds\n[15:12:36] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:36] Training until validation scores don't improve for 200 rounds\n[15:12:39] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:39] Training until validation scores don't improve for 200 rounds\n[15:12:42] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:42] Training until validation scores don't improve for 200 rounds\n[15:12:43] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:43] Training until validation scores don't improve for 200 rounds\n[15:12:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15453.402571168665\u001b[0m\n[15:12:47] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:12:47] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.8649174147658507, 'num_leaves': 131, 'bagging_fraction': 0.5953886036367442, 'min_sum_hessian_in_leaf': 0.40994077665983253, 'reg_alpha': 9.904158506776536e-05, 'reg_lambda': 3.4333254884718856e-07} scored -15453.402571168665 in 0:00:12.261568\n[15:12:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:12:47] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:47] Training until validation scores don't improve for 200 rounds\n[15:12:49] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:49] Training until validation scores don't improve for 200 rounds\n[15:12:53] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:53] Training until validation scores don't improve for 200 rounds\n[15:12:55] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:55] Training until validation scores don't improve for 200 rounds\n[15:12:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:12:57] Training until validation scores don't improve for 200 rounds\n[15:13:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15665.102401942422\u001b[0m\n[15:13:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:13:00] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.983814271289712, 'num_leaves': 252, 'bagging_fraction': 0.7363632266278268, 'min_sum_hessian_in_leaf': 2.6888372747929346, 'reg_alpha': 0.1201298254197091, 'reg_lambda': 0.14184312049385903} scored -15665.102401942422 in 0:00:12.983493\n[15:13:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:13:00] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:00] Training until validation scores don't improve for 200 rounds\n[15:13:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:01] Training until validation scores don't improve for 200 rounds\n[15:13:04] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:04] Training until validation scores don't improve for 200 rounds\n[15:13:06] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:06] Training until validation scores don't improve for 200 rounds\n[15:13:07] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:08] Training until validation scores don't improve for 200 rounds\n[15:13:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15374.605709546233\u001b[0m\n[15:13:09] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:13:09] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.5774066839224946, 'num_leaves': 211, 'bagging_fraction': 0.6334518760377763, 'min_sum_hessian_in_leaf': 0.4923790444339164, 'reg_alpha': 3.7513471718484984e-06, 'reg_lambda': 0.004670674208244537} scored -15374.605709546233 in 0:00:09.444611\n[15:13:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:13:09] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:09] Training until validation scores don't improve for 200 rounds\n[15:13:11] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:11] Training until validation scores don't improve for 200 rounds\n[15:13:14] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:14] Training until validation scores don't improve for 200 rounds\n[15:13:18] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:18] Training until validation scores don't improve for 200 rounds\n[15:13:20] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:20] Training until validation scores don't improve for 200 rounds\n[15:13:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15434.908467331978\u001b[0m\n[15:13:22] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:13:22] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.5777312798935237, 'num_leaves': 217, 'bagging_fraction': 0.6944442737222888, 'min_sum_hessian_in_leaf': 0.055191805483702804, 'reg_alpha': 1.9747568224995754e-06, 'reg_lambda': 0.008249391770260135} scored -15434.908467331978 in 0:00:12.540491\n[15:13:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:13:22] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:22] Training until validation scores don't improve for 200 rounds\n[15:13:24] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:24] Training until validation scores don't improve for 200 rounds\n[15:13:26] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:26] Training until validation scores don't improve for 200 rounds\n[15:13:29] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:29] Training until validation scores don't improve for 200 rounds\n[15:13:31] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:31] Training until validation scores don't improve for 200 rounds\n[15:13:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15678.29961740154\u001b[0m\n[15:13:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:13:33] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.5534205971854996, 'num_leaves': 109, 'bagging_fraction': 0.9501074183915024, 'min_sum_hessian_in_leaf': 0.8006360011078646, 'reg_alpha': 4.361156887662707e-05, 'reg_lambda': 0.0017770834811939998} scored -15678.29961740154 in 0:00:11.679071\n[15:13:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:13:33] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:33] Training until validation scores don't improve for 200 rounds\n[15:13:35] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:35] Training until validation scores don't improve for 200 rounds\n[15:13:37] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:37] Training until validation scores don't improve for 200 rounds\n[15:13:39] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:39] Training until validation scores don't improve for 200 rounds\n[15:13:41] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:41] Training until validation scores don't improve for 200 rounds\n[15:13:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15421.256461365581\u001b[0m\n[15:13:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:13:43] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.6298504796903425, 'num_leaves': 183, 'bagging_fraction': 0.633555688507686, 'min_sum_hessian_in_leaf': 0.39049275630850333, 'reg_alpha': 1.020706149716422e-06, 'reg_lambda': 3.490876138256685e-05} scored -15421.256461365581 in 0:00:09.292906\n[15:13:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:13:43] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:43] Training until validation scores don't improve for 200 rounds\n[15:13:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:45] Training until validation scores don't improve for 200 rounds\n[15:13:47] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:47] Training until validation scores don't improve for 200 rounds\n[15:13:51] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:51] Training until validation scores don't improve for 200 rounds\n[15:13:52] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:52] Training until validation scores don't improve for 200 rounds\n[15:13:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15380.438904644692\u001b[0m\n[15:13:54] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:13:54] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.5045725343208632, 'num_leaves': 219, 'bagging_fraction': 0.5652851143537311, 'min_sum_hessian_in_leaf': 3.4937800367374754, 'reg_alpha': 0.00025460352995051473, 'reg_lambda': 0.04835975613371037} scored -15380.438904644692 in 0:00:10.932434\n[15:13:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:13:54] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:54] Training until validation scores don't improve for 200 rounds\n[15:13:55] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:55] Training until validation scores don't improve for 200 rounds\n[15:13:57] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:57] Training until validation scores don't improve for 200 rounds\n[15:13:59] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:13:59] Training until validation scores don't improve for 200 rounds\n[15:14:00] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:00] Training until validation scores don't improve for 200 rounds\n[15:14:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15424.674918396831\u001b[0m\n[15:14:02] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:14:02] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.5034291048917302, 'num_leaves': 227, 'bagging_fraction': 0.5378741022556315, 'min_sum_hessian_in_leaf': 3.723473533858999, 'reg_alpha': 1.4215926051017967e-05, 'reg_lambda': 0.07536522672775768} scored -15424.674918396831 in 0:00:08.628191\n[15:14:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:14:02] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:02] Training until validation scores don't improve for 200 rounds\n[15:14:07] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:07] Training until validation scores don't improve for 200 rounds\n[15:14:10] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:10] Training until validation scores don't improve for 200 rounds\n[15:14:12] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:12] Training until validation scores don't improve for 200 rounds\n[15:14:13] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:13] Training until validation scores don't improve for 200 rounds\n[15:14:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15491.110478649402\u001b[0m\n[15:14:15] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:14:15] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5384785013779714, 'num_leaves': 160, 'bagging_fraction': 0.5642576797328802, 'min_sum_hessian_in_leaf': 2.2642445226778163, 'reg_alpha': 0.00018883985304173537, 'reg_lambda': 0.022135006937783804} scored -15491.110478649402 in 0:00:12.971099\n[15:14:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:14:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:15] Training until validation scores don't improve for 200 rounds\n[15:14:17] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:17] Training until validation scores don't improve for 200 rounds\n[15:14:19] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:19] Training until validation scores don't improve for 200 rounds\n[15:14:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:23] Training until validation scores don't improve for 200 rounds\n[15:14:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:25] Training until validation scores don't improve for 200 rounds\n[15:14:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15459.795604130994\u001b[0m\n[15:14:26] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:14:26] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.5678465366603198, 'num_leaves': 255, 'bagging_fraction': 0.6598215836190691, 'min_sum_hessian_in_leaf': 0.9710829900978315, 'reg_alpha': 0.0004530781170200388, 'reg_lambda': 0.4809758589194788} scored -15459.795604130994 in 0:00:11.201764\n[15:14:26] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[15:14:26] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}\u001b[0m\n achieve -15245.9128 mae\n[15:14:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:14:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:26] Training until validation scores don't improve for 100 rounds\n[15:14:27] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:27] Training until validation scores don't improve for 100 rounds\n[15:14:28] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:28] Training until validation scores don't improve for 100 rounds\n[15:14:28] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:28] Training until validation scores don't improve for 100 rounds\n[15:14:29] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:14:29] Training until validation scores don't improve for 100 rounds\n[15:14:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15500.594412189641\u001b[0m\n[15:14:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:14:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[15:14:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:14:29] 0:\tlearn: 53997.0990293\ttest: 55987.0264997\tbest: 55987.0264997 (0)\ttotal: 2.5ms\tremaining: 5.01s\n[15:14:31] Stopped by overfitting detector  (300 iterations wait)\n[15:14:31] bestTest = 14318.75668\n[15:14:31] bestIteration = 620\n[15:14:31] Shrink model to first 621 iterations.\n[15:14:31] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:14:31] 0:\tlearn: 53997.5172609\ttest: 54976.8121666\tbest: 54976.8121666 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:14:33] Stopped by overfitting detector  (300 iterations wait)\n[15:14:33] bestTest = 17137.41117\n[15:14:33] bestIteration = 735\n[15:14:33] Shrink model to first 736 iterations.\n[15:14:33] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:14:33] 0:\tlearn: 53816.6114909\ttest: 53652.3726891\tbest: 53652.3726891 (0)\ttotal: 2.16ms\tremaining: 4.33s\n[15:14:35] Stopped by overfitting detector  (300 iterations wait)\n[15:14:35] bestTest = 14494.10666\n[15:14:35] bestIteration = 660\n[15:14:35] Shrink model to first 661 iterations.\n[15:14:35] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:14:35] 0:\tlearn: 55133.8724995\ttest: 52219.5943666\tbest: 52219.5943666 (0)\ttotal: 2.1ms\tremaining: 4.21s\n[15:14:37] Stopped by overfitting detector  (300 iterations wait)\n[15:14:37] bestTest = 15184.39043\n[15:14:37] bestIteration = 618\n[15:14:37] Shrink model to first 619 iterations.\n[15:14:37] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:14:37] 0:\tlearn: 54317.9681078\ttest: 55188.0142363\tbest: 55188.0142363 (0)\ttotal: 2.12ms\tremaining: 4.24s\n[15:14:39] Stopped by overfitting detector  (300 iterations wait)\n[15:14:39] bestTest = 14443.38175\n[15:14:39] bestIteration = 671\n[15:14:39] Shrink model to first 672 iterations.\n[15:14:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15116.125892952698\u001b[0m\n[15:14:39] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[15:14:39] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[15:14:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:14:39] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:39] 0:\tlearn: 54069.4029363\ttest: 56068.7497178\tbest: 56068.7497178 (0)\ttotal: 1.58ms\tremaining: 3.15s\n[15:14:40] Stopped by overfitting detector  (300 iterations wait)\n[15:14:40] bestTest = 14622.07856\n[15:14:40] bestIteration = 394\n[15:14:40] Shrink model to first 395 iterations.\n[15:14:40] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:40] 0:\tlearn: 54106.7466239\ttest: 55035.1483672\tbest: 55035.1483672 (0)\ttotal: 1.61ms\tremaining: 3.23s\n[15:14:42] Stopped by overfitting detector  (300 iterations wait)\n[15:14:42] bestTest = 17111.90102\n[15:14:42] bestIteration = 918\n[15:14:42] Shrink model to first 919 iterations.\n[15:14:42] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:42] 0:\tlearn: 53906.0726550\ttest: 53723.1095459\tbest: 53723.1095459 (0)\ttotal: 1.69ms\tremaining: 3.38s\n[15:14:44] Stopped by overfitting detector  (300 iterations wait)\n[15:14:44] bestTest = 14151.75966\n[15:14:44] bestIteration = 1014\n[15:14:44] Shrink model to first 1015 iterations.\n[15:14:44] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:44] 0:\tlearn: 55243.4788415\ttest: 52311.6889790\tbest: 52311.6889790 (0)\ttotal: 2.01ms\tremaining: 4.01s\n[15:14:46] Stopped by overfitting detector  (300 iterations wait)\n[15:14:46] bestTest = 15110.04393\n[15:14:46] bestIteration = 794\n[15:14:46] Shrink model to first 795 iterations.\n[15:14:46] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:46] 0:\tlearn: 54396.5298482\ttest: 55239.7428195\tbest: 55239.7428195 (0)\ttotal: 1.83ms\tremaining: 3.66s\n[15:14:49] bestTest = 13999.40225\n[15:14:49] bestIteration = 1999\n[15:14:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14994.829583154966\u001b[0m\n[15:14:49] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:14:49] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -14994.829583154966 in 0:00:10.008575\n[15:14:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:14:49] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:49] 0:\tlearn: 54075.2395442\ttest: 56060.4247329\tbest: 56060.4247329 (0)\ttotal: 1.37ms\tremaining: 2.73s\n[15:14:51] Stopped by overfitting detector  (300 iterations wait)\n[15:14:51] bestTest = 14822.15154\n[15:14:51] bestIteration = 1666\n[15:14:51] Shrink model to first 1667 iterations.\n[15:14:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:51] 0:\tlearn: 54125.1501594\ttest: 55034.7484797\tbest: 55034.7484797 (0)\ttotal: 1.97ms\tremaining: 3.94s\n[15:14:53] Stopped by overfitting detector  (300 iterations wait)\n[15:14:53] bestTest = 16935.70841\n[15:14:53] bestIteration = 1204\n[15:14:53] Shrink model to first 1205 iterations.\n[15:14:53] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:53] 0:\tlearn: 53946.3326702\ttest: 53710.9081375\tbest: 53710.9081375 (0)\ttotal: 1.43ms\tremaining: 2.86s\n[15:14:55] bestTest = 13895.50696\n[15:14:55] bestIteration = 1825\n[15:14:55] Shrink model to first 1826 iterations.\n[15:14:55] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:56] 0:\tlearn: 55347.4736959\ttest: 52373.6626831\tbest: 52373.6626831 (0)\ttotal: 1.16ms\tremaining: 2.32s\n[15:14:57] Stopped by overfitting detector  (300 iterations wait)\n[15:14:57] bestTest = 15168.33191\n[15:14:57] bestIteration = 894\n[15:14:57] Shrink model to first 895 iterations.\n[15:14:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:57] 0:\tlearn: 54407.3536525\ttest: 55211.9399794\tbest: 55211.9399794 (0)\ttotal: 1.35ms\tremaining: 2.69s\n[15:14:59] bestTest = 14219.48015\n[15:14:59] bestIteration = 1984\n[15:14:59] Shrink model to first 1985 iterations.\n[15:14:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15008.774069590112\u001b[0m\n[15:14:59] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:14:59] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -15008.774069590112 in 0:00:10.148880\n[15:14:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:14:59] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:14:59] 0:\tlearn: 54075.1699721\ttest: 56060.3784350\tbest: 56060.3784350 (0)\ttotal: 1.21ms\tremaining: 2.42s\n[15:15:01] Stopped by overfitting detector  (300 iterations wait)\n[15:15:01] bestTest = 14625.1799\n[15:15:01] bestIteration = 1669\n[15:15:01] Shrink model to first 1670 iterations.\n[15:15:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:01] 0:\tlearn: 54125.0759405\ttest: 55034.6744893\tbest: 55034.6744893 (0)\ttotal: 1.25ms\tremaining: 2.5s\n[15:15:03] Stopped by overfitting detector  (300 iterations wait)\n[15:15:03] bestTest = 16887.13138\n[15:15:03] bestIteration = 1225\n[15:15:03] Shrink model to first 1226 iterations.\n[15:15:03] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:03] 0:\tlearn: 53946.2958847\ttest: 53710.8745285\tbest: 53710.8745285 (0)\ttotal: 1.19ms\tremaining: 2.39s\n[15:15:05] Stopped by overfitting detector  (300 iterations wait)\n[15:15:05] bestTest = 13923.80023\n[15:15:05] bestIteration = 1001\n[15:15:05] Shrink model to first 1002 iterations.\n[15:15:05] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:05] 0:\tlearn: 55347.3984772\ttest: 52373.5580773\tbest: 52373.5580773 (0)\ttotal: 1.24ms\tremaining: 2.48s\n[15:15:06] Stopped by overfitting detector  (300 iterations wait)\n[15:15:06] bestTest = 15492.68482\n[15:15:06] bestIteration = 781\n[15:15:06] Shrink model to first 782 iterations.\n[15:15:06] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:06] 0:\tlearn: 54407.2828482\ttest: 55211.8513920\tbest: 55211.8513920 (0)\ttotal: 1.22ms\tremaining: 2.43s\n[15:15:07] Stopped by overfitting detector  (300 iterations wait)\n[15:15:07] bestTest = 14205.68172\n[15:15:07] bestIteration = 921\n[15:15:07] Shrink model to first 922 iterations.\n[15:15:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15028.83568667059\u001b[0m\n[15:15:07] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:15:07] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -15028.83568667059 in 0:00:08.124649\n[15:15:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:15:07] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:07] 0:\tlearn: 54075.1720417\ttest: 56060.3798109\tbest: 56060.3798109 (0)\ttotal: 1.4ms\tremaining: 2.79s\n[15:15:09] Stopped by overfitting detector  (300 iterations wait)\n[15:15:09] bestTest = 14890.01276\n[15:15:09] bestIteration = 1133\n[15:15:09] Shrink model to first 1134 iterations.\n[15:15:09] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:09] 0:\tlearn: 54125.0781468\ttest: 55034.6766888\tbest: 55034.6766888 (0)\ttotal: 1.25ms\tremaining: 2.49s\n[15:15:11] Stopped by overfitting detector  (300 iterations wait)\n[15:15:11] bestTest = 16870.97219\n[15:15:11] bestIteration = 1448\n[15:15:11] Shrink model to first 1449 iterations.\n[15:15:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:11] 0:\tlearn: 53946.2969780\ttest: 53710.8755273\tbest: 53710.8755273 (0)\ttotal: 1.29ms\tremaining: 2.59s\n[15:15:13] bestTest = 13804.05957\n[15:15:13] bestIteration = 1756\n[15:15:13] Shrink model to first 1757 iterations.\n[15:15:13] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:13] 0:\tlearn: 55347.4007129\ttest: 52373.5611866\tbest: 52373.5611866 (0)\ttotal: 1.22ms\tremaining: 2.44s\n[15:15:14] Stopped by overfitting detector  (300 iterations wait)\n[15:15:14] bestTest = 15392.46361\n[15:15:14] bestIteration = 845\n[15:15:14] Shrink model to first 846 iterations.\n[15:15:14] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:14] 0:\tlearn: 54407.2849525\ttest: 55211.8540249\tbest: 55211.8540249 (0)\ttotal: 1.2ms\tremaining: 2.4s\n[15:15:17] bestTest = 14498.46807\n[15:15:17] bestIteration = 1990\n[15:15:17] Shrink model to first 1991 iterations.\n[15:15:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15091.444687098672\u001b[0m\n[15:15:17] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:15:17] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -15091.444687098672 in 0:00:09.396265\n[15:15:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:15:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:17] 0:\tlearn: 53885.0881650\ttest: 55955.9504936\tbest: 55955.9504936 (0)\ttotal: 3.61ms\tremaining: 7.21s\n[15:15:19] Stopped by overfitting detector  (300 iterations wait)\n[15:15:19] bestTest = 14584.01186\n[15:15:19] bestIteration = 726\n[15:15:19] Shrink model to first 727 iterations.\n[15:15:20] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:20] 0:\tlearn: 53928.5094317\ttest: 54934.9869249\tbest: 54934.9869249 (0)\ttotal: 3.54ms\tremaining: 7.07s\n[15:15:23] Stopped by overfitting detector  (300 iterations wait)\n[15:15:23] bestTest = 17733.92876\n[15:15:23] bestIteration = 833\n[15:15:23] Shrink model to first 834 iterations.\n[15:15:23] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:23] 0:\tlearn: 53751.5837555\ttest: 53651.4212001\tbest: 53651.4212001 (0)\ttotal: 2.95ms\tremaining: 5.9s\n[15:15:25] Stopped by overfitting detector  (300 iterations wait)\n[15:15:25] bestTest = 14635.55096\n[15:15:25] bestIteration = 627\n[15:15:25] Shrink model to first 628 iterations.\n[15:15:25] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:26] 0:\tlearn: 55053.7138161\ttest: 52107.9481631\tbest: 52107.9481631 (0)\ttotal: 3.54ms\tremaining: 7.09s\n[15:15:28] Stopped by overfitting detector  (300 iterations wait)\n[15:15:28] bestTest = 14600.4051\n[15:15:28] bestIteration = 367\n[15:15:28] Shrink model to first 368 iterations.\n[15:15:28] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:28] 0:\tlearn: 54191.0799296\ttest: 55208.6521463\tbest: 55208.6521463 (0)\ttotal: 2.93ms\tremaining: 5.86s\n[15:15:30] Stopped by overfitting detector  (300 iterations wait)\n[15:15:30] bestTest = 15380.10778\n[15:15:30] bestIteration = 479\n[15:15:30] Shrink model to first 480 iterations.\n[15:15:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15387.47990020334\u001b[0m\n[15:15:30] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:15:30] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -15387.47990020334 in 0:00:13.429602\n[15:15:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:15:30] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:30] 0:\tlearn: 53885.4551764\ttest: 55956.2086397\tbest: 55956.2086397 (0)\ttotal: 3.07ms\tremaining: 6.14s\n[15:15:32] Stopped by overfitting detector  (300 iterations wait)\n[15:15:32] bestTest = 14363.18505\n[15:15:32] bestIteration = 359\n[15:15:32] Shrink model to first 360 iterations.\n[15:15:32] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:32] 0:\tlearn: 53928.8221505\ttest: 54935.2506245\tbest: 54935.2506245 (0)\ttotal: 2.94ms\tremaining: 5.89s\n[15:15:35] Stopped by overfitting detector  (300 iterations wait)\n[15:15:35] bestTest = 17911.46444\n[15:15:35] bestIteration = 798\n[15:15:35] Shrink model to first 799 iterations.\n[15:15:35] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:35] 0:\tlearn: 53751.8483780\ttest: 53651.7596844\tbest: 53651.7596844 (0)\ttotal: 3.14ms\tremaining: 6.28s\n[15:15:37] Stopped by overfitting detector  (300 iterations wait)\n[15:15:37] bestTest = 14761.94532\n[15:15:37] bestIteration = 374\n[15:15:37] Shrink model to first 375 iterations.\n[15:15:37] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:37] 0:\tlearn: 55054.1455774\ttest: 52108.4037417\tbest: 52108.4037417 (0)\ttotal: 2.75ms\tremaining: 5.5s\n[15:15:41] Stopped by overfitting detector  (300 iterations wait)\n[15:15:41] bestTest = 14475.72953\n[15:15:41] bestIteration = 990\n[15:15:41] Shrink model to first 991 iterations.\n[15:15:41] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:41] 0:\tlearn: 54191.4227403\ttest: 55208.9659253\tbest: 55208.9659253 (0)\ttotal: 2.85ms\tremaining: 5.71s\n[15:15:43] Stopped by overfitting detector  (300 iterations wait)\n[15:15:43] bestTest = 15388.07062\n[15:15:43] bestIteration = 457\n[15:15:43] Shrink model to first 458 iterations.\n[15:15:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15380.84653922303\u001b[0m\n[15:15:43] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:15:43] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -15380.84653922303 in 0:00:12.654652\n[15:15:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:15:43] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:43] 0:\tlearn: 54219.2349281\ttest: 56236.7535191\tbest: 56236.7535191 (0)\ttotal: 2.96ms\tremaining: 5.92s\n[15:15:45] Stopped by overfitting detector  (300 iterations wait)\n[15:15:45] bestTest = 14307.51037\n[15:15:45] bestIteration = 601\n[15:15:45] Shrink model to first 602 iterations.\n[15:15:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:45] 0:\tlearn: 54226.9006802\ttest: 55173.8459559\tbest: 55173.8459559 (0)\ttotal: 2.98ms\tremaining: 5.96s\n[15:15:48] Stopped by overfitting detector  (300 iterations wait)\n[15:15:48] bestTest = 17267.86386\n[15:15:48] bestIteration = 694\n[15:15:48] Shrink model to first 695 iterations.\n[15:15:48] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:48] 0:\tlearn: 53984.8280418\ttest: 54009.6327131\tbest: 54009.6327131 (0)\ttotal: 3.22ms\tremaining: 6.44s\n[15:15:50] Stopped by overfitting detector  (300 iterations wait)\n[15:15:50] bestTest = 14908.1055\n[15:15:50] bestIteration = 532\n[15:15:50] Shrink model to first 533 iterations.\n[15:15:50] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:50] 0:\tlearn: 55034.1913611\ttest: 52197.7676594\tbest: 52197.7676594 (0)\ttotal: 2.92ms\tremaining: 5.84s\n[15:15:53] Stopped by overfitting detector  (300 iterations wait)\n[15:15:53] bestTest = 13898.98358\n[15:15:53] bestIteration = 604\n[15:15:53] Shrink model to first 605 iterations.\n[15:15:53] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:53] 0:\tlearn: 54468.4482630\ttest: 55284.7710886\tbest: 55284.7710886 (0)\ttotal: 3.46ms\tremaining: 6.92s\n[15:15:55] Stopped by overfitting detector  (300 iterations wait)\n[15:15:55] bestTest = 15142.35929\n[15:15:55] bestIteration = 607\n[15:15:55] Shrink model to first 608 iterations.\n[15:15:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15109.82735244542\u001b[0m\n[15:15:55] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:15:55] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -15109.82735244542 in 0:00:12.518585\n[15:15:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:15:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:55] 0:\tlearn: 53879.8452884\ttest: 56022.3595437\tbest: 56022.3595437 (0)\ttotal: 5.06ms\tremaining: 10.1s\n[15:15:58] Stopped by overfitting detector  (300 iterations wait)\n[15:15:58] bestTest = 14952.68894\n[15:15:58] bestIteration = 228\n[15:15:58] Shrink model to first 229 iterations.\n[15:15:58] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:15:58] 0:\tlearn: 53906.1296498\ttest: 54907.2753368\tbest: 54907.2753368 (0)\ttotal: 5.64ms\tremaining: 11.3s\n[15:16:03] Stopped by overfitting detector  (300 iterations wait)\n[15:16:03] bestTest = 18242.92199\n[15:16:03] bestIteration = 950\n[15:16:03] Shrink model to first 951 iterations.\n[15:16:03] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:03] 0:\tlearn: 53635.4898274\ttest: 53590.1538081\tbest: 53590.1538081 (0)\ttotal: 4.34ms\tremaining: 8.68s\n[15:16:07] Stopped by overfitting detector  (300 iterations wait)\n[15:16:07] bestTest = 14831.60447\n[15:16:07] bestIteration = 726\n[15:16:07] Shrink model to first 727 iterations.\n[15:16:07] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:07] 0:\tlearn: 54983.5688631\ttest: 52025.2280652\tbest: 52025.2280652 (0)\ttotal: 4.31ms\tremaining: 8.61s\n[15:16:15] bestTest = 14248.24988\n[15:16:15] bestIteration = 1919\n[15:16:15] Shrink model to first 1920 iterations.\n[15:16:15] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:15] 0:\tlearn: 54176.6938921\ttest: 55116.8501129\tbest: 55116.8501129 (0)\ttotal: 3.97ms\tremaining: 7.93s\n[15:16:17] Stopped by overfitting detector  (300 iterations wait)\n[15:16:17] bestTest = 15680.60245\n[15:16:17] bestIteration = 337\n[15:16:17] Shrink model to first 338 iterations.\n[15:16:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15591.079278815283\u001b[0m\n[15:16:17] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:16:17] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -15591.079278815283 in 0:00:22.263431\n[15:16:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:16:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:18] 0:\tlearn: 54105.7075401\ttest: 56087.0188827\tbest: 56087.0188827 (0)\ttotal: 1.27ms\tremaining: 2.54s\n[15:16:19] Stopped by overfitting detector  (300 iterations wait)\n[15:16:19] bestTest = 14896.442\n[15:16:19] bestIteration = 886\n[15:16:19] Shrink model to first 887 iterations.\n[15:16:19] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:19] 0:\tlearn: 54162.6500144\ttest: 55072.1076459\tbest: 55072.1076459 (0)\ttotal: 1.29ms\tremaining: 2.58s\n[15:16:21] bestTest = 16576.55853\n[15:16:21] bestIteration = 1997\n[15:16:21] Shrink model to first 1998 iterations.\n[15:16:21] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:21] 0:\tlearn: 53966.9443131\ttest: 53730.6025695\tbest: 53730.6025695 (0)\ttotal: 2.45ms\tremaining: 4.91s\n[15:16:23] Stopped by overfitting detector  (300 iterations wait)\n[15:16:23] bestTest = 13881.97486\n[15:16:23] bestIteration = 1638\n[15:16:23] Shrink model to first 1639 iterations.\n[15:16:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:23] 0:\tlearn: 55387.5270423\ttest: 52428.1178687\tbest: 52428.1178687 (0)\ttotal: 1.16ms\tremaining: 2.31s\n[15:16:25] Stopped by overfitting detector  (300 iterations wait)\n[15:16:25] bestTest = 15414.13693\n[15:16:25] bestIteration = 926\n[15:16:25] Shrink model to first 927 iterations.\n[15:16:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:25] 0:\tlearn: 54446.9424562\ttest: 55260.6451331\tbest: 55260.6451331 (0)\ttotal: 1.16ms\tremaining: 2.32s\n[15:16:26] Stopped by overfitting detector  (300 iterations wait)\n[15:16:26] bestTest = 14853.26165\n[15:16:26] bestIteration = 1127\n[15:16:26] Shrink model to first 1128 iterations.\n[15:16:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15125.330037992295\u001b[0m\n[15:16:26] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:16:26] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -15125.330037992295 in 0:00:08.761300\n[15:16:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:16:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:27] 0:\tlearn: 53885.2284815\ttest: 55956.0491637\tbest: 55956.0491637 (0)\ttotal: 2.83ms\tremaining: 5.67s\n[15:16:31] Stopped by overfitting detector  (300 iterations wait)\n[15:16:31] bestTest = 14270.22724\n[15:16:31] bestIteration = 1133\n[15:16:31] Shrink model to first 1134 iterations.\n[15:16:31] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:31] 0:\tlearn: 53928.6289949\ttest: 54935.0877522\tbest: 54935.0877522 (0)\ttotal: 3.45ms\tremaining: 6.89s\n[15:16:33] Stopped by overfitting detector  (300 iterations wait)\n[15:16:33] bestTest = 17966.03622\n[15:16:33] bestIteration = 464\n[15:16:33] Shrink model to first 465 iterations.\n[15:16:33] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:33] 0:\tlearn: 53751.6849248\ttest: 53651.5506154\tbest: 53651.5506154 (0)\ttotal: 2.8ms\tremaining: 5.59s\n[15:16:35] Stopped by overfitting detector  (300 iterations wait)\n[15:16:35] bestTest = 14866.07562\n[15:16:35] bestIteration = 492\n[15:16:35] Shrink model to first 493 iterations.\n[15:16:35] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:35] 0:\tlearn: 55053.8789341\ttest: 52108.1224226\tbest: 52108.1224226 (0)\ttotal: 3.02ms\tremaining: 6.04s\n[15:16:37] Stopped by overfitting detector  (300 iterations wait)\n[15:16:37] bestTest = 14594.93569\n[15:16:37] bestIteration = 354\n[15:16:37] Shrink model to first 355 iterations.\n[15:16:37] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:37] 0:\tlearn: 54191.2109927\ttest: 55208.7721111\tbest: 55208.7721111 (0)\ttotal: 2.79ms\tremaining: 5.58s\n[15:16:43] bestTest = 15330.17208\n[15:16:43] bestIteration = 1707\n[15:16:43] Shrink model to first 1708 iterations.\n[15:16:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15406.247866277825\u001b[0m\n[15:16:43] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:16:43] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -15406.247866277825 in 0:00:16.505602\n[15:16:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:16:43] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:43] 0:\tlearn: 54069.3006328\ttest: 56068.6747552\tbest: 56068.6747552 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[15:16:44] Stopped by overfitting detector  (300 iterations wait)\n[15:16:44] bestTest = 14621.8246\n[15:16:44] bestIteration = 394\n[15:16:44] Shrink model to first 395 iterations.\n[15:16:44] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:44] 0:\tlearn: 54106.6089848\ttest: 55035.0546514\tbest: 55035.0546514 (0)\ttotal: 1.64ms\tremaining: 3.27s\n[15:16:46] Stopped by overfitting detector  (300 iterations wait)\n[15:16:46] bestTest = 17336.52734\n[15:16:46] bestIteration = 953\n[15:16:46] Shrink model to first 954 iterations.\n[15:16:46] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:46] 0:\tlearn: 53905.9880831\ttest: 53723.0473890\tbest: 53723.0473890 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[15:16:48] Stopped by overfitting detector  (300 iterations wait)\n[15:16:48] bestTest = 14044.21916\n[15:16:48] bestIteration = 969\n[15:16:48] Shrink model to first 970 iterations.\n[15:16:48] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:48] 0:\tlearn: 55243.3212350\ttest: 52311.4982647\tbest: 52311.4982647 (0)\ttotal: 1.83ms\tremaining: 3.65s\n[15:16:49] Stopped by overfitting detector  (300 iterations wait)\n[15:16:49] bestTest = 15158.59955\n[15:16:49] bestIteration = 583\n[15:16:49] Shrink model to first 584 iterations.\n[15:16:49] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:49] 0:\tlearn: 54396.4601281\ttest: 55239.6620077\tbest: 55239.6620077 (0)\ttotal: 1.6ms\tremaining: 3.2s\n[15:16:51] Stopped by overfitting detector  (300 iterations wait)\n[15:16:51] bestTest = 14305.69021\n[15:16:51] bestIteration = 964\n[15:16:51] Shrink model to first 965 iterations.\n[15:16:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15086.078910932149\u001b[0m\n[15:16:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:16:51] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 14} scored -15086.078910932149 in 0:00:08.278652\n[15:16:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:16:51] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:51] 0:\tlearn: 54071.3305725\ttest: 56070.1792173\tbest: 56070.1792173 (0)\ttotal: 3.99ms\tremaining: 7.98s\n[15:16:53] Stopped by overfitting detector  (300 iterations wait)\n[15:16:53] bestTest = 14246.42248\n[15:16:53] bestIteration = 719\n[15:16:53] Shrink model to first 720 iterations.\n[15:16:53] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:53] 0:\tlearn: 54109.3283064\ttest: 55036.9291048\tbest: 55036.9291048 (0)\ttotal: 1.62ms\tremaining: 3.24s\n[15:16:55] Stopped by overfitting detector  (300 iterations wait)\n[15:16:55] bestTest = 17037.49739\n[15:16:55] bestIteration = 1193\n[15:16:55] Shrink model to first 1194 iterations.\n[15:16:55] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:55] 0:\tlearn: 53907.6683442\ttest: 53724.2956502\tbest: 53724.2956502 (0)\ttotal: 2.02ms\tremaining: 4.04s\n[15:16:56] Stopped by overfitting detector  (300 iterations wait)\n[15:16:56] bestTest = 14554.35673\n[15:16:56] bestIteration = 562\n[15:16:56] Shrink model to first 563 iterations.\n[15:16:56] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:56] 0:\tlearn: 55236.3063598\ttest: 52303.0690644\tbest: 52303.0690644 (0)\ttotal: 1.52ms\tremaining: 3.05s\n[15:16:57] Stopped by overfitting detector  (300 iterations wait)\n[15:16:57] bestTest = 15563.37438\n[15:16:57] bestIteration = 366\n[15:16:57] Shrink model to first 367 iterations.\n[15:16:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:57] 0:\tlearn: 54366.8111463\ttest: 55263.8483211\tbest: 55263.8483211 (0)\ttotal: 1.64ms\tremaining: 3.27s\n[15:16:58] Stopped by overfitting detector  (300 iterations wait)\n[15:16:58] bestTest = 14472.89101\n[15:16:58] bestIteration = 448\n[15:16:58] Shrink model to first 449 iterations.\n[15:16:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15175.176874866223\u001b[0m\n[15:16:58] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:16:58] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04911057229628098, 'min_data_in_leaf': 16} scored -15175.176874866223 in 0:00:07.425722\n[15:16:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:16:59] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:16:59] 0:\tlearn: 54073.7321809\ttest: 56072.0033254\tbest: 56072.0033254 (0)\ttotal: 1.59ms\tremaining: 3.18s\n[15:17:00] Stopped by overfitting detector  (300 iterations wait)\n[15:17:00] bestTest = 14410.28943\n[15:17:00] bestIteration = 480\n[15:17:00] Shrink model to first 481 iterations.\n[15:17:00] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:00] 0:\tlearn: 54112.5141893\ttest: 55039.1841845\tbest: 55039.1841845 (0)\ttotal: 1.62ms\tremaining: 3.23s\n[15:17:02] Stopped by overfitting detector  (300 iterations wait)\n[15:17:02] bestTest = 17204.40852\n[15:17:02] bestIteration = 934\n[15:17:02] Shrink model to first 935 iterations.\n[15:17:02] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:02] 0:\tlearn: 53909.6616459\ttest: 53725.8113890\tbest: 53725.8113890 (0)\ttotal: 1.61ms\tremaining: 3.22s\n[15:17:05] Stopped by overfitting detector  (300 iterations wait)\n[15:17:05] bestTest = 14265.22717\n[15:17:05] bestIteration = 1572\n[15:17:05] Shrink model to first 1573 iterations.\n[15:17:05] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:05] 0:\tlearn: 55250.2198269\ttest: 52319.7972976\tbest: 52319.7972976 (0)\ttotal: 1.54ms\tremaining: 3.07s\n[15:17:06] Stopped by overfitting detector  (300 iterations wait)\n[15:17:06] bestTest = 15306.7757\n[15:17:06] bestIteration = 578\n[15:17:06] Shrink model to first 579 iterations.\n[15:17:06] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:06] 0:\tlearn: 54399.5446749\ttest: 55243.2433439\tbest: 55243.2433439 (0)\ttotal: 1.57ms\tremaining: 3.13s\n[15:17:07] Stopped by overfitting detector  (300 iterations wait)\n[15:17:07] bestTest = 14051.80753\n[15:17:07] bestIteration = 434\n[15:17:07] Shrink model to first 435 iterations.\n[15:17:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15048.515849074272\u001b[0m\n[15:17:07] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:17:07] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10888374230503725, 'min_data_in_leaf': 14} scored -15048.515849074272 in 0:00:08.983954\n[15:17:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:17:08] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:08] 0:\tlearn: 54069.3008954\ttest: 56068.6749475\tbest: 56068.6749475 (0)\ttotal: 1.57ms\tremaining: 3.14s\n[15:17:09] Stopped by overfitting detector  (300 iterations wait)\n[15:17:09] bestTest = 14243.85876\n[15:17:09] bestIteration = 672\n[15:17:09] Shrink model to first 673 iterations.\n[15:17:09] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:09] 0:\tlearn: 54106.6093382\ttest: 55035.0548920\tbest: 55035.0548920 (0)\ttotal: 1.57ms\tremaining: 3.13s\n[15:17:11] Stopped by overfitting detector  (300 iterations wait)\n[15:17:11] bestTest = 16973.94772\n[15:17:11] bestIteration = 1177\n[15:17:11] Shrink model to first 1178 iterations.\n[15:17:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:12] 0:\tlearn: 53905.9883002\ttest: 53723.0475485\tbest: 53723.0475485 (0)\ttotal: 2.21ms\tremaining: 4.43s\n[15:17:13] Stopped by overfitting detector  (300 iterations wait)\n[15:17:13] bestTest = 14168.65314\n[15:17:13] bestIteration = 771\n[15:17:13] Shrink model to first 772 iterations.\n[15:17:13] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:13] 0:\tlearn: 55232.9070853\ttest: 52297.8042952\tbest: 52297.8042952 (0)\ttotal: 1.66ms\tremaining: 3.32s\n[15:17:14] Stopped by overfitting detector  (300 iterations wait)\n[15:17:14] bestTest = 15471.27062\n[15:17:14] bestIteration = 523\n[15:17:14] Shrink model to first 524 iterations.\n[15:17:14] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:15] 0:\tlearn: 54364.9014579\ttest: 55261.7161685\tbest: 55261.7161685 (0)\ttotal: 1.64ms\tremaining: 3.28s\n[15:17:17] Stopped by overfitting detector  (300 iterations wait)\n[15:17:17] bestTest = 14310.79174\n[15:17:17] bestIteration = 1138\n[15:17:17] Shrink model to first 1139 iterations.\n[15:17:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15033.948897688357\u001b[0m\n[15:17:17] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:17:17] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 6.2796364199058425e-06, 'min_data_in_leaf': 19} scored -15033.948897688357 in 0:00:09.115050\n[15:17:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:17:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:17] 0:\tlearn: 53996.6841499\ttest: 55986.6871380\tbest: 55986.6871380 (0)\ttotal: 2.14ms\tremaining: 4.27s\n[15:17:19] Stopped by overfitting detector  (300 iterations wait)\n[15:17:19] bestTest = 14384.44248\n[15:17:19] bestIteration = 844\n[15:17:19] Shrink model to first 845 iterations.\n[15:17:19] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:19] 0:\tlearn: 53997.0718796\ttest: 54976.5176801\tbest: 54976.5176801 (0)\ttotal: 2.71ms\tremaining: 5.42s\n[15:17:22] Stopped by overfitting detector  (300 iterations wait)\n[15:17:22] bestTest = 17066.16829\n[15:17:22] bestIteration = 1029\n[15:17:22] Shrink model to first 1030 iterations.\n[15:17:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:22] 0:\tlearn: 53816.2832925\ttest: 53652.0869011\tbest: 53652.0869011 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:17:24] Stopped by overfitting detector  (300 iterations wait)\n[15:17:24] bestTest = 14427.97524\n[15:17:24] bestIteration = 1043\n[15:17:24] Shrink model to first 1044 iterations.\n[15:17:24] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:24] 0:\tlearn: 55138.0805133\ttest: 52250.1001461\tbest: 52250.1001461 (0)\ttotal: 2.03ms\tremaining: 4.05s\n[15:17:26] Stopped by overfitting detector  (300 iterations wait)\n[15:17:26] bestTest = 14877.31173\n[15:17:26] bestIteration = 545\n[15:17:26] Shrink model to first 546 iterations.\n[15:17:26] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:26] 0:\tlearn: 54342.0736577\ttest: 55136.1957268\tbest: 55136.1957268 (0)\ttotal: 2.91ms\tremaining: 5.81s\n[15:17:27] Stopped by overfitting detector  (300 iterations wait)\n[15:17:27] bestTest = 13910.445\n[15:17:27] bestIteration = 287\n[15:17:27] Shrink model to first 288 iterations.\n[15:17:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14940.363856485445\u001b[0m\n[15:17:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:17:27] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.004995415461748956, 'min_data_in_leaf': 13} scored -14940.363856485445 in 0:00:10.789776\n[15:17:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:17:27] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:28] 0:\tlearn: 54026.0885577\ttest: 56011.8263501\tbest: 56011.8263501 (0)\ttotal: 2.15ms\tremaining: 4.29s\n[15:17:30] Stopped by overfitting detector  (300 iterations wait)\n[15:17:30] bestTest = 14431.2687\n[15:17:30] bestIteration = 949\n[15:17:30] Shrink model to first 950 iterations.\n[15:17:30] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:30] 0:\tlearn: 54028.1920613\ttest: 54998.3571492\tbest: 54998.3571492 (0)\ttotal: 2.1ms\tremaining: 4.2s\n[15:17:34] Stopped by overfitting detector  (300 iterations wait)\n[15:17:34] bestTest = 17027.88462\n[15:17:34] bestIteration = 1570\n[15:17:34] Shrink model to first 1571 iterations.\n[15:17:34] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:34] 0:\tlearn: 53839.5842095\ttest: 53673.6295652\tbest: 53673.6295652 (0)\ttotal: 2.07ms\tremaining: 4.14s\n[15:17:37] Stopped by overfitting detector  (300 iterations wait)\n[15:17:37] bestTest = 14462.66395\n[15:17:37] bestIteration = 1332\n[15:17:37] Shrink model to first 1333 iterations.\n[15:17:37] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:38] 0:\tlearn: 55184.2661080\ttest: 52289.8755622\tbest: 52289.8755622 (0)\ttotal: 2.2ms\tremaining: 4.39s\n[15:17:39] Stopped by overfitting detector  (300 iterations wait)\n[15:17:39] bestTest = 15316.8564\n[15:17:39] bestIteration = 528\n[15:17:39] Shrink model to first 529 iterations.\n[15:17:39] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:39] 0:\tlearn: 54364.8584590\ttest: 55163.6010198\tbest: 55163.6010198 (0)\ttotal: 2.2ms\tremaining: 4.39s\n[15:17:42] Stopped by overfitting detector  (300 iterations wait)\n[15:17:42] bestTest = 13209.12963\n[15:17:42] bestIteration = 843\n[15:17:42] Shrink model to first 844 iterations.\n[15:17:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14885.713562847817\u001b[0m\n[15:17:42] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:17:42] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.39488606566082224, 'min_data_in_leaf': 12} scored -14885.713562847817 in 0:00:14.178778\n[15:17:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:17:42] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:42] 0:\tlearn: 54032.0878299\ttest: 56017.1676219\tbest: 56017.1676219 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[15:17:43] Stopped by overfitting detector  (300 iterations wait)\n[15:17:43] bestTest = 14567.88869\n[15:17:43] bestIteration = 459\n[15:17:43] Shrink model to first 460 iterations.\n[15:17:43] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:43] 0:\tlearn: 54034.4544308\ttest: 55002.9989262\tbest: 55002.9989262 (0)\ttotal: 2.25ms\tremaining: 4.49s\n[15:17:45] Stopped by overfitting detector  (300 iterations wait)\n[15:17:45] bestTest = 17122.33535\n[15:17:45] bestIteration = 418\n[15:17:45] Shrink model to first 419 iterations.\n[15:17:45] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:45] 0:\tlearn: 53844.3551792\ttest: 53678.2948690\tbest: 53678.2948690 (0)\ttotal: 2.1ms\tremaining: 4.2s\n[15:17:48] Stopped by overfitting detector  (300 iterations wait)\n[15:17:48] bestTest = 14592.83197\n[15:17:48] bestIteration = 1545\n[15:17:48] Shrink model to first 1546 iterations.\n[15:17:48] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:48] 0:\tlearn: 55193.3462429\ttest: 52297.4878388\tbest: 52297.4878388 (0)\ttotal: 2.37ms\tremaining: 4.73s\n[15:17:50] Stopped by overfitting detector  (300 iterations wait)\n[15:17:50] bestTest = 14934.97823\n[15:17:50] bestIteration = 703\n[15:17:50] Shrink model to first 704 iterations.\n[15:17:50] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:51] 0:\tlearn: 54369.7118256\ttest: 55169.4376117\tbest: 55169.4376117 (0)\ttotal: 2.14ms\tremaining: 4.27s\n[15:17:53] Stopped by overfitting detector  (300 iterations wait)\n[15:17:53] bestTest = 13696.08881\n[15:17:53] bestIteration = 1109\n[15:17:53] Shrink model to first 1110 iterations.\n[15:17:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14990.84704422624\u001b[0m\n[15:17:53] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:17:53] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.48264660064505915, 'min_data_in_leaf': 12} scored -14990.84704422624 in 0:00:11.709480\n[15:17:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:17:53] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:53] 0:\tlearn: 54319.2512210\ttest: 56299.9035577\tbest: 56299.9035577 (0)\ttotal: 2.08ms\tremaining: 4.16s\n[15:17:55] Stopped by overfitting detector  (300 iterations wait)\n[15:17:55] bestTest = 14424.32642\n[15:17:55] bestIteration = 723\n[15:17:55] Shrink model to first 724 iterations.\n[15:17:55] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:56] 0:\tlearn: 54552.0089380\ttest: 55397.6696888\tbest: 55397.6696888 (0)\ttotal: 2.06ms\tremaining: 4.12s\n[15:17:58] Stopped by overfitting detector  (300 iterations wait)\n[15:17:58] bestTest = 16825.08548\n[15:17:58] bestIteration = 1090\n[15:17:58] Shrink model to first 1091 iterations.\n[15:17:58] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:17:58] 0:\tlearn: 54141.7610080\ttest: 54036.7761337\tbest: 54036.7761337 (0)\ttotal: 2.08ms\tremaining: 4.15s\n[15:18:01] Stopped by overfitting detector  (300 iterations wait)\n[15:18:01] bestTest = 14337.48971\n[15:18:01] bestIteration = 1107\n[15:18:01] Shrink model to first 1108 iterations.\n[15:18:01] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:01] 0:\tlearn: 55165.9142778\ttest: 52243.6724415\tbest: 52243.6724415 (0)\ttotal: 2.21ms\tremaining: 4.42s\n[15:18:04] Stopped by overfitting detector  (300 iterations wait)\n[15:18:04] bestTest = 14589.83379\n[15:18:04] bestIteration = 1121\n[15:18:04] Shrink model to first 1122 iterations.\n[15:18:04] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:04] 0:\tlearn: 54803.3473748\ttest: 55601.4216998\tbest: 55601.4216998 (0)\ttotal: 2.08ms\tremaining: 4.15s\n[15:18:07] Stopped by overfitting detector  (300 iterations wait)\n[15:18:07] bestTest = 14240.54044\n[15:18:07] bestIteration = 1061\n[15:18:07] Shrink model to first 1062 iterations.\n[15:18:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14884.050172570634\u001b[0m\n[15:18:07] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:18:07] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 9.86874546485378, 'min_data_in_leaf': 12} scored -14884.050172570634 in 0:00:13.472511\n[15:18:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:18:07] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:07] 0:\tlearn: 54311.8893758\ttest: 56292.5101724\tbest: 56292.5101724 (0)\ttotal: 2.65ms\tremaining: 5.29s\n[15:18:10] Stopped by overfitting detector  (300 iterations wait)\n[15:18:10] bestTest = 14748.42973\n[15:18:10] bestIteration = 888\n[15:18:10] Shrink model to first 889 iterations.\n[15:18:10] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:10] 0:\tlearn: 54542.8679131\ttest: 55390.4702278\tbest: 55390.4702278 (0)\ttotal: 2.12ms\tremaining: 4.24s\n[15:18:12] Stopped by overfitting detector  (300 iterations wait)\n[15:18:12] bestTest = 16861.3705\n[15:18:12] bestIteration = 1022\n[15:18:12] Shrink model to first 1023 iterations.\n[15:18:12] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:12] 0:\tlearn: 54133.5431407\ttest: 54027.8030732\tbest: 54027.8030732 (0)\ttotal: 2.1ms\tremaining: 4.21s\n[15:18:16] bestTest = 14408.50443\n[15:18:16] bestIteration = 1999\n[15:18:16] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:16] 0:\tlearn: 55240.4238454\ttest: 52377.0030005\tbest: 52377.0030005 (0)\ttotal: 2.65ms\tremaining: 5.31s\n[15:18:18] Stopped by overfitting detector  (300 iterations wait)\n[15:18:18] bestTest = 14626.28553\n[15:18:18] bestIteration = 676\n[15:18:18] Shrink model to first 677 iterations.\n[15:18:18] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:18] 0:\tlearn: 54795.2895039\ttest: 55594.2312468\tbest: 55594.2312468 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:18:21] Stopped by overfitting detector  (300 iterations wait)\n[15:18:21] bestTest = 14246.83888\n[15:18:21] bestIteration = 959\n[15:18:21] Shrink model to first 960 iterations.\n[15:18:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14982.75552828018\u001b[0m\n[15:18:21] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:18:21] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 9.502594710075206, 'min_data_in_leaf': 8} scored -14982.75552828018 in 0:00:13.809027\n[15:18:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:18:21] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:21] 0:\tlearn: 53952.1709812\ttest: 56076.1485573\tbest: 56076.1485573 (0)\ttotal: 4.09ms\tremaining: 8.17s\n[15:18:29] bestTest = 14956.81\n[15:18:29] bestIteration = 1884\n[15:18:29] Shrink model to first 1885 iterations.\n[15:18:29] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:29] 0:\tlearn: 53970.6045983\ttest: 54957.8728056\tbest: 54957.8728056 (0)\ttotal: 4.15ms\tremaining: 8.29s\n[15:18:33] Stopped by overfitting detector  (300 iterations wait)\n[15:18:33] bestTest = 18082.35504\n[15:18:33] bestIteration = 832\n[15:18:33] Shrink model to first 833 iterations.\n[15:18:33] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:33] 0:\tlearn: 53683.7839156\ttest: 53659.4587994\tbest: 53659.4587994 (0)\ttotal: 4.84ms\tremaining: 9.67s\n[15:18:36] Stopped by overfitting detector  (300 iterations wait)\n[15:18:36] bestTest = 15121.78795\n[15:18:36] bestIteration = 516\n[15:18:36] Shrink model to first 517 iterations.\n[15:18:36] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:36] 0:\tlearn: 55049.2988523\ttest: 52144.8853587\tbest: 52144.8853587 (0)\ttotal: 4.05ms\tremaining: 8.09s\n[15:18:39] Stopped by overfitting detector  (300 iterations wait)\n[15:18:39] bestTest = 14246.725\n[15:18:39] bestIteration = 259\n[15:18:39] Shrink model to first 260 iterations.\n[15:18:39] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:39] 0:\tlearn: 54251.1009875\ttest: 55219.5139474\tbest: 55219.5139474 (0)\ttotal: 4.4ms\tremaining: 8.79s\n[15:18:42] Stopped by overfitting detector  (300 iterations wait)\n[15:18:42] bestTest = 15661.21396\n[15:18:42] bestIteration = 304\n[15:18:42] Shrink model to first 305 iterations.\n[15:18:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15614.90828339041\u001b[0m\n[15:18:42] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:18:42] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.3232715850545053, 'min_data_in_leaf': 17} scored -15614.90828339041 in 0:00:21.022916\n[15:18:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:18:42] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:42] 0:\tlearn: 54069.6987716\ttest: 56051.5643104\tbest: 56051.5643104 (0)\ttotal: 2.21ms\tremaining: 4.41s\n[15:18:44] Stopped by overfitting detector  (300 iterations wait)\n[15:18:44] bestTest = 14293.79374\n[15:18:44] bestIteration = 1104\n[15:18:44] Shrink model to first 1105 iterations.\n[15:18:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:45] 0:\tlearn: 54073.2486561\ttest: 55032.8625880\tbest: 55032.8625880 (0)\ttotal: 2.33ms\tremaining: 4.67s\n[15:18:47] Stopped by overfitting detector  (300 iterations wait)\n[15:18:47] bestTest = 17190.07289\n[15:18:47] bestIteration = 902\n[15:18:47] Shrink model to first 903 iterations.\n[15:18:47] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:47] 0:\tlearn: 53874.4017578\ttest: 53708.9492223\tbest: 53708.9492223 (0)\ttotal: 2.06ms\tremaining: 4.13s\n[15:18:50] Stopped by overfitting detector  (300 iterations wait)\n[15:18:50] bestTest = 14692.39094\n[15:18:50] bestIteration = 1149\n[15:18:50] Shrink model to first 1150 iterations.\n[15:18:50] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:50] 0:\tlearn: 55247.5430081\ttest: 52342.0853043\tbest: 52342.0853043 (0)\ttotal: 2.2ms\tremaining: 4.41s\n[15:18:52] Stopped by overfitting detector  (300 iterations wait)\n[15:18:52] bestTest = 14973.20671\n[15:18:52] bestIteration = 527\n[15:18:52] Shrink model to first 528 iterations.\n[15:18:52] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:52] 0:\tlearn: 54401.0874127\ttest: 55206.8403854\tbest: 55206.8403854 (0)\ttotal: 2.05ms\tremaining: 4.1s\n[15:18:53] Stopped by overfitting detector  (300 iterations wait)\n[15:18:53] bestTest = 14103.19478\n[15:18:53] bestIteration = 415\n[15:18:53] Shrink model to first 416 iterations.\n[15:18:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15053.11657547624\u001b[0m\n[15:18:53] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:18:53] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.088125466787591, 'min_data_in_leaf': 12} scored -15053.11657547624 in 0:00:11.478369\n[15:18:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:18:53] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:53] 0:\tlearn: 53997.2158843\ttest: 55987.1221803\tbest: 55987.1221803 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:18:56] Stopped by overfitting detector  (300 iterations wait)\n[15:18:56] bestTest = 14390.29491\n[15:18:56] bestIteration = 1224\n[15:18:56] Shrink model to first 1225 iterations.\n[15:18:56] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:56] 0:\tlearn: 53997.6426679\ttest: 54976.8951980\tbest: 54976.8951980 (0)\ttotal: 2.14ms\tremaining: 4.28s\n[15:18:59] Stopped by overfitting detector  (300 iterations wait)\n[15:18:59] bestTest = 17303.88807\n[15:18:59] bestIteration = 1146\n[15:18:59] Shrink model to first 1147 iterations.\n[15:18:59] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:18:59] 0:\tlearn: 53816.7039322\ttest: 53652.4532919\tbest: 53652.4532919 (0)\ttotal: 2.13ms\tremaining: 4.26s\n[15:19:03] Stopped by overfitting detector  (300 iterations wait)\n[15:19:03] bestTest = 14149.89662\n[15:19:03] bestIteration = 1522\n[15:19:03] Shrink model to first 1523 iterations.\n[15:19:03] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:03] 0:\tlearn: 55138.9400090\ttest: 52250.8604540\tbest: 52250.8604540 (0)\ttotal: 2.11ms\tremaining: 4.22s\n[15:19:05] Stopped by overfitting detector  (300 iterations wait)\n[15:19:05] bestTest = 14823.80189\n[15:19:05] bestIteration = 753\n[15:19:05] Shrink model to first 754 iterations.\n[15:19:05] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:05] 0:\tlearn: 54342.4676684\ttest: 55136.6676328\tbest: 55136.6676328 (0)\ttotal: 2.05ms\tremaining: 4.09s\n[15:19:08] Stopped by overfitting detector  (300 iterations wait)\n[15:19:08] bestTest = 13795.88449\n[15:19:08] bestIteration = 915\n[15:19:08] Shrink model to first 916 iterations.\n[15:19:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14893.569252327698\u001b[0m\n[15:19:08] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:19:08] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.011412305745306937, 'min_data_in_leaf': 12} scored -14893.569252327698 in 0:00:14.448630\n[15:19:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:19:08] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:08] 0:\tlearn: 54000.0430411\ttest: 55989.4496118\tbest: 55989.4496118 (0)\ttotal: 2.1ms\tremaining: 4.2s\n[15:19:09] Stopped by overfitting detector  (300 iterations wait)\n[15:19:09] bestTest = 14500.2618\n[15:19:09] bestIteration = 447\n[15:19:09] Shrink model to first 448 iterations.\n[15:19:09] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:09] 0:\tlearn: 54000.6716041\ttest: 54978.9153133\tbest: 54978.9153133 (0)\ttotal: 2.22ms\tremaining: 4.44s\n[15:19:11] Stopped by overfitting detector  (300 iterations wait)\n[15:19:11] bestTest = 17326.39619\n[15:19:11] bestIteration = 450\n[15:19:11] Shrink model to first 451 iterations.\n[15:19:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:11] 0:\tlearn: 53818.9405874\ttest: 53654.4175687\tbest: 53654.4175687 (0)\ttotal: 2.59ms\tremaining: 5.17s\n[15:19:13] Stopped by overfitting detector  (300 iterations wait)\n[15:19:13] bestTest = 14728.4147\n[15:19:13] bestIteration = 450\n[15:19:13] Shrink model to first 451 iterations.\n[15:19:13] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:13] 0:\tlearn: 55143.4952037\ttest: 52254.8752114\tbest: 52254.8752114 (0)\ttotal: 2.68ms\tremaining: 5.35s\n[15:19:16] Stopped by overfitting detector  (300 iterations wait)\n[15:19:16] bestTest = 15224.89717\n[15:19:16] bestIteration = 1165\n[15:19:16] Shrink model to first 1166 iterations.\n[15:19:16] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:16] 0:\tlearn: 54344.5753456\ttest: 55139.1944029\tbest: 55139.1944029 (0)\ttotal: 2.28ms\tremaining: 4.55s\n[15:19:19] Stopped by overfitting detector  (300 iterations wait)\n[15:19:19] bestTest = 13788.34623\n[15:19:19] bestIteration = 1339\n[15:19:19] Shrink model to first 1340 iterations.\n[15:19:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15123.80204208583\u001b[0m\n[15:19:19] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:19:19] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.045942358953880026, 'min_data_in_leaf': 11} scored -15123.80204208583 in 0:00:11.758386\n[15:19:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:19:19] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:20] 0:\tlearn: 54327.7302454\ttest: 56308.7492457\tbest: 56308.7492457 (0)\ttotal: 2.91ms\tremaining: 5.82s\n[15:19:24] Stopped by overfitting detector  (300 iterations wait)\n[15:19:24] bestTest = 14529.49437\n[15:19:24] bestIteration = 1268\n[15:19:24] Shrink model to first 1269 iterations.\n[15:19:24] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:24] 0:\tlearn: 54399.4089497\ttest: 55264.9440146\tbest: 55264.9440146 (0)\ttotal: 2.95ms\tremaining: 5.89s\n[15:19:27] Stopped by overfitting detector  (300 iterations wait)\n[15:19:27] bestTest = 16988.31893\n[15:19:27] bestIteration = 889\n[15:19:27] Shrink model to first 890 iterations.\n[15:19:27] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:27] 0:\tlearn: 54087.7352413\ttest: 53990.3046834\tbest: 53990.3046834 (0)\ttotal: 3.42ms\tremaining: 6.84s\n[15:19:30] Stopped by overfitting detector  (300 iterations wait)\n[15:19:30] bestTest = 14288.98313\n[15:19:30] bestIteration = 993\n[15:19:30] Shrink model to first 994 iterations.\n[15:19:30] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:30] 0:\tlearn: 55310.4435510\ttest: 52401.1107788\tbest: 52401.1107788 (0)\ttotal: 3.06ms\tremaining: 6.11s\n[15:19:33] Stopped by overfitting detector  (300 iterations wait)\n[15:19:33] bestTest = 14280.00904\n[15:19:33] bestIteration = 847\n[15:19:33] Shrink model to first 848 iterations.\n[15:19:33] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:34] 0:\tlearn: 54658.0342124\ttest: 55413.9525752\tbest: 55413.9525752 (0)\ttotal: 2.83ms\tremaining: 5.65s\n[15:19:37] Stopped by overfitting detector  (300 iterations wait)\n[15:19:37] bestTest = 15192.08008\n[15:19:37] bestIteration = 846\n[15:19:37] Shrink model to first 847 iterations.\n[15:19:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15058.646942556721\u001b[0m\n[15:19:37] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:19:37] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 7.7375215021765165, 'min_data_in_leaf': 17} scored -15058.646942556721 in 0:00:17.243455\n[15:19:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:19:37] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:37] 0:\tlearn: 54024.1533887\ttest: 56010.1158908\tbest: 56010.1158908 (0)\ttotal: 2.12ms\tremaining: 4.24s\n[15:19:38] Stopped by overfitting detector  (300 iterations wait)\n[15:19:38] bestTest = 14583.75075\n[15:19:38] bestIteration = 486\n[15:19:38] Shrink model to first 487 iterations.\n[15:19:38] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:38] 0:\tlearn: 54026.1669760\ttest: 54996.8705947\tbest: 54996.8705947 (0)\ttotal: 2.18ms\tremaining: 4.36s\n[15:19:40] Stopped by overfitting detector  (300 iterations wait)\n[15:19:40] bestTest = 16928.87333\n[15:19:40] bestIteration = 691\n[15:19:40] Shrink model to first 692 iterations.\n[15:19:40] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:40] 0:\tlearn: 53838.0468203\ttest: 53672.1416300\tbest: 53672.1416300 (0)\ttotal: 2.13ms\tremaining: 4.25s\n[15:19:43] Stopped by overfitting detector  (300 iterations wait)\n[15:19:43] bestTest = 14469.57133\n[15:19:43] bestIteration = 1184\n[15:19:43] Shrink model to first 1185 iterations.\n[15:19:43] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:43] 0:\tlearn: 55181.3122155\ttest: 52287.3871720\tbest: 52287.3871720 (0)\ttotal: 2.25ms\tremaining: 4.49s\n[15:19:45] Stopped by overfitting detector  (300 iterations wait)\n[15:19:45] bestTest = 14950.00673\n[15:19:45] bestIteration = 351\n[15:19:45] Shrink model to first 352 iterations.\n[15:19:45] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:45] 0:\tlearn: 54363.3053968\ttest: 55161.7318276\tbest: 55161.7318276 (0)\ttotal: 2.48ms\tremaining: 4.96s\n[15:19:47] Stopped by overfitting detector  (300 iterations wait)\n[15:19:47] bestTest = 13486.43501\n[15:19:47] bestIteration = 459\n[15:19:47] Shrink model to first 460 iterations.\n[15:19:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14884.541420296448\u001b[0m\n[15:19:47] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:19:47] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.36714255469878165, 'min_data_in_leaf': 8} scored -14884.541420296448 in 0:00:10.009632\n[15:19:47] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[15:19:47] The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 9.86874546485378, 'min_data_in_leaf': 12}\u001b[0m\n achieve -14884.0502 mae\n[15:19:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:19:47] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:47] 0:\tlearn: 54955.6744358\ttest: 56932.8786546\tbest: 56932.8786546 (0)\ttotal: 2.12ms\tremaining: 6.35s\n[15:19:49] Stopped by overfitting detector  (100 iterations wait)\n[15:19:49] bestTest = 14410.85286\n[15:19:49] bestIteration = 1228\n[15:19:49] Shrink model to first 1229 iterations.\n[15:19:49] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:49] 0:\tlearn: 55191.6685795\ttest: 55982.9266204\tbest: 55982.9266204 (0)\ttotal: 2.64ms\tremaining: 7.91s\n[15:19:54] Stopped by overfitting detector  (100 iterations wait)\n[15:19:54] bestTest = 16517.18209\n[15:19:54] bestIteration = 2239\n[15:19:54] Shrink model to first 2240 iterations.\n[15:19:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:54] 0:\tlearn: 54793.8139253\ttest: 54727.2697782\tbest: 54727.2697782 (0)\ttotal: 2.13ms\tremaining: 6.4s\n[15:19:57] Stopped by overfitting detector  (100 iterations wait)\n[15:19:57] bestTest = 14339.28335\n[15:19:57] bestIteration = 1534\n[15:19:57] Shrink model to first 1535 iterations.\n[15:19:57] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:19:57] 0:\tlearn: 55964.1853312\ttest: 53006.9204331\tbest: 53006.9204331 (0)\ttotal: 2.05ms\tremaining: 6.15s\n[15:20:00] Stopped by overfitting detector  (100 iterations wait)\n[15:20:00] bestTest = 14421.45656\n[15:20:00] bestIteration = 1615\n[15:20:00] Shrink model to first 1616 iterations.\n[15:20:00] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:20:00] 0:\tlearn: 55458.1943090\ttest: 56264.9731792\tbest: 56264.9731792 (0)\ttotal: 2.03ms\tremaining: 6.1s\n[15:20:03] Stopped by overfitting detector  (100 iterations wait)\n[15:20:03] bestTest = 14273.70524\n[15:20:03] bestIteration = 1428\n[15:20:03] Shrink model to first 1429 iterations.\n[15:20:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14796.980916898545\u001b[0m\n[15:20:03] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:20:03] Time left 2332.97 secs\n\n[15:20:03] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[15:20:03] Blending: optimization starts with equal weights and score \u001b[1m-14620.262146832192\u001b[0m\n[15:20:03] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14556.68505859375\u001b[0m, weights = \u001b[1m[0.14697333 0.05535056 0.14285827 0.27979106 0.3750268 ]\u001b[0m\n[15:20:03] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14548.590532694778\u001b[0m, weights = \u001b[1m[0.15284312 0.05380862 0.15164451 0.18866222 0.45304155]\u001b[0m\n[15:20:03] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14547.2134424497\u001b[0m, weights = \u001b[1m[0.16183718 0.05697498 0.16899084 0.13249615 0.4797008 ]\u001b[0m\n[15:20:03] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14546.412320071704\u001b[0m, weights = \u001b[1m[0.16382873 0.05648973 0.14917043 0.12545736 0.50505376]\u001b[0m\n[15:20:03] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14546.380217251712\u001b[0m, weights = \u001b[1m[0.16689253 0.05665579 0.14946073 0.12045249 0.5065384 ]\u001b[0m\n[15:20:03] \u001b[1mAutoml preset training completed in 667.56 seconds\u001b[0m\n\n[15:20:03] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.16689 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.05666 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.14946 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.12045 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.50654 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[15:20:03] ==================================================\n[15:20:03] Start 6 automl preset configuration:\n[15:20:03] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 48}, 'nn_params': {'random_state': 48}, 'general_params': {'return_all_predictions': False}}\n[15:20:03] Found reader_params in kwargs, need to combine\n[15:20:03] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 48, 'cv': 5}\n[15:20:03] Stdout logging level is INFO3.\n[15:20:03] Task: reg\n\n[15:20:03] Start automl preset with listed constraints:\n[15:20:03] - time: 2332.82 seconds\n[15:20:03] - CPU: 4 cores\n[15:20:03] - memory: 16 GB\n\n[15:20:03] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[15:20:09] Feats was rejected during automatic roles guess: []\n[15:20:09] Layer \u001b[1m1\u001b[0m train process start. Time left 2326.66 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:20:10] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[15:20:10] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:20:10] Linear model: C = 1e-05 score = -35979.62780448718\n[15:20:10] Linear model: C = 5e-05 score = -23699.727297008547\n[15:20:11] Linear model: C = 0.0001 score = -20812.270265758547\n[15:20:11] Linear model: C = 0.0005 score = -18482.72702991453\n[15:20:11] Linear model: C = 0.001 score = -18387.051048344016\n[15:20:11] Linear model: C = 0.005 score = -18870.25731169872\n[15:20:12] Linear model: C = 0.01 score = -19227.95783253205\n[15:20:12] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:20:12] Linear model: C = 1e-05 score = -39327.20215678419\n[15:20:12] Linear model: C = 5e-05 score = -25516.848774706195\n[15:20:12] Linear model: C = 0.0001 score = -22486.94766209268\n[15:20:12] Linear model: C = 0.0005 score = -18731.03586154514\n[15:20:13] Linear model: C = 0.001 score = -17787.151984842414\n[15:20:13] Linear model: C = 0.005 score = -17283.054270165598\n[15:20:13] Linear model: C = 0.01 score = -17283.054228432156\n[15:20:13] Linear model: C = 0.05 score = -19144.539730235043\n[15:20:14] Linear model: C = 0.1 score = -20284.851570846688\n[15:20:14] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:20:14] Linear model: C = 1e-05 score = -34790.20763221154\n[15:20:14] Linear model: C = 5e-05 score = -21073.661408253207\n[15:20:14] Linear model: C = 0.0001 score = -18363.454243456195\n[15:20:14] Linear model: C = 0.0005 score = -15940.581747462607\n[15:20:15] Linear model: C = 0.001 score = -15871.92217548077\n[15:20:15] Linear model: C = 0.005 score = -15871.922542735043\n[15:20:15] Linear model: C = 0.01 score = -16859.32779113248\n[15:20:15] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:20:15] Linear model: C = 1e-05 score = -38543.078661480686\n[15:20:15] Linear model: C = 5e-05 score = -24925.417214324036\n[15:20:16] Linear model: C = 0.0001 score = -21903.58090799356\n[15:20:16] Linear model: C = 0.0005 score = -18720.210048953864\n[15:20:16] Linear model: C = 0.001 score = -18558.26173551502\n[15:20:16] Linear model: C = 0.005 score = -19046.00035206545\n[15:20:17] Linear model: C = 0.01 score = -19597.8500787956\n[15:20:17] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:20:17] Linear model: C = 1e-05 score = -35917.150516362664\n[15:20:18] Linear model: C = 5e-05 score = -22884.10649141631\n[15:20:19] Linear model: C = 0.0001 score = -20805.43369434013\n[15:20:19] Linear model: C = 0.0005 score = -18615.035541845493\n[15:20:19] Linear model: C = 0.001 score = -18615.035541845493\n[15:20:19] Linear model: C = 0.005 score = -18615.03629627146\n[15:20:19] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17741.620453298907\u001b[0m\n[15:20:19] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[15:20:19] Time left 2317.23 secs\n\n[15:20:19] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:20:21] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[15:20:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[15:20:21] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:20:21] Training until validation scores don't improve for 200 rounds\n[15:20:22] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:20:22] Training until validation scores don't improve for 200 rounds\n[15:20:24] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:20:24] Training until validation scores don't improve for 200 rounds\n[15:20:29] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:20:29] Training until validation scores don't improve for 200 rounds\n[15:20:31] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:20:31] Training until validation scores don't improve for 200 rounds\n[15:20:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15579.749220756636\u001b[0m\n[15:20:33] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[15:20:33] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[15:20:33] Training until validation scores don't improve for 200 rounds\n[15:20:34] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15532.50390625 in 0:00:01.492853\n[15:20:34] Training until validation scores don't improve for 200 rounds\n[15:20:36] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -15427.396000267094 in 0:00:01.282075\n[15:20:36] Training until validation scores don't improve for 200 rounds\n[15:20:37] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -15571.940671741453 in 0:00:01.596194\n[15:20:37] Training until validation scores don't improve for 200 rounds\n[15:20:39] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -15608.049646100428 in 0:00:01.612831\n[15:20:39] Training until validation scores don't improve for 200 rounds\n[15:20:40] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -15415.956129807691 in 0:00:01.276727\n[15:20:40] Training until validation scores don't improve for 200 rounds\n[15:20:42] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -15512.923243856838 in 0:00:01.569568\n[15:20:42] Training until validation scores don't improve for 200 rounds\n[15:20:43] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15659.66032318376 in 0:00:01.469084\n[15:20:43] Training until validation scores don't improve for 200 rounds\n[15:20:44] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -15644.563568376068 in 0:00:01.200768\n[15:20:44] Training until validation scores don't improve for 200 rounds\n[15:20:46] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15853.153879540598 in 0:00:01.889550\n[15:20:46] Training until validation scores don't improve for 200 rounds\n[15:20:48] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -15641.634081196582 in 0:00:01.233597\n[15:20:48] Training until validation scores don't improve for 200 rounds\n[15:20:51] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 177, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.050888616200595385, 'reg_alpha': 0.010510985525196167, 'reg_lambda': 2.2311398834761413e-08} scored -15623.096420940172 in 0:00:03.353006\n[15:20:51] Training until validation scores don't improve for 200 rounds\n[15:20:52] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.507000435419826, 'num_leaves': 179, 'bagging_fraction': 0.737571231283732, 'min_sum_hessian_in_leaf': 1.2231191041377976, 'reg_alpha': 0.002361732332366152, 'reg_lambda': 0.032149846080107444} scored -15207.764356303418 in 0:00:01.543188\n[15:20:52] Training until validation scores don't improve for 200 rounds\n[15:20:54] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5966110417019752, 'num_leaves': 153, 'bagging_fraction': 0.6712579968688783, 'min_sum_hessian_in_leaf': 4.615678403573609, 'reg_alpha': 0.003901119676509275, 'reg_lambda': 0.02823938619073735} scored -15361.783987713676 in 0:00:01.377584\n[15:20:54] Training until validation scores don't improve for 200 rounds\n[15:20:55] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.604450313887544, 'num_leaves': 138, 'bagging_fraction': 0.7103230214383208, 'min_sum_hessian_in_leaf': 9.854464546022568, 'reg_alpha': 0.08810028012678793, 'reg_lambda': 0.03524462633103717} scored -15357.789730235043 in 0:00:01.466711\n[15:20:55] Training until validation scores don't improve for 200 rounds\n[15:20:57] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.6130842808451558, 'num_leaves': 115, 'bagging_fraction': 0.7361101529543853, 'min_sum_hessian_in_leaf': 9.639757903159524, 'reg_alpha': 0.419725263567943, 'reg_lambda': 0.01475150509529616} scored -15404.940504807691 in 0:00:01.256737\n[15:20:57] Training until validation scores don't improve for 200 rounds\n[15:20:58] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.567070907117541, 'num_leaves': 124, 'bagging_fraction': 0.7484483315394532, 'min_sum_hessian_in_leaf': 1.7486494359045366, 'reg_alpha': 0.07999917446425558, 'reg_lambda': 0.014775475739688166} scored -15377.865685096154 in 0:00:01.214047\n[15:20:58] Training until validation scores don't improve for 200 rounds\n[15:20:59] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5065701578589041, 'num_leaves': 174, 'bagging_fraction': 0.9171981962581278, 'min_sum_hessian_in_leaf': 2.4424581437924626, 'reg_alpha': 0.00020904272156122862, 'reg_lambda': 0.24070100562759592} scored -15615.000868055555 in 0:00:01.338433\n[15:20:59] Training until validation scores don't improve for 200 rounds\n[15:21:01] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6367984031400119, 'num_leaves': 104, 'bagging_fraction': 0.6733906991067409, 'min_sum_hessian_in_leaf': 2.6888372747929346, 'reg_alpha': 9.936568802609569e-05, 'reg_lambda': 0.0028274589843440734} scored -15400.318776709402 in 0:00:01.438440\n[15:21:01] Training until validation scores don't improve for 200 rounds\n[15:21:02] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.56391216214132, 'num_leaves': 150, 'bagging_fraction': 0.7214244113708117, 'min_sum_hessian_in_leaf': 0.8073047826147841, 'reg_alpha': 0.07072098012950213, 'reg_lambda': 6.243069797304186} scored -15214.392528044871 in 0:00:01.507030\n[15:21:02] Training until validation scores don't improve for 200 rounds\n[15:21:04] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8529694011819124, 'num_leaves': 186, 'bagging_fraction': 0.7840643880417812, 'min_sum_hessian_in_leaf': 0.019952294375329655, 'reg_alpha': 0.027541689582038544, 'reg_lambda': 4.673265848282597} scored -15430.69921875 in 0:00:01.671408\n[15:21:04] Training until validation scores don't improve for 200 rounds\n[15:21:05] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.5624761421265899, 'num_leaves': 150, 'bagging_fraction': 0.8879124430248126, 'min_sum_hessian_in_leaf': 0.2503590977010438, 'reg_alpha': 0.0004682991667363102, 'reg_lambda': 0.6058346408417852} scored -15564.554153311965 in 0:00:01.462466\n[15:21:05] Training until validation scores don't improve for 200 rounds\n[15:21:07] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5697202345601189, 'num_leaves': 140, 'bagging_fraction': 0.71804991678614, 'min_sum_hessian_in_leaf': 1.1492729523452752, 'reg_alpha': 0.24566385921540562, 'reg_lambda': 0.08018995270975335} scored -15255.41796875 in 0:00:01.468177\n[15:21:07] Training until validation scores don't improve for 200 rounds\n[15:21:08] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.5462231785887334, 'num_leaves': 157, 'bagging_fraction': 0.7638845046579814, 'min_sum_hessian_in_leaf': 0.7933687965262252, 'reg_alpha': 0.5940391232866644, 'reg_lambda': 8.269839145014647} scored -15273.684027777777 in 0:00:01.274583\n[15:21:08] Training until validation scores don't improve for 200 rounds\n[15:21:09] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.671200943998317, 'num_leaves': 196, 'bagging_fraction': 0.7180081380016254, 'min_sum_hessian_in_leaf': 0.28119641073239837, 'reg_alpha': 0.26405234558810925, 'reg_lambda': 0.1495778458466777} scored -15379.840845352564 in 0:00:01.455072\n[15:21:10] Training until validation scores don't improve for 200 rounds\n[15:21:11] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5751101869167934, 'num_leaves': 99, 'bagging_fraction': 0.6472992542462006, 'min_sum_hessian_in_leaf': 1.0430051227322639, 'reg_alpha': 0.0022543761448475005, 'reg_lambda': 0.003667335734895317} scored -15504.706196581197 in 0:00:01.218629\n[15:21:11] Training until validation scores don't improve for 200 rounds\n[15:21:12] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.5182986160345634, 'num_leaves': 215, 'bagging_fraction': 0.8289527843656461, 'min_sum_hessian_in_leaf': 2.813412480432145, 'reg_alpha': 0.026198380775188965, 'reg_lambda': 1.3538798263084824} scored -15395.06984508547 in 0:00:01.330116\n[15:21:12] Training until validation scores don't improve for 200 rounds\n[15:21:14] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.6191619608907877, 'num_leaves': 140, 'bagging_fraction': 0.7055716313962374, 'min_sum_hessian_in_leaf': 0.40403725100591803, 'reg_alpha': 4.171666854599811e-05, 'reg_lambda': 0.1007466779386794} scored -15306.455996260684 in 0:00:01.464884\n[15:21:14] Training until validation scores don't improve for 200 rounds\n[15:21:15] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.571358751916057, 'num_leaves': 170, 'bagging_fraction': 0.7655861314080077, 'min_sum_hessian_in_leaf': 0.11726076586409678, 'reg_alpha': 2.56347050305229, 'reg_lambda': 0.005203059480728187} scored -15222.596955128205 in 0:00:01.275041\n[15:21:15] Training until validation scores don't improve for 200 rounds\n[15:21:16] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.6853514755463233, 'num_leaves': 182, 'bagging_fraction': 0.7670103407347095, 'min_sum_hessian_in_leaf': 0.11434952698192287, 'reg_alpha': 1.744870247945709, 'reg_lambda': 4.162343247070241e-05} scored -15365.023404113248 in 0:00:01.374248\n[15:21:16] Training until validation scores don't improve for 200 rounds\n[15:21:18] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6584176056288116, 'num_leaves': 255, 'bagging_fraction': 0.8844806471828219, 'min_sum_hessian_in_leaf': 0.0013030133773607152, 'reg_alpha': 6.997066436309694, 'reg_lambda': 2.898347864988663e-06} scored -15615.868856837607 in 0:00:01.524771\n[15:21:18] Training until validation scores don't improve for 200 rounds\n[15:21:19] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.7148790638928988, 'num_leaves': 166, 'bagging_fraction': 0.8476134104785895, 'min_sum_hessian_in_leaf': 0.02228113622513842, 'reg_alpha': 0.0006195711319598134, 'reg_lambda': 0.002418205313519174} scored -15740.531784188035 in 0:00:01.676364\n[15:21:19] Training until validation scores don't improve for 200 rounds\n[15:21:21] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5802892795732806, 'num_leaves': 127, 'bagging_fraction': 0.7451044393646202, 'min_sum_hessian_in_leaf': 0.6323436891328693, 'reg_alpha': 0.1366252576621179, 'reg_lambda': 0.006031267765524654} scored -15251.54390357906 in 0:00:01.257039\n[15:21:21] Training until validation scores don't improve for 200 rounds\n[15:21:24] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.547884894679953, 'num_leaves': 121, 'bagging_fraction': 0.8055110742746786, 'min_sum_hessian_in_leaf': 0.49826823041643353, 'reg_alpha': 0.7941642651230381, 'reg_lambda': 0.000117440224376242} scored -15428.821915064103 in 0:00:02.969118\n[15:21:24] Training until validation scores don't improve for 200 rounds\n[15:21:25] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5394463051220458, 'num_leaves': 163, 'bagging_fraction': 0.749811158953428, 'min_sum_hessian_in_leaf': 0.1373304687180432, 'reg_alpha': 0.049440311164876745, 'reg_lambda': 0.004559179021308005} scored -15357.475260416666 in 0:00:01.274326\n[15:21:25] Training until validation scores don't improve for 200 rounds\n[15:21:26] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5022479150448247, 'num_leaves': 16, 'bagging_fraction': 0.7870473687630744, 'min_sum_hessian_in_leaf': 0.19563571358473406, 'reg_alpha': 0.009695532463258853, 'reg_lambda': 0.001041499016453935} scored -15591.69641426282 in 0:00:01.212149\n[15:21:26] Training until validation scores don't improve for 200 rounds\n[15:21:27] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5842958983157746, 'num_leaves': 200, 'bagging_fraction': 0.6145801881350942, 'min_sum_hessian_in_leaf': 0.06246680519018736, 'reg_alpha': 0.14404708618221498, 'reg_lambda': 0.00011771131546853119} scored -15579.36608573718 in 0:00:01.260091\n[15:21:27] Training until validation scores don't improve for 200 rounds\n[15:21:29] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.6335082284873432, 'num_leaves': 212, 'bagging_fraction': 0.8119107095812874, 'min_sum_hessian_in_leaf': 0.5179433264159901, 'reg_alpha': 1.417075666137829, 'reg_lambda': 0.01365832747783395} scored -15629.333032852564 in 0:00:01.397140\n[15:21:29] Training until validation scores don't improve for 200 rounds\n[15:21:30] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.5302902575224377, 'num_leaves': 90, 'bagging_fraction': 0.6582298493618003, 'min_sum_hessian_in_leaf': 0.02622911028942481, 'reg_alpha': 0.01244653170741188, 'reg_lambda': 3.959375143012411e-07} scored -15344.448617788461 in 0:00:01.310371\n[15:21:30] Training until validation scores don't improve for 200 rounds\n[15:21:32] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.5905744209837588, 'num_leaves': 128, 'bagging_fraction': 0.6931445826607182, 'min_sum_hessian_in_leaf': 0.7057527675846031, 'reg_alpha': 0.0019079314020572246, 'reg_lambda': 2.617849617103079} scored -15262.72686298077 in 0:00:01.491982\n[15:21:32] Training until validation scores don't improve for 200 rounds\n[15:21:33] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.8895125346601398, 'num_leaves': 77, 'bagging_fraction': 0.7259297752217888, 'min_sum_hessian_in_leaf': 0.1656296832335573, 'reg_alpha': 1.4244998836103183e-05, 'reg_lambda': 0.570648121449815} scored -15677.290665064103 in 0:00:01.711182\n[15:21:33] Training until validation scores don't improve for 200 rounds\n[15:21:35] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.714909650975559, 'num_leaves': 188, 'bagging_fraction': 0.5558483080245697, 'min_sum_hessian_in_leaf': 0.31440212272690043, 'reg_alpha': 3.435313388927094, 'reg_lambda': 0.0009211821741745446} scored -15487.999632745727 in 0:00:01.519188\n[15:21:35] Training until validation scores don't improve for 200 rounds\n[15:21:36] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5603675117917057, 'num_leaves': 144, 'bagging_fraction': 0.7317421682665155, 'min_sum_hessian_in_leaf': 1.462302348519684, 'reg_alpha': 0.2218233672240896, 'reg_lambda': 0.06369641462896795} scored -15130.466112446582 in 0:00:01.537103\n[15:21:37] Training until validation scores don't improve for 200 rounds\n[15:21:38] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5456033499143192, 'num_leaves': 167, 'bagging_fraction': 0.7729890824456268, 'min_sum_hessian_in_leaf': 4.721733422101544, 'reg_alpha': 0.7145784914524412, 'reg_lambda': 0.03602734314390326} scored -15327.52577457265 in 0:00:01.434655\n[15:21:38] Training until validation scores don't improve for 200 rounds\n[15:21:39] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.6302420722995019, 'num_leaves': 148, 'bagging_fraction': 0.7430626399510584, 'min_sum_hessian_in_leaf': 1.5227656529670424, 'reg_alpha': 0.11881670002185683, 'reg_lambda': 0.006731509253268685} scored -15306.452256944445 in 0:00:01.331700\n[15:21:39] Training until validation scores don't improve for 200 rounds\n[15:21:41] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.503010921042665, 'num_leaves': 115, 'bagging_fraction': 0.6474085681879439, 'min_sum_hessian_in_leaf': 0.815041471984175, 'reg_alpha': 7.570983844221184, 'reg_lambda': 0.33651997648810306} scored -15333.20078792735 in 0:00:01.251486\n[15:21:41] Training until validation scores don't improve for 200 rounds\n[15:21:42] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.746657354281442, 'num_leaves': 131, 'bagging_fraction': 0.6966349577869225, 'min_sum_hessian_in_leaf': 2.192683539096186, 'reg_alpha': 6.145326970254036e-07, 'reg_lambda': 0.0002495346832039776} scored -15628.210436698719 in 0:00:01.638228\n[15:21:42] Training until validation scores don't improve for 200 rounds\n[15:21:43] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.5941578584677011, 'num_leaves': 172, 'bagging_fraction': 0.5871319248742302, 'min_sum_hessian_in_leaf': 3.900839560252879, 'reg_alpha': 0.039844576513613436, 'reg_lambda': 0.0013223627935363854} scored -15466.963675213676 in 0:00:01.297318\n[15:21:44] Training until validation scores don't improve for 200 rounds\n[15:21:45] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.5291047340507967, 'num_leaves': 147, 'bagging_fraction': 0.7962094994065014, 'min_sum_hessian_in_leaf': 0.09114867137867387, 'reg_alpha': 0.005702084883393458, 'reg_lambda': 0.07125766285026087} scored -15306.721120459402 in 0:00:01.288449\n[15:21:45] Training until validation scores don't improve for 200 rounds\n[15:21:47] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.9713386595732587, 'num_leaves': 106, 'bagging_fraction': 0.8306325791273385, 'min_sum_hessian_in_leaf': 1.180617051081026, 'reg_alpha': 1.665134442201063, 'reg_lambda': 0.01743772281901259} scored -15674.329126602564 in 0:00:02.001163\n[15:21:47] Training until validation scores don't improve for 200 rounds\n[15:21:48] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.560171498935114, 'num_leaves': 223, 'bagging_fraction': 0.737941748632095, 'min_sum_hessian_in_leaf': 1.7124538724960976, 'reg_alpha': 0.0013868089172452093, 'reg_lambda': 0.008131772363312228} scored -15128.81436965812 in 0:00:01.547968\n[15:21:48] Training until validation scores don't improve for 200 rounds\n[15:21:50] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.5587033595118555, 'num_leaves': 236, 'bagging_fraction': 0.9993204662796429, 'min_sum_hessian_in_leaf': 6.914330977797168, 'reg_alpha': 0.0009450914955650073, 'reg_lambda': 1.4578003345099564} scored -16008.454760950855 in 0:00:01.592045\n[15:21:50] Training until validation scores don't improve for 200 rounds\n[15:21:51] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.6063874696464998, 'num_leaves': 227, 'bagging_fraction': 0.755423703351205, 'min_sum_hessian_in_leaf': 1.8265058976684223, 'reg_alpha': 0.020513481485520915, 'reg_lambda': 0.007260159540156492} scored -15327.764790331197 in 0:00:01.469424\n[15:21:52] Training until validation scores don't improve for 200 rounds\n[15:21:53] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.5216388871129267, 'num_leaves': 159, 'bagging_fraction': 0.7356735955142835, 'min_sum_hessian_in_leaf': 3.3061033988885784, 'reg_alpha': 0.2352948224746863, 'reg_lambda': 0.04616077426413371} scored -15339.61548477564 in 0:00:01.469051\n[15:21:53] Training until validation scores don't improve for 200 rounds\n[15:21:56] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.5756525682634244, 'num_leaves': 191, 'bagging_fraction': 0.6856745053323561, 'min_sum_hessian_in_leaf': 0.8414075866550745, 'reg_alpha': 0.00011966526621705219, 'reg_lambda': 0.01038464370908765} scored -15501.797208867521 in 0:00:03.063116\n[15:21:56] Training until validation scores don't improve for 200 rounds\n[15:21:57] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.6118241967062061, 'num_leaves': 137, 'bagging_fraction': 0.7795529406728189, 'min_sum_hessian_in_leaf': 0.5713226690437344, 'reg_alpha': 0.0013384731203459428, 'reg_lambda': 0.0019605799690891787} scored -15411.83092948718 in 0:00:01.350126\n[15:21:57] Training until validation scores don't improve for 200 rounds\n[15:21:59] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5561953972916484, 'num_leaves': 213, 'bagging_fraction': 0.7257344668723212, 'min_sum_hessian_in_leaf': 0.34959337300751125, 'reg_alpha': 0.0029379463478776736, 'reg_lambda': 0.0005416336575284773} scored -15203.609375 in 0:00:01.474121\n[15:21:59] Training until validation scores don't improve for 200 rounds\n[15:22:00] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.5582013958559682, 'num_leaves': 206, 'bagging_fraction': 0.7129500978973219, 'min_sum_hessian_in_leaf': 0.3700423111227362, 'reg_alpha': 0.005497082889618412, 'reg_lambda': 0.0002890816158837988} scored -15123.065972222223 in 0:00:01.487707\n[15:22:00] Training until validation scores don't improve for 200 rounds\n[15:22:02] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.5534348413119833, 'num_leaves': 209, 'bagging_fraction': 0.6735604981870644, 'min_sum_hessian_in_leaf': 0.32987646298519274, 'reg_alpha': 0.00485180253422577, 'reg_lambda': 0.0004523058736339003} scored -15511.087406517094 in 0:00:01.416434\n[15:22:02] Training until validation scores don't improve for 200 rounds\n[15:22:03] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.5245118129366445, 'num_leaves': 223, 'bagging_fraction': 0.7100072521225262, 'min_sum_hessian_in_leaf': 1.6906589682190862, 'reg_alpha': 0.00026938602376805543, 'reg_lambda': 0.0001715163936451626} scored -15233.115518162393 in 0:00:01.411509\n[15:22:03] Training until validation scores don't improve for 200 rounds\n[15:22:05] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.6404916509686354, 'num_leaves': 224, 'bagging_fraction': 0.7261840143204155, 'min_sum_hessian_in_leaf': 1.0982653088732772, 'reg_alpha': 0.002986826986139825, 'reg_lambda': 5.278767705560406e-05} scored -15317.605969551281 in 0:00:01.555033\n[15:22:05] Training until validation scores don't improve for 200 rounds\n[15:22:06] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.7872264026943085, 'num_leaves': 247, 'bagging_fraction': 0.7024265627356805, 'min_sum_hessian_in_leaf': 0.3928770931559211, 'reg_alpha': 0.01002116338235156, 'reg_lambda': 1.1822749381891178e-05} scored -15461.162827190172 in 0:00:01.568448\n[15:22:06] Training until validation scores don't improve for 200 rounds\n[15:22:08] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.5583132871069914, 'num_leaves': 204, 'bagging_fraction': 0.7588860328974628, 'min_sum_hessian_in_leaf': 0.20167574305234434, 'reg_alpha': 0.06086450029045913, 'reg_lambda': 0.0005408713801413426} scored -15202.350060096154 in 0:00:01.536160\n[15:22:08] Training until validation scores don't improve for 200 rounds\n[15:22:10] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5355487140145665, 'num_leaves': 203, 'bagging_fraction': 0.7262284241656501, 'min_sum_hessian_in_leaf': 0.21534492725935092, 'reg_alpha': 0.04848245658585363, 'reg_lambda': 0.0006811753767039735} scored -15241.58122996795 in 0:00:01.643465\n[15:22:10] Training until validation scores don't improve for 200 rounds\n[15:22:11] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.8241012917547152, 'num_leaves': 217, 'bagging_fraction': 0.6738293175583441, 'min_sum_hessian_in_leaf': 0.0816475065273884, 'reg_alpha': 0.0006688753233521546, 'reg_lambda': 4.2025629396556955e-06} scored -15464.89142628205 in 0:00:01.583530\n[15:22:11] Training until validation scores don't improve for 200 rounds\n[15:22:13] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.5563996394198276, 'num_leaves': 198, 'bagging_fraction': 0.505139687665829, 'min_sum_hessian_in_leaf': 0.25297612517611245, 'reg_alpha': 0.005589179632567341, 'reg_lambda': 5.0214864827186444e-05} scored -15424.347122061965 in 0:00:01.292240\n[15:22:13] Training until validation scores don't improve for 200 rounds\n[15:22:14] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5067941352345521, 'num_leaves': 182, 'bagging_fraction': 0.7580424580336402, 'min_sum_hessian_in_leaf': 0.9191622487371733, 'reg_alpha': 0.013724013535891326, 'reg_lambda': 0.0003005014818740536} scored -15300.568376068377 in 0:00:01.500825\n[15:22:14] Training until validation scores don't improve for 200 rounds\n[15:22:15] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.5626408018320846, 'num_leaves': 230, 'bagging_fraction': 0.6309334303230613, 'min_sum_hessian_in_leaf': 1.4149028387146143, 'reg_alpha': 0.07369434930244445, 'reg_lambda': 0.18130131877931757} scored -15789.424712873932 in 0:00:01.292581\n[15:22:15] Training until validation scores don't improve for 200 rounds\n[15:22:17] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.5958344653266072, 'num_leaves': 207, 'bagging_fraction': 0.7319365578635192, 'min_sum_hessian_in_leaf': 0.3990010202409955, 'reg_alpha': 0.001595428303549756, 'reg_lambda': 0.0017428170043595416} scored -15265.918536324787 in 0:00:01.283538\n[15:22:17] Training until validation scores don't improve for 200 rounds\n[15:22:18] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.6179983401821753, 'num_leaves': 246, 'bagging_fraction': 0.7924781398157668, 'min_sum_hessian_in_leaf': 0.16067137011935645, 'reg_alpha': 0.00013925131506162893, 'reg_lambda': 0.023664792271999753} scored -15464.853198450855 in 0:00:01.390269\n[15:22:18] Training until validation scores don't improve for 200 rounds\n[15:22:20] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.5177920555243964, 'num_leaves': 217, 'bagging_fraction': 0.9480450770644245, 'min_sum_hessian_in_leaf': 2.5868385410380714, 'reg_alpha': 0.00039323057974804764, 'reg_lambda': 2.277992978170189e-05} scored -15687.10313167735 in 0:00:01.505319\n[15:22:20] Training until validation scores don't improve for 200 rounds\n[15:22:21] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.5412944842759781, 'num_leaves': 193, 'bagging_fraction': 0.8167095540056627, 'min_sum_hessian_in_leaf': 0.5657489572097306, 'reg_alpha': 0.0029939720799744165, 'reg_lambda': 4.114630707115587} scored -15256.142294337607 in 0:00:01.344745\n[15:22:21] Training until validation scores don't improve for 200 rounds\n[15:22:22] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.5666752834869245, 'num_leaves': 178, 'bagging_fraction': 0.7629008195420091, 'min_sum_hessian_in_leaf': 0.031522287603105575, 'reg_alpha': 0.3194106364131234, 'reg_lambda': 0.0033108161142681746} scored -15169.155982905982 in 0:00:01.408526\n[15:22:22] Training until validation scores don't improve for 200 rounds\n[15:22:24] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.5819595070989589, 'num_leaves': 178, 'bagging_fraction': 0.7729720387604214, 'min_sum_hessian_in_leaf': 0.028564048660709183, 'reg_alpha': 0.3555617310290614, 'reg_lambda': 0.0034875902596434045} scored -15402.165397970086 in 0:00:01.304766\n[15:22:24] Training until validation scores don't improve for 200 rounds\n[15:22:26] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.562076941610857, 'num_leaves': 185, 'bagging_fraction': 0.7190492309212407, 'min_sum_hessian_in_leaf': 0.010618873049586308, 'reg_alpha': 0.019059776744336294, 'reg_lambda': 0.0005131216566480501} scored -15213.70860042735 in 0:00:02.014483\n[15:22:27] Training until validation scores don't improve for 200 rounds\n[15:22:29] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.5693302814595214, 'num_leaves': 202, 'bagging_fraction': 0.7137486583078645, 'min_sum_hessian_in_leaf': 0.00815847756455667, 'reg_alpha': 0.022016039505031924, 'reg_lambda': 7.205990189147696e-05} scored -15212.585503472223 in 0:00:02.809850\n[15:22:29] Training until validation scores don't improve for 200 rounds\n[15:22:30] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.5379828730741724, 'num_leaves': 203, 'bagging_fraction': 0.7455850661200428, 'min_sum_hessian_in_leaf': 0.0022120918751868607, 'reg_alpha': 0.032083103342888844, 'reg_lambda': 0.0008692868297245308} scored -15250.255842681623 in 0:00:01.275884\n[15:22:30] Training until validation scores don't improve for 200 rounds\n[15:22:31] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.657209724104652, 'num_leaves': 213, 'bagging_fraction': 0.6874468036803865, 'min_sum_hessian_in_leaf': 0.004258270430805225, 'reg_alpha': 0.008224938809132257, 'reg_lambda': 0.00012050927562814694} scored -15499.329093215812 in 0:00:01.369720\n[15:22:31] Training until validation scores don't improve for 200 rounds\n[15:22:33] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.5754195282803076, 'num_leaves': 197, 'bagging_fraction': 0.7075542588879452, 'min_sum_hessian_in_leaf': 0.014535278073006011, 'reg_alpha': 0.17880022514823024, 'reg_lambda': 6.077600146859049e-05} scored -15280.35546875 in 0:00:01.557813\n[15:22:33] Training until validation scores don't improve for 200 rounds\n[15:22:34] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.6034498204549847, 'num_leaves': 222, 'bagging_fraction': 0.763819290763876, 'min_sum_hessian_in_leaf': 0.07997043975895782, 'reg_alpha': 0.5240646908801022, 'reg_lambda': 0.060091293401670506} scored -15181.87092681624 in 0:00:01.318323\n[15:22:34] Training until validation scores don't improve for 200 rounds\n[15:22:36] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.6022946814133378, 'num_leaves': 220, 'bagging_fraction': 0.7619813040575323, 'min_sum_hessian_in_leaf': 0.131189403455489, 'reg_alpha': 0.4564396453447036, 'reg_lambda': 0.048091203342908874} scored -15201.997362446582 in 0:00:01.553110\n[15:22:36] Training until validation scores don't improve for 200 rounds\n[15:22:37] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.6883564175919417, 'num_leaves': 238, 'bagging_fraction': 0.7611926827598434, 'min_sum_hessian_in_leaf': 0.039485916646299864, 'reg_alpha': 0.5200874371933948, 'reg_lambda': 0.1045525229113904} scored -15412.379139957266 in 0:00:01.509507\n[15:22:37] Training until validation scores don't improve for 200 rounds\n[15:22:39] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.5960180490554442, 'num_leaves': 220, 'bagging_fraction': 0.7792329515396967, 'min_sum_hessian_in_leaf': 0.0715639942330725, 'reg_alpha': 0.3760415741791731, 'reg_lambda': 0.053754053598874224} scored -15319.509047809828 in 0:00:01.348634\n[15:22:39] Training until validation scores don't improve for 200 rounds\n[15:22:40] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5512812407591855, 'num_leaves': 230, 'bagging_fraction': 0.7422736719139459, 'min_sum_hessian_in_leaf': 0.04135208613513724, 'reg_alpha': 1.0998685204640877, 'reg_lambda': 0.02213969104887782} scored -15164.754874465812 in 0:00:01.249497\n[15:22:40] Training until validation scores don't improve for 200 rounds\n[15:22:41] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.6058901878624108, 'num_leaves': 233, 'bagging_fraction': 0.7506202755740534, 'min_sum_hessian_in_leaf': 0.04198551343491146, 'reg_alpha': 2.33529984767458, 'reg_lambda': 0.026121069383243108} scored -15382.479200053418 in 0:00:01.332741\n[15:22:41] Training until validation scores don't improve for 200 rounds\n[15:22:43] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.6210054261265965, 'num_leaves': 239, 'bagging_fraction': 0.8010512826860656, 'min_sum_hessian_in_leaf': 0.046874497627887035, 'reg_alpha': 4.21717116224778, 'reg_lambda': 0.010934421114288863} scored -15600.197749732906 in 0:00:01.447371\n[15:22:43] Training until validation scores don't improve for 200 rounds\n[15:22:44] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.58429153807992, 'num_leaves': 251, 'bagging_fraction': 0.7340476315142893, 'min_sum_hessian_in_leaf': 0.03290825413381111, 'reg_alpha': 1.2273850677580778, 'reg_lambda': 0.0031092613383383733} scored -15243.383947649572 in 0:00:01.276981\n[15:22:44] Training until validation scores don't improve for 200 rounds\n[15:22:46] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.6426969785959243, 'num_leaves': 225, 'bagging_fraction': 0.7672881988508488, 'min_sum_hessian_in_leaf': 0.10654189816808607, 'reg_alpha': 1.0659486852916535, 'reg_lambda': 0.25198190323423} scored -15258.243823450855 in 0:00:01.541542\n[15:22:46] Training until validation scores don't improve for 200 rounds\n[15:22:47] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.5527285209359089, 'num_leaves': 231, 'bagging_fraction': 0.8518963809677829, 'min_sum_hessian_in_leaf': 0.05764622711907904, 'reg_alpha': 0.7857990265381426, 'reg_lambda': 0.13226651658031607} scored -15467.336471688035 in 0:00:01.364169\n[15:22:47] Training until validation scores don't improve for 200 rounds\n[15:22:48] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.5458515734860359, 'num_leaves': 210, 'bagging_fraction': 0.8224107225834472, 'min_sum_hessian_in_leaf': 0.12990467277498793, 'reg_alpha': 0.09713688611513685, 'reg_lambda': 0.513498874981699} scored -15512.339943910256 in 0:00:01.339671\n[15:22:48] Training until validation scores don't improve for 200 rounds\n[15:22:50] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.5914470290983054, 'num_leaves': 242, 'bagging_fraction': 0.7878638739250959, 'min_sum_hessian_in_leaf': 0.17786537786130224, 'reg_alpha': 0.3089313336041136, 'reg_lambda': 5.272944194842171e-08} scored -15449.357305021367 in 0:00:01.327099\n[15:22:50] Training until validation scores don't improve for 200 rounds\n[15:22:51] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.6225423642845312, 'num_leaves': 215, 'bagging_fraction': 0.7380489060980212, 'min_sum_hessian_in_leaf': 0.01710386152912048, 'reg_alpha': 4.380397096621905e-05, 'reg_lambda': 0.00859896881098473} scored -15323.151442307691 in 0:00:01.506792\n[15:22:51] Training until validation scores don't improve for 200 rounds\n[15:22:53] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.5152365441668901, 'num_leaves': 220, 'bagging_fraction': 0.7539902249716057, 'min_sum_hessian_in_leaf': 0.21672935064447366, 'reg_alpha': 0.0007933071322706236, 'reg_lambda': 0.021488256904190026} scored -15234.718716613248 in 0:00:01.369430\n[15:22:53] Training until validation scores don't improve for 200 rounds\n[15:22:54] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.5356893673925229, 'num_leaves': 191, 'bagging_fraction': 0.6971747268227675, 'min_sum_hessian_in_leaf': 0.08525487312979675, 'reg_alpha': 0.1734844317675224, 'reg_lambda': 0.056448432791829234} scored -15176.639857104701 in 0:00:01.412865\n[15:22:54] Training until validation scores don't improve for 200 rounds\n[15:22:55] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.5320510540908849, 'num_leaves': 191, 'bagging_fraction': 0.6613513502017492, 'min_sum_hessian_in_leaf': 0.06959092992470818, 'reg_alpha': 0.1594999141534107, 'reg_lambda': 0.06888614848072136} scored -15351.236845619658 in 0:00:01.364370\n[15:22:55] Training until validation scores don't improve for 200 rounds\n[15:22:57] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.5730482501588138, 'num_leaves': 205, 'bagging_fraction': 0.6964371486448135, 'min_sum_hessian_in_leaf': 0.05447273924881572, 'reg_alpha': 0.06577268648745059, 'reg_lambda': 0.04083546058089922} scored -15424.882211538461 in 0:00:01.206137\n[15:22:57] Training until validation scores don't improve for 200 rounds\n[15:23:00] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.54802264615572, 'num_leaves': 229, 'bagging_fraction': 0.7202894230436999, 'min_sum_hessian_in_leaf': 0.09798669688404926, 'reg_alpha': 0.5035518118678416, 'reg_lambda': 0.001444313276619763} scored -15205.730101495727 in 0:00:03.111260\n[15:23:00] Training until validation scores don't improve for 200 rounds\n[15:23:01] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.6025016231838521, 'num_leaves': 209, 'bagging_fraction': 0.7409995829980518, 'min_sum_hessian_in_leaf': 0.13491959900562553, 'reg_alpha': 0.23921002203300798, 'reg_lambda': 0.005107304096277677} scored -15222.13752003205 in 0:00:01.295297\n[15:23:01] Training until validation scores don't improve for 200 rounds\n[15:23:02] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.5660708363898519, 'num_leaves': 197, 'bagging_fraction': 0.7778917954462305, 'min_sum_hessian_in_leaf': 0.0765975431067998, 'reg_alpha': 0.7858684454324308, 'reg_lambda': 0.00022265029119360457} scored -15322.699452457266 in 0:00:01.433491\n[15:23:03] Training until validation scores don't improve for 200 rounds\n[15:23:04] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.5317414283446908, 'num_leaves': 188, 'bagging_fraction': 0.7028461477075154, 'min_sum_hessian_in_leaf': 0.3215574872797342, 'reg_alpha': 9.837542021234334, 'reg_lambda': 0.00041720553567038384} scored -15235.305422008547 in 0:00:01.430933\n[15:23:04] Training until validation scores don't improve for 200 rounds\n[15:23:05] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.5112953618148947, 'num_leaves': 222, 'bagging_fraction': 0.6798667776514812, 'min_sum_hessian_in_leaf': 0.16508483334702118, 'reg_alpha': 0.1236916371217504, 'reg_lambda': 0.38829458920937054} scored -15238.524272168803 in 0:00:01.279825\n[15:23:05] Training until validation scores don't improve for 200 rounds\n[15:23:07] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.5854843453323371, 'num_leaves': 173, 'bagging_fraction': 0.7665133514541527, 'min_sum_hessian_in_leaf': 0.029292429077057845, 'reg_alpha': 2.53447289630795, 'reg_lambda': 0.014150289211242397} scored -15275.519564636752 in 0:00:01.321910\n[15:23:07] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[15:23:07] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5582013958559682, 'num_leaves': 206, 'bagging_fraction': 0.7129500978973219, 'min_sum_hessian_in_leaf': 0.3700423111227362, 'reg_alpha': 0.005497082889618412, 'reg_lambda': 0.0002890816158837988}\u001b[0m\n achieve -15123.0660 mae\n[15:23:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:23:07] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:23:07] Training until validation scores don't improve for 100 rounds\n[15:23:07] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:23:07] Training until validation scores don't improve for 100 rounds\n[15:23:08] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:23:08] Training until validation scores don't improve for 100 rounds\n[15:23:08] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:23:08] Training until validation scores don't improve for 100 rounds\n[15:23:09] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:23:09] Training until validation scores don't improve for 100 rounds\n[15:23:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15679.099478943706\u001b[0m\n[15:23:09] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:23:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[15:23:10] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:23:10] 0:\tlearn: 54688.6804451\ttest: 52000.1091650\tbest: 52000.1091650 (0)\ttotal: 2.48ms\tremaining: 4.95s\n[15:23:11] Stopped by overfitting detector  (300 iterations wait)\n[15:23:11] bestTest = 15843.85602\n[15:23:11] bestIteration = 540\n[15:23:11] Shrink model to first 541 iterations.\n[15:23:11] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:23:11] 0:\tlearn: 53113.3480768\ttest: 56530.5650395\tbest: 56530.5650395 (0)\ttotal: 2.11ms\tremaining: 4.21s\n[15:23:12] Stopped by overfitting detector  (300 iterations wait)\n[15:23:12] bestTest = 15483.53443\n[15:23:12] bestIteration = 418\n[15:23:12] Shrink model to first 419 iterations.\n[15:23:12] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:23:13] 0:\tlearn: 54524.2764356\ttest: 52659.3206963\tbest: 52659.3206963 (0)\ttotal: 2.05ms\tremaining: 4.1s\n[15:23:14] Stopped by overfitting detector  (300 iterations wait)\n[15:23:14] bestTest = 11654.06884\n[15:23:14] bestIteration = 650\n[15:23:14] Shrink model to first 651 iterations.\n[15:23:14] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:23:14] 0:\tlearn: 53935.9946216\ttest: 56273.3124502\tbest: 56273.3124502 (0)\ttotal: 2.12ms\tremaining: 4.23s\n[15:23:16] Stopped by overfitting detector  (300 iterations wait)\n[15:23:16] bestTest = 18011.55035\n[15:23:16] bestIteration = 740\n[15:23:16] Shrink model to first 741 iterations.\n[15:23:16] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:23:16] 0:\tlearn: 54698.2984917\ttest: 54150.2025064\tbest: 54150.2025064 (0)\ttotal: 1.99ms\tremaining: 3.98s\n[15:23:18] Stopped by overfitting detector  (300 iterations wait)\n[15:23:18] bestTest = 15136.88068\n[15:23:18] bestIteration = 681\n[15:23:18] Shrink model to first 682 iterations.\n[15:23:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15223.669266374143\u001b[0m\n[15:23:18] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[15:23:18] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[15:23:18] 0:\tlearn: 54861.7071358\ttest: 52146.7340128\tbest: 52146.7340128 (0)\ttotal: 1.45ms\tremaining: 2.91s\n[15:23:19] Stopped by overfitting detector  (300 iterations wait)\n[15:23:19] bestTest = 16007.41602\n[15:23:19] bestIteration = 501\n[15:23:19] Shrink model to first 502 iterations.\n[15:23:19] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -16007.416466346154 in 0:00:01.183226\n[15:23:19] 0:\tlearn: 55046.9071805\ttest: 52218.3059347\tbest: 52218.3059347 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[15:23:20] Stopped by overfitting detector  (300 iterations wait)\n[15:23:20] bestTest = 15981.14075\n[15:23:20] bestIteration = 803\n[15:23:20] Shrink model to first 804 iterations.\n[15:23:20] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -15981.141025641025 in 0:00:01.222446\n[15:23:21] 0:\tlearn: 55046.8175552\ttest: 52218.2451308\tbest: 52218.2451308 (0)\ttotal: 1.23ms\tremaining: 2.45s\n[15:23:22] Stopped by overfitting detector  (300 iterations wait)\n[15:23:22] bestTest = 16237.5682\n[15:23:22] bestIteration = 1417\n[15:23:22] Shrink model to first 1418 iterations.\n[15:23:22] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -16237.568175747863 in 0:00:01.861674\n[15:23:22] 0:\tlearn: 55046.8202201\ttest: 52218.2469390\tbest: 52218.2469390 (0)\ttotal: 1.15ms\tremaining: 2.31s\n[15:23:24] Stopped by overfitting detector  (300 iterations wait)\n[15:23:24] bestTest = 16216.88249\n[15:23:24] bestIteration = 803\n[15:23:24] Shrink model to first 804 iterations.\n[15:23:24] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -16216.882678952992 in 0:00:01.227398\n[15:23:24] 0:\tlearn: 54584.0143305\ttest: 51974.5967494\tbest: 51974.5967494 (0)\ttotal: 3.36ms\tremaining: 6.72s\n[15:23:25] Stopped by overfitting detector  (300 iterations wait)\n[15:23:25] bestTest = 15439.37413\n[15:23:25] bestIteration = 437\n[15:23:25] Shrink model to first 438 iterations.\n[15:23:25] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -15439.374966613248 in 0:00:01.929202\n[15:23:26] 0:\tlearn: 54584.3170021\ttest: 51974.8289426\tbest: 51974.8289426 (0)\ttotal: 3ms\tremaining: 6.01s\n[15:23:29] Stopped by overfitting detector  (300 iterations wait)\n[15:23:29] bestTest = 15645.5368\n[15:23:29] bestIteration = 949\n[15:23:29] Shrink model to first 950 iterations.\n[15:23:29] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -15645.536658653846 in 0:00:03.214249\n[15:23:29] 0:\tlearn: 54702.9665468\ttest: 52111.6346262\tbest: 52111.6346262 (0)\ttotal: 2.94ms\tremaining: 5.88s\n[15:23:31] Stopped by overfitting detector  (300 iterations wait)\n[15:23:31] bestTest = 15780.69094\n[15:23:31] bestIteration = 336\n[15:23:31] Shrink model to first 337 iterations.\n[15:23:31] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -15780.690638354701 in 0:00:01.978085\n[15:23:31] 0:\tlearn: 54505.1639661\ttest: 51972.2459511\tbest: 51972.2459511 (0)\ttotal: 5.97ms\tremaining: 11.9s\n[15:23:33] Stopped by overfitting detector  (300 iterations wait)\n[15:23:33] bestTest = 15191.28071\n[15:23:33] bestIteration = 220\n[15:23:33] Shrink model to first 221 iterations.\n[15:23:33] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -15191.28094951923 in 0:00:02.129509\n[15:23:33] 0:\tlearn: 54759.5949342\ttest: 51985.2452086\tbest: 51985.2452086 (0)\ttotal: 1.15ms\tremaining: 2.3s\n[15:23:35] Stopped by overfitting detector  (300 iterations wait)\n[15:23:35] bestTest = 16393.85716\n[15:23:35] bestIteration = 1456\n[15:23:35] Shrink model to first 1457 iterations.\n[15:23:35] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -16393.856837606836 in 0:00:01.831842\n[15:23:35] 0:\tlearn: 54584.1300568\ttest: 51974.6855324\tbest: 51974.6855324 (0)\ttotal: 2.64ms\tremaining: 5.28s\n[15:23:37] Stopped by overfitting detector  (300 iterations wait)\n[15:23:37] bestTest = 15378.36394\n[15:23:37] bestIteration = 449\n[15:23:37] Shrink model to first 450 iterations.\n[15:23:37] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -15378.363848824787 in 0:00:01.946034\n[15:23:37] 0:\tlearn: 54502.1233514\ttest: 51970.7297689\tbest: 51970.7297689 (0)\ttotal: 4.22ms\tremaining: 8.44s\n[15:23:38] Stopped by overfitting detector  (300 iterations wait)\n[15:23:38] bestTest = 15107.34681\n[15:23:38] bestIteration = 181\n[15:23:38] Shrink model to first 182 iterations.\n[15:23:38] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 12} scored -15107.347021901709 in 0:00:01.840599\n[15:23:39] 0:\tlearn: 54502.1233519\ttest: 51970.7297691\tbest: 51970.7297691 (0)\ttotal: 3.83ms\tremaining: 7.67s\n[15:23:40] Stopped by overfitting detector  (300 iterations wait)\n[15:23:40] bestTest = 15107.34681\n[15:23:40] bestIteration = 181\n[15:23:40] Shrink model to first 182 iterations.\n[15:23:40] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3815073407783029e-08, 'min_data_in_leaf': 11} scored -15107.347021901709 in 0:00:01.829270\n[15:23:40] 0:\tlearn: 54502.1233519\ttest: 51970.7297691\tbest: 51970.7297691 (0)\ttotal: 3.72ms\tremaining: 7.43s\n[15:23:42] Stopped by overfitting detector  (300 iterations wait)\n[15:23:42] bestTest = 15107.34681\n[15:23:42] bestIteration = 181\n[15:23:42] Shrink model to first 182 iterations.\n[15:23:42] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3858728884475828e-08, 'min_data_in_leaf': 14} scored -15107.347021901709 in 0:00:01.890167\n[15:23:42] 0:\tlearn: 54502.1233530\ttest: 51970.7297697\tbest: 51970.7297697 (0)\ttotal: 3.83ms\tremaining: 7.65s\n[15:23:44] Stopped by overfitting detector  (300 iterations wait)\n[15:23:44] bestTest = 15107.34681\n[15:23:44] bestIteration = 181\n[15:23:44] Shrink model to first 182 iterations.\n[15:23:44] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.899122762406167e-08, 'min_data_in_leaf': 14} scored -15107.347021901709 in 0:00:01.832137\n[15:23:44] 0:\tlearn: 54687.8475713\ttest: 51999.5620461\tbest: 51999.5620461 (0)\ttotal: 1.91ms\tremaining: 3.83s\n[15:23:45] Stopped by overfitting detector  (300 iterations wait)\n[15:23:45] bestTest = 16023.48291\n[15:23:45] bestIteration = 309\n[15:23:45] Shrink model to first 310 iterations.\n[15:23:45] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 7.161723243485632e-07, 'min_data_in_leaf': 17} scored -16023.482905982906 in 0:00:01.237105\n[15:23:45] 0:\tlearn: 54687.8475439\ttest: 51999.5620281\tbest: 51999.5620281 (0)\ttotal: 1.9ms\tremaining: 3.81s\n[15:23:46] Stopped by overfitting detector  (300 iterations wait)\n[15:23:46] bestTest = 16023.48303\n[15:23:46] bestIteration = 309\n[15:23:46] Shrink model to first 310 iterations.\n[15:23:46] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.8794455088186337e-07, 'min_data_in_leaf': 12} scored -16023.482872596154 in 0:00:01.227865\n[15:23:47] 0:\tlearn: 54502.1233686\ttest: 51970.7297774\tbest: 51970.7297774 (0)\ttotal: 4.18ms\tremaining: 8.37s\n[15:23:48] Stopped by overfitting detector  (300 iterations wait)\n[15:23:48] bestTest = 15107.34681\n[15:23:48] bestIteration = 181\n[15:23:48] Shrink model to first 182 iterations.\n[15:23:48] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 9.247206024258267e-08, 'min_data_in_leaf': 9} scored -15107.347055288461 in 0:00:01.833093\n[15:23:49] 0:\tlearn: 54502.1250635\ttest: 51970.7306198\tbest: 51970.7306198 (0)\ttotal: 3.71ms\tremaining: 7.42s\n[15:23:50] Stopped by overfitting detector  (300 iterations wait)\n[15:23:50] bestTest = 15107.34586\n[15:23:50] bestIteration = 181\n[15:23:50] Shrink model to first 182 iterations.\n[15:23:50] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 8.061173629825617e-06, 'min_data_in_leaf': 12} scored -15107.345853365385 in 0:00:01.846103\n[15:23:50] 0:\tlearn: 54861.5702538\ttest: 52146.6695357\tbest: 52146.6695357 (0)\ttotal: 1.45ms\tremaining: 2.9s\n[15:23:52] Stopped by overfitting detector  (300 iterations wait)\n[15:23:52] bestTest = 15870.79044\n[15:23:52] bestIteration = 770\n[15:23:52] Shrink model to first 771 iterations.\n[15:23:52] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 6.608741458931454e-06, 'min_data_in_leaf': 20} scored -15870.790331196582 in 0:00:01.631972\n[15:23:52] 0:\tlearn: 54602.6217382\ttest: 51988.8264207\tbest: 51988.8264207 (0)\ttotal: 2.8ms\tremaining: 5.61s\n[15:23:53] Stopped by overfitting detector  (300 iterations wait)\n[15:23:53] bestTest = 15762.87228\n[15:23:53] bestIteration = 184\n[15:23:53] Shrink model to first 185 iterations.\n[15:23:53] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.13782251757945607, 'min_data_in_leaf': 17} scored -15762.872262286324 in 0:00:01.330885\n[15:23:54] 0:\tlearn: 54687.8483794\ttest: 51999.5625758\tbest: 51999.5625758 (0)\ttotal: 1.88ms\tremaining: 3.75s\n[15:23:55] Stopped by overfitting detector  (300 iterations wait)\n[15:23:55] bestTest = 16023.47951\n[15:23:55] bestIteration = 309\n[15:23:55] Shrink model to first 310 iterations.\n[15:23:55] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0385996327356297e-05, 'min_data_in_leaf': 12} scored -16023.478999732906 in 0:00:01.527080\n[15:23:55] 0:\tlearn: 54502.1233648\ttest: 51970.7297755\tbest: 51970.7297755 (0)\ttotal: 3.75ms\tremaining: 7.5s\n[15:23:57] Stopped by overfitting detector  (300 iterations wait)\n[15:23:57] bestTest = 15107.34681\n[15:23:57] bestIteration = 181\n[15:23:57] Shrink model to first 182 iterations.\n[15:23:57] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 7.434738957851517e-08, 'min_data_in_leaf': 12} scored -15107.347055288461 in 0:00:01.858190\n[15:23:57] 0:\tlearn: 54502.1238834\ttest: 51970.7300333\tbest: 51970.7300333 (0)\ttotal: 3.71ms\tremaining: 7.41s\n[15:23:58] Stopped by overfitting detector  (300 iterations wait)\n[15:23:58] bestTest = 15107.34652\n[15:23:58] bestIteration = 181\n[15:23:58] Shrink model to first 182 iterations.\n[15:23:58] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.5126366362517494e-06, 'min_data_in_leaf': 7} scored -15107.347055288461 in 0:00:01.877280\n[15:23:59] 0:\tlearn: 54502.1233619\ttest: 51970.7297741\tbest: 51970.7297741 (0)\ttotal: 3.7ms\tremaining: 7.39s\n[15:24:00] Stopped by overfitting detector  (300 iterations wait)\n[15:24:00] bestTest = 15107.34681\n[15:24:00] bestIteration = 181\n[15:24:00] Shrink model to first 182 iterations.\n[15:24:00] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.107224041802643e-08, 'min_data_in_leaf': 11} scored -15107.347055288461 in 0:00:01.845279\n[15:24:00] 0:\tlearn: 54584.0115077\ttest: 51974.5945838\tbest: 51974.5945838 (0)\ttotal: 2.72ms\tremaining: 5.43s\n[15:24:01] Stopped by overfitting detector  (300 iterations wait)\n[15:24:01] bestTest = 15649.75704\n[15:24:01] bestIteration = 95\n[15:24:01] Shrink model to first 96 iterations.\n[15:24:01] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0779341786421853e-08, 'min_data_in_leaf': 16} scored -15649.757111378205 in 0:00:01.159084\n[15:24:02] 0:\tlearn: 54502.1234004\ttest: 51970.7297932\tbest: 51970.7297932 (0)\ttotal: 3.67ms\tremaining: 7.34s\n[15:24:04] Stopped by overfitting detector  (300 iterations wait)\n[15:24:04] bestTest = 15107.34679\n[15:24:04] bestIteration = 181\n[15:24:04] Shrink model to first 182 iterations.\n[15:24:04] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.420438089315928e-07, 'min_data_in_leaf': 13} scored -15107.34718883547 in 0:00:02.335494\n[15:24:04] 0:\tlearn: 54584.0271839\ttest: 51974.6066105\tbest: 51974.6066105 (0)\ttotal: 2.55ms\tremaining: 5.11s\n[15:24:06] Stopped by overfitting detector  (300 iterations wait)\n[15:24:06] bestTest = 15463.10443\n[15:24:06] bestIteration = 348\n[15:24:06] Shrink model to first 349 iterations.\n[15:24:06] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00011006259361537608, 'min_data_in_leaf': 8} scored -15463.104300213676 in 0:00:01.732699\n[15:24:06] 0:\tlearn: 54502.1238211\ttest: 51970.7300023\tbest: 51970.7300023 (0)\ttotal: 3.65ms\tremaining: 7.3s\n[15:24:07] Stopped by overfitting detector  (300 iterations wait)\n[15:24:07] bestTest = 15107.34655\n[15:24:07] bestIteration = 181\n[15:24:07] Shrink model to first 182 iterations.\n[15:24:07] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.2200229928511808e-06, 'min_data_in_leaf': 11} scored -15107.346788194445 in 0:00:01.867221\n[15:24:08] 0:\tlearn: 54861.5730104\ttest: 52146.6708332\tbest: 52146.6708332 (0)\ttotal: 1.47ms\tremaining: 2.95s\n[15:24:09] Stopped by overfitting detector  (300 iterations wait)\n[15:24:09] bestTest = 15870.79403\n[15:24:09] bestIteration = 770\n[15:24:09] Shrink model to first 771 iterations.\n[15:24:09] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.5639169845452935e-05, 'min_data_in_leaf': 10} scored -15870.79407051282 in 0:00:01.593353\n[15:24:09] 0:\tlearn: 54584.0118255\ttest: 51974.5948275\tbest: 51974.5948275 (0)\ttotal: 2.67ms\tremaining: 5.33s\n[15:24:10] Stopped by overfitting detector  (300 iterations wait)\n[15:24:10] bestTest = 15649.75614\n[15:24:10] bestIteration = 95\n[15:24:10] Shrink model to first 96 iterations.\n[15:24:10] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 2.2414664619199712e-06, 'min_data_in_leaf': 18} scored -15649.75610977564 in 0:00:01.123690\n[15:24:10] 0:\tlearn: 54502.1945464\ttest: 51970.7651568\tbest: 51970.7651568 (0)\ttotal: 3.61ms\tremaining: 7.21s\n[15:24:12] Stopped by overfitting detector  (300 iterations wait)\n[15:24:12] bestTest = 15107.30698\n[15:24:12] bestIteration = 181\n[15:24:12] Shrink model to first 182 iterations.\n[15:24:12] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.000334794324006071, 'min_data_in_leaf': 14} scored -15107.307224893162 in 0:00:01.896506\n[15:24:12] 0:\tlearn: 54502.2039644\ttest: 51970.7698386\tbest: 51970.7698386 (0)\ttotal: 3.63ms\tremaining: 7.25s\n[15:24:14] Stopped by overfitting detector  (300 iterations wait)\n[15:24:14] bestTest = 15107.30172\n[15:24:14] bestIteration = 181\n[15:24:14] Shrink model to first 182 iterations.\n[15:24:14] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00037908895278569623, 'min_data_in_leaf': 14} scored -15107.30171607906 in 0:00:01.819200\n[15:24:14] 0:\tlearn: 54502.2375980\ttest: 51970.7865586\tbest: 51970.7865586 (0)\ttotal: 3.62ms\tremaining: 7.24s\n[15:24:16] Stopped by overfitting detector  (300 iterations wait)\n[15:24:16] bestTest = 15107.28291\n[15:24:16] bestIteration = 181\n[15:24:16] Shrink model to first 182 iterations.\n[15:24:16] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.000537288176441148, 'min_data_in_leaf': 14} scored -15107.282752403846 in 0:00:01.847443\n[15:24:16] 0:\tlearn: 54502.2196953\ttest: 51970.7776586\tbest: 51970.7776586 (0)\ttotal: 3.64ms\tremaining: 7.29s\n[15:24:18] Stopped by overfitting detector  (300 iterations wait)\n[15:24:18] bestTest = 15107.29292\n[15:24:18] bestIteration = 181\n[15:24:18] Shrink model to first 182 iterations.\n[15:24:18] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0004530781170200388, 'min_data_in_leaf': 15} scored -15107.293035523504 in 0:00:01.818207\n[15:24:18] 0:\tlearn: 54502.2128870\ttest: 51970.7742741\tbest: 51970.7742741 (0)\ttotal: 3.62ms\tremaining: 7.24s\n[15:24:21] Stopped by overfitting detector  (300 iterations wait)\n[15:24:21] bestTest = 15529.19338\n[15:24:21] bestIteration = 548\n[15:24:21] Shrink model to first 549 iterations.\n[15:24:21] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0004210551484183283, 'min_data_in_leaf': 14} scored -15529.192875267094 in 0:00:03.111440\n[15:24:21] 0:\tlearn: 54586.2124293\ttest: 51976.2822541\tbest: 51976.2822541 (0)\ttotal: 2.58ms\tremaining: 5.15s\n[15:24:22] Stopped by overfitting detector  (300 iterations wait)\n[15:24:22] bestTest = 15561.89955\n[15:24:22] bestIteration = 260\n[15:24:22] Shrink model to first 261 iterations.\n[15:24:22] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.01554993565295892, 'min_data_in_leaf': 15} scored -15561.899272168803 in 0:00:01.540671\n[15:24:22] 0:\tlearn: 54585.7393383\ttest: 51975.9196321\tbest: 51975.9196321 (0)\ttotal: 2.53ms\tremaining: 5.06s\n[15:24:24] Stopped by overfitting detector  (300 iterations wait)\n[15:24:24] bestTest = 15566.4408\n[15:24:24] bestIteration = 184\n[15:24:24] Shrink model to first 185 iterations.\n[15:24:24] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.012190665805447615, 'min_data_in_leaf': 16} scored -15566.440738514957 in 0:00:01.327283\n[15:24:24] 0:\tlearn: 54502.1706533\ttest: 51970.7532800\tbest: 51970.7532800 (0)\ttotal: 5.58ms\tremaining: 11.2s\n[15:24:25] Stopped by overfitting detector  (300 iterations wait)\n[15:24:25] bestTest = 15107.32035\n[15:24:25] bestIteration = 181\n[15:24:25] Shrink model to first 182 iterations.\n[15:24:25] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00022242943290850758, 'min_data_in_leaf': 15} scored -15107.320345886752 in 0:00:01.832115\n[15:24:26] 0:\tlearn: 54584.2535085\ttest: 51974.7802366\tbest: 51974.7802366 (0)\ttotal: 2.63ms\tremaining: 5.26s\n[15:24:27] Stopped by overfitting detector  (300 iterations wait)\n[15:24:27] bestTest = 15606.34644\n[15:24:27] bestIteration = 177\n[15:24:27] Shrink model to first 178 iterations.\n[15:24:27] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0017000620870549256, 'min_data_in_leaf': 19} scored -15606.346654647436 in 0:00:01.296359\n[15:24:27] 0:\tlearn: 54502.1311339\ttest: 51970.7336369\tbest: 51970.7336369 (0)\ttotal: 3.74ms\tremaining: 7.47s\n[15:24:34] Stopped by overfitting detector  (300 iterations wait)\n[15:24:34] bestTest = 15478.46308\n[15:24:34] bestIteration = 1629\n[15:24:34] Shrink model to first 1630 iterations.\n[15:24:34] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 3.660219149046079e-05, 'min_data_in_leaf': 16} scored -15478.46297409188 in 0:00:06.956974\n[15:24:34] 0:\tlearn: 54584.6313450\ttest: 51975.0700532\tbest: 51975.0700532 (0)\ttotal: 2.58ms\tremaining: 5.16s\n[15:24:35] Stopped by overfitting detector  (300 iterations wait)\n[15:24:35] bestTest = 15525.73701\n[15:24:35] bestIteration = 247\n[15:24:35] Shrink model to first 248 iterations.\n[15:24:35] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00435915907134356, 'min_data_in_leaf': 18} scored -15525.73671207265 in 0:00:01.720792\n[15:24:36] 0:\tlearn: 54502.1618003\ttest: 51970.7488795\tbest: 51970.7488795 (0)\ttotal: 4.49ms\tremaining: 8.98s\n[15:24:37] Stopped by overfitting detector  (300 iterations wait)\n[15:24:37] bestTest = 15107.3253\n[15:24:37] bestIteration = 181\n[15:24:37] Shrink model to first 182 iterations.\n[15:24:37] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00018079831411475973, 'min_data_in_leaf': 15} scored -15107.32468616453 in 0:00:01.978261\n[15:24:38] 0:\tlearn: 54502.2261408\ttest: 51970.7808628\tbest: 51970.7808628 (0)\ttotal: 3.66ms\tremaining: 7.32s\n[15:24:39] Stopped by overfitting detector  (300 iterations wait)\n[15:24:39] bestTest = 15107.28932\n[15:24:39] bestIteration = 181\n[15:24:39] Shrink model to first 182 iterations.\n[15:24:40] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00048339568717653764, 'min_data_in_leaf': 15} scored -15107.289830395299 in 0:00:02.073139\n[15:24:40] 0:\tlearn: 54502.2596456\ttest: 51970.7975196\tbest: 51970.7975196 (0)\ttotal: 3.6ms\tremaining: 7.19s\n[15:24:41] Stopped by overfitting detector  (300 iterations wait)\n[15:24:41] bestTest = 15107.27059\n[15:24:41] bestIteration = 181\n[15:24:41] Shrink model to first 182 iterations.\n[15:24:41] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.000641004399813547, 'min_data_in_leaf': 17} scored -15107.270365918803 in 0:00:01.852401\n[15:24:42] 0:\tlearn: 54503.1871144\ttest: 51971.2590832\tbest: 51971.2590832 (0)\ttotal: 3.81ms\tremaining: 7.62s\n[15:24:44] Stopped by overfitting detector  (300 iterations wait)\n[15:24:44] bestTest = 15021.67865\n[15:24:44] bestIteration = 368\n[15:24:44] Shrink model to first 369 iterations.\n[15:24:44] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.005013064020439869, 'min_data_in_leaf': 17} scored -15021.678452190172 in 0:00:02.493968\n[15:24:44] 0:\tlearn: 54520.0392331\ttest: 51979.8074512\tbest: 51979.8074512 (0)\ttotal: 3.71ms\tremaining: 7.41s\n[15:24:47] Stopped by overfitting detector  (300 iterations wait)\n[15:24:47] bestTest = 15395.99072\n[15:24:47] bestIteration = 506\n[15:24:47] Shrink model to first 507 iterations.\n[15:24:47] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.08759105189424689, 'min_data_in_leaf': 18} scored -15395.990451388889 in 0:00:02.945269\n[15:24:47] 0:\tlearn: 55046.9787889\ttest: 52218.3545045\tbest: 52218.3545045 (0)\ttotal: 1.19ms\tremaining: 2.38s\n[15:24:49] Stopped by overfitting detector  (300 iterations wait)\n[15:24:49] bestTest = 16262.24727\n[15:24:49] bestIteration = 1308\n[15:24:49] Shrink model to first 1309 iterations.\n[15:24:49] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0046261098071806546, 'min_data_in_leaf': 17} scored -16262.247596153846 in 0:00:01.699324\n[15:24:49] 0:\tlearn: 54502.3487279\ttest: 51970.8418124\tbest: 51970.8418124 (0)\ttotal: 3.63ms\tremaining: 7.25s\n[15:24:52] Stopped by overfitting detector  (300 iterations wait)\n[15:24:52] bestTest = 15536.11087\n[15:24:52] bestIteration = 518\n[15:24:52] Shrink model to first 519 iterations.\n[15:24:52] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0010601657712446002, 'min_data_in_leaf': 16} scored -15536.111478365385 in 0:00:03.034882\n[15:24:52] 0:\tlearn: 54586.8695678\ttest: 51976.7858226\tbest: 51976.7858226 (0)\ttotal: 3.26ms\tremaining: 6.51s\n[15:24:53] Stopped by overfitting detector  (300 iterations wait)\n[15:24:53] bestTest = 15719.56332\n[15:24:53] bestIteration = 387\n[15:24:53] Shrink model to first 388 iterations.\n[15:24:53] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.020231352665292673, 'min_data_in_leaf': 19} scored -15719.563334668803 in 0:00:01.802754\n[15:24:54] 0:\tlearn: 54511.0459065\ttest: 51975.2071430\tbest: 51975.2071430 (0)\ttotal: 3.71ms\tremaining: 7.42s\n[15:24:56] Stopped by overfitting detector  (300 iterations wait)\n[15:24:56] bestTest = 15242.02205\n[15:24:56] bestIteration = 277\n[15:24:56] Shrink model to first 278 iterations.\n[15:24:56] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0427764393076223, 'min_data_in_leaf': 13} scored -15242.022235576924 in 0:00:02.145869\n[15:24:56] 0:\tlearn: 54687.9212588\ttest: 51999.6103677\tbest: 51999.6103677 (0)\ttotal: 1.85ms\tremaining: 3.71s\n[15:24:57] Stopped by overfitting detector  (300 iterations wait)\n[15:24:57] bestTest = 16058.64537\n[15:24:57] bestIteration = 562\n[15:24:57] Shrink model to first 563 iterations.\n[15:24:57] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0008827983030940715, 'min_data_in_leaf': 1} scored -16056.07532051282 in 0:00:01.686381\n[15:24:57] 0:\tlearn: 54502.9468995\ttest: 51971.1394499\tbest: 51971.1394499 (0)\ttotal: 3.63ms\tremaining: 7.25s\n[15:24:59] Stopped by overfitting detector  (300 iterations wait)\n[15:24:59] bestTest = 15110.14059\n[15:24:59] bestIteration = 179\n[15:24:59] Shrink model to first 180 iterations.\n[15:24:59] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0038789959999928065, 'min_data_in_leaf': 13} scored -15110.140090811965 in 0:00:01.818380\n[15:24:59] 0:\tlearn: 54502.2331581\ttest: 51970.7843513\tbest: 51970.7843513 (0)\ttotal: 3.63ms\tremaining: 7.26s\n[15:25:01] Stopped by overfitting detector  (300 iterations wait)\n[15:25:01] bestTest = 15107.28539\n[15:25:01] bestIteration = 181\n[15:25:01] Shrink model to first 182 iterations.\n[15:25:01] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0005164033456689108, 'min_data_in_leaf': 17} scored -15107.284755608975 in 0:00:01.832191\n[15:25:01] 0:\tlearn: 54566.0910813\ttest: 51973.5869003\tbest: 51973.5869003 (0)\ttotal: 3.57ms\tremaining: 7.14s\n[15:25:03] Stopped by overfitting detector  (300 iterations wait)\n[15:25:03] bestTest = 15548.6984\n[15:25:03] bestIteration = 329\n[15:25:03] Shrink model to first 330 iterations.\n[15:25:03] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.43587356584516207, 'min_data_in_leaf': 17} scored -15548.698083600428 in 0:00:02.385574\n[15:25:03] 0:\tlearn: 54502.1464510\ttest: 51970.7412501\tbest: 51970.7412501 (0)\ttotal: 3.68ms\tremaining: 7.36s\n[15:25:05] Stopped by overfitting detector  (300 iterations wait)\n[15:25:05] bestTest = 15107.33389\n[15:25:05] bestIteration = 181\n[15:25:05] Shrink model to first 182 iterations.\n[15:25:05] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00010862219261246065, 'min_data_in_leaf': 19} scored -15107.333800747863 in 0:00:01.832014\n[15:25:05] 0:\tlearn: 54502.1293148\ttest: 51970.7327328\tbest: 51970.7327328 (0)\ttotal: 3.62ms\tremaining: 7.23s\n[15:25:07] Stopped by overfitting detector  (300 iterations wait)\n[15:25:07] bestTest = 15107.34348\n[15:25:07] bestIteration = 181\n[15:25:07] Shrink model to first 182 iterations.\n[15:25:07] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.8049408008753074e-05, 'min_data_in_leaf': 15} scored -15107.343516292734 in 0:00:01.956182\n[15:25:07] 0:\tlearn: 54502.5425331\ttest: 51970.9382040\tbest: 51970.9382040 (0)\ttotal: 4.63ms\tremaining: 9.26s\n[15:25:09] Stopped by overfitting detector  (300 iterations wait)\n[15:25:09] bestTest = 15095.58753\n[15:25:09] bestIteration = 241\n[15:25:09] Shrink model to first 242 iterations.\n[15:25:09] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0019726479441021885, 'min_data_in_leaf': 17} scored -15095.587473290598 in 0:00:02.336804\n[15:25:10] 0:\tlearn: 54584.2390727\ttest: 51974.7691627\tbest: 51974.7691627 (0)\ttotal: 3.26ms\tremaining: 6.52s\n[15:25:11] Stopped by overfitting detector  (300 iterations wait)\n[15:25:11] bestTest = 15606.38681\n[15:25:11] bestIteration = 177\n[15:25:11] Shrink model to first 178 iterations.\n[15:25:11] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0015985833452637401, 'min_data_in_leaf': 18} scored -15606.386485042734 in 0:00:01.593114\n[15:25:11] 0:\tlearn: 54503.6154137\ttest: 51971.4725405\tbest: 51971.4725405 (0)\ttotal: 8.2ms\tremaining: 16.4s\n[15:25:14] Stopped by overfitting detector  (300 iterations wait)\n[15:25:14] bestTest = 14964.27418\n[15:25:14] bestIteration = 285\n[15:25:14] Shrink model to first 286 iterations.\n[15:25:14] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007038045572248034, 'min_data_in_leaf': 20} scored -14964.274272168803 in 0:00:02.633133\n[15:25:14] 0:\tlearn: 54503.9992332\ttest: 51971.6639964\tbest: 51971.6639964 (0)\ttotal: 3.77ms\tremaining: 7.54s\n[15:25:17] Stopped by overfitting detector  (300 iterations wait)\n[15:25:17] bestTest = 15026.02224\n[15:25:17] bestIteration = 479\n[15:25:17] Shrink model to first 480 iterations.\n[15:25:17] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.008855950023807853, 'min_data_in_leaf': 20} scored -15026.021901709402 in 0:00:02.901607\n[15:25:17] 0:\tlearn: 54585.2194531\ttest: 51975.5210530\tbest: 51975.5210530 (0)\ttotal: 2.56ms\tremaining: 5.12s\n[15:25:18] Stopped by overfitting detector  (300 iterations wait)\n[15:25:18] bestTest = 15413.77945\n[15:25:18] bestIteration = 299\n[15:25:18] Shrink model to first 300 iterations.\n[15:25:18] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.008509739158363354, 'min_data_in_leaf': 20} scored -15413.778879540598 in 0:00:01.603878\n[15:25:18] 0:\tlearn: 54503.2488102\ttest: 51971.2898194\tbest: 51971.2898194 (0)\ttotal: 3.85ms\tremaining: 7.7s\n[15:25:21] Stopped by overfitting detector  (300 iterations wait)\n[15:25:21] bestTest = 15073.22845\n[15:25:21] bestIteration = 432\n[15:25:21] Shrink model to first 433 iterations.\n[15:25:21] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.005304525993665025, 'min_data_in_leaf': 19} scored -15073.228665865385 in 0:00:02.688048\n[15:25:21] 0:\tlearn: 54513.0501434\ttest: 51976.2247070\tbest: 51976.2247070 (0)\ttotal: 3.68ms\tremaining: 7.35s\n[15:25:23] Stopped by overfitting detector  (300 iterations wait)\n[15:25:23] bestTest = 15329.92936\n[15:25:23] bestIteration = 324\n[15:25:23] Shrink model to first 325 iterations.\n[15:25:23] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.052614613060455825, 'min_data_in_leaf': 19} scored -15329.929487179486 in 0:00:02.376861\n[15:25:24] 0:\tlearn: 54503.5746955\ttest: 51971.4522388\tbest: 51971.4522388 (0)\ttotal: 3.71ms\tremaining: 7.41s\n[15:25:26] Stopped by overfitting detector  (300 iterations wait)\n[15:25:26] bestTest = 14955.21203\n[15:25:26] bestIteration = 332\n[15:25:26] Shrink model to first 333 iterations.\n[15:25:26] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006845368711687715, 'min_data_in_leaf': 20} scored -14955.211772168803 in 0:00:02.352027\n[15:25:26] 0:\tlearn: 54508.5489432\ttest: 51973.9455155\tbest: 51973.9455155 (0)\ttotal: 3.66ms\tremaining: 7.31s\n[15:25:28] Stopped by overfitting detector  (300 iterations wait)\n[15:25:28] bestTest = 15363.22568\n[15:25:28] bestIteration = 223\n[15:25:28] Shrink model to first 224 iterations.\n[15:25:28] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.030638072602739895, 'min_data_in_leaf': 20} scored -15363.22576121795 in 0:00:02.007942\n[15:25:28] 0:\tlearn: 54549.3238182\ttest: 51995.4115452\tbest: 51995.4115452 (0)\ttotal: 3.83ms\tremaining: 7.65s\n[15:25:30] Stopped by overfitting detector  (300 iterations wait)\n[15:25:30] bestTest = 15477.05363\n[15:25:30] bestIteration = 433\n[15:25:30] Shrink model to first 434 iterations.\n[15:25:30] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.24583386733541468, 'min_data_in_leaf': 20} scored -15477.054019764957 in 0:00:02.732242\n[15:25:31] 0:\tlearn: 54503.6841092\ttest: 51971.5067955\tbest: 51971.5067955 (0)\ttotal: 3.83ms\tremaining: 7.66s\n[15:25:33] Stopped by overfitting detector  (300 iterations wait)\n[15:25:33] bestTest = 14964.22234\n[15:25:33] bestIteration = 285\n[15:25:33] Shrink model to first 286 iterations.\n[15:25:33] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007363187882362319, 'min_data_in_leaf': 19} scored -14964.222689636752 in 0:00:02.535530\n[15:25:33] 0:\tlearn: 54503.6935894\ttest: 51971.5115231\tbest: 51971.5115231 (0)\ttotal: 3.69ms\tremaining: 7.38s\n[15:25:35] Stopped by overfitting detector  (300 iterations wait)\n[15:25:35] bestTest = 14964.21519\n[15:25:35] bestIteration = 285\n[15:25:35] Shrink model to first 286 iterations.\n[15:25:35] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007408066280167389, 'min_data_in_leaf': 19} scored -14964.214910523504 in 0:00:02.196510\n[15:25:35] 0:\tlearn: 54861.9165242\ttest: 52146.8328392\tbest: 52146.8328392 (0)\ttotal: 1.5ms\tremaining: 3s\n[15:25:37] Stopped by overfitting detector  (300 iterations wait)\n[15:25:37] bestTest = 15932.19759\n[15:25:37] bestIteration = 767\n[15:25:37] Shrink model to first 768 iterations.\n[15:25:37] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006176987163784839, 'min_data_in_leaf': 19} scored -15932.197916666666 in 0:00:01.543014\n[15:25:37] 0:\tlearn: 54636.3073955\ttest: 52025.1825519\tbest: 52025.1825519 (0)\ttotal: 4.01ms\tremaining: 8.01s\n[15:25:39] Stopped by overfitting detector  (300 iterations wait)\n[15:25:39] bestTest = 15601.69144\n[15:25:39] bestIteration = 261\n[15:25:39] Shrink model to first 262 iterations.\n[15:25:39] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0516008326233972, 'min_data_in_leaf': 20} scored -15601.691639957266 in 0:00:02.124252\n[15:25:39] 0:\tlearn: 55093.6142391\ttest: 52319.9326267\tbest: 52319.9326267 (0)\ttotal: 4.53ms\tremaining: 9.05s\n[15:25:43] Stopped by overfitting detector  (300 iterations wait)\n[15:25:43] bestTest = 15861.41625\n[15:25:43] bestIteration = 624\n[15:25:43] Shrink model to first 625 iterations.\n[15:25:43] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 9.722286010927427, 'min_data_in_leaf': 19} scored -15861.41626602564 in 0:00:03.874898\n[15:25:43] 0:\tlearn: 54502.7004237\ttest: 51971.0167625\tbest: 51971.0167625 (0)\ttotal: 3.71ms\tremaining: 7.42s\n[15:25:46] Stopped by overfitting detector  (300 iterations wait)\n[15:25:46] bestTest = 14994.05758\n[15:25:46] bestIteration = 450\n[15:25:46] Shrink model to first 451 iterations.\n[15:25:46] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00271660723344596, 'min_data_in_leaf': 18} scored -14994.057158119658 in 0:00:02.794300\n[15:25:46] 0:\tlearn: 54504.1302966\ttest: 51971.7294092\tbest: 51971.7294092 (0)\ttotal: 3.92ms\tremaining: 7.83s\n[15:25:50] Stopped by overfitting detector  (300 iterations wait)\n[15:25:50] bestTest = 15059.33204\n[15:25:50] bestIteration = 903\n[15:25:50] Shrink model to first 904 iterations.\n[15:25:50] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.009477410756476387, 'min_data_in_leaf': 18} scored -15059.332064636752 in 0:00:04.396154\n[15:25:50] 0:\tlearn: 54503.9833765\ttest: 51971.6560837\tbest: 51971.6560837 (0)\ttotal: 4ms\tremaining: 7.99s\n[15:25:53] Stopped by overfitting detector  (300 iterations wait)\n[15:25:53] bestTest = 15026.03175\n[15:25:53] bestIteration = 479\n[15:25:53] Shrink model to first 480 iterations.\n[15:25:53] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00878078642926287, 'min_data_in_leaf': 18} scored -15026.031951121795 in 0:00:03.020202\n[15:25:53] 0:\tlearn: 54519.3222507\ttest: 51979.4374432\tbest: 51979.4374432 (0)\ttotal: 3.71ms\tremaining: 7.42s\n[15:25:56] Stopped by overfitting detector  (300 iterations wait)\n[15:25:56] bestTest = 15219.09792\n[15:25:56] bestIteration = 418\n[15:25:56] Shrink model to first 419 iterations.\n[15:25:56] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.08395473393771687, 'min_data_in_leaf': 20} scored -15219.098023504273 in 0:00:02.733971\n[15:25:56] 0:\tlearn: 54502.7150521\ttest: 51971.0240423\tbest: 51971.0240423 (0)\ttotal: 3.71ms\tremaining: 7.42s\n[15:25:59] Stopped by overfitting detector  (300 iterations wait)\n[15:25:59] bestTest = 14978.30114\n[15:25:59] bestIteration = 659\n[15:25:59] Shrink model to first 660 iterations.\n[15:25:59] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0027855604364965692, 'min_data_in_leaf': 18} scored -14978.301382211539 in 0:00:03.515303\n[15:26:00] 0:\tlearn: 54502.6438642\ttest: 51970.9886183\tbest: 51970.9886183 (0)\ttotal: 3.69ms\tremaining: 7.38s\n[15:26:05] Stopped by overfitting detector  (300 iterations wait)\n[15:26:05] bestTest = 15012.73025\n[15:26:05] bestIteration = 1256\n[15:26:05] Shrink model to first 1257 iterations.\n[15:26:05] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024500474381020246, 'min_data_in_leaf': 2} scored -15012.729734241453 in 0:00:05.819448\n[15:26:05] 0:\tlearn: 54502.7742926\ttest: 51971.0535252\tbest: 51971.0535252 (0)\ttotal: 3.72ms\tremaining: 7.43s\n[15:26:07] Stopped by overfitting detector  (300 iterations wait)\n[15:26:07] bestTest = 15069.97621\n[15:26:07] bestIteration = 250\n[15:26:07] Shrink model to first 251 iterations.\n[15:26:07] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0030648440976521903, 'min_data_in_leaf': 4} scored -15069.975694444445 in 0:00:02.107016\n[15:26:07] 0:\tlearn: 54587.2692130\ttest: 51977.0920037\tbest: 51977.0920037 (0)\ttotal: 2.62ms\tremaining: 5.24s\n[15:26:09] Stopped by overfitting detector  (300 iterations wait)\n[15:26:09] bestTest = 15419.43245\n[15:26:09] bestIteration = 324\n[15:26:09] Shrink model to first 325 iterations.\n[15:26:09] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.02308710236439206, 'min_data_in_leaf': 2} scored -15419.432725694445 in 0:00:01.700006\n[15:26:09] 0:\tlearn: 54688.0656290\ttest: 51999.7050878\tbest: 51999.7050878 (0)\ttotal: 1.96ms\tremaining: 3.91s\n[15:26:11] Stopped by overfitting detector  (300 iterations wait)\n[15:26:11] bestTest = 16057.99989\n[15:26:11] bestIteration = 562\n[15:26:11] Shrink model to first 563 iterations.\n[15:26:11] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0026124511115721925, 'min_data_in_leaf': 7} scored -16055.433493589744 in 0:00:01.703708\n[15:26:11] 0:\tlearn: 54502.3662482\ttest: 51970.8505248\tbest: 51970.8505248 (0)\ttotal: 3.7ms\tremaining: 7.4s\n[15:26:13] Stopped by overfitting detector  (300 iterations wait)\n[15:26:13] bestTest = 15056.96659\n[15:26:13] bestIteration = 285\n[15:26:13] Shrink model to first 286 iterations.\n[15:26:13] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.001142623902347238, 'min_data_in_leaf': 3} scored -15056.967013888889 in 0:00:02.685996\n[15:26:14] 0:\tlearn: 54505.2128708\ttest: 51972.2704180\tbest: 51972.2704180 (0)\ttotal: 3.68ms\tremaining: 7.36s\n[15:26:15] Stopped by overfitting detector  (300 iterations wait)\n[15:26:15] bestTest = 15191.22583\n[15:26:15] bestIteration = 220\n[15:26:15] Shrink model to first 221 iterations.\n[15:26:15] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014624237361809178, 'min_data_in_leaf': 5} scored -15191.225861378205 in 0:00:02.034207\n[15:26:16] 0:\tlearn: 54509.0785971\ttest: 51974.2125671\tbest: 51974.2125671 (0)\ttotal: 3.74ms\tremaining: 7.49s\n[15:26:18] Stopped by overfitting detector  (300 iterations wait)\n[15:26:18] bestTest = 15381.14959\n[15:26:18] bestIteration = 474\n[15:26:18] Shrink model to first 475 iterations.\n[15:26:18] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.033201909772854615, 'min_data_in_leaf': 20} scored -15381.149806356838 in 0:00:02.910640\n[15:26:19] 0:\tlearn: 54502.6331088\ttest: 51970.9832667\tbest: 51970.9832667 (0)\ttotal: 3.71ms\tremaining: 7.41s\n[15:26:23] Stopped by overfitting detector  (300 iterations wait)\n[15:26:23] bestTest = 15017.89356\n[15:26:23] bestIteration = 852\n[15:26:23] Shrink model to first 853 iterations.\n[15:26:23] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0023993654522541036, 'min_data_in_leaf': 19} scored -15017.893696581197 in 0:00:04.305093\n[15:26:23] 0:\tlearn: 54502.6845752\ttest: 51971.0088759\tbest: 51971.0088759 (0)\ttotal: 3.71ms\tremaining: 7.41s\n[15:26:26] Stopped by overfitting detector  (300 iterations wait)\n[15:26:26] bestTest = 14994.06438\n[15:26:26] bestIteration = 450\n[15:26:26] Shrink model to first 451 iterations.\n[15:26:26] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.002641907834472496, 'min_data_in_leaf': 18} scored -14994.064636752137 in 0:00:02.835348\n[15:26:26] 0:\tlearn: 54502.6229179\ttest: 51970.9781962\tbest: 51970.9781962 (0)\ttotal: 3.73ms\tremaining: 7.46s\n[15:26:33] bestTest = 15019.40095\n[15:26:33] bestIteration = 1992\n[15:26:33] Shrink model to first 1993 iterations.\n[15:26:33] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0023513460292753736, 'min_data_in_leaf': 19} scored -15019.400807959402 in 0:00:07.392864\n[15:26:33] 0:\tlearn: 54502.4016823\ttest: 51970.8681460\tbest: 51970.8681460 (0)\ttotal: 3.63ms\tremaining: 7.27s\n[15:26:35] Stopped by overfitting detector  (300 iterations wait)\n[15:26:35] bestTest = 15056.96181\n[15:26:35] bestIteration = 285\n[15:26:35] Shrink model to first 286 iterations.\n[15:26:35] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.001309411296273069, 'min_data_in_leaf': 18} scored -15056.961905715812 in 0:00:02.271180\n[15:26:35] 0:\tlearn: 54502.7185309\ttest: 51971.0257735\tbest: 51971.0257735 (0)\ttotal: 3.81ms\tremaining: 7.61s\n[15:26:39] Stopped by overfitting detector  (300 iterations wait)\n[15:26:39] bestTest = 14978.30045\n[15:26:39] bestIteration = 659\n[15:26:39] Shrink model to first 660 iterations.\n[15:26:39] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.002801958676616055, 'min_data_in_leaf': 18} scored -14978.300180288461 in 0:00:03.632459\n[15:26:39] 0:\tlearn: 54505.6883261\ttest: 51972.5084206\tbest: 51972.5084206 (0)\ttotal: 3.86ms\tremaining: 7.71s\n[15:26:41] Stopped by overfitting detector  (300 iterations wait)\n[15:26:41] bestTest = 15280.14662\n[15:26:41] bestIteration = 278\n[15:26:41] Shrink model to first 279 iterations.\n[15:26:41] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.01689235456965892, 'min_data_in_leaf': 18} scored -15280.146534455129 in 0:00:02.283220\n[15:26:41] 0:\tlearn: 54584.0383936\ttest: 51974.6152106\tbest: 51974.6152106 (0)\ttotal: 2.99ms\tremaining: 5.98s\n[15:26:42] Stopped by overfitting detector  (300 iterations wait)\n[15:26:42] bestTest = 15649.68121\n[15:26:42] bestIteration = 95\n[15:26:42] Shrink model to first 96 iterations.\n[15:26:42] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00018876528108153188, 'min_data_in_leaf': 16} scored -15649.681223290598 in 0:00:01.191014\n[15:26:43] 0:\tlearn: 54517.0373635\ttest: 51978.2620718\tbest: 51978.2620718 (0)\ttotal: 3.77ms\tremaining: 7.53s\n[15:26:46] Stopped by overfitting detector  (300 iterations wait)\n[15:26:46] bestTest = 15576.62111\n[15:26:46] bestIteration = 476\n[15:26:46] Shrink model to first 477 iterations.\n[15:26:46] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.07244029793656034, 'min_data_in_leaf': 18} scored -15576.620726495727 in 0:00:03.969038\n[15:26:47] 0:\tlearn: 54502.8228111\ttest: 51971.0776748\tbest: 51971.0776748 (0)\ttotal: 3.91ms\tremaining: 7.81s\n[15:26:49] Stopped by overfitting detector  (300 iterations wait)\n[15:26:49] bestTest = 15069.95354\n[15:26:49] bestIteration = 250\n[15:26:49] Shrink model to first 251 iterations.\n[15:26:49] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.003293634195042733, 'min_data_in_leaf': 19} scored -15069.953959668803 in 0:00:02.187355\n[15:26:49] 0:\tlearn: 54502.3275996\ttest: 51970.8313064\tbest: 51970.8313064 (0)\ttotal: 3.82ms\tremaining: 7.64s\n[15:26:51] Stopped by overfitting detector  (300 iterations wait)\n[15:26:51] bestTest = 15056.9718\n[15:26:51] bestIteration = 285\n[15:26:51] Shrink model to first 286 iterations.\n[15:26:51] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0009607353389656884, 'min_data_in_leaf': 9} scored -15056.972255608975 in 0:00:02.292777\n[15:26:51] 0:\tlearn: 54503.5120924\ttest: 51971.4210290\tbest: 51971.4210290 (0)\ttotal: 3.71ms\tremaining: 7.42s\n[15:26:53] Stopped by overfitting detector  (300 iterations wait)\n[15:26:53] bestTest = 14955.27757\n[15:26:53] bestIteration = 332\n[15:26:53] Shrink model to first 333 iterations.\n[15:26:53] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006549200260260813, 'min_data_in_leaf': 19} scored -14955.27717681624 in 0:00:02.516554\n[15:26:54] 0:\tlearn: 54503.4610592\ttest: 51971.3955902\tbest: 51971.3955902 (0)\ttotal: 3.7ms\tremaining: 7.4s\n[15:26:56] Stopped by overfitting detector  (300 iterations wait)\n[15:26:56] bestTest = 14971.29137\n[15:26:56] bestIteration = 279\n[15:26:56] Shrink model to first 280 iterations.\n[15:26:56] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006307827456676339, 'min_data_in_leaf': 20} scored -14971.291165865385 in 0:00:02.245513\n[15:26:56] 0:\tlearn: 54503.5295756\ttest: 51971.4297445\tbest: 51971.4297445 (0)\ttotal: 3.69ms\tremaining: 7.38s\n[15:26:58] Stopped by overfitting detector  (300 iterations wait)\n[15:26:58] bestTest = 14955.25927\n[15:26:58] bestIteration = 332\n[15:26:58] Shrink model to first 333 iterations.\n[15:26:58] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006631902947677622, 'min_data_in_leaf': 20} scored -14955.25938167735 in 0:00:02.413644\n[15:26:58] 0:\tlearn: 54503.6128694\ttest: 51971.4712719\tbest: 51971.4712719 (0)\ttotal: 4.84ms\tremaining: 9.67s\n[15:27:00] Stopped by overfitting detector  (300 iterations wait)\n[15:27:00] bestTest = 14964.2761\n[15:27:00] bestIteration = 285\n[15:27:00] Shrink model to first 286 iterations.\n[15:27:00] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.007026005000180298, 'min_data_in_leaf': 20} scored -14964.276442307691 in 0:00:02.275662\n[15:27:01] 0:\tlearn: 54503.4472415\ttest: 51971.3887029\tbest: 51971.3887029 (0)\ttotal: 3.67ms\tremaining: 7.35s\n[15:27:03] Stopped by overfitting detector  (300 iterations wait)\n[15:27:03] bestTest = 14961.69608\n[15:27:03] bestIteration = 328\n[15:27:03] Shrink model to first 329 iterations.\n[15:27:03] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00624248262325517, 'min_data_in_leaf': 20} scored -14961.695846688035 in 0:00:02.471670\n[15:27:03] 0:\tlearn: 54508.0372586\ttest: 51973.6878117\tbest: 51973.6878117 (0)\ttotal: 3.69ms\tremaining: 7.38s\n[15:27:05] Stopped by overfitting detector  (300 iterations wait)\n[15:27:05] bestTest = 15256.30992\n[15:27:05] bestIteration = 280\n[15:27:05] Shrink model to first 281 iterations.\n[15:27:05] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.028166796519580404, 'min_data_in_leaf': 20} scored -15256.31016292735 in 0:00:02.269387\n[15:27:05] 0:\tlearn: 54535.6274294\ttest: 51987.9931959\tbest: 51987.9931959 (0)\ttotal: 3.97ms\tremaining: 7.95s\n[15:27:07] Stopped by overfitting detector  (300 iterations wait)\n[15:27:07] bestTest = 15402.45169\n[15:27:07] bestIteration = 248\n[15:27:07] Shrink model to first 249 iterations.\n[15:27:07] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16942901160487125, 'min_data_in_leaf': 20} scored -15402.451789529914 in 0:00:02.151022\n[15:27:08] 0:\tlearn: 54503.4516143\ttest: 51971.3908825\tbest: 51971.3908825 (0)\ttotal: 3.77ms\tremaining: 7.54s\n[15:27:10] Stopped by overfitting detector  (300 iterations wait)\n[15:27:10] bestTest = 14961.69154\n[15:27:10] bestIteration = 328\n[15:27:10] Shrink model to first 329 iterations.\n[15:27:10] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006263161738573593, 'min_data_in_leaf': 19} scored -14961.691172542734 in 0:00:02.422097\n[15:27:10] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[15:27:10] The set of hyperparameters \u001b[1m{'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.006845368711687715, 'min_data_in_leaf': 20}\u001b[0m\n achieve -14955.2118 mae\n[15:27:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:27:10] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:27:10] 0:\tlearn: 55371.3998257\ttest: 52740.6447299\tbest: 52740.6447299 (0)\ttotal: 3.66ms\tremaining: 11s\n[15:27:12] Stopped by overfitting detector  (100 iterations wait)\n[15:27:12] bestTest = 15386.36668\n[15:27:12] bestIteration = 403\n[15:27:12] Shrink model to first 404 iterations.\n[15:27:12] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:27:12] 0:\tlearn: 53941.7540188\ttest: 57474.9469845\tbest: 57474.9469845 (0)\ttotal: 3.79ms\tremaining: 11.4s\n[15:27:14] Stopped by overfitting detector  (100 iterations wait)\n[15:27:14] bestTest = 15917.79628\n[15:27:14] bestIteration = 394\n[15:27:14] Shrink model to first 395 iterations.\n[15:27:14] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:27:14] 0:\tlearn: 55278.0267321\ttest: 53475.8425063\tbest: 53475.8425063 (0)\ttotal: 3.92ms\tremaining: 11.8s\n[15:27:16] Stopped by overfitting detector  (100 iterations wait)\n[15:27:16] bestTest = 13104.02023\n[15:27:16] bestIteration = 569\n[15:27:16] Shrink model to first 570 iterations.\n[15:27:16] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:27:16] 0:\tlearn: 54707.3602084\ttest: 57150.1029799\tbest: 57150.1029799 (0)\ttotal: 3.75ms\tremaining: 11.2s\n[15:27:19] Stopped by overfitting detector  (100 iterations wait)\n[15:27:19] bestTest = 17930.2843\n[15:27:19] bestIteration = 400\n[15:27:19] Shrink model to first 401 iterations.\n[15:27:19] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:27:19] 0:\tlearn: 55383.8547602\ttest: 54605.1207670\tbest: 54605.1207670 (0)\ttotal: 3.8ms\tremaining: 11.4s\n[15:27:22] Stopped by overfitting detector  (100 iterations wait)\n[15:27:22] bestTest = 14508.09587\n[15:27:22] bestIteration = 899\n[15:27:22] Shrink model to first 900 iterations.\n[15:27:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15367.562981592466\u001b[0m\n[15:27:22] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:27:22] Time left 1893.87 secs\n\n[15:27:22] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[15:27:22] Blending: optimization starts with equal weights and score \u001b[1m-14803.861010407749\u001b[0m\n[15:27:22] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14766.285323469607\u001b[0m, weights = \u001b[1m[0.14768405 0.23568608 0.13605702 0.36154148 0.11903136]\u001b[0m\n[15:27:22] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14763.386367588828\u001b[0m, weights = \u001b[1m[0.13306198 0.26801014 0.11287539 0.3473062  0.13874629]\u001b[0m\n[15:27:22] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14762.846763297302\u001b[0m, weights = \u001b[1m[0.13360134 0.28538674 0.10643116 0.3318178  0.14276297]\u001b[0m\n[15:27:22] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14762.638969525899\u001b[0m, weights = \u001b[1m[0.13316964 0.2931265  0.09550855 0.3291337  0.14906165]\u001b[0m\n[15:27:22] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14762.594940603596\u001b[0m, weights = \u001b[1m[0.13188238 0.29368213 0.09670322 0.32881492 0.1489173 ]\u001b[0m\n[15:27:22] \u001b[1mAutoml preset training completed in 439.07 seconds\u001b[0m\n\n[15:27:22] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.13188 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.29368 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.09670 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.32881 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.14892 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[15:27:22] ==================================================\n[15:27:22] ==================================================\n[15:27:22] Start 0 automl preset configuration:\n[15:27:22] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 49}, 'nn_params': {'random_state': 49}, 'general_params': {'return_all_predictions': False}}\n[15:27:22] Found reader_params in kwargs, need to combine\n[15:27:22] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 49, 'cv': 5}\n[15:27:22] Stdout logging level is INFO3.\n[15:27:22] Task: reg\n\n[15:27:22] Start automl preset with listed constraints:\n[15:27:22] - time: 1893.71 seconds\n[15:27:22] - CPU: 4 cores\n[15:27:22] - memory: 16 GB\n\n[15:27:22] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[15:27:29] Feats was rejected during automatic roles guess: []\n[15:27:29] Layer \u001b[1m1\u001b[0m train process start. Time left 1887.37 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:27:29] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[15:27:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:27:30] Linear model: C = 1e-05 score = -34184.7063301282\n[15:27:30] Linear model: C = 5e-05 score = -20692.306156517094\n[15:27:30] Linear model: C = 0.0001 score = -17982.522986778848\n[15:27:30] Linear model: C = 0.0005 score = -16544.76830428686\n[15:27:30] Linear model: C = 0.001 score = -16795.779263488246\n[15:27:30] Linear model: C = 0.005 score = -16909.856845953527\n[15:27:30] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:27:31] Linear model: C = 1e-05 score = -35713.599559294875\n[15:27:31] Linear model: C = 5e-05 score = -23857.462055956195\n[15:27:31] Linear model: C = 0.0001 score = -21479.27043269231\n[15:27:31] Linear model: C = 0.0005 score = -19104.74757111378\n[15:27:31] Linear model: C = 0.001 score = -18816.590236044336\n[15:27:31] Linear model: C = 0.005 score = -18816.590786925746\n[15:27:32] Linear model: C = 0.01 score = -18036.676532451922\n[15:27:32] Linear model: C = 0.05 score = -18762.528929620727\n[15:27:32] Linear model: C = 0.1 score = -18762.528929620727\n[15:27:32] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:27:32] Linear model: C = 1e-05 score = -37773.473557692305\n[15:27:33] Linear model: C = 5e-05 score = -23867.637453258547\n[15:27:33] Linear model: C = 0.0001 score = -21068.46467681624\n[15:27:33] Linear model: C = 0.0005 score = -18271.601746127137\n[15:27:33] Linear model: C = 0.001 score = -17864.02896300748\n[15:27:33] Linear model: C = 0.005 score = -17864.029814369656\n[15:27:33] Linear model: C = 0.01 score = -17864.02841212607\n[15:27:34] Linear model: C = 0.05 score = -19262.220436030984\n[15:27:34] Linear model: C = 0.1 score = -19262.220436030984\n[15:27:34] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:27:34] Linear model: C = 1e-05 score = -39319.89142972103\n[15:27:34] Linear model: C = 5e-05 score = -23767.189847103004\n[15:27:34] Linear model: C = 0.0001 score = -20849.19947022532\n[15:27:34] Linear model: C = 0.0005 score = -18332.11282859442\n[15:27:34] Linear model: C = 0.001 score = -18332.113549490343\n[15:27:35] Linear model: C = 0.005 score = -18037.7387506706\n[15:27:35] Linear model: C = 0.01 score = -18037.7387506706\n[15:27:35] Linear model: C = 0.05 score = -18037.7387506706\n[15:27:35] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:27:35] Linear model: C = 1e-05 score = -37654.569675429186\n[15:27:35] Linear model: C = 5e-05 score = -24812.049155042918\n[15:27:35] Linear model: C = 0.0001 score = -21905.186175563304\n[15:27:35] Linear model: C = 0.0005 score = -18833.618059281114\n[15:27:36] Linear model: C = 0.001 score = -18236.125318535407\n[15:27:36] Linear model: C = 0.005 score = -18236.125318535407\n[15:27:36] Linear model: C = 0.01 score = -18236.125318535407\n[15:27:36] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17743.19440784193\u001b[0m\n[15:27:36] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[15:27:36] Time left 1880.56 secs\n\n[15:27:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[15:27:36] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:27:36] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:27:39] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:27:39] Training until validation scores don't improve for 200 rounds\n[15:27:44] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:27:44] Training until validation scores don't improve for 200 rounds\n[15:27:46] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:27:46] Training until validation scores don't improve for 200 rounds\n[15:27:48] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:27:48] Training until validation scores don't improve for 200 rounds\n[15:27:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15688.75551155822\u001b[0m\n[15:27:52] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[15:27:52] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n[15:27:52] Training until validation scores don't improve for 200 rounds\n[15:27:55] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15728.773036858975 in 0:00:03.027319\n[15:27:55] Training until validation scores don't improve for 200 rounds\n[15:27:57] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -15322.868656517094 in 0:00:02.564019\n[15:27:57] Training until validation scores don't improve for 200 rounds\n[15:28:00] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -14797.957565438035 in 0:00:02.887220\n[15:28:00] Training until validation scores don't improve for 200 rounds\n[15:28:03] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -15444.874031784188 in 0:00:03.073431\n[15:28:03] Training until validation scores don't improve for 200 rounds\n[15:28:06] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -14936.207264957266 in 0:00:02.666478\n[15:28:06] Training until validation scores don't improve for 200 rounds\n[15:28:09] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -14808.652844551281 in 0:00:02.549212\n[15:28:09] Training until validation scores don't improve for 200 rounds\n[15:28:12] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15525.543536324787 in 0:00:03.192644\n[15:28:12] Training until validation scores don't improve for 200 rounds\n[15:28:14] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -15227.366753472223 in 0:00:02.447500\n[15:28:14] Training until validation scores don't improve for 200 rounds\n[15:28:19] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -16017.087256276709 in 0:00:04.489952\n[15:28:19] Training until validation scores don't improve for 200 rounds\n[15:28:23] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -14743.21467681624 in 0:00:04.287640\n[15:28:23] Training until validation scores don't improve for 200 rounds\n[15:28:26] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9767330701904702, 'num_leaves': 151, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.001179906252315926, 'reg_alpha': 0.0054178682150133484, 'reg_lambda': 4.028557496519062e-06} scored -15236.918369391025 in 0:00:03.275398\n[15:28:26] Training until validation scores don't improve for 200 rounds\n[15:28:29] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.9228573503195511, 'num_leaves': 120, 'bagging_fraction': 0.5186241764926587, 'min_sum_hessian_in_leaf': 0.01584995629637164, 'reg_alpha': 2.3968328731206036e-05, 'reg_lambda': 0.008879323535210724} scored -14992.298410790598 in 0:00:02.410876\n[15:28:29] Training until validation scores don't improve for 200 rounds\n[15:28:33] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.8681448411699153, 'num_leaves': 158, 'bagging_fraction': 0.6987460969406105, 'min_sum_hessian_in_leaf': 0.009125703046060927, 'reg_alpha': 1.5028479017132854e-08, 'reg_lambda': 1.5933523153411743e-05} scored -15357.980101495727 in 0:00:03.928677\n[15:28:33] Training until validation scores don't improve for 200 rounds\n[15:28:35] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.8562687109240171, 'num_leaves': 109, 'bagging_fraction': 0.5887802199549697, 'min_sum_hessian_in_leaf': 0.024142096469713267, 'reg_alpha': 0.0001653282123997984, 'reg_lambda': 0.0034614046545207093} scored -14912.332565438035 in 0:00:02.739505\n[15:28:36] Training until validation scores don't improve for 200 rounds\n[15:28:38] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.9910756206562926, 'num_leaves': 196, 'bagging_fraction': 0.502074105863486, 'min_sum_hessian_in_leaf': 0.0012103374344461517, 'reg_alpha': 4.872969385182971e-07, 'reg_lambda': 1.7665377337320058e-06} scored -14752.96734775641 in 0:00:02.785669\n[15:28:38] Training until validation scores don't improve for 200 rounds\n[15:28:41] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 189, 'bagging_fraction': 0.5127747474052715, 'min_sum_hessian_in_leaf': 0.0014444377866540013, 'reg_alpha': 3.0472874740892375e-07, 'reg_lambda': 6.666878191190833e-07} scored -14961.64342948718 in 0:00:02.850793\n[15:28:41] Training until validation scores don't improve for 200 rounds\n[15:28:44] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5971814629613712, 'num_leaves': 178, 'bagging_fraction': 0.66815657205288, 'min_sum_hessian_in_leaf': 0.0034550650505516902, 'reg_alpha': 0.09986295928605152, 'reg_lambda': 2.1190401870864314e-08} scored -15093.213708600428 in 0:00:02.431707\n[15:28:44] Training until validation scores don't improve for 200 rounds\n[15:28:47] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.856953229057569, 'num_leaves': 252, 'bagging_fraction': 0.7361609808336007, 'min_sum_hessian_in_leaf': 0.03465743419765038, 'reg_alpha': 5.482417813288472e-07, 'reg_lambda': 7.788001919016916e-07} scored -15625.58814102564 in 0:00:03.531084\n[15:28:47] Training until validation scores don't improve for 200 rounds\n[15:28:50] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.7950108960389427, 'num_leaves': 211, 'bagging_fraction': 0.563586504110322, 'min_sum_hessian_in_leaf': 0.0015817926218829324, 'reg_alpha': 1.069097601305956e-08, 'reg_lambda': 1.6101189405580244e-05} scored -14905.628004807691 in 0:00:02.436078\n[15:28:50] Training until validation scores don't improve for 200 rounds\n[15:28:52] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.9479292338070223, 'num_leaves': 183, 'bagging_fraction': 0.5002148844292106, 'min_sum_hessian_in_leaf': 0.011433721178263233, 'reg_alpha': 0.00019423090242216102, 'reg_lambda': 1.4618182190661578e-07} scored -15128.967514690172 in 0:00:02.481102\n[15:28:52] Training until validation scores don't improve for 200 rounds\n[15:28:56] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.6398299664093289, 'num_leaves': 163, 'bagging_fraction': 0.6397011882476666, 'min_sum_hessian_in_leaf': 0.002527229985671911, 'reg_alpha': 7.691552343527566e-08, 'reg_lambda': 7.482879404932238e-05} scored -15278.879674145299 in 0:00:03.790199\n[15:28:56] Training until validation scores don't improve for 200 rounds\n[15:28:59] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.9073751787833929, 'num_leaves': 91, 'bagging_fraction': 0.5636769002045873, 'min_sum_hessian_in_leaf': 0.006215736752956051, 'reg_alpha': 2.043442636576258e-06, 'reg_lambda': 0.005240190449163283} scored -15000.254139957266 in 0:00:02.922910\n[15:28:59] Training until validation scores don't improve for 200 rounds\n[15:29:02] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.9021143416238775, 'num_leaves': 207, 'bagging_fraction': 0.566554044914702, 'min_sum_hessian_in_leaf': 0.00507229642952513, 'reg_alpha': 1.9212039190474533e-05, 'reg_lambda': 2.3382249721376745e-06} scored -14888.506376869658 in 0:00:02.993275\n[15:29:02] Training until validation scores don't improve for 200 rounds\n[15:29:05] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.9634214648396022, 'num_leaves': 131, 'bagging_fraction': 0.6223128396331998, 'min_sum_hessian_in_leaf': 0.0010161506523545067, 'reg_alpha': 1.1183186330623455e-06, 'reg_lambda': 8.667457935123515e-05} scored -15084.869891826924 in 0:00:02.948857\n[15:29:05] Training until validation scores don't improve for 200 rounds\n[15:29:08] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.8380549877235325, 'num_leaves': 30, 'bagging_fraction': 0.5441996092227983, 'min_sum_hessian_in_leaf': 0.00711300313989739, 'reg_alpha': 6.0902080812867e-08, 'reg_lambda': 0.001437876613921752} scored -14713.070846688035 in 0:00:03.457464\n[15:29:08] Training until validation scores don't improve for 200 rounds\n[15:29:11] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.822274603078319, 'num_leaves': 35, 'bagging_fraction': 0.5437540468271767, 'min_sum_hessian_in_leaf': 0.08690656411198724, 'reg_alpha': 5.742319370178113e-08, 'reg_lambda': 0.049226309941907694} scored -14705.043202457266 in 0:00:02.410592\n[15:29:11] Training until validation scores don't improve for 200 rounds\n[15:29:13] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.8116902388396408, 'num_leaves': 18, 'bagging_fraction': 0.9969213925248543, 'min_sum_hessian_in_leaf': 0.08557814950082362, 'reg_alpha': 5.694999487499061e-08, 'reg_lambda': 0.08194560848289441} scored -15908.207264957266 in 0:00:02.563645\n[15:29:13] Training until validation scores don't improve for 200 rounds\n[15:29:15] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.7564614538833921, 'num_leaves': 16, 'bagging_fraction': 0.5493648566018814, 'min_sum_hessian_in_leaf': 0.03341689384296963, 'reg_alpha': 5.8116249939132864e-08, 'reg_lambda': 0.041957960350171714} scored -14758.10725494124 in 0:00:02.268369\n[15:29:16] Training until validation scores don't improve for 200 rounds\n[15:29:19] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.8293948872008855, 'num_leaves': 38, 'bagging_fraction': 0.7177458283419875, 'min_sum_hessian_in_leaf': 2.418971603067845, 'reg_alpha': 2.6612421708329856e-05, 'reg_lambda': 0.002108963882849148} scored -15382.581797542734 in 0:00:03.110283\n[15:29:19] Training until validation scores don't improve for 200 rounds\n[15:29:22] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6870348347895183, 'num_leaves': 37, 'bagging_fraction': 0.9313235884212911, 'min_sum_hessian_in_leaf': 0.19038025426783808, 'reg_alpha': 4.7369985262286874e-08, 'reg_lambda': 0.0161649343296531} scored -15935.733490251068 in 0:00:03.276543\n[15:29:22] Training until validation scores don't improve for 200 rounds\n[15:29:24] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.8371104160570052, 'num_leaves': 80, 'bagging_fraction': 0.6548547518162446, 'min_sum_hessian_in_leaf': 0.2009080747953187, 'reg_alpha': 2.579708256605169e-07, 'reg_lambda': 0.4885717300518779} scored -15366.353632478633 in 0:00:02.574413\n[15:29:25] Training until validation scores don't improve for 200 rounds\n[15:29:29] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.8829415600223249, 'num_leaves': 238, 'bagging_fraction': 0.5346392807551223, 'min_sum_hessian_in_leaf': 0.002410301567992404, 'reg_alpha': 5.84065235121594e-07, 'reg_lambda': 4.453288072505006e-06} scored -14955.702757745727 in 0:00:04.189416\n[15:29:29] Training until validation scores don't improve for 200 rounds\n[15:29:32] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.7641201327152095, 'num_leaves': 231, 'bagging_fraction': 0.6107299833797389, 'min_sum_hessian_in_leaf': 0.011724185925064974, 'reg_alpha': 1.0414377431905699e-08, 'reg_lambda': 1.2905900902759858e-07} scored -14989.441306089744 in 0:00:02.857469\n[15:29:32] Training until validation scores don't improve for 200 rounds\n[15:29:34] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.7295044865568536, 'num_leaves': 215, 'bagging_fraction': 0.5002409260355478, 'min_sum_hessian_in_leaf': 0.019573352081534667, 'reg_alpha': 3.4881202472658934e-08, 'reg_lambda': 0.001303412022125763} scored -15004.31219951923 in 0:00:02.316144\n[15:29:34] Training until validation scores don't improve for 200 rounds\n[15:29:37] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.7818515523997903, 'num_leaves': 250, 'bagging_fraction': 0.582110949046712, 'min_sum_hessian_in_leaf': 0.007542481148626191, 'reg_alpha': 1.603633652309801e-07, 'reg_lambda': 8.294667356727814} scored -15259.196013621795 in 0:00:02.811175\n[15:29:37] Training until validation scores don't improve for 200 rounds\n[15:29:39] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5632613446856177, 'num_leaves': 105, 'bagging_fraction': 0.7661364137894671, 'min_sum_hessian_in_leaf': 0.00263135348191228, 'reg_alpha': 1.6318490440419919e-06, 'reg_lambda': 0.00010957225460492335} scored -15341.931590544871 in 0:00:02.789756\n[15:29:40] Training until validation scores don't improve for 200 rounds\n[15:29:42] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.8323031627629769, 'num_leaves': 46, 'bagging_fraction': 0.5479186154874027, 'min_sum_hessian_in_leaf': 0.4500188007572929, 'reg_alpha': 2.986263071771405e-08, 'reg_lambda': 2.994834939094182e-05} scored -14794.07999465812 in 0:00:02.803009\n[15:29:42] Training until validation scores don't improve for 200 rounds\n[15:29:45] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.6950761787213046, 'num_leaves': 73, 'bagging_fraction': 0.5378827706638211, 'min_sum_hessian_in_leaf': 0.04415719795843541, 'reg_alpha': 1.6563801310901673e-07, 'reg_lambda': 1.3567092888012604} scored -14731.385817307691 in 0:00:02.712201\n[15:29:45] Training until validation scores don't improve for 200 rounds\n[15:29:47] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.6824526696565536, 'num_leaves': 74, 'bagging_fraction': 0.6064388923261915, 'min_sum_hessian_in_leaf': 0.05705244982066528, 'reg_alpha': 0.0012836551651256734, 'reg_lambda': 1.9361876760757333} scored -14910.76188568376 in 0:00:02.392181\n[15:29:47] Training until validation scores don't improve for 200 rounds\n[15:29:51] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.7420702515633186, 'num_leaves': 29, 'bagging_fraction': 0.8789622334230687, 'min_sum_hessian_in_leaf': 0.100503813590245, 'reg_alpha': 1.6562757952583386e-07, 'reg_lambda': 0.17672141931328567} scored -15879.319861778846 in 0:00:03.894548\n[15:29:51] Training until validation scores don't improve for 200 rounds\n[15:29:54] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.7082221227870128, 'num_leaves': 50, 'bagging_fraction': 0.5376017607145502, 'min_sum_hessian_in_leaf': 0.04689737069929347, 'reg_alpha': 2.9590537575017074e-06, 'reg_lambda': 2.2500144711335226} scored -14826.47576121795 in 0:00:02.321134\n[15:29:54] Training until validation scores don't improve for 200 rounds\n[15:29:56] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.6165246609440673, 'num_leaves': 68, 'bagging_fraction': 0.5794785082681996, 'min_sum_hessian_in_leaf': 0.004300257196436232, 'reg_alpha': 7.775130492083879e-06, 'reg_lambda': 0.29249276566975657} scored -15123.155982905982 in 0:00:02.095613\n[15:29:56] Training until validation scores don't improve for 200 rounds\n[15:30:00] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.66032453138575, 'num_leaves': 194, 'bagging_fraction': 0.527010029216165, 'min_sum_hessian_in_leaf': 0.02642759617860034, 'reg_alpha': 6.835059024511678e-07, 'reg_lambda': 0.027938115084625664} scored -14810.694177350428 in 0:00:03.916363\n[15:30:00] Training until validation scores don't improve for 200 rounds\n[15:30:03] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.8070668276944712, 'num_leaves': 25, 'bagging_fraction': 0.5502188177240083, 'min_sum_hessian_in_leaf': 0.13137779571700156, 'reg_alpha': 1.4282629708265335e-07, 'reg_lambda': 0.0007345564742179176} scored -14736.480602297008 in 0:00:02.780705\n[15:30:03] Training until validation scores don't improve for 200 rounds\n[15:30:05] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.805685294524646, 'num_leaves': 28, 'bagging_fraction': 0.5575098693058498, 'min_sum_hessian_in_leaf': 0.13651293167306175, 'reg_alpha': 2.4996704116679907e-08, 'reg_lambda': 0.000752694454416884} scored -14860.713307959402 in 0:00:02.692319\n[15:30:05] Training until validation scores don't improve for 200 rounds\n[15:30:08] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.7129839942199946, 'num_leaves': 59, 'bagging_fraction': 0.5954110253657836, 'min_sum_hessian_in_leaf': 0.5891750246585887, 'reg_alpha': 1.2905931262602592e-07, 'reg_lambda': 0.0002495346832039776} scored -14886.305188301281 in 0:00:02.778494\n[15:30:08] Training until validation scores don't improve for 200 rounds\n[15:30:11] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.7934422618715543, 'num_leaves': 94, 'bagging_fraction': 0.6404275688108658, 'min_sum_hessian_in_leaf': 0.30335760968045195, 'reg_alpha': 0.08312739580440567, 'reg_lambda': 0.07647206665074315} scored -15135.039630074787 in 0:00:02.988306\n[15:30:11] Training until validation scores don't improve for 200 rounds\n[15:30:14] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.8174138593775077, 'num_leaves': 28, 'bagging_fraction': 0.527113319152772, 'min_sum_hessian_in_leaf': 0.08292559069820815, 'reg_alpha': 2.116368569459093e-08, 'reg_lambda': 0.01224738334026542} scored -14862.335670405982 in 0:00:02.577786\n[15:30:14] Training until validation scores don't improve for 200 rounds\n[15:30:16] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.8821515679169804, 'num_leaves': 43, 'bagging_fraction': 0.5811522248202843, 'min_sum_hessian_in_leaf': 0.3135564230905291, 'reg_alpha': 1.0061953325335516e-07, 'reg_lambda': 0.0008343983681913819} scored -14944.517561431623 in 0:00:02.720009\n[15:30:16] Training until validation scores don't improve for 200 rounds\n[15:30:19] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.769403977138087, 'num_leaves': 52, 'bagging_fraction': 0.6189397795161173, 'min_sum_hessian_in_leaf': 0.015983876083914935, 'reg_alpha': 6.92183211482152e-05, 'reg_lambda': 0.7983897532128298} scored -14914.01719417735 in 0:00:02.722693\n[15:30:19] Training until validation scores don't improve for 200 rounds\n[15:30:21] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.8584120078458477, 'num_leaves': 66, 'bagging_fraction': 0.8022568646083734, 'min_sum_hessian_in_leaf': 1.1093335463880556, 'reg_alpha': 3.019333224958037e-07, 'reg_lambda': 0.004330784212841704} scored -15583.316272702992 in 0:00:02.152260\n[15:30:21] Training until validation scores don't improve for 200 rounds\n[15:30:24] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.9414114791972179, 'num_leaves': 24, 'bagging_fraction': 0.5111015551045972, 'min_sum_hessian_in_leaf': 0.06602067088252254, 'reg_alpha': 5.046938713642176e-07, 'reg_lambda': 1.0329531521503833e-06} scored -15090.561030982906 in 0:00:02.744657\n[15:30:24] Training until validation scores don't improve for 200 rounds\n[15:30:26] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.7486545366435494, 'num_leaves': 172, 'bagging_fraction': 0.5423208943663107, 'min_sum_hessian_in_leaf': 0.001897001763806018, 'reg_alpha': 9.294036070475742e-08, 'reg_lambda': 5.0805432835361795e-08} scored -14861.165798611111 in 0:00:02.272961\n[15:30:26] Training until validation scores don't improve for 200 rounds\n[15:30:29] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.9958340636369624, 'num_leaves': 224, 'bagging_fraction': 0.5127308870212481, 'min_sum_hessian_in_leaf': 0.03540118856882056, 'reg_alpha': 1.1448527767188797e-06, 'reg_lambda': 8.854053872113764e-06} scored -14875.63171073718 in 0:00:02.812595\n[15:30:29] Training until validation scores don't improve for 200 rounds\n[15:30:33] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.841865806941458, 'num_leaves': 141, 'bagging_fraction': 0.5609179105608906, 'min_sum_hessian_in_leaf': 0.011599719060213788, 'reg_alpha': 6.32368625974723e-06, 'reg_lambda': 0.00018564643561099346} scored -14975.328258547008 in 0:00:04.099425\n[15:30:33] Training until validation scores don't improve for 200 rounds\n[15:30:36] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.7860451906476199, 'num_leaves': 194, 'bagging_fraction': 0.5240419609022537, 'min_sum_hessian_in_leaf': 0.1201432938286346, 'reg_alpha': 2.2238127979282972e-08, 'reg_lambda': 4.9165969253942834e-05} scored -14833.469985309828 in 0:00:02.468294\n[15:30:36] Training until validation scores don't improve for 200 rounds\n[15:30:38] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.5007250058963767, 'num_leaves': 38, 'bagging_fraction': 0.5772413583680804, 'min_sum_hessian_in_leaf': 0.00722352890692542, 'reg_alpha': 1.0365763495572277e-08, 'reg_lambda': 3.833161102394921} scored -14883.332431891025 in 0:00:02.138544\n[15:30:38] Training until validation scores don't improve for 200 rounds\n[15:30:40] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.9225535342552413, 'num_leaves': 123, 'bagging_fraction': 0.5034987349733728, 'min_sum_hessian_in_leaf': 0.1562254852306777, 'reg_alpha': 2.2940509108511558e-07, 'reg_lambda': 3.6492121472499167e-07} scored -14932.885082799145 in 0:00:02.342940\n[15:30:40] Training until validation scores don't improve for 200 rounds\n[15:30:44] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.8817389597150744, 'num_leaves': 145, 'bagging_fraction': 0.678580400863646, 'min_sum_hessian_in_leaf': 0.003442043497338809, 'reg_alpha': 5.09766253118373e-08, 'reg_lambda': 0.00043566330193824717} scored -15394.566205929486 in 0:00:03.427614\n[15:30:44] Training until validation scores don't improve for 200 rounds\n[15:30:46] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.7253196164522979, 'num_leaves': 20, 'bagging_fraction': 0.5993027752026775, 'min_sum_hessian_in_leaf': 0.0014115089190051917, 'reg_alpha': 4.1108286188474434e-07, 'reg_lambda': 1.6608740549984324e-06} scored -14970.19556290064 in 0:00:02.527124\n[15:30:46] Training until validation scores don't improve for 200 rounds\n[15:30:49] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.6694525941826162, 'num_leaves': 33, 'bagging_fraction': 0.5461759645566892, 'min_sum_hessian_in_leaf': 9.488721648613701, 'reg_alpha': 0.8801636891943835, 'reg_lambda': 8.19475519406499e-06} scored -14943.879674145299 in 0:00:02.403038\n[15:30:49] Training until validation scores don't improve for 200 rounds\n[15:30:51] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.7592957630325974, 'num_leaves': 16, 'bagging_fraction': 0.5528602658892324, 'min_sum_hessian_in_leaf': 0.04029947998937906, 'reg_alpha': 7.472076920278471e-08, 'reg_lambda': 0.037125873936274416} scored -14666.289680154914 in 0:00:02.324304\n[15:30:51] Training until validation scores don't improve for 200 rounds\n[15:30:53] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.8158093954770863, 'num_leaves': 17, 'bagging_fraction': 0.5660935187953405, 'min_sum_hessian_in_leaf': 0.04051248040478389, 'reg_alpha': 8.368664017204913e-08, 'reg_lambda': 0.002104433956052828} scored -14662.888788728633 in 0:00:02.477698\n[15:30:54] Training until validation scores don't improve for 200 rounds\n[15:30:56] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.8163308722124963, 'num_leaves': 16, 'bagging_fraction': 0.5626312676134225, 'min_sum_hessian_in_leaf': 0.04581020225492112, 'reg_alpha': 9.019161587602754e-08, 'reg_lambda': 0.0019634424102533145} scored -14634.415915464744 in 0:00:02.345971\n[15:30:56] Training until validation scores don't improve for 200 rounds\n[15:30:58] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.8076656604444435, 'num_leaves': 16, 'bagging_fraction': 0.5690727634321029, 'min_sum_hessian_in_leaf': 0.05295631984259503, 'reg_alpha': 7.591526738210704e-08, 'reg_lambda': 0.0021020546529378287} scored -14721.28804420406 in 0:00:02.405934\n[15:30:58] Training until validation scores don't improve for 200 rounds\n[15:31:01] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.8246842237114702, 'num_leaves': 17, 'bagging_fraction': 0.6363946577437853, 'min_sum_hessian_in_leaf': 0.04287893294476082, 'reg_alpha': 6.832162757369301e-08, 'reg_lambda': 0.0020403736780500547} scored -15072.787126068377 in 0:00:02.485312\n[15:31:01] Training until validation scores don't improve for 200 rounds\n[15:31:05] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.7815654370946516, 'num_leaves': 44, 'bagging_fraction': 0.5701197582433849, 'min_sum_hessian_in_leaf': 0.06985260748134882, 'reg_alpha': 8.361906404018344e-07, 'reg_lambda': 0.0084195104023359} scored -14864.871961805555 in 0:00:04.428108\n[15:31:05] Training until validation scores don't improve for 200 rounds\n[15:31:08] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.8413157409658635, 'num_leaves': 32, 'bagging_fraction': 0.5888092296669462, 'min_sum_hessian_in_leaf': 0.02170517426205844, 'reg_alpha': 1.86191822824261e-08, 'reg_lambda': 0.022791337715705903} scored -14899.738181089744 in 0:00:02.753429\n[15:31:08] Training until validation scores don't improve for 200 rounds\n[15:31:12] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.6984875436544621, 'num_leaves': 57, 'bagging_fraction': 0.7740042719050636, 'min_sum_hessian_in_leaf': 0.04938056612341372, 'reg_alpha': 3.7128207563950595e-08, 'reg_lambda': 0.10336490976662084} scored -15451.53014823718 in 0:00:03.685416\n[15:31:12] Training until validation scores don't improve for 200 rounds\n[15:31:15] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.7420842985114032, 'num_leaves': 19, 'bagging_fraction': 0.6588377172759416, 'min_sum_hessian_in_leaf': 0.026225995097333327, 'reg_alpha': 2.2960527270745148e-07, 'reg_lambda': 0.002402461383480807} scored -15015.730819310897 in 0:00:03.362494\n[15:31:15] Training until validation scores don't improve for 200 rounds\n[15:31:17] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.8633377851995813, 'num_leaves': 35, 'bagging_fraction': 0.8505507277550817, 'min_sum_hessian_in_leaf': 0.03701066604603672, 'reg_alpha': 2.9439113074369012e-06, 'reg_lambda': 0.00689832602274244} scored -15849.327390491453 in 0:00:02.083323\n[15:31:17] Training until validation scores don't improve for 200 rounds\n[15:31:20] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.8086906198492109, 'num_leaves': 25, 'bagging_fraction': 0.5559266014848052, 'min_sum_hessian_in_leaf': 0.0818271836700481, 'reg_alpha': 1.1167582852710938e-07, 'reg_lambda': 0.0013355627778158976} scored -14736.549779647436 in 0:00:02.804143\n[15:31:20] Training until validation scores don't improve for 200 rounds\n[15:31:22] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.8464070167521845, 'num_leaves': 24, 'bagging_fraction': 0.5256748867847523, 'min_sum_hessian_in_leaf': 0.23701686844676198, 'reg_alpha': 7.093906273703366e-08, 'reg_lambda': 0.04068963676685258} scored -14784.567007211539 in 0:00:02.539839\n[15:31:23] Training until validation scores don't improve for 200 rounds\n[15:31:25] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.7670792368220654, 'num_leaves': 49, 'bagging_fraction': 0.569954711110367, 'min_sum_hessian_in_leaf': 0.016228711019237556, 'reg_alpha': 1.7435867234739514e-07, 'reg_lambda': 0.0035040608259757516} scored -14821.686899038461 in 0:00:02.683274\n[15:31:25] Training until validation scores don't improve for 200 rounds\n[15:31:28] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.8000996195503259, 'num_leaves': 41, 'bagging_fraction': 0.5412771524740575, 'min_sum_hessian_in_leaf': 0.05848425390348382, 'reg_alpha': 3.548282155439672e-08, 'reg_lambda': 0.0006019778978104657} scored -14828.671040331197 in 0:00:02.600699\n[15:31:28] Training until validation scores don't improve for 200 rounds\n[15:31:30] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.8191004519145666, 'num_leaves': 17, 'bagging_fraction': 0.6044861986225505, 'min_sum_hessian_in_leaf': 0.162967530769325, 'reg_alpha': 3.141598729349674e-07, 'reg_lambda': 0.0012234230198478848} scored -15062.482438568377 in 0:00:02.431844\n[15:31:30] Training until validation scores don't improve for 200 rounds\n[15:31:33] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.8948803417349668, 'num_leaves': 32, 'bagging_fraction': 0.6169848391480395, 'min_sum_hessian_in_leaf': 0.10593284055268963, 'reg_alpha': 1.5172653885451482e-06, 'reg_lambda': 0.00016363762596469108} scored -15022.556490384615 in 0:00:03.211649\n[15:31:34] Training until validation scores don't improve for 200 rounds\n[15:31:38] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.7563598029858515, 'num_leaves': 24, 'bagging_fraction': 0.5544978209453882, 'min_sum_hessian_in_leaf': 0.030268908565697458, 'reg_alpha': 0.011827629295958183, 'reg_lambda': 0.01157568244552235} scored -14825.680755876068 in 0:00:04.187276\n[15:31:38] Training until validation scores don't improve for 200 rounds\n[15:31:40] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.7776501310488877, 'num_leaves': 64, 'bagging_fraction': 0.5180337853003099, 'min_sum_hessian_in_leaf': 0.048692695198377815, 'reg_alpha': 1.5696551552975547e-08, 'reg_lambda': 0.32688576720336004} scored -14657.013221153846 in 0:00:02.433205\n[15:31:40] Training until validation scores don't improve for 200 rounds\n[15:31:43] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.7287359338642605, 'num_leaves': 77, 'bagging_fraction': 0.517858578792657, 'min_sum_hessian_in_leaf': 0.04204475117034934, 'reg_alpha': 1.4098921194088071e-08, 'reg_lambda': 0.2668865988309841} scored -14750.45890090812 in 0:00:02.533381\n[15:31:43] Training until validation scores don't improve for 200 rounds\n[15:31:46] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.7791352512898275, 'num_leaves': 62, 'bagging_fraction': 0.5947007554284224, 'min_sum_hessian_in_leaf': 0.05194481438408493, 'reg_alpha': 4.7144346288652026e-08, 'reg_lambda': 0.6995036700747815} scored -15011.688401442309 in 0:00:03.620751\n[15:31:46] Training until validation scores don't improve for 200 rounds\n[15:31:49] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.7980634153779345, 'num_leaves': 16, 'bagging_fraction': 0.5374702997040021, 'min_sum_hessian_in_leaf': 0.08191489612664064, 'reg_alpha': 1.2535524152864523e-07, 'reg_lambda': 0.12375358373772635} scored -14609.063785389957 in 0:00:02.370991\n[15:31:49] Training until validation scores don't improve for 200 rounds\n[15:31:51] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.8292515698710047, 'num_leaves': 16, 'bagging_fraction': 0.5343523325868168, 'min_sum_hessian_in_leaf': 0.07121567966741564, 'reg_alpha': 9.887663810619742e-08, 'reg_lambda': 0.15392075944253966} scored -14616.034655448719 in 0:00:02.223334\n[15:31:51] Training until validation scores don't improve for 200 rounds\n[15:31:54] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.8244931596857045, 'num_leaves': 16, 'bagging_fraction': 0.5348885469337177, 'min_sum_hessian_in_leaf': 0.06731272024499374, 'reg_alpha': 1.6688364027559342e-08, 'reg_lambda': 0.13457915280970664} scored -14531.844184027777 in 0:00:02.519418\n[15:31:54] Training until validation scores don't improve for 200 rounds\n[15:31:57] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.8503401244482556, 'num_leaves': 39, 'bagging_fraction': 0.5355774164914492, 'min_sum_hessian_in_leaf': 0.07719861581836729, 'reg_alpha': 1.8199908793611937e-08, 'reg_lambda': 0.10366073443067916} scored -14799.941372863248 in 0:00:03.111404\n[15:31:57] Training until validation scores don't improve for 200 rounds\n[15:31:59] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.8710645691727914, 'num_leaves': 31, 'bagging_fraction': 0.5169127214413164, 'min_sum_hessian_in_leaf': 0.09519691625105771, 'reg_alpha': 3.2168222485950013e-08, 'reg_lambda': 0.05703425989989876} scored -14822.95983573718 in 0:00:02.501208\n[15:31:59] Training until validation scores don't improve for 200 rounds\n[15:32:02] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.8287264411268623, 'num_leaves': 22, 'bagging_fraction': 0.5291564036384077, 'min_sum_hessian_in_leaf': 0.01946037643012591, 'reg_alpha': 1.2729158847246453e-08, 'reg_lambda': 0.2912598554283565} scored -14743.620092147436 in 0:00:03.077577\n[15:32:02] Training until validation scores don't improve for 200 rounds\n[15:32:05] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.7920299416306082, 'num_leaves': 47, 'bagging_fraction': 0.5084079250045093, 'min_sum_hessian_in_leaf': 0.030038782844423698, 'reg_alpha': 0.0006184085204980928, 'reg_lambda': 0.452534053944414} scored -14826.328725961539 in 0:00:02.452629\n[15:32:05] Training until validation scores don't improve for 200 rounds\n[15:32:09] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.8297589965515272, 'num_leaves': 54, 'bagging_fraction': 0.5536755942272069, 'min_sum_hessian_in_leaf': 0.06589268661711868, 'reg_alpha': 9.390557041238325e-08, 'reg_lambda': 0.19747901149637395} scored -14688.560697115385 in 0:00:04.307619\n[15:32:09] Training until validation scores don't improve for 200 rounds\n[15:32:12] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.8184265683899915, 'num_leaves': 36, 'bagging_fraction': 0.5849933589801686, 'min_sum_hessian_in_leaf': 0.06557192492571938, 'reg_alpha': 1.1938723023585148e-07, 'reg_lambda': 0.18573396808710788} scored -14930.194911858975 in 0:00:02.726864\n[15:32:12] Training until validation scores don't improve for 200 rounds\n[15:32:14] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.7915049934062218, 'num_leaves': 51, 'bagging_fraction': 0.5587288265884867, 'min_sum_hessian_in_leaf': 0.10507837523154478, 'reg_alpha': 4.0671705873258503e-07, 'reg_lambda': 0.13774813839363256} scored -14836.421240651709 in 0:00:02.674347\n[15:32:15] Training until validation scores don't improve for 200 rounds\n[15:32:17] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.8341275054514007, 'num_leaves': 29, 'bagging_fraction': 0.5475178129918585, 'min_sum_hessian_in_leaf': 0.06717208182509933, 'reg_alpha': 5.149505786628761e-08, 'reg_lambda': 0.03517501843858124} scored -14851.975026709402 in 0:00:02.353717\n[15:32:17] Training until validation scores don't improve for 200 rounds\n[15:32:19] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.7727228439196475, 'num_leaves': 21, 'bagging_fraction': 0.5369841902588004, 'min_sum_hessian_in_leaf': 0.03997049634995721, 'reg_alpha': 2.581592372485437e-08, 'reg_lambda': 0.019712778847236757} scored -14879.84608707265 in 0:00:02.484356\n[15:32:19] Training until validation scores don't improve for 200 rounds\n[15:32:22] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.871039710460785, 'num_leaves': 54, 'bagging_fraction': 0.5742193454844227, 'min_sum_hessian_in_leaf': 0.14540073585270516, 'reg_alpha': 7.188849151929522e-08, 'reg_lambda': 0.062310229551531746} scored -14961.984608707266 in 0:00:02.791940\n[15:32:22] Training until validation scores don't improve for 200 rounds\n[15:32:25] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.8233323320181779, 'num_leaves': 42, 'bagging_fraction': 0.5155678260485326, 'min_sum_hessian_in_leaf': 0.08867041499962232, 'reg_alpha': 2.0901353792108656e-07, 'reg_lambda': 1.2135204001612738} scored -14842.71484375 in 0:00:02.459660\n[15:32:25] Training until validation scores don't improve for 200 rounds\n[15:32:28] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.8513861668446234, 'num_leaves': 27, 'bagging_fraction': 0.7017004106913368, 'min_sum_hessian_in_leaf': 0.12181467136222365, 'reg_alpha': 9.773542271877743e-08, 'reg_lambda': 0.5040877391077956} scored -15320.852797809828 in 0:00:03.615738\n[15:32:28] Training until validation scores don't improve for 200 rounds\n[15:32:35] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.8027772643421067, 'num_leaves': 16, 'bagging_fraction': 0.8951430989761531, 'min_sum_hessian_in_leaf': 0.18422181736937426, 'reg_alpha': 1.6661910621090652e-08, 'reg_lambda': 0.21613786532900403} scored -15434.394130608975 in 0:00:06.260782\n[15:32:35] Training until validation scores don't improve for 200 rounds\n[15:32:37] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.7578432226071162, 'num_leaves': 87, 'bagging_fraction': 0.5331513428317829, 'min_sum_hessian_in_leaf': 0.009453436482631852, 'reg_alpha': 1.016318257478711e-08, 'reg_lambda': 0.13527984258117934} scored -14672.621227297008 in 0:00:02.506662\n[15:32:37] Training until validation scores don't improve for 200 rounds\n[15:32:41] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.7581499356000703, 'num_leaves': 94, 'bagging_fraction': 0.5002236661471496, 'min_sum_hessian_in_leaf': 0.02482099140323452, 'reg_alpha': 3.564359444981991e-08, 'reg_lambda': 0.11388316103048858} scored -15002.792100694445 in 0:00:03.995987\n[15:32:41] Training until validation scores don't improve for 200 rounds\n[15:32:43] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.7430246120202273, 'num_leaves': 103, 'bagging_fraction': 0.5292866904607754, 'min_sum_hessian_in_leaf': 0.05719546585163268, 'reg_alpha': 1.000526376358591e-08, 'reg_lambda': 0.7049190925208041} scored -14617.832732371795 in 0:00:02.351577\n[15:32:44] Training until validation scores don't improve for 200 rounds\n[15:32:46] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.7324366546633506, 'num_leaves': 87, 'bagging_fraction': 0.5289441785020169, 'min_sum_hessian_in_leaf': 0.06218556186288604, 'reg_alpha': 1.2881092602979792e-08, 'reg_lambda': 0.4208898098779548} scored -14729.445880074787 in 0:00:02.411469\n[15:32:46] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[15:32:46] The set of hyperparameters \u001b[1m{'feature_fraction': 0.8244931596857045, 'num_leaves': 16, 'bagging_fraction': 0.5348885469337177, 'min_sum_hessian_in_leaf': 0.06731272024499374, 'reg_alpha': 1.6688364027559342e-08, 'reg_lambda': 0.13457915280970664}\u001b[0m\n achieve -14531.8442 mae\n[15:32:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:32:46] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:32:46] Training until validation scores don't improve for 100 rounds\n[15:32:47] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:32:47] Training until validation scores don't improve for 100 rounds\n[15:32:47] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:32:47] Training until validation scores don't improve for 100 rounds\n[15:32:48] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:32:48] Training until validation scores don't improve for 100 rounds\n[15:32:48] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:32:48] Training until validation scores don't improve for 100 rounds\n[15:32:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15418.110358251284\u001b[0m\n[15:32:49] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:32:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[15:32:49] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:32:49] 0:\tlearn: 54803.1950575\ttest: 51809.1894545\tbest: 51809.1894545 (0)\ttotal: 2.77ms\tremaining: 5.54s\n[15:32:51] Stopped by overfitting detector  (300 iterations wait)\n[15:32:51] bestTest = 15092.35903\n[15:32:51] bestIteration = 465\n[15:32:51] Shrink model to first 466 iterations.\n[15:32:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:32:51] 0:\tlearn: 54936.5341019\ttest: 52103.1507529\tbest: 52103.1507529 (0)\ttotal: 2.42ms\tremaining: 4.83s\n[15:32:54] Stopped by overfitting detector  (300 iterations wait)\n[15:32:54] bestTest = 15654.27621\n[15:32:54] bestIteration = 1414\n[15:32:54] Shrink model to first 1415 iterations.\n[15:32:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:32:55] 0:\tlearn: 53808.2156576\ttest: 55189.1320718\tbest: 55189.1320718 (0)\ttotal: 2.41ms\tremaining: 4.81s\n[15:32:56] Stopped by overfitting detector  (300 iterations wait)\n[15:32:56] bestTest = 14323.6927\n[15:32:56] bestIteration = 403\n[15:32:56] Shrink model to first 404 iterations.\n[15:32:56] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:32:56] 0:\tlearn: 53638.7264412\ttest: 57801.3258585\tbest: 57801.3258585 (0)\ttotal: 2.38ms\tremaining: 4.77s\n[15:32:58] Stopped by overfitting detector  (300 iterations wait)\n[15:32:58] bestTest = 14154.01202\n[15:32:58] bestIteration = 450\n[15:32:58] Shrink model to first 451 iterations.\n[15:32:58] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:32:58] 0:\tlearn: 54083.7032931\ttest: 54609.6260003\tbest: 54609.6260003 (0)\ttotal: 2.19ms\tremaining: 4.38s\n[15:33:00] Stopped by overfitting detector  (300 iterations wait)\n[15:33:00] bestTest = 16194.36834\n[15:33:00] bestIteration = 484\n[15:33:00] Shrink model to first 485 iterations.\n[15:33:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15083.586793664384\u001b[0m\n[15:33:00] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[15:33:00] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[15:33:00] 0:\tlearn: 55083.1349839\ttest: 52061.4941809\tbest: 52061.4941809 (0)\ttotal: 1.74ms\tremaining: 3.48s\n[15:33:03] bestTest = 15065.92171\n[15:33:03] bestIteration = 1878\n[15:33:03] Shrink model to first 1879 iterations.\n[15:33:03] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -15065.921908386752 in 0:00:03.366697\n[15:33:03] 0:\tlearn: 54846.7069004\ttest: 51877.8699369\tbest: 51877.8699369 (0)\ttotal: 1.46ms\tremaining: 2.92s\n[15:33:06] bestTest = 14397.41049\n[15:33:06] bestIteration = 1992\n[15:33:06] Shrink model to first 1993 iterations.\n[15:33:06] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -14397.410490117521 in 0:00:02.470608\n[15:33:06] 0:\tlearn: 55099.5375169\ttest: 52078.0631284\tbest: 52078.0631284 (0)\ttotal: 1.48ms\tremaining: 2.95s\n[15:33:07] Stopped by overfitting detector  (300 iterations wait)\n[15:33:07] bestTest = 15412.55077\n[15:33:07] bestIteration = 1125\n[15:33:07] Shrink model to first 1126 iterations.\n[15:33:07] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -15412.55053084936 in 0:00:01.810663\n[15:33:08] 0:\tlearn: 54846.6673070\ttest: 51877.8278173\tbest: 51877.8278173 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[15:33:09] Stopped by overfitting detector  (300 iterations wait)\n[15:33:09] bestTest = 14494.62087\n[15:33:09] bestIteration = 1148\n[15:33:09] Shrink model to first 1149 iterations.\n[15:33:09] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -14494.620676415598 in 0:00:01.830667\n[15:33:10] 0:\tlearn: 54791.3383178\ttest: 51770.6371373\tbest: 51770.6371373 (0)\ttotal: 4.13ms\tremaining: 8.25s\n[15:33:16] bestTest = 16047.60714\n[15:33:16] bestIteration = 1997\n[15:33:16] Shrink model to first 1998 iterations.\n[15:33:16] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -16047.60687099359 in 0:00:06.496174\n[15:33:16] 0:\tlearn: 54791.5936601\ttest: 51771.0044687\tbest: 51771.0044687 (0)\ttotal: 3.58ms\tremaining: 7.15s\n[15:33:18] Stopped by overfitting detector  (300 iterations wait)\n[15:33:18] bestTest = 15844.68991\n[15:33:18] bestIteration = 393\n[15:33:18] Shrink model to first 394 iterations.\n[15:33:18] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -15844.690087473291 in 0:00:02.209515\n[15:33:18] 0:\tlearn: 55067.7767767\ttest: 52002.5466402\tbest: 52002.5466402 (0)\ttotal: 3.57ms\tremaining: 7.14s\n[15:33:23] Stopped by overfitting detector  (300 iterations wait)\n[15:33:23] bestTest = 14909.28564\n[15:33:23] bestIteration = 1381\n[15:33:23] Shrink model to first 1382 iterations.\n[15:33:23] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -14911.307258279914 in 0:00:05.047716\n[15:33:23] 0:\tlearn: 54889.8842087\ttest: 52014.8030884\tbest: 52014.8030884 (0)\ttotal: 5.35ms\tremaining: 10.7s\n[15:33:28] Stopped by overfitting detector  (300 iterations wait)\n[15:33:28] bestTest = 15960.19995\n[15:33:28] bestIteration = 878\n[15:33:28] Shrink model to first 879 iterations.\n[15:33:28] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -16039.227597489316 in 0:00:05.132131\n[15:33:28] 0:\tlearn: 55121.4141792\ttest: 52099.5823325\tbest: 52099.5823325 (0)\ttotal: 1.34ms\tremaining: 2.67s\n[15:33:31] bestTest = 15394.07646\n[15:33:31] bestIteration = 1977\n[15:33:31] Shrink model to first 1978 iterations.\n[15:33:31] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -15394.076138488248 in 0:00:02.502085\n[15:33:31] 0:\tlearn: 54791.4359529\ttest: 51770.7776361\tbest: 51770.7776361 (0)\ttotal: 3.33ms\tremaining: 6.67s\n[15:33:33] Stopped by overfitting detector  (300 iterations wait)\n[15:33:33] bestTest = 15946.1854\n[15:33:33] bestIteration = 359\n[15:33:33] Shrink model to first 360 iterations.\n[15:33:33] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -15946.185596955129 in 0:00:02.137428\n[15:33:33] 0:\tlearn: 54836.6557829\ttest: 51870.4593229\tbest: 51870.4593229 (0)\ttotal: 1.77ms\tremaining: 3.55s\n[15:33:35] Stopped by overfitting detector  (300 iterations wait)\n[15:33:35] bestTest = 14951.87657\n[15:33:35] bestIteration = 1095\n[15:33:35] Shrink model to first 1096 iterations.\n[15:33:35] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 17} scored -14951.876719417734 in 0:00:02.372521\n[15:33:35] 0:\tlearn: 54836.6564080\ttest: 51870.4602206\tbest: 51870.4602206 (0)\ttotal: 1.83ms\tremaining: 3.66s\n[15:33:38] Stopped by overfitting detector  (300 iterations wait)\n[15:33:38] bestTest = 14951.84835\n[15:33:38] bestIteration = 1095\n[15:33:38] Shrink model to first 1096 iterations.\n[15:33:38] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5624722374695954e-05, 'min_data_in_leaf': 14} scored -14951.84820713141 in 0:00:02.400163\n[15:33:38] 0:\tlearn: 54847.7270812\ttest: 51878.9551183\tbest: 51878.9551183 (0)\ttotal: 1.38ms\tremaining: 2.75s\n[15:33:39] Stopped by overfitting detector  (300 iterations wait)\n[15:33:39] bestTest = 14504.77535\n[15:33:39] bestIteration = 1092\n[15:33:39] Shrink model to first 1093 iterations.\n[15:33:39] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0668602867950036, 'min_data_in_leaf': 14} scored -14504.775424011752 in 0:00:01.789369\n[15:33:40] 0:\tlearn: 54836.6562667\ttest: 51870.4600177\tbest: 51870.4600177 (0)\ttotal: 1.84ms\tremaining: 3.68s\n[15:33:42] Stopped by overfitting detector  (300 iterations wait)\n[15:33:42] bestTest = 14951.86113\n[15:33:42] bestIteration = 1095\n[15:33:42] Shrink model to first 1096 iterations.\n[15:33:42] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2096060313323935e-05, 'min_data_in_leaf': 13} scored -14951.861144497863 in 0:00:02.431565\n[15:33:42] 0:\tlearn: 54811.0835650\ttest: 51818.2404783\tbest: 51818.2404783 (0)\ttotal: 2.39ms\tremaining: 4.78s\n[15:33:46] Stopped by overfitting detector  (300 iterations wait)\n[15:33:46] bestTest = 14918.17399\n[15:33:46] bestIteration = 1090\n[15:33:46] Shrink model to first 1091 iterations.\n[15:33:46] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.125932335717553, 'min_data_in_leaf': 8} scored -14918.174278846154 in 0:00:03.703340\n[15:33:46] 0:\tlearn: 54846.6687068\ttest: 51877.8293064\tbest: 51877.8293064 (0)\ttotal: 1.37ms\tremaining: 2.74s\n[15:33:47] Stopped by overfitting detector  (300 iterations wait)\n[15:33:47] bestTest = 14494.65618\n[15:33:47] bestIteration = 1148\n[15:33:47] Shrink model to first 1149 iterations.\n[15:33:48] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0001653282123997984, 'min_data_in_leaf': 12} scored -14494.65650040064 in 0:00:01.904780\n[15:33:48] 0:\tlearn: 54802.4862688\ttest: 51808.3680624\tbest: 51808.3680624 (0)\ttotal: 2.31ms\tremaining: 4.63s\n[15:33:52] Stopped by overfitting detector  (300 iterations wait)\n[15:33:52] bestTest = 15145.54178\n[15:33:52] bestIteration = 1613\n[15:33:52] Shrink model to first 1614 iterations.\n[15:33:52] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.9521444921739376e-07, 'min_data_in_leaf': 17} scored -15145.541282719018 in 0:00:04.629312\n[15:33:52] 0:\tlearn: 54846.6674746\ttest: 51877.8279956\tbest: 51877.8279956 (0)\ttotal: 1.34ms\tremaining: 2.68s\n[15:33:54] Stopped by overfitting detector  (300 iterations wait)\n[15:33:54] bestTest = 14494.62169\n[15:33:54] bestIteration = 1148\n[15:33:54] Shrink model to first 1149 iterations.\n[15:33:54] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 8.773472263092467e-05, 'min_data_in_leaf': 16} scored -14494.622061965812 in 0:00:01.882935\n[15:33:54] 0:\tlearn: 54836.6558611\ttest: 51870.4594353\tbest: 51870.4594353 (0)\ttotal: 1.83ms\tremaining: 3.67s\n[15:33:56] Stopped by overfitting detector  (300 iterations wait)\n[15:33:56] bestTest = 14951.85805\n[15:33:56] bestIteration = 1095\n[15:33:56] Shrink model to first 1096 iterations.\n[15:33:56] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9664284171166767e-06, 'min_data_in_leaf': 7} scored -14951.85844017094 in 0:00:02.417479\n[15:33:57] 0:\tlearn: 54804.7797945\ttest: 51811.0209261\tbest: 51811.0209261 (0)\ttotal: 2.3ms\tremaining: 4.6s\n[15:33:59] Stopped by overfitting detector  (300 iterations wait)\n[15:33:59] bestTest = 15203.6828\n[15:33:59] bestIteration = 983\n[15:33:59] Shrink model to first 984 iterations.\n[15:33:59] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.03260715855144935, 'min_data_in_leaf': 20} scored -15203.682475293803 in 0:00:02.946491\n[15:34:00] 0:\tlearn: 54854.1580965\ttest: 51885.7918373\tbest: 51885.7918373 (0)\ttotal: 1.4ms\tremaining: 2.81s\n[15:34:02] Stopped by overfitting detector  (300 iterations wait)\n[15:34:02] bestTest = 14205.67489\n[15:34:02] bestIteration = 1386\n[15:34:02] Shrink model to first 1387 iterations.\n[15:34:02] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.474041064227797, 'min_data_in_leaf': 11} scored -14205.67462940705 in 0:00:02.207097\n[15:34:02] 0:\tlearn: 54854.3893413\ttest: 51886.0375404\tbest: 51886.0375404 (0)\ttotal: 1.34ms\tremaining: 2.67s\n[15:34:04] Stopped by overfitting detector  (300 iterations wait)\n[15:34:04] bestTest = 14465.17895\n[15:34:04] bestIteration = 1210\n[15:34:04] Shrink model to first 1211 iterations.\n[15:34:04] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4887440296884294, 'min_data_in_leaf': 11} scored -14465.178602430555 in 0:00:01.960916\n[15:34:04] 0:\tlearn: 54855.7240323\ttest: 51887.4555049\tbest: 51887.4555049 (0)\ttotal: 1.39ms\tremaining: 2.79s\n[15:34:06] Stopped by overfitting detector  (300 iterations wait)\n[15:34:06] bestTest = 14307.55271\n[15:34:06] bestIteration = 1295\n[15:34:06] Shrink model to first 1296 iterations.\n[15:34:06] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.5736898526589478, 'min_data_in_leaf': 11} scored -14307.55303485577 in 0:00:02.038961\n[15:34:06] 0:\tlearn: 54924.1881500\ttest: 51896.7541680\tbest: 51896.7541680 (0)\ttotal: 1.78ms\tremaining: 3.56s\n[15:34:09] bestTest = 14774.97018\n[15:34:09] bestIteration = 1992\n[15:34:09] Shrink model to first 1993 iterations.\n[15:34:09] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 5.85895221362631, 'min_data_in_leaf': 11} scored -14774.96976829594 in 0:00:03.339022\n[15:34:09] 0:\tlearn: 54852.4747874\ttest: 51884.0030102\tbest: 51884.0030102 (0)\ttotal: 1.32ms\tremaining: 2.64s\n[15:34:11] Stopped by overfitting detector  (300 iterations wait)\n[15:34:11] bestTest = 14499.66271\n[15:34:11] bestIteration = 1238\n[15:34:11] Shrink model to first 1239 iterations.\n[15:34:11] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.36714255469878165, 'min_data_in_leaf': 15} scored -14499.66257678953 in 0:00:01.991547\n[15:34:11] 0:\tlearn: 54836.9895323\ttest: 51870.9379951\tbest: 51870.9379951 (0)\ttotal: 1.78ms\tremaining: 3.56s\n[15:34:14] Stopped by overfitting detector  (300 iterations wait)\n[15:34:14] bestTest = 14869.49033\n[15:34:14] bestIteration = 1493\n[15:34:14] Shrink model to first 1494 iterations.\n[15:34:14] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.008354663210727082, 'min_data_in_leaf': 18} scored -14869.490551549145 in 0:00:03.046061\n[15:34:14] 0:\tlearn: 55105.2317153\ttest: 52083.6572563\tbest: 52083.6572563 (0)\ttotal: 1.41ms\tremaining: 2.83s\n[15:34:17] bestTest = 15223.4853\n[15:34:17] bestIteration = 1737\n[15:34:17] Shrink model to first 1738 iterations.\n[15:34:17] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.39213944481747826, 'min_data_in_leaf': 13} scored -15223.485026041666 in 0:00:03.015210\n[15:34:17] 0:\tlearn: 55504.1071404\ttest: 52491.8442579\tbest: 52491.8442579 (0)\ttotal: 4.79ms\tremaining: 9.58s\n[15:34:26] bestTest = 15139.48018\n[15:34:26] bestIteration = 1976\n[15:34:26] Shrink model to first 1977 iterations.\n[15:34:26] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 9.738892792790312, 'min_data_in_leaf': 9} scored -15139.480134882479 in 0:00:08.591864\n[15:34:26] 0:\tlearn: 54836.9535271\ttest: 51870.8864147\tbest: 51870.8864147 (0)\ttotal: 1.76ms\tremaining: 3.53s\n[15:34:29] bestTest = 14811.68545\n[15:34:29] bestIteration = 1996\n[15:34:29] Shrink model to first 1997 iterations.\n[15:34:29] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.007451529391132327, 'min_data_in_leaf': 12} scored -14811.685780582266 in 0:00:03.351389\n[15:34:29] 0:\tlearn: 55083.1190248\ttest: 52061.4795330\tbest: 52061.4795330 (0)\ttotal: 1.78ms\tremaining: 3.56s\n[15:34:31] Stopped by overfitting detector  (300 iterations wait)\n[15:34:31] bestTest = 15111.77024\n[15:34:31] bestIteration = 759\n[15:34:31] Shrink model to first 760 iterations.\n[15:34:31] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0016425674392396316, 'min_data_in_leaf': 15} scored -15111.769931891025 in 0:00:01.890376\n[15:34:31] 0:\tlearn: 54865.7332722\ttest: 51898.0796914\tbest: 51898.0796914 (0)\ttotal: 1.36ms\tremaining: 2.71s\n[15:34:33] Stopped by overfitting detector  (300 iterations wait)\n[15:34:33] bestTest = 14322.55196\n[15:34:33] bestIteration = 1439\n[15:34:33] Shrink model to first 1440 iterations.\n[15:34:33] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2153025282029444, 'min_data_in_leaf': 10} scored -14322.551849626068 in 0:00:02.475829\n[15:34:34] 0:\tlearn: 54849.9765407\ttest: 51881.3472800\tbest: 51881.3472800 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[15:34:35] Stopped by overfitting detector  (300 iterations wait)\n[15:34:35] bestTest = 14473.77894\n[15:34:35] bestIteration = 1174\n[15:34:35] Shrink model to first 1175 iterations.\n[15:34:35] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.20890948321975808, 'min_data_in_leaf': 10} scored -14473.77882946047 in 0:00:01.921966\n[15:34:36] 0:\tlearn: 54861.1009148\ttest: 51893.1648236\tbest: 51893.1648236 (0)\ttotal: 1.39ms\tremaining: 2.77s\n[15:34:37] Stopped by overfitting detector  (300 iterations wait)\n[15:34:37] bestTest = 14536.15218\n[15:34:37] bestIteration = 1259\n[15:34:37] Shrink model to first 1260 iterations.\n[15:34:37] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.917351917747394, 'min_data_in_leaf': 8} scored -14536.15217681624 in 0:00:02.021429\n[15:34:38] 0:\tlearn: 54876.3202180\ttest: 51909.2988114\tbest: 51909.2988114 (0)\ttotal: 1.34ms\tremaining: 2.69s\n[15:34:39] Stopped by overfitting detector  (300 iterations wait)\n[15:34:39] bestTest = 14547.56973\n[15:34:39] bestIteration = 1255\n[15:34:39] Shrink model to first 1256 iterations.\n[15:34:39] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9028186413303592, 'min_data_in_leaf': 12} scored -14547.569795005342 in 0:00:01.981505\n[15:34:40] 0:\tlearn: 54847.1139874\ttest: 51878.3029825\tbest: 51878.3029825 (0)\ttotal: 1.32ms\tremaining: 2.63s\n[15:34:41] Stopped by overfitting detector  (300 iterations wait)\n[15:34:41] bestTest = 14725.40946\n[15:34:41] bestIteration = 1221\n[15:34:41] Shrink model to first 1222 iterations.\n[15:34:41] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.028214456422822245, 'min_data_in_leaf': 9} scored -14725.409889155982 in 0:00:02.024583\n[15:34:42] 0:\tlearn: 54847.8811240\ttest: 51879.1189606\tbest: 51879.1189606 (0)\ttotal: 1.31ms\tremaining: 2.63s\n[15:34:43] Stopped by overfitting detector  (300 iterations wait)\n[15:34:43] bestTest = 14459.38609\n[15:34:43] bestIteration = 1036\n[15:34:43] Shrink model to first 1037 iterations.\n[15:34:43] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.07657494371637036, 'min_data_in_leaf': 11} scored -14459.386134481838 in 0:00:01.750427\n[15:34:43] 0:\tlearn: 55083.1663010\ttest: 52061.5229255\tbest: 52061.5229255 (0)\ttotal: 1.81ms\tremaining: 3.62s\n[15:34:46] Stopped by overfitting detector  (300 iterations wait)\n[15:34:46] bestTest = 15337.96014\n[15:34:46] bestIteration = 1569\n[15:34:46] Shrink model to first 1570 iterations.\n[15:34:46] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.004014593827466227, 'min_data_in_leaf': 3} scored -15337.960453392094 in 0:00:03.131712\n[15:34:47] 0:\tlearn: 54883.8290474\ttest: 51917.2446862\tbest: 51917.2446862 (0)\ttotal: 1.33ms\tremaining: 2.65s\n[15:34:49] Stopped by overfitting detector  (300 iterations wait)\n[15:34:49] bestTest = 14663.67924\n[15:34:49] bestIteration = 1481\n[15:34:49] Shrink model to first 1482 iterations.\n[15:34:49] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 2.3960336829385263, 'min_data_in_leaf': 13} scored -14663.67913661859 in 0:00:02.603672\n[15:34:49] 0:\tlearn: 55099.5452369\ttest: 52078.0707090\tbest: 52078.0707090 (0)\ttotal: 1.56ms\tremaining: 3.13s\n[15:34:51] Stopped by overfitting detector  (300 iterations wait)\n[15:34:51] bestTest = 15372.41068\n[15:34:51] bestIteration = 1118\n[15:34:51] Shrink model to first 1119 iterations.\n[15:34:51] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0005299290522060043, 'min_data_in_leaf': 5} scored -15372.410907451924 in 0:00:01.868094\n[15:34:51] 0:\tlearn: 54867.9915045\ttest: 51911.3339165\tbest: 51911.3339165 (0)\ttotal: 1.74ms\tremaining: 3.48s\n[15:34:54] bestTest = 14860.77007\n[15:34:54] bestIteration = 1858\n[15:34:54] Shrink model to first 1859 iterations.\n[15:34:54] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.9450197115430674, 'min_data_in_leaf': 10} scored -14860.769881810897 in 0:00:03.409711\n[15:34:54] 0:\tlearn: 54846.9318723\ttest: 51878.1092580\tbest: 51878.1092580 (0)\ttotal: 1.4ms\tremaining: 2.79s\n[15:34:56] Stopped by overfitting detector  (300 iterations wait)\n[15:34:56] bestTest = 14736.74867\n[15:34:56] bestIteration = 1089\n[15:34:56] Shrink model to first 1090 iterations.\n[15:34:56] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.01674075231402579, 'min_data_in_leaf': 7} scored -14736.748747996795 in 0:00:01.798100\n[15:34:56] 0:\tlearn: 54847.6438370\ttest: 51878.8665768\tbest: 51878.8665768 (0)\ttotal: 1.32ms\tremaining: 2.64s\n[15:34:58] Stopped by overfitting detector  (300 iterations wait)\n[15:34:58] bestTest = 14579.2019\n[15:34:58] bestIteration = 1099\n[15:34:58] Shrink model to first 1100 iterations.\n[15:34:58] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.061611310947330016, 'min_data_in_leaf': 11} scored -14579.201822916666 in 0:00:01.806143\n[15:34:58] 0:\tlearn: 54848.2931928\ttest: 51879.5572236\tbest: 51879.5572236 (0)\ttotal: 1.36ms\tremaining: 2.73s\n[15:35:00] Stopped by overfitting detector  (300 iterations wait)\n[15:35:00] bestTest = 14708.56016\n[15:35:00] bestIteration = 1284\n[15:35:00] Shrink model to first 1285 iterations.\n[15:35:00] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.10257121192290626, 'min_data_in_leaf': 10} scored -14708.560530181623 in 0:00:02.297170\n[15:35:00] 0:\tlearn: 54849.6547270\ttest: 51881.0051033\tbest: 51881.0051033 (0)\ttotal: 1.39ms\tremaining: 2.78s\n[15:35:02] Stopped by overfitting detector  (300 iterations wait)\n[15:35:02] bestTest = 14472.01574\n[15:35:02] bestIteration = 1050\n[15:35:02] Shrink model to first 1051 iterations.\n[15:35:02] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1885628108979544, 'min_data_in_leaf': 14} scored -14472.015224358975 in 0:00:01.827499\n[15:35:02] 0:\tlearn: 54891.1048331\ttest: 51924.9350269\tbest: 51924.9350269 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[15:35:04] bestTest = 14455.29548\n[15:35:04] bestIteration = 1988\n[15:35:04] Shrink model to first 1989 iterations.\n[15:35:04] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 2.8784148934310205, 'min_data_in_leaf': 9} scored -14455.295105502137 in 0:00:02.505396\n[15:35:05] 0:\tlearn: 54879.7698445\ttest: 51849.0120334\tbest: 51849.0120334 (0)\ttotal: 1.75ms\tremaining: 3.51s\n[15:35:08] bestTest = 14851.20078\n[15:35:08] bestIteration = 1726\n[15:35:08] Shrink model to first 1727 iterations.\n[15:35:08] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 4.027512319819173, 'min_data_in_leaf': 8} scored -14851.20062099359 in 0:00:03.325324\n[15:35:08] 0:\tlearn: 54936.3650869\ttest: 51876.8629388\tbest: 51876.8629388 (0)\ttotal: 3.06ms\tremaining: 6.12s\n[15:35:14] bestTest = 14927.43569\n[15:35:14] bestIteration = 1896\n[15:35:14] Shrink model to first 1897 iterations.\n[15:35:14] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.7612308513119214, 'min_data_in_leaf': 6} scored -14927.435430021367 in 0:00:06.059888\n[15:35:14] 0:\tlearn: 54883.7138976\ttest: 51917.1229049\tbest: 51917.1229049 (0)\ttotal: 1.31ms\tremaining: 2.62s\n[15:35:16] Stopped by overfitting detector  (300 iterations wait)\n[15:35:16] bestTest = 14583.95958\n[15:35:16] bestIteration = 1144\n[15:35:16] Shrink model to first 1145 iterations.\n[15:35:16] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 2.3884349693091984, 'min_data_in_leaf': 9} scored -14583.959668803418 in 0:00:01.888701\n[15:35:16] 0:\tlearn: 54850.5231851\ttest: 51881.9284736\tbest: 51881.9284736 (0)\ttotal: 1.37ms\tremaining: 2.74s\n[15:35:18] Stopped by overfitting detector  (300 iterations wait)\n[15:35:18] bestTest = 14351.06336\n[15:35:18] bestIteration = 1082\n[15:35:18] Shrink model to first 1083 iterations.\n[15:35:18] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.24349002056230054, 'min_data_in_leaf': 7} scored -14351.06360176282 in 0:00:01.820317\n[15:35:18] 0:\tlearn: 54846.0740532\ttest: 51883.5348201\tbest: 51883.5348201 (0)\ttotal: 1.76ms\tremaining: 3.51s\n[15:35:20] Stopped by overfitting detector  (300 iterations wait)\n[15:35:20] bestTest = 14938.85323\n[15:35:20] bestIteration = 1098\n[15:35:20] Shrink model to first 1099 iterations.\n[15:35:20] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.2502372923656908, 'min_data_in_leaf': 3} scored -14938.853031517094 in 0:00:02.574348\n[15:35:20] 0:\tlearn: 54773.7372609\ttest: 51796.1199579\tbest: 51796.1199579 (0)\ttotal: 6.2ms\tremaining: 12.4s\n[15:35:28] Stopped by overfitting detector  (300 iterations wait)\n[15:35:28] bestTest = 15670.53405\n[15:35:28] bestIteration = 1314\n[15:35:28] Shrink model to first 1315 iterations.\n[15:35:28] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04073006220997768, 'min_data_in_leaf': 18} scored -15670.533687232906 in 0:00:07.443677\n[15:35:28] 0:\tlearn: 54948.9737732\ttest: 51985.7926690\tbest: 51985.7926690 (0)\ttotal: 1.34ms\tremaining: 2.69s\n[15:35:30] Stopped by overfitting detector  (300 iterations wait)\n[15:35:30] bestTest = 14919.96037\n[15:35:30] bestIteration = 1658\n[15:35:30] Shrink model to first 1659 iterations.\n[15:35:30] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 6.876802589310074, 'min_data_in_leaf': 7} scored -14919.960403311965 in 0:00:02.440246\n[15:35:30] 0:\tlearn: 54869.2972754\ttest: 51901.8586023\tbest: 51901.8586023 (0)\ttotal: 1.34ms\tremaining: 2.69s\n[15:35:32] Stopped by overfitting detector  (300 iterations wait)\n[15:35:32] bestTest = 14506.48785\n[15:35:32] bestIteration = 1295\n[15:35:32] Shrink model to first 1296 iterations.\n[15:35:32] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.4457249957307514, 'min_data_in_leaf': 8} scored -14506.487763755342 in 0:00:02.113432\n[15:35:32] 0:\tlearn: 54856.3379680\ttest: 51888.1076443\tbest: 51888.1076443 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[15:35:34] Stopped by overfitting detector  (300 iterations wait)\n[15:35:34] bestTest = 14373.94118\n[15:35:34] bestIteration = 1429\n[15:35:34] Shrink model to first 1430 iterations.\n[15:35:34] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.6128116149427137, 'min_data_in_leaf': 5} scored -14373.94115584936 in 0:00:02.210892\n[15:35:35] 0:\tlearn: 54857.0469069\ttest: 51888.8606198\tbest: 51888.8606198 (0)\ttotal: 1.41ms\tremaining: 2.81s\n[15:35:37] Stopped by overfitting detector  (300 iterations wait)\n[15:35:37] bestTest = 14450.16669\n[15:35:37] bestIteration = 1360\n[15:35:37] Shrink model to first 1361 iterations.\n[15:35:37] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.6580249676130109, 'min_data_in_leaf': 1} scored -14450.16609909188 in 0:00:02.143681\n[15:35:37] 0:\tlearn: 54849.0067722\ttest: 51880.3160957\tbest: 51880.3160957 (0)\ttotal: 1.33ms\tremaining: 2.65s\n[15:35:39] Stopped by overfitting detector  (300 iterations wait)\n[15:35:39] bestTest = 14570.04957\n[15:35:39] bestIteration = 1264\n[15:35:39] Shrink model to first 1265 iterations.\n[15:35:39] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.14762092507808697, 'min_data_in_leaf': 5} scored -14570.049863114316 in 0:00:02.299028\n[15:35:39] 0:\tlearn: 54846.6660821\ttest: 51877.8265143\tbest: 51877.8265143 (0)\ttotal: 1.32ms\tremaining: 2.65s\n[15:35:41] Stopped by overfitting detector  (300 iterations wait)\n[15:35:41] bestTest = 14492.68395\n[15:35:41] bestIteration = 1148\n[15:35:41] Shrink model to first 1149 iterations.\n[15:35:41] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 4.389045301678059e-08, 'min_data_in_leaf': 5} scored -14492.684027777777 in 0:00:01.882600\n[15:35:41] 0:\tlearn: 54802.4897876\ttest: 51808.3721438\tbest: 51808.3721438 (0)\ttotal: 2.29ms\tremaining: 4.57s\n[15:35:45] Stopped by overfitting detector  (300 iterations wait)\n[15:35:45] bestTest = 15145.53145\n[15:35:45] bestIteration = 1613\n[15:35:45] Shrink model to first 1614 iterations.\n[15:35:45] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 4.97691495592378e-05, 'min_data_in_leaf': 6} scored -15145.531099759615 in 0:00:04.327535\n[15:35:45] 0:\tlearn: 54852.4661671\ttest: 51891.9678459\tbest: 51891.9678459 (0)\ttotal: 1.76ms\tremaining: 3.52s\n[15:35:48] bestTest = 15218.65137\n[15:35:48] bestIteration = 1923\n[15:35:49] Shrink model to first 1924 iterations.\n[15:35:49] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.43692131736864964, 'min_data_in_leaf': 3} scored -15218.652059962607 in 0:00:03.364732\n[15:35:49] 0:\tlearn: 55099.5375647\ttest: 52078.0631753\tbest: 52078.0631753 (0)\ttotal: 1.32ms\tremaining: 2.64s\n[15:35:50] Stopped by overfitting detector  (300 iterations wait)\n[15:35:50] bestTest = 15412.40362\n[15:35:50] bestIteration = 1125\n[15:35:50] Shrink model to first 1126 iterations.\n[15:35:50] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 4.090556602882469e-06, 'min_data_in_leaf': 2} scored -15412.404113247863 in 0:00:01.869944\n[15:35:51] 0:\tlearn: 54837.4499074\ttest: 51871.5962690\tbest: 51871.5962690 (0)\ttotal: 1.74ms\tremaining: 3.48s\n[15:35:53] Stopped by overfitting detector  (300 iterations wait)\n[15:35:53] bestTest = 15067.49926\n[15:35:53] bestIteration = 1195\n[15:35:53] Shrink model to first 1196 iterations.\n[15:35:53] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.019941380443069395, 'min_data_in_leaf': 12} scored -15067.498881543803 in 0:00:02.978078\n[15:35:54] 0:\tlearn: 54858.1546093\ttest: 51890.0369592\tbest: 51890.0369592 (0)\ttotal: 1.58ms\tremaining: 3.16s\n[15:35:55] Stopped by overfitting detector  (300 iterations wait)\n[15:35:55] bestTest = 14351.53369\n[15:35:55] bestIteration = 1144\n[15:35:55] Shrink model to first 1145 iterations.\n[15:35:55] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.728750911626566, 'min_data_in_leaf': 2} scored -14351.53405448718 in 0:00:01.956353\n[15:35:56] 0:\tlearn: 54864.9517600\ttest: 51897.2507700\tbest: 51897.2507700 (0)\ttotal: 1.44ms\tremaining: 2.89s\n[15:35:57] Stopped by overfitting detector  (300 iterations wait)\n[15:35:57] bestTest = 14425.55643\n[15:35:57] bestIteration = 1235\n[15:35:57] Shrink model to first 1236 iterations.\n[15:35:57] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1649139809158817, 'min_data_in_leaf': 4} scored -14425.556373530982 in 0:00:01.983080\n[15:35:58] 0:\tlearn: 54852.5942887\ttest: 51884.1300182\tbest: 51884.1300182 (0)\ttotal: 1.34ms\tremaining: 2.67s\n[15:36:00] Stopped by overfitting detector  (300 iterations wait)\n[15:36:00] bestTest = 14492.52827\n[15:36:00] bestIteration = 1392\n[15:36:00] Shrink model to first 1393 iterations.\n[15:36:00] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.37472399459837363, 'min_data_in_leaf': 16} scored -14492.528395432691 in 0:00:02.169331\n[15:36:00] 0:\tlearn: 54846.7992976\ttest: 51877.9682285\tbest: 51877.9682285 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[15:36:02] bestTest = 14829.98035\n[15:36:02] bestIteration = 1945\n[15:36:02] Shrink model to first 1946 iterations.\n[15:36:02] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00838987644427999, 'min_data_in_leaf': 7} scored -14829.980401976496 in 0:00:02.570565\n[15:36:02] 0:\tlearn: 54933.4003880\ttest: 51969.4683565\tbest: 51969.4683565 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[15:36:04] Stopped by overfitting detector  (300 iterations wait)\n[15:36:04] bestTest = 14630.56944\n[15:36:04] bestIteration = 1204\n[15:36:04] Shrink model to first 1205 iterations.\n[15:36:04] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 5.7719149612247165, 'min_data_in_leaf': 13} scored -14630.569110576924 in 0:00:01.939494\n[15:36:04] 0:\tlearn: 54846.6850387\ttest: 51877.8466804\tbest: 51877.8466804 (0)\ttotal: 1.35ms\tremaining: 2.7s\n[15:36:06] Stopped by overfitting detector  (300 iterations wait)\n[15:36:06] bestTest = 14596.19274\n[15:36:06] bestIteration = 1144\n[15:36:06] Shrink model to first 1145 iterations.\n[15:36:06] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0011938323956433281, 'min_data_in_leaf': 2} scored -14596.19234107906 in 0:00:01.913782\n[15:36:07] 0:\tlearn: 54846.6694590\ttest: 51877.8301066\tbest: 51877.8301066 (0)\ttotal: 1.36ms\tremaining: 2.73s\n[15:36:08] Stopped by overfitting detector  (300 iterations wait)\n[15:36:08] bestTest = 14494.65987\n[15:36:08] bestIteration = 1148\n[15:36:08] Shrink model to first 1149 iterations.\n[15:36:08] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00021270208486890641, 'min_data_in_leaf': 19} scored -14494.660006009615 in 0:00:02.172259\n[15:36:08] 0:\tlearn: 54839.0403244\ttest: 51873.8528567\tbest: 51873.8528567 (0)\ttotal: 1.84ms\tremaining: 3.68s\n[15:36:11] Stopped by overfitting detector  (300 iterations wait)\n[15:36:11] bestTest = 15181.08975\n[15:36:11] bestIteration = 1034\n[15:36:11] Shrink model to first 1035 iterations.\n[15:36:11] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.06052358355557167, 'min_data_in_leaf': 15} scored -15181.089860443377 in 0:00:02.320114\n[15:36:11] 0:\tlearn: 54850.7940743\ttest: 51882.2164649\tbest: 51882.2164649 (0)\ttotal: 1.34ms\tremaining: 2.68s\n[15:36:13] Stopped by overfitting detector  (300 iterations wait)\n[15:36:13] bestTest = 14543.37167\n[15:36:13] bestIteration = 1357\n[15:36:13] Shrink model to first 1358 iterations.\n[15:36:13] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.2606352202725956, 'min_data_in_leaf': 4} scored -14543.371694711539 in 0:00:02.191247\n[15:36:13] 0:\tlearn: 54986.7434529\ttest: 52094.6699191\tbest: 52094.6699191 (0)\ttotal: 3.09ms\tremaining: 6.17s\n[15:36:18] Stopped by overfitting detector  (300 iterations wait)\n[15:36:18] bestTest = 15258.95154\n[15:36:18] bestIteration = 1547\n[15:36:18] Shrink model to first 1548 iterations.\n[15:36:18] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0027581860838518674, 'min_data_in_leaf': 10} scored -15258.951322115385 in 0:00:05.632280\n[15:36:19] 0:\tlearn: 54863.1360039\ttest: 51895.3244687\tbest: 51895.3244687 (0)\ttotal: 1.33ms\tremaining: 2.65s\n[15:36:20] Stopped by overfitting detector  (300 iterations wait)\n[15:36:20] bestTest = 14338.2805\n[15:36:20] bestIteration = 1257\n[15:36:20] Shrink model to first 1258 iterations.\n[15:36:20] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.048033364505382, 'min_data_in_leaf': 4} scored -14338.28023170406 in 0:00:02.031801\n[15:36:21] 0:\tlearn: 54871.1862128\ttest: 51903.8605802\tbest: 51903.8605802 (0)\ttotal: 1.33ms\tremaining: 2.67s\n[15:36:22] Stopped by overfitting detector  (300 iterations wait)\n[15:36:22] bestTest = 14355.72111\n[15:36:22] bestIteration = 1238\n[15:36:22] Shrink model to first 1239 iterations.\n[15:36:22] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5682703025396012, 'min_data_in_leaf': 2} scored -14355.721437633547 in 0:00:02.042447\n[15:36:23] 0:\tlearn: 54867.2737846\ttest: 51899.7133569\tbest: 51899.7133569 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[15:36:25] Stopped by overfitting detector  (300 iterations wait)\n[15:36:25] bestTest = 14459.25443\n[15:36:25] bestIteration = 1290\n[15:36:25] Shrink model to first 1291 iterations.\n[15:36:25] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3147737815412146, 'min_data_in_leaf': 1} scored -14459.254323584402 in 0:00:02.135751\n[15:36:25] 0:\tlearn: 54901.1856931\ttest: 51935.5758153\tbest: 51935.5758153 (0)\ttotal: 2.03ms\tremaining: 4.05s\n[15:36:27] Stopped by overfitting detector  (300 iterations wait)\n[15:36:27] bestTest = 14714.46672\n[15:36:27] bestIteration = 1205\n[15:36:27] Shrink model to first 1206 iterations.\n[15:36:27] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 3.55412344674554, 'min_data_in_leaf': 2} scored -14714.466346153846 in 0:00:02.170774\n[15:36:27] 0:\tlearn: 54858.3820039\ttest: 51890.2784184\tbest: 51890.2784184 (0)\ttotal: 1.4ms\tremaining: 2.8s\n[15:36:29] Stopped by overfitting detector  (300 iterations wait)\n[15:36:29] bestTest = 14586.09175\n[15:36:29] bestIteration = 1238\n[15:36:29] Shrink model to first 1239 iterations.\n[15:36:29] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.7432820777649359, 'min_data_in_leaf': 3} scored -14586.09209735577 in 0:00:02.009029\n[15:36:29] 0:\tlearn: 54848.7388215\ttest: 51880.0311476\tbest: 51880.0311476 (0)\ttotal: 1.41ms\tremaining: 2.82s\n[15:36:31] Stopped by overfitting detector  (300 iterations wait)\n[15:36:31] bestTest = 14495.02983\n[15:36:31] bestIteration = 1241\n[15:36:31] Shrink model to first 1242 iterations.\n[15:36:31] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.13069989890794492, 'min_data_in_leaf': 5} scored -14495.029797676281 in 0:00:01.995725\n[15:36:31] 0:\tlearn: 54961.1913479\ttest: 51998.5722431\tbest: 51998.5722431 (0)\ttotal: 1.34ms\tremaining: 2.67s\n[15:36:33] bestTest = 14955.19082\n[15:36:33] bestIteration = 1923\n[15:36:33] Shrink model to first 1924 iterations.\n[15:36:33] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.758947195307095, 'min_data_in_leaf': 4} scored -14955.190905448719 in 0:00:02.540211\n[15:36:34] 0:\tlearn: 54854.5028403\ttest: 51886.1581325\tbest: 51886.1581325 (0)\ttotal: 1.32ms\tremaining: 2.63s\n[15:36:35] Stopped by overfitting detector  (300 iterations wait)\n[15:36:35] bestTest = 14452.02531\n[15:36:35] bestIteration = 1087\n[15:36:35] Shrink model to first 1088 iterations.\n[15:36:35] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.49596205871376187, 'min_data_in_leaf': 2} scored -14452.026175213676 in 0:00:01.820110\n[15:36:36] 0:\tlearn: 54868.9085831\ttest: 51901.4465753\tbest: 51901.4465753 (0)\ttotal: 1.35ms\tremaining: 2.69s\n[15:36:38] Stopped by overfitting detector  (300 iterations wait)\n[15:36:38] bestTest = 14430.29765\n[15:36:38] bestIteration = 1393\n[15:36:38] Shrink model to first 1394 iterations.\n[15:36:38] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.4205446512876692, 'min_data_in_leaf': 6} scored -14430.297793135684 in 0:00:02.428334\n[15:36:38] 0:\tlearn: 54874.0640950\ttest: 51842.8511984\tbest: 51842.8511984 (0)\ttotal: 1.76ms\tremaining: 3.51s\n[15:36:41] bestTest = 14556.17635\n[15:36:41] bestIteration = 1759\n[15:36:41] Shrink model to first 1760 iterations.\n[15:36:41] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 3.800956433760411, 'min_data_in_leaf': 1} scored -14556.176348824787 in 0:00:03.388396\n[15:36:41] 0:\tlearn: 54851.1486072\ttest: 51882.5933619\tbest: 51882.5933619 (0)\ttotal: 1.48ms\tremaining: 2.96s\n[15:36:43] Stopped by overfitting detector  (300 iterations wait)\n[15:36:43] bestTest = 14660.60753\n[15:36:43] bestIteration = 1259\n[15:36:43] Shrink model to first 1260 iterations.\n[15:36:43] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.2830833011763273, 'min_data_in_leaf': 12} scored -14660.607321714744 in 0:00:02.052880\n[15:36:43] 0:\tlearn: 54877.4086111\ttest: 51910.4511349\tbest: 51910.4511349 (0)\ttotal: 1.4ms\tremaining: 2.81s\n[15:36:45] Stopped by overfitting detector  (300 iterations wait)\n[15:36:45] bestTest = 14555.22596\n[15:36:45] bestIteration = 1473\n[15:36:45] Shrink model to first 1474 iterations.\n[15:36:45] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9740205094627117, 'min_data_in_leaf': 4} scored -14555.22554420406 in 0:00:02.241627\n[15:36:46] 0:\tlearn: 54856.6112506\ttest: 51888.3979123\tbest: 51888.3979123 (0)\ttotal: 1.31ms\tremaining: 2.61s\n[15:36:48] Stopped by overfitting detector  (300 iterations wait)\n[15:36:48] bestTest = 14405.15688\n[15:36:48] bestIteration = 1392\n[15:36:48] Shrink model to first 1393 iterations.\n[15:36:48] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.6302357082112374, 'min_data_in_leaf': 3} scored -14405.157485309828 in 0:00:02.149948\n[15:36:48] 0:\tlearn: 54848.1749116\ttest: 51879.4314264\tbest: 51879.4314264 (0)\ttotal: 1.36ms\tremaining: 2.72s\n[15:36:50] Stopped by overfitting detector  (300 iterations wait)\n[15:36:50] bestTest = 14649.26637\n[15:36:50] bestIteration = 1390\n[15:36:50] Shrink model to first 1391 iterations.\n[15:36:50] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.095107791560981, 'min_data_in_leaf': 11} scored -14649.266292735043 in 0:00:02.150360\n[15:36:50] 0:\tlearn: 54849.5449034\ttest: 51880.8883266\tbest: 51880.8883266 (0)\ttotal: 1.35ms\tremaining: 2.71s\n[15:36:52] Stopped by overfitting detector  (300 iterations wait)\n[15:36:52] bestTest = 14761.10628\n[15:36:52] bestIteration = 1354\n[15:36:52] Shrink model to first 1355 iterations.\n[15:36:52] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1816211000714363, 'min_data_in_leaf': 14} scored -14761.106103098291 in 0:00:02.193633\n[15:36:52] 0:\tlearn: 55130.2022106\ttest: 52108.2454631\tbest: 52108.2454631 (0)\ttotal: 1.35ms\tremaining: 2.69s\n[15:36:54] bestTest = 15073.43296\n[15:36:54] bestIteration = 1808\n[15:36:54] Shrink model to first 1809 iterations.\n[15:36:55] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.1564640375870967, 'min_data_in_leaf': 5} scored -15073.43274238782 in 0:00:02.532196\n[15:36:55] 0:\tlearn: 54847.2807611\ttest: 51878.4803827\tbest: 51878.4803827 (0)\ttotal: 1.35ms\tremaining: 2.69s\n[15:36:56] Stopped by overfitting detector  (300 iterations wait)\n[15:36:56] bestTest = 14656.14476\n[15:36:56] bestIteration = 1224\n[15:36:56] Shrink model to first 1225 iterations.\n[15:36:57] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.038723929433861645, 'min_data_in_leaf': 2} scored -14656.144214075855 in 0:00:02.000991\n[15:36:57] 0:\tlearn: 54864.5877905\ttest: 51896.8646859\tbest: 51896.8646859 (0)\ttotal: 1.63ms\tremaining: 3.26s\n[15:36:59] Stopped by overfitting detector  (300 iterations wait)\n[15:36:59] bestTest = 14289.09839\n[15:36:59] bestIteration = 1445\n[15:36:59] Shrink model to first 1446 iterations.\n[15:36:59] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1414637238518797, 'min_data_in_leaf': 8} scored -14289.09804019765 in 0:00:02.621726\n[15:36:59] 0:\tlearn: 54858.9523096\ttest: 51870.5318428\tbest: 51870.5318428 (0)\ttotal: 2.33ms\tremaining: 4.66s\n[15:37:02] Stopped by overfitting detector  (300 iterations wait)\n[15:37:02] bestTest = 15295.28706\n[15:37:02] bestIteration = 764\n[15:37:02] Shrink model to first 765 iterations.\n[15:37:02] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0044171324672664, 'min_data_in_leaf': 8} scored -15295.287126068377 in 0:00:02.531743\n[15:37:02] 0:\tlearn: 54924.4828986\ttest: 51960.1033006\tbest: 51960.1033006 (0)\ttotal: 1.33ms\tremaining: 2.65s\n[15:37:04] bestTest = 14761.17362\n[15:37:04] bestIteration = 1906\n[15:37:04] Shrink model to first 1907 iterations.\n[15:37:04] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 5.148953242840955, 'min_data_in_leaf': 9} scored -14761.173778044871 in 0:00:02.770359\n[15:37:05] 0:\tlearn: 54854.9041794\ttest: 51886.5845356\tbest: 51886.5845356 (0)\ttotal: 1.41ms\tremaining: 2.82s\n[15:37:07] Stopped by overfitting detector  (300 iterations wait)\n[15:37:07] bestTest = 14419.91862\n[15:37:07] bestIteration = 1393\n[15:37:07] Shrink model to first 1394 iterations.\n[15:37:07] \u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.521493735743152, 'min_data_in_leaf': 7} scored -14419.918703258547 in 0:00:02.184743\n[15:37:07] 0:\tlearn: 54851.8006021\ttest: 51883.2864296\tbest: 51883.2864296 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[15:37:09] Stopped by overfitting detector  (300 iterations wait)\n[15:37:09] bestTest = 14773.76279\n[15:37:09] bestIteration = 1263\n[15:37:09] Shrink model to first 1264 iterations.\n[15:37:09] \u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.32439207477216014, 'min_data_in_leaf': 10} scored -14773.762586805555 in 0:00:02.013643\n[15:37:09] 0:\tlearn: 54986.0537978\ttest: 52024.5055669\tbest: 52024.5055669 (0)\ttotal: 1.4ms\tremaining: 2.79s\n[15:37:11] bestTest = 15033.92182\n[15:37:11] bestIteration = 1942\n[15:37:11] Shrink model to first 1943 iterations.\n[15:37:11] \u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 9.596748953569511, 'min_data_in_leaf': 6} scored -15033.921991853633 in 0:00:02.519363\n[15:37:11] 0:\tlearn: 54872.7366115\ttest: 51905.5033146\tbest: 51905.5033146 (0)\ttotal: 1.32ms\tremaining: 2.63s\n[15:37:13] Stopped by overfitting detector  (300 iterations wait)\n[15:37:13] bestTest = 14809.02682\n[15:37:13] bestIteration = 1422\n[15:37:13] Shrink model to first 1423 iterations.\n[15:37:13] \u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 1.6690712347548502, 'min_data_in_leaf': 9} scored -14809.027160122863 in 0:00:02.185403\n[15:37:14] 0:\tlearn: 54885.9407454\ttest: 51919.4776065\tbest: 51919.4776065 (0)\ttotal: 1.34ms\tremaining: 2.69s\n[15:37:16] bestTest = 14458.84429\n[15:37:16] bestIteration = 1850\n[15:37:16] Shrink model to first 1851 iterations.\n[15:37:16] \u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 2.535583084627398, 'min_data_in_leaf': 11} scored -14458.84391693376 in 0:00:02.527786\n[15:37:16] 0:\tlearn: 54861.7308822\ttest: 51893.8334218\tbest: 51893.8334218 (0)\ttotal: 1.27ms\tremaining: 2.55s\n[15:37:18] Stopped by overfitting detector  (300 iterations wait)\n[15:37:18] bestTest = 14568.51924\n[15:37:18] bestIteration = 1455\n[15:37:18] Shrink model to first 1456 iterations.\n[15:37:18] \u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.9577688702612644, 'min_data_in_leaf': 8} scored -14568.519163995727 in 0:00:02.236425\n[15:37:18] 0:\tlearn: 54849.5908438\ttest: 51880.9371757\tbest: 51880.9371757 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[15:37:20] Stopped by overfitting detector  (300 iterations wait)\n[15:37:20] bestTest = 14628.71232\n[15:37:20] bestIteration = 1271\n[15:37:20] Shrink model to first 1272 iterations.\n[15:37:20] \u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1845247692400858, 'min_data_in_leaf': 7} scored -14628.712256276709 in 0:00:02.018684\n[15:37:21] 0:\tlearn: 54862.3817031\ttest: 51904.4932178\tbest: 51904.4932178 (0)\ttotal: 2.03ms\tremaining: 4.06s\n[15:37:23] Stopped by overfitting detector  (300 iterations wait)\n[15:37:23] bestTest = 15201.00079\n[15:37:23] bestIteration = 1036\n[15:37:23] Shrink model to first 1037 iterations.\n[15:37:23] \u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.7526915159899664, 'min_data_in_leaf': 5} scored -15201.001118456197 in 0:00:02.390912\n[15:37:23] 0:\tlearn: 55100.3845348\ttest: 52078.8949202\tbest: 52078.8949202 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[15:37:24] Stopped by overfitting detector  (300 iterations wait)\n[15:37:24] bestTest = 15350.40538\n[15:37:24] bestIteration = 1063\n[15:37:24] Shrink model to first 1064 iterations.\n[15:37:24] \u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.05809504952907122, 'min_data_in_leaf': 6} scored -15350.405348557691 in 0:00:01.778679\n[15:37:25] 0:\tlearn: 54907.9238731\ttest: 51942.6789404\tbest: 51942.6789404 (0)\ttotal: 1.33ms\tremaining: 2.66s\n[15:37:26] Stopped by overfitting detector  (300 iterations wait)\n[15:37:26] bestTest = 14640.33968\n[15:37:26] bestIteration = 1146\n[15:37:26] Shrink model to first 1147 iterations.\n[15:37:26] \u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 4.010586515604111, 'min_data_in_leaf': 10} scored -14640.339242788461 in 0:00:01.887150\n[15:37:26] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[15:37:26] The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.474041064227797, 'min_data_in_leaf': 11}\u001b[0m\n achieve -14205.6746 mae\n[15:37:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:37:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:37:27] 0:\tlearn: 55731.5954043\ttest: 52724.1830780\tbest: 52724.1830780 (0)\ttotal: 1.32ms\tremaining: 3.95s\n[15:37:28] Stopped by overfitting detector  (100 iterations wait)\n[15:37:28] bestTest = 14669.97479\n[15:37:28] bestIteration = 1462\n[15:37:28] Shrink model to first 1463 iterations.\n[15:37:28] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:37:29] 0:\tlearn: 55675.7544171\ttest: 52854.0136041\tbest: 52854.0136041 (0)\ttotal: 1.63ms\tremaining: 4.89s\n[15:37:32] Stopped by overfitting detector  (100 iterations wait)\n[15:37:32] bestTest = 15949.69284\n[15:37:32] bestIteration = 1985\n[15:37:32] Shrink model to first 1986 iterations.\n[15:37:32] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:37:32] 0:\tlearn: 54668.4723473\ttest: 56046.7422434\tbest: 56046.7422434 (0)\ttotal: 1.34ms\tremaining: 4.01s\n[15:37:32] Stopped by overfitting detector  (100 iterations wait)\n[15:37:32] bestTest = 14813.22456\n[15:37:32] bestIteration = 659\n[15:37:32] Shrink model to first 660 iterations.\n[15:37:32] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:37:33] 0:\tlearn: 54506.8073125\ttest: 58679.7815586\tbest: 58679.7815586 (0)\ttotal: 1.32ms\tremaining: 3.96s\n[15:37:34] Stopped by overfitting detector  (100 iterations wait)\n[15:37:34] bestTest = 16323.20825\n[15:37:34] bestIteration = 1035\n[15:37:34] Shrink model to first 1036 iterations.\n[15:37:34] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:37:34] 0:\tlearn: 54937.4678886\ttest: 55519.6039046\tbest: 55519.6039046 (0)\ttotal: 1.29ms\tremaining: 3.88s\n[15:37:36] Stopped by overfitting detector  (100 iterations wait)\n[15:37:36] bestTest = 15138.08358\n[15:37:36] bestIteration = 1398\n[15:37:36] Shrink model to first 1399 iterations.\n[15:37:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15378.234592385488\u001b[0m\n[15:37:36] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:37:36] Time left 1280.45 secs\n\n[15:37:36] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[15:37:36] Blending: optimization starts with equal weights and score \u001b[1m-14784.691523303723\u001b[0m\n[15:37:36] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14707.550005351028\u001b[0m, weights = \u001b[1m[0.11187175 0.1329339  0.2988686  0.45632574 0.        ]\u001b[0m\n[15:37:36] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14705.99951171875\u001b[0m, weights = \u001b[1m[0.11550207 0.11784247 0.3013742  0.46528122 0.        ]\u001b[0m\n[15:37:36] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14705.99960870612\u001b[0m, weights = \u001b[1m[0.11550207 0.11784247 0.3013742  0.46528125 0.        ]\u001b[0m\n[15:37:36] Blending: no score update. Terminated\n\n[15:37:36] \u001b[1mAutoml preset training completed in 613.34 seconds\u001b[0m\n\n[15:37:36] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.11550 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.11784 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.30137 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.46528 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n\n[15:37:36] ==================================================\n[15:37:36] Start 1 automl preset configuration:\n[15:37:36] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 50}, 'nn_params': {'random_state': 50}, 'general_params': {'return_all_predictions': False}}\n[15:37:36] Found reader_params in kwargs, need to combine\n[15:37:36] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 50, 'cv': 5}\n[15:37:36] Stdout logging level is INFO3.\n[15:37:36] Task: reg\n\n[15:37:36] Start automl preset with listed constraints:\n[15:37:36] - time: 1280.33 seconds\n[15:37:36] - CPU: 4 cores\n[15:37:36] - memory: 16 GB\n\n[15:37:36] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[15:37:42] Feats was rejected during automatic roles guess: []\n[15:37:42] Layer \u001b[1m1\u001b[0m train process start. Time left 1274.06 secs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:37:43] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[15:37:43] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:37:43] Linear model: C = 1e-05 score = -36159.33246527778\n[15:37:43] Linear model: C = 5e-05 score = -22347.60987580128\n[15:37:43] Linear model: C = 0.0001 score = -19273.610109508547\n[15:37:44] Linear model: C = 0.0005 score = -16587.219784989316\n[15:37:44] Linear model: C = 0.001 score = -16347.442224225428\n[15:37:44] Linear model: C = 0.005 score = -16347.442224225428\n[15:37:44] Linear model: C = 0.01 score = -16347.441639957266\n[15:37:44] Linear model: C = 0.05 score = -18558.546858306625\n[15:37:44] Linear model: C = 0.1 score = -18558.546858306625\n[15:37:44] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:37:44] Linear model: C = 1e-05 score = -30897.134114583332\n[15:37:44] Linear model: C = 5e-05 score = -19754.27236912393\n[15:37:45] Linear model: C = 0.0001 score = -17687.33393429487\n[15:37:45] Linear model: C = 0.0005 score = -14752.284421741453\n[15:37:45] Linear model: C = 0.001 score = -14752.284421741453\n[15:37:45] Linear model: C = 0.005 score = -14752.284288194445\n[15:37:45] Linear model: C = 0.01 score = -14486.714743589744\n[15:37:45] Linear model: C = 0.05 score = -14486.716179220086\n[15:37:45] Linear model: C = 0.1 score = -14486.717548076924\n[15:37:45] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:37:46] Linear model: C = 1e-05 score = -43621.97699652778\n[15:37:46] Linear model: C = 5e-05 score = -29220.511735443375\n[15:37:46] Linear model: C = 0.0001 score = -25629.721237313035\n[15:37:46] Linear model: C = 0.0005 score = -21079.597119453625\n[15:37:46] Linear model: C = 0.001 score = -21079.597119453625\n[15:37:47] Linear model: C = 0.005 score = -20077.68318058894\n[15:37:47] Linear model: C = 0.01 score = -20423.19567558093\n[15:37:47] Linear model: C = 0.05 score = -21681.35497003539\n[15:37:47] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:37:47] Linear model: C = 1e-05 score = -32823.77310219957\n[15:37:47] Linear model: C = 5e-05 score = -20525.79446083691\n[15:37:47] Linear model: C = 0.0001 score = -18317.300261534336\n[15:37:48] Linear model: C = 0.0005 score = -15821.158471365343\n[15:37:48] Linear model: C = 0.001 score = -15622.423794594957\n[15:37:48] Linear model: C = 0.005 score = -16194.93393743294\n[15:37:48] Linear model: C = 0.01 score = -16194.934599651287\n[15:37:48] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:37:49] Linear model: C = 1e-05 score = -38696.485716201714\n[15:37:49] Linear model: C = 5e-05 score = -25858.404238197425\n[15:37:49] Linear model: C = 0.0001 score = -23546.896576582618\n[15:37:49] Linear model: C = 0.0005 score = -20662.26986655043\n[15:37:49] Linear model: C = 0.001 score = -20344.82274342811\n[15:37:50] Linear model: C = 0.005 score = -20316.091034066525\n[15:37:50] Linear model: C = 0.01 score = -20520.962932537554\n[15:37:50] Linear model: C = 0.05 score = -20520.962932537554\n[15:37:50] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-17369.044874217412\u001b[0m\n[15:37:50] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[15:37:50] Time left 1266.13 secs\n\n[15:37:50] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:37:53] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[15:37:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[15:37:53] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:37:53] Training until validation scores don't improve for 200 rounds\n[15:37:55] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:37:55] Training until validation scores don't improve for 200 rounds\n[15:37:57] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:37:57] Training until validation scores don't improve for 200 rounds\n[15:37:59] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:37:59] Training until validation scores don't improve for 200 rounds\n[15:38:01] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:38:01] Training until validation scores don't improve for 200 rounds\n[15:38:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-16258.893390812285\u001b[0m\n[15:38:06] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[15:38:06] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 218.73 secs\n[15:38:06] Training until validation scores don't improve for 200 rounds\n[15:38:08] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15134.221955128205 in 0:00:02.205472\n[15:38:08] Training until validation scores don't improve for 200 rounds\n[15:38:10] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -14603.014857104701 in 0:00:02.071200\n[15:38:10] Training until validation scores don't improve for 200 rounds\n[15:38:12] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -14670.780381944445 in 0:00:02.045505\n[15:38:12] Training until validation scores don't improve for 200 rounds\n[15:38:14] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -14837.376969818377 in 0:00:02.082154\n[15:38:14] Training until validation scores don't improve for 200 rounds\n[15:38:16] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -14495.692541399572 in 0:00:01.669518\n[15:38:16] Training until validation scores don't improve for 200 rounds\n[15:38:18] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -14572.512553418803 in 0:00:01.898375\n[15:38:18] Training until validation scores don't improve for 200 rounds\n[15:38:20] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15012.13752003205 in 0:00:01.976233\n[15:38:20] Training until validation scores don't improve for 200 rounds\n[15:38:21] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -14302.083867521367 in 0:00:01.636210\n[15:38:21] Training until validation scores don't improve for 200 rounds\n[15:38:24] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15244.238514957266 in 0:00:02.639179\n[15:38:24] Training until validation scores don't improve for 200 rounds\n[15:38:26] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -14496.486511752137 in 0:00:01.927356\n[15:38:26] Training until validation scores don't improve for 200 rounds\n[15:38:27] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527} scored -14335.24439102564 in 0:00:01.623831\n[15:38:27] Training until validation scores don't improve for 200 rounds\n[15:38:29] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5075634079566923, 'num_leaves': 165, 'bagging_fraction': 0.6795146156302498, 'min_sum_hessian_in_leaf': 0.026738277166992196, 'reg_alpha': 0.0015258645761591619, 'reg_lambda': 0.01881061891210943} scored -14464.294704861111 in 0:00:01.735040\n[15:38:29] Training until validation scores don't improve for 200 rounds\n[15:38:31] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 129, 'bagging_fraction': 0.6794216628122437, 'min_sum_hessian_in_leaf': 0.01875620628228737, 'reg_alpha': 0.0437281057923299, 'reg_lambda': 0.008452229729634516} scored -14479.891392895299 in 0:00:01.813143\n[15:38:31] Training until validation scores don't improve for 200 rounds\n[15:38:33] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.580632857909944, 'num_leaves': 175, 'bagging_fraction': 0.6931449938963745, 'min_sum_hessian_in_leaf': 0.0012748888933395554, 'reg_alpha': 7.743660314424457e-05, 'reg_lambda': 0.004387238736364167} scored -14554.061899038461 in 0:00:01.969706\n[15:38:33] Training until validation scores don't improve for 200 rounds\n[15:38:36] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.6050778051161564, 'num_leaves': 117, 'bagging_fraction': 0.7406442464830113, 'min_sum_hessian_in_leaf': 0.49597135657371333, 'reg_alpha': 0.07389181849439323, 'reg_lambda': 3.806966588951351e-05} scored -14541.754006410256 in 0:00:03.532455\n[15:38:37] Training until validation scores don't improve for 200 rounds\n[15:38:39] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 185, 'bagging_fraction': 0.6223441463224709, 'min_sum_hessian_in_leaf': 3.113484383311032, 'reg_alpha': 4.150722101207275e-05, 'reg_lambda': 0.23706626312372373} scored -14736.083233173076 in 0:00:02.033055\n[15:38:39] Training until validation scores don't improve for 200 rounds\n[15:38:41] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5065701578589041, 'num_leaves': 153, 'bagging_fraction': 0.7382891993530122, 'min_sum_hessian_in_leaf': 0.1341831353198184, 'reg_alpha': 0.012787488060337839, 'reg_lambda': 0.0006027209302579824} scored -14609.194143963676 in 0:00:02.000997\n[15:38:41] Training until validation scores don't improve for 200 rounds\n[15:38:43] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6426075673808482, 'num_leaves': 105, 'bagging_fraction': 0.6461408885576574, 'min_sum_hessian_in_leaf': 0.03465743419765038, 'reg_alpha': 6.176204999488035e-06, 'reg_lambda': 1.4162462058323914e-06} scored -14529.74328926282 in 0:00:02.040809\n[15:38:43] Training until validation scores don't improve for 200 rounds\n[15:38:45] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.560545561591961, 'num_leaves': 203, 'bagging_fraction': 0.9790786324781682, 'min_sum_hessian_in_leaf': 1.7662420267092591, 'reg_alpha': 0.0003812005870016122, 'reg_lambda': 0.03988487774796662} scored -14895.21968482906 in 0:00:02.253005\n[15:38:45] Training until validation scores don't improve for 200 rounds\n[15:38:47] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8696664761533919, 'num_leaves': 21, 'bagging_fraction': 0.5011551454270256, 'min_sum_hessian_in_leaf': 0.31914768556465484, 'reg_alpha': 0.36714255469878165, 'reg_lambda': 0.0015579107174789602} scored -14485.061231303418 in 0:00:02.203825\n[15:38:47] Training until validation scores don't improve for 200 rounds\n[15:38:49] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.5542640757916181, 'num_leaves': 150, 'bagging_fraction': 0.8879124430248126, 'min_sum_hessian_in_leaf': 0.012701877952916336, 'reg_alpha': 6.308891891166231e-07, 'reg_lambda': 0.00010079030010438313} scored -14977.96264022436 in 0:00:02.089194\n[15:38:49] Training until validation scores don't improve for 200 rounds\n[15:38:51] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5217842204063585, 'num_leaves': 166, 'bagging_fraction': 0.688672075673601, 'min_sum_hessian_in_leaf': 0.030022925029790565, 'reg_alpha': 0.0015190357837644327, 'reg_lambda': 0.0175826527889143} scored -14436.296908386752 in 0:00:01.797954\n[15:38:51] Training until validation scores don't improve for 200 rounds\n[15:38:53] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.6298581949137815, 'num_leaves': 199, 'bagging_fraction': 0.7022391969391486, 'min_sum_hessian_in_leaf': 0.06507298551895836, 'reg_alpha': 0.0031918818263396145, 'reg_lambda': 0.06259574029281156} scored -14542.734508547008 in 0:00:02.131213\n[15:38:53] Training until validation scores don't improve for 200 rounds\n[15:38:55] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.5014723328935634, 'num_leaves': 137, 'bagging_fraction': 0.5770863182333468, 'min_sum_hessian_in_leaf': 0.012405319719901478, 'reg_alpha': 7.756566674341428e-05, 'reg_lambda': 0.0029088409681667206} scored -14247.82502003205 in 0:00:01.498285\n[15:38:55] Training until validation scores don't improve for 200 rounds\n[15:38:56] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5446537895254564, 'num_leaves': 105, 'bagging_fraction': 0.5642576797328802, 'min_sum_hessian_in_leaf': 0.001862683251243229, 'reg_alpha': 0.000121044433366855, 'reg_lambda': 0.0018280161334575833} scored -14492.510550213676 in 0:00:01.634859\n[15:38:56] Training until validation scores don't improve for 200 rounds\n[15:38:58] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.5826639565668909, 'num_leaves': 254, 'bagging_fraction': 0.6473513716864755, 'min_sum_hessian_in_leaf': 0.010050379085250484, 'reg_alpha': 1.646760751869591e-05, 'reg_lambda': 4.833089703289832e-06} scored -14371.50093482906 in 0:00:01.785611\n[15:38:58] Training until validation scores don't improve for 200 rounds\n[15:39:00] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.5072888054434992, 'num_leaves': 138, 'bagging_fraction': 0.5802465427439707, 'min_sum_hessian_in_leaf': 0.15669611811550388, 'reg_alpha': 0.00023690840352723252, 'reg_lambda': 8.989819719913048e-05} scored -14418.774873130342 in 0:00:01.498114\n[15:39:00] Training until validation scores don't improve for 200 rounds\n[15:39:01] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.6823394355164146, 'num_leaves': 227, 'bagging_fraction': 0.6299741561672756, 'min_sum_hessian_in_leaf': 0.0542680618330701, 'reg_alpha': 1.0047492105683768e-06, 'reg_lambda': 0.2490150539658742} scored -14444.130976228633 in 0:00:01.753109\n[15:39:01] Training until validation scores don't improve for 200 rounds\n[15:39:03] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.6220196277305837, 'num_leaves': 91, 'bagging_fraction': 0.7799866395392466, 'min_sum_hessian_in_leaf': 0.003409829764153039, 'reg_alpha': 0.00041793097401918855, 'reg_lambda': 1.3650185065094187} scored -14617.801148504273 in 0:00:01.928144\n[15:39:03] Training until validation scores don't improve for 200 rounds\n[15:39:05] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6806906568643938, 'num_leaves': 188, 'bagging_fraction': 0.5185056120337801, 'min_sum_hessian_in_leaf': 0.20548911823668425, 'reg_alpha': 1.2447243203270268e-06, 'reg_lambda': 0.003679970135780667} scored -14510.18329326923 in 0:00:01.719815\n[15:39:05] Training until validation scores don't improve for 200 rounds\n[15:39:08] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5684555852198888, 'num_leaves': 134, 'bagging_fraction': 0.6095719100435864, 'min_sum_hessian_in_leaf': 0.01638975746099182, 'reg_alpha': 0.012282727445768457, 'reg_lambda': 1.0209699332115752e-07} scored -14388.878872863248 in 0:00:03.221694\n[15:39:08] Training until validation scores don't improve for 200 rounds\n[15:39:10] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5464649767830625, 'num_leaves': 255, 'bagging_fraction': 0.6479248597224845, 'min_sum_hessian_in_leaf': 0.008749825930144426, 'reg_alpha': 2.741455013718485e-05, 'reg_lambda': 2.851606327596062e-06} scored -14443.816038995727 in 0:00:01.731850\n[15:39:10] Training until validation scores don't improve for 200 rounds\n[15:39:12] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.585980103723178, 'num_leaves': 252, 'bagging_fraction': 0.6590671516543318, 'min_sum_hessian_in_leaf': 0.011775977648152601, 'reg_alpha': 1.7936505732593054e-05, 'reg_lambda': 0.00023498796241233066} scored -14392.545205662393 in 0:00:01.808049\n[15:39:12] Training until validation scores don't improve for 200 rounds\n[15:39:13] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5343198546696936, 'num_leaves': 225, 'bagging_fraction': 0.562296220482492, 'min_sum_hessian_in_leaf': 0.006236045079136774, 'reg_alpha': 1.4178383324609216e-07, 'reg_lambda': 6.360519077079365e-07} scored -14372.70329193376 in 0:00:01.608256\n[15:39:13] Training until validation scores don't improve for 200 rounds\n[15:39:15] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5022893016523609, 'num_leaves': 214, 'bagging_fraction': 0.7166467691393597, 'min_sum_hessian_in_leaf': 0.37200808980947453, 'reg_alpha': 9.170367873496892e-06, 'reg_lambda': 7.089560547924296e-06} scored -14569.208700587607 in 0:00:01.667523\n[15:39:15] Training until validation scores don't improve for 200 rounds\n[15:39:17] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5368966323987681, 'num_leaves': 236, 'bagging_fraction': 0.775683549735668, 'min_sum_hessian_in_leaf': 0.0023694333889151616, 'reg_alpha': 2.6289224585073036e-06, 'reg_lambda': 0.0011560080689684582} scored -14652.717147435897 in 0:00:01.832492\n[15:39:17] Training until validation scores don't improve for 200 rounds\n[15:39:19] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.5757312595227064, 'num_leaves': 215, 'bagging_fraction': 0.5889166863192875, 'min_sum_hessian_in_leaf': 0.739116835065696, 'reg_alpha': 0.0005354268482017275, 'reg_lambda': 1.6468177519646233e-07} scored -14642.728465544871 in 0:00:01.921614\n[15:39:19] Training until validation scores don't improve for 200 rounds\n[15:39:20] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.5302902575224377, 'num_leaves': 73, 'bagging_fraction': 0.6149547837767193, 'min_sum_hessian_in_leaf': 0.07830738511597746, 'reg_alpha': 8.461074731703286e-05, 'reg_lambda': 3.939761050161341e-05} scored -14363.361344818377 in 0:00:01.561830\n[15:39:20] Training until validation scores don't improve for 200 rounds\n[15:39:22] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.7215514614076, 'num_leaves': 74, 'bagging_fraction': 0.6114491970541841, 'min_sum_hessian_in_leaf': 0.08916219001048725, 'reg_alpha': 0.0044079047986167125, 'reg_lambda': 3.629953737227891e-05} scored -14666.021668002137 in 0:00:01.787415\n[15:39:22] Training until validation scores don't improve for 200 rounds\n[15:39:24] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.6137749215573269, 'num_leaves': 90, 'bagging_fraction': 0.5562643243805424, 'min_sum_hessian_in_leaf': 0.039047483073679765, 'reg_alpha': 8.849642582578387e-05, 'reg_lambda': 0.00019215418671224543} scored -14524.907685630342 in 0:00:01.702830\n[15:39:24] Training until validation scores don't improve for 200 rounds\n[15:39:26] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.6623277011022988, 'num_leaves': 44, 'bagging_fraction': 0.5855994076232525, 'min_sum_hessian_in_leaf': 0.9737725747766045, 'reg_alpha': 5.3124754480249214e-08, 'reg_lambda': 0.0005584993089847983} scored -14562.542634882479 in 0:00:01.606495\n[15:39:26] Training until validation scores don't improve for 200 rounds\n[15:39:27] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5284038371037538, 'num_leaves': 243, 'bagging_fraction': 0.6606178038753195, 'min_sum_hessian_in_leaf': 0.01815402945403281, 'reg_alpha': 1.6499237122999915e-05, 'reg_lambda': 1.076976622013562e-05} scored -14344.382779113248 in 0:00:01.807928\n[15:39:27] Training until validation scores don't improve for 200 rounds\n[15:39:29] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5229341311721801, 'num_leaves': 148, 'bagging_fraction': 0.6661387889056093, 'min_sum_hessian_in_leaf': 0.021825519452991517, 'reg_alpha': 3.4901798959618e-06, 'reg_lambda': 2.069665731501817e-05} scored -14450.911324786324 in 0:00:01.606020\n[15:39:29] Training until validation scores don't improve for 200 rounds\n[15:39:31] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5319393147065887, 'num_leaves': 123, 'bagging_fraction': 0.7201199681908231, 'min_sum_hessian_in_leaf': 0.08028526158018182, 'reg_alpha': 0.000858952924106715, 'reg_lambda': 9.428194314445795e-05} scored -14521.852764423076 in 0:00:01.921652\n[15:39:31] Training until validation scores don't improve for 200 rounds\n[15:39:33] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.8503556862611004, 'num_leaves': 111, 'bagging_fraction': 0.6318835350772831, 'min_sum_hessian_in_leaf': 0.005927287087566258, 'reg_alpha': 0.0001492307205007012, 'reg_lambda': 0.0062456133060571455} scored -14527.166332799145 in 0:00:02.026789\n[15:39:33] Training until validation scores don't improve for 200 rounds\n[15:39:34] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.746657354281442, 'num_leaves': 73, 'bagging_fraction': 0.5362994772175272, 'min_sum_hessian_in_leaf': 0.04557431905753664, 'reg_alpha': 1.14950806426981e-05, 'reg_lambda': 1.6177364135898325e-05} scored -14604.944177350428 in 0:00:01.514081\n[15:39:35] Training until validation scores don't improve for 200 rounds\n[15:39:37] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.504660667389432, 'num_leaves': 238, 'bagging_fraction': 0.6716779609714151, 'min_sum_hessian_in_leaf': 0.19542190766751452, 'reg_alpha': 5.177583357251708e-05, 'reg_lambda': 8.464634073263467} scored -14512.225794604701 in 0:00:02.116189\n[15:39:37] Training until validation scores don't improve for 200 rounds\n[15:39:40] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.599351001806568, 'num_leaves': 160, 'bagging_fraction': 0.6077393744098595, 'min_sum_hessian_in_leaf': 0.10716168653939297, 'reg_alpha': 3.558251079462484e-07, 'reg_lambda': 1.7819653870832216e-08} scored -14369.160723824787 in 0:00:03.265394\n[15:39:40] Training until validation scores don't improve for 200 rounds\n[15:39:42] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.5636486366064252, 'num_leaves': 177, 'bagging_fraction': 0.6317213769689488, 'min_sum_hessian_in_leaf': 0.02024362558871943, 'reg_alpha': 3.26739920387789e-05, 'reg_lambda': 0.051486477443386795} scored -14474.656016292734 in 0:00:01.672769\n[15:39:42] Training until validation scores don't improve for 200 rounds\n[15:39:44] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.9443096783813314, 'num_leaves': 192, 'bagging_fraction': 0.7624658483372897, 'min_sum_hessian_in_leaf': 0.027283089521839374, 'reg_alpha': 1.9593583310376773e-06, 'reg_lambda': 0.0008186654505151445} scored -15008.397936698719 in 0:00:02.417579\n[15:39:44] Training until validation scores don't improve for 200 rounds\n[15:39:46] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.5282751096735867, 'num_leaves': 22, 'bagging_fraction': 0.8298270958892233, 'min_sum_hessian_in_leaf': 4.88617412553765, 'reg_alpha': 0.0164197275071446, 'reg_lambda': 0.013780020987709592} scored -14667.27530715812 in 0:00:01.599850\n[15:39:46] Training until validation scores don't improve for 200 rounds\n[15:39:47] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.6037226874624408, 'num_leaves': 163, 'bagging_fraction': 0.6047789355585278, 'min_sum_hessian_in_leaf': 0.10379490146796183, 'reg_alpha': 2.687609096738644e-07, 'reg_lambda': 1.2292514995978488e-08} scored -14346.461772168803 in 0:00:01.638181\n[15:39:47] Training until validation scores don't improve for 200 rounds\n[15:39:49] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.5543932613164914, 'num_leaves': 141, 'bagging_fraction': 0.593936672347642, 'min_sum_hessian_in_leaf': 0.295877132410011, 'reg_alpha': 5.830025703453273e-06, 'reg_lambda': 3.570708722527539e-07} scored -14683.317007211539 in 0:00:01.565094\n[15:39:49] Training until validation scores don't improve for 200 rounds\n[15:39:51] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.5190714945905887, 'num_leaves': 175, 'bagging_fraction': 0.7125577004556467, 'min_sum_hessian_in_leaf': 0.050417874317133106, 'reg_alpha': 1.4643959496773652e-08, 'reg_lambda': 8.169290806758277e-08} scored -14561.304420405982 in 0:00:01.936548\n[15:39:51] Training until validation scores don't improve for 200 rounds\n[15:39:53] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.5478543872359534, 'num_leaves': 128, 'bagging_fraction': 0.5765240262539012, 'min_sum_hessian_in_leaf': 0.4812716764278234, 'reg_alpha': 2.2835781277042109e-07, 'reg_lambda': 4.4001924578151015e-08} scored -14530.564469818377 in 0:00:01.686561\n[15:39:53] Training until validation scores don't improve for 200 rounds\n[15:39:54] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5005496175115561, 'num_leaves': 162, 'bagging_fraction': 0.6207422435777463, 'min_sum_hessian_in_leaf': 1.583112374775711, 'reg_alpha': 5.366189277312664e-08, 'reg_lambda': 0.002516299920487167} scored -14469.399138621795 in 0:00:01.594062\n[15:39:54] Training until validation scores don't improve for 200 rounds\n[15:39:56] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.5970321226829425, 'num_leaves': 218, 'bagging_fraction': 0.6817993250781083, 'min_sum_hessian_in_leaf': 0.008107060591991903, 'reg_alpha': 0.00022241197340740405, 'reg_lambda': 1.0261010150065325e-06} scored -14460.903979700855 in 0:00:01.874842\n[15:39:56] Training until validation scores don't improve for 200 rounds\n[15:39:58] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.5218325507473919, 'num_leaves': 118, 'bagging_fraction': 0.65223059120405, 'min_sum_hessian_in_leaf': 0.014239333664402536, 'reg_alpha': 0.16478342845382438, 'reg_lambda': 0.1294533615608368} scored -14349.45532852564 in 0:00:01.714356\n[15:39:58] Training until validation scores don't improve for 200 rounds\n[15:40:00] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.5773158754021879, 'num_leaves': 116, 'bagging_fraction': 0.7328167380355911, 'min_sum_hessian_in_leaf': 0.014719807868149653, 'reg_alpha': 1.660816898982449, 'reg_lambda': 0.11820978133727757} scored -14714.01983173077 in 0:00:01.949327\n[15:40:00] Training until validation scores don't improve for 200 rounds\n[15:40:02] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.6356398560768804, 'num_leaves': 148, 'bagging_fraction': 0.6964628957974832, 'min_sum_hessian_in_leaf': 0.003466628964386372, 'reg_alpha': 0.05398484932164476, 'reg_lambda': 1.0910532907141794} scored -14407.525574252137 in 0:00:02.090249\n[15:40:02] Training until validation scores don't improve for 200 rounds\n[15:40:04] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.5498196466786758, 'num_leaves': 99, 'bagging_fraction': 0.6535411960703562, 'min_sum_hessian_in_leaf': 9.488721648613701, 'reg_alpha': 0.29255164933607425, 'reg_lambda': 0.00987514025420214} scored -14527.928251869658 in 0:00:01.714974\n[15:40:04] Training until validation scores don't improve for 200 rounds\n[15:40:05] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.5223286893116811, 'num_leaves': 124, 'bagging_fraction': 0.6406752982737811, 'min_sum_hessian_in_leaf': 0.030877932012918736, 'reg_alpha': 0.39120127293526885, 'reg_lambda': 0.02756296295434059} scored -14334.123397435897 in 0:00:01.681132\n[15:40:05] Training until validation scores don't improve for 200 rounds\n[15:40:07] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5181948757647906, 'num_leaves': 126, 'bagging_fraction': 0.6382619410867207, 'min_sum_hessian_in_leaf': 0.024802334989594523, 'reg_alpha': 0.16128873312135966, 'reg_lambda': 0.4330726958683388} scored -14347.82782451923 in 0:00:01.667723\n[15:40:07] Training until validation scores don't improve for 200 rounds\n[15:40:09] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.5164120261128369, 'num_leaves': 140, 'bagging_fraction': 0.6365902201419826, 'min_sum_hessian_in_leaf': 0.02953229085369318, 'reg_alpha': 1.1426265308866155, 'reg_lambda': 0.03140620141719793} scored -14474.13421474359 in 0:00:01.614919\n[15:40:09] Training until validation scores don't improve for 200 rounds\n[15:40:11] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.5638885998183633, 'num_leaves': 155, 'bagging_fraction': 0.6007791278627617, 'min_sum_hessian_in_leaf': 0.03735775383842757, 'reg_alpha': 9.541857636350798, 'reg_lambda': 0.5599222098672434} scored -14440.487613514957 in 0:00:02.325161\n[15:40:12] Training until validation scores don't improve for 200 rounds\n[15:40:14] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5409976881519714, 'num_leaves': 245, 'bagging_fraction': 0.6746098561469621, 'min_sum_hessian_in_leaf': 0.022409182425394275, 'reg_alpha': 0.8526185449170529, 'reg_lambda': 0.025076548181730832} scored -14583.57251602564 in 0:00:02.681184\n[15:40:14] Training until validation scores don't improve for 200 rounds\n[15:40:16] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.7815654370946516, 'num_leaves': 127, 'bagging_fraction': 0.8894270564243927, 'min_sum_hessian_in_leaf': 0.14769081391459044, 'reg_alpha': 0.13456285058590645, 'reg_lambda': 0.004097186034305165} scored -15064.994858440172 in 0:00:02.278086\n[15:40:16] Training until validation scores don't improve for 200 rounds\n[15:40:18] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.699451653265898, 'num_leaves': 171, 'bagging_fraction': 0.5683771765967136, 'min_sum_hessian_in_leaf': 0.004694484027948542, 'reg_alpha': 5.40650122325352e-07, 'reg_lambda': 0.0003390315290758614} scored -14396.020132211539 in 0:00:01.651372\n[15:40:18] Training until validation scores don't improve for 200 rounds\n[15:40:19] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.5156707593741158, 'num_leaves': 106, 'bagging_fraction': 0.5209995308294711, 'min_sum_hessian_in_leaf': 0.010391175579503517, 'reg_alpha': 0.5366250905452586, 'reg_lambda': 2.661792631622223} scored -14391.152844551281 in 0:00:01.434935\n[15:40:19] Training until validation scores don't improve for 200 rounds\n[15:40:21] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.587803868967162, 'num_leaves': 208, 'bagging_fraction': 0.544450555249939, 'min_sum_hessian_in_leaf': 0.06655669392382373, 'reg_alpha': 0.027854412244163157, 'reg_lambda': 0.3208563402525212} scored -14269.879941239316 in 0:00:01.702601\n[15:40:21] Training until validation scores don't improve for 200 rounds\n[15:40:22] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.6493192188843051, 'num_leaves': 206, 'bagging_fraction': 0.5478681604643161, 'min_sum_hessian_in_leaf': 0.053707992111442227, 'reg_alpha': 0.009395590787691222, 'reg_lambda': 0.01435162936746534} scored -14481.721354166666 in 0:00:01.684252\n[15:40:22] Training until validation scores don't improve for 200 rounds\n[15:40:24] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.5859080181757591, 'num_leaves': 233, 'bagging_fraction': 0.5956882119982031, 'min_sum_hessian_in_leaf': 0.01844812140142154, 'reg_alpha': 0.03280372909402308, 'reg_lambda': 0.31829092170486495} scored -14494.434728899572 in 0:00:01.595221\n[15:40:24] Training until validation scores don't improve for 200 rounds\n[15:40:26] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.5673643053285106, 'num_leaves': 245, 'bagging_fraction': 0.5047775807667804, 'min_sum_hessian_in_leaf': 0.06921726501491485, 'reg_alpha': 0.08180525366357182, 'reg_lambda': 0.07681980049565809} scored -14403.730435363248 in 0:00:01.947702\n[15:40:26] Training until validation scores don't improve for 200 rounds\n[15:40:28] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.5024363695939675, 'num_leaves': 137, 'bagging_fraction': 0.5478094704334524, 'min_sum_hessian_in_leaf': 0.03067614729117477, 'reg_alpha': 0.004766827261699702, 'reg_lambda': 0.43479446225455215} scored -14498.70622996795 in 0:00:01.591301\n[15:40:28] Training until validation scores don't improve for 200 rounds\n[15:40:29] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.6083132831009239, 'num_leaves': 198, 'bagging_fraction': 0.6393205107627272, 'min_sum_hessian_in_leaf': 0.007599078635660704, 'reg_alpha': 0.03221056367483272, 'reg_lambda': 0.8013320322609441} scored -14566.385216346154 in 0:00:01.754133\n[15:40:29] Training until validation scores don't improve for 200 rounds\n[15:40:31] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.534855696403098, 'num_leaves': 208, 'bagging_fraction': 0.6649654796490306, 'min_sum_hessian_in_leaf': 0.10425437091189371, 'reg_alpha': 0.0015921969962308456, 'reg_lambda': 0.0017396705406789476} scored -14415.002103365385 in 0:00:01.608140\n[15:40:31] Training until validation scores don't improve for 200 rounds\n[15:40:33] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.5470060214496704, 'num_leaves': 183, 'bagging_fraction': 0.576938070480971, 'min_sum_hessian_in_leaf': 0.038528046633911496, 'reg_alpha': 0.13850279735181673, 'reg_lambda': 2.0771437267675656} scored -14476.906283386752 in 0:00:01.700247\n[15:40:33] Training until validation scores don't improve for 200 rounds\n[15:40:34] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.6209021114266368, 'num_leaves': 229, 'bagging_fraction': 0.621663027429877, 'min_sum_hessian_in_leaf': 0.011796085989804158, 'reg_alpha': 0.24901680299011972, 'reg_lambda': 0.167399106866059} scored -14552.605068108975 in 0:00:01.574666\n[15:40:34] Training until validation scores don't improve for 200 rounds\n[15:40:36] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.5136316940772921, 'num_leaves': 143, 'bagging_fraction': 0.5281824414160898, 'min_sum_hessian_in_leaf': 0.02558496166648007, 'reg_alpha': 0.0007153001248779072, 'reg_lambda': 1.0723985915705004e-08} scored -14410.47045272436 in 0:00:01.433553\n[15:40:36] Training until validation scores don't improve for 200 rounds\n[15:40:37] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.5578533323830839, 'num_leaves': 155, 'bagging_fraction': 0.6882518287591988, 'min_sum_hessian_in_leaf': 0.0625198202727918, 'reg_alpha': 1.6469250364680815e-05, 'reg_lambda': 0.008688605738565352} scored -14425.421674679486 in 0:00:01.667587\n[15:40:38] Training until validation scores don't improve for 200 rounds\n[15:40:40] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.8324365266728688, 'num_leaves': 221, 'bagging_fraction': 0.9494999414808015, 'min_sum_hessian_in_leaf': 0.01740878665313166, 'reg_alpha': 2.3379959212337655, 'reg_lambda': 4.321068934904121} scored -15030.825721153846 in 0:00:02.497733\n[15:40:40] Training until validation scores don't improve for 200 rounds\n[15:40:42] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.5232135353061168, 'num_leaves': 119, 'bagging_fraction': 0.654005142660054, 'min_sum_hessian_in_leaf': 0.04622933400117417, 'reg_alpha': 0.17719742924323278, 'reg_lambda': 0.11070744665469011} scored -14319.410289797008 in 0:00:01.813099\n[15:40:42] Training until validation scores don't improve for 200 rounds\n[15:40:45] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5308589296385178, 'num_leaves': 131, 'bagging_fraction': 0.6553949168985925, 'min_sum_hessian_in_leaf': 0.044962608069277474, 'reg_alpha': 0.48741471943772163, 'reg_lambda': 0.08114495592071753} scored -14345.33390090812 in 0:00:03.318004\n[15:40:45] Training until validation scores don't improve for 200 rounds\n[15:40:47] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.535541097917897, 'num_leaves': 133, 'bagging_fraction': 0.6050258129886452, 'min_sum_hessian_in_leaf': 0.04379266546430412, 'reg_alpha': 4.90643336700577, 'reg_lambda': 0.08911733223626112} scored -14542.138020833334 in 0:00:01.533859\n[15:40:47] Training until validation scores don't improve for 200 rounds\n[15:40:48] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.5790585046507571, 'num_leaves': 132, 'bagging_fraction': 0.6591097898577594, 'min_sum_hessian_in_leaf': 0.1318261927695964, 'reg_alpha': 0.43119969992067014, 'reg_lambda': 0.03456592246093707} scored -14385.61812232906 in 0:00:01.753680\n[15:40:49] Training until validation scores don't improve for 200 rounds\n[15:40:50] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.500685897587881, 'num_leaves': 119, 'bagging_fraction': 0.6204348797975364, 'min_sum_hessian_in_leaf': 2.439007127451739, 'reg_alpha': 0.6560094686905512, 'reg_lambda': 0.05819127997646091} scored -14526.100126869658 in 0:00:01.434207\n[15:40:50] Training until validation scores don't improve for 200 rounds\n[15:40:52] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.5317976900216331, 'num_leaves': 98, 'bagging_fraction': 0.6992877082248605, 'min_sum_hessian_in_leaf': 0.09055574471584611, 'reg_alpha': 0.02101920797125027, 'reg_lambda': 0.005711554607435428} scored -14327.724025106838 in 0:00:01.789249\n[15:40:52] Training until validation scores don't improve for 200 rounds\n[15:40:53] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.5260566713157794, 'num_leaves': 97, 'bagging_fraction': 0.7021820673542838, 'min_sum_hessian_in_leaf': 0.21281374746032639, 'reg_alpha': 0.01982988327050044, 'reg_lambda': 0.005607357436909785} scored -14566.09064503205 in 0:00:01.670239\n[15:40:53] Training until validation scores don't improve for 200 rounds\n[15:40:55] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.5550987059812187, 'num_leaves': 111, 'bagging_fraction': 0.7481054680164604, 'min_sum_hessian_in_leaf': 0.07825702622209108, 'reg_alpha': 0.003170092106086535, 'reg_lambda': 0.0009400527794458898} scored -14628.94234107906 in 0:00:01.802152\n[15:40:55] Training until validation scores don't improve for 200 rounds\n[15:40:57] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.5405516670532634, 'num_leaves': 91, 'bagging_fraction': 0.7117735177848562, 'min_sum_hessian_in_leaf': 0.06033833675923365, 'reg_alpha': 0.007916858336855351, 'reg_lambda': 0.018404815114287036} scored -14569.061665331197 in 0:00:01.936607\n[15:40:57] Training until validation scores don't improve for 200 rounds\n[15:40:59] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.5133623925283727, 'num_leaves': 240, 'bagging_fraction': 0.7281485608632083, 'min_sum_hessian_in_leaf': 0.03195586444038986, 'reg_alpha': 0.0812525704710799, 'reg_lambda': 0.0036058923104760167} scored -14580.59782318376 in 0:00:01.909026\n[15:40:59] Training until validation scores don't improve for 200 rounds\n[15:41:01] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.5317724976278653, 'num_leaves': 168, 'bagging_fraction': 0.6837962482778213, 'min_sum_hessian_in_leaf': 0.09203413131546521, 'reg_alpha': 4.437051770010824e-05, 'reg_lambda': 0.002622714221172148} scored -14392.741619925213 in 0:00:01.654005\n[15:41:01] Training until validation scores don't improve for 200 rounds\n[15:41:03] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.6659837251429535, 'num_leaves': 250, 'bagging_fraction': 0.6464619605534551, 'min_sum_hessian_in_leaf': 0.04709617596241211, 'reg_alpha': 0.023392288410705002, 'reg_lambda': 0.009816903650397226} scored -14514.79483840812 in 0:00:01.941157\n[15:41:03] Training until validation scores don't improve for 200 rounds\n[15:41:04] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.5900253267973627, 'num_leaves': 144, 'bagging_fraction': 0.6790936844212471, 'min_sum_hessian_in_leaf': 0.1704276730485519, 'reg_alpha': 0.05251688953743115, 'reg_lambda': 0.20647101089336742} scored -14356.61485042735 in 0:00:01.712772\n[15:41:05] Training until validation scores don't improve for 200 rounds\n[15:41:06] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.5646416758380308, 'num_leaves': 84, 'bagging_fraction': 0.6658474727074059, 'min_sum_hessian_in_leaf': 0.2526407327118635, 'reg_alpha': 1.0250814530023176e-06, 'reg_lambda': 0.045454081129663704} scored -14536.756376869658 in 0:00:01.657996\n[15:41:06] Training until validation scores don't improve for 200 rounds\n[15:41:08] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.5719668761154642, 'num_leaves': 112, 'bagging_fraction': 0.6982904862341686, 'min_sum_hessian_in_leaf': 0.13103802614722534, 'reg_alpha': 9.859498560043964e-06, 'reg_lambda': 0.0001635209828606145} scored -14549.963775373932 in 0:00:01.726869\n[15:41:08] Training until validation scores don't improve for 200 rounds\n[15:41:09] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.5244952017697955, 'num_leaves': 159, 'bagging_fraction': 0.5821096636939671, 'min_sum_hessian_in_leaf': 0.035616863580765476, 'reg_alpha': 1.8610139642127705e-06, 'reg_lambda': 0.0003836500353633035} scored -14412.908019497863 in 0:00:01.530101\n[15:41:10] Training until validation scores don't improve for 200 rounds\n[15:41:11] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.5112624583738282, 'num_leaves': 103, 'bagging_fraction': 0.6240087481910684, 'min_sum_hessian_in_leaf': 0.42943078892007186, 'reg_alpha': 2.5170020600063516e-05, 'reg_lambda': 0.02261526144092842} scored -14408.962606837607 in 0:00:01.597282\n[15:41:11] Training until validation scores don't improve for 200 rounds\n[15:41:13] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.5451744345328783, 'num_leaves': 146, 'bagging_fraction': 0.5591360018628825, 'min_sum_hessian_in_leaf': 0.6365391726476256, 'reg_alpha': 2.7298163002429155e-08, 'reg_lambda': 2.2279682247994255e-06} scored -14407.082999465812 in 0:00:01.761405\n[15:41:13] Training until validation scores don't improve for 200 rounds\n[15:41:16] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.555376984895589, 'num_leaves': 123, 'bagging_fraction': 0.6499479274121278, 'min_sum_hessian_in_leaf': 0.02071119762730049, 'reg_alpha': 0.0001808814872173844, 'reg_lambda': 0.09700854929315432} scored -14388.808794070514 in 0:00:03.446180\n[15:41:16] Training until validation scores don't improve for 200 rounds\n[15:41:18] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.5291810794284463, 'num_leaves': 152, 'bagging_fraction': 0.6126767990725062, 'min_sum_hessian_in_leaf': 0.06989385603131909, 'reg_alpha': 0.0066689262369664945, 'reg_lambda': 0.0012098619149408614} scored -14298.851796207266 in 0:00:01.509862\n[15:41:18] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[15:41:18] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5014723328935634, 'num_leaves': 137, 'bagging_fraction': 0.5770863182333468, 'min_sum_hessian_in_leaf': 0.012405319719901478, 'reg_alpha': 7.756566674341428e-05, 'reg_lambda': 0.0029088409681667206}\u001b[0m\n achieve -14247.8250 mae\n[15:41:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:41:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:41:18] Training until validation scores don't improve for 100 rounds\n[15:41:18] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:41:18] Training until validation scores don't improve for 100 rounds\n[15:41:19] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:41:19] Training until validation scores don't improve for 100 rounds\n[15:41:19] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:41:19] Training until validation scores don't improve for 100 rounds\n[15:41:20] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:41:20] Training until validation scores don't improve for 100 rounds\n[15:41:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15918.047691031677\u001b[0m\n[15:41:20] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:41:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[15:41:21] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:41:21] 0:\tlearn: 54293.4011471\ttest: 54876.1945752\tbest: 54876.1945752 (0)\ttotal: 2.93ms\tremaining: 5.85s\n[15:41:25] bestTest = 13853.74351\n[15:41:25] bestIteration = 1979\n[15:41:25] Shrink model to first 1980 iterations.\n[15:41:25] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:41:25] 0:\tlearn: 56021.9372034\ttest: 48647.4552104\tbest: 48647.4552104 (0)\ttotal: 2.37ms\tremaining: 4.74s\n[15:41:26] Stopped by overfitting detector  (300 iterations wait)\n[15:41:26] bestTest = 13105.26986\n[15:41:26] bestIteration = 482\n[15:41:26] Shrink model to first 483 iterations.\n[15:41:26] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:41:26] 0:\tlearn: 51888.8014652\ttest: 61108.8811458\tbest: 61108.8811458 (0)\ttotal: 2.28ms\tremaining: 4.56s\n[15:41:28] Stopped by overfitting detector  (300 iterations wait)\n[15:41:28] bestTest = 18781.17035\n[15:41:28] bestIteration = 433\n[15:41:28] Shrink model to first 434 iterations.\n[15:41:28] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:41:28] 0:\tlearn: 55898.7077366\ttest: 50837.8249119\tbest: 50837.8249119 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[15:41:32] Stopped by overfitting detector  (300 iterations wait)\n[15:41:32] bestTest = 13757.34169\n[15:41:32] bestIteration = 1570\n[15:41:32] Shrink model to first 1571 iterations.\n[15:41:32] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:41:32] 0:\tlearn: 53017.0338978\ttest: 56766.8644148\tbest: 56766.8644148 (0)\ttotal: 2.62ms\tremaining: 5.23s\n[15:41:36] bestTest = 16149.32312\n[15:41:36] bestIteration = 1976\n[15:41:36] Shrink model to first 1977 iterations.\n[15:41:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15129.671145922517\u001b[0m\n[15:41:36] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[15:41:36] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[15:41:36] 0:\tlearn: 54420.4485839\ttest: 54934.1334155\tbest: 54934.1334155 (0)\ttotal: 1.65ms\tremaining: 3.29s\n[15:41:39] bestTest = 13623.88339\n[15:41:39] bestIteration = 1926\n[15:41:39] Shrink model to first 1927 iterations.\n[15:41:39] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -13623.8828125 in 0:00:03.144957\n[15:41:39] 0:\tlearn: 54451.6457407\ttest: 54922.9035872\tbest: 54922.9035872 (0)\ttotal: 1.44ms\tremaining: 2.88s\n[15:41:40] Stopped by overfitting detector  (300 iterations wait)\n[15:41:40] bestTest = 14765.24911\n[15:41:40] bestIteration = 789\n[15:41:40] Shrink model to first 790 iterations.\n[15:41:40] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -14765.249265491453 in 0:00:01.345415\n[15:41:41] 0:\tlearn: 54451.6091831\ttest: 54922.8774522\tbest: 54922.8774522 (0)\ttotal: 1.27ms\tremaining: 2.54s\n[15:41:42] Stopped by overfitting detector  (300 iterations wait)\n[15:41:42] bestTest = 14817.16421\n[15:41:42] bestIteration = 1022\n[15:41:42] Shrink model to first 1023 iterations.\n[15:41:42] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -14817.164262820514 in 0:00:01.666280\n[15:41:42] 0:\tlearn: 54451.6102696\ttest: 54922.8782289\tbest: 54922.8782289 (0)\ttotal: 1.48ms\tremaining: 2.95s\n[15:41:44] Stopped by overfitting detector  (300 iterations wait)\n[15:41:44] bestTest = 14676.45006\n[15:41:44] bestIteration = 998\n[15:41:44] Shrink model to first 999 iterations.\n[15:41:44] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -14676.44968616453 in 0:00:01.572369\n[15:41:44] 0:\tlearn: 54254.3379958\ttest: 54898.3008976\tbest: 54898.3008976 (0)\ttotal: 3.65ms\tremaining: 7.29s\n[15:41:49] Stopped by overfitting detector  (300 iterations wait)\n[15:41:49] bestTest = 13777.06231\n[15:41:49] bestIteration = 1549\n[15:41:49] Shrink model to first 1550 iterations.\n[15:41:49] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -13777.062366452992 in 0:00:05.750879\n[15:41:50] 0:\tlearn: 54254.5702765\ttest: 54898.4069148\tbest: 54898.4069148 (0)\ttotal: 3.25ms\tremaining: 6.49s\n[15:41:55] bestTest = 13728.71313\n[15:41:55] bestIteration = 1998\n[15:41:55] Shrink model to first 1999 iterations.\n[15:41:55] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -13728.712773771367 in 0:00:06.084955\n[15:41:56] 0:\tlearn: 54430.8564813\ttest: 55009.3046570\tbest: 55009.3046570 (0)\ttotal: 3.11ms\tremaining: 6.22s\n[15:42:01] bestTest = 13992.15248\n[15:42:01] bestIteration = 1979\n[15:42:01] Shrink model to first 1980 iterations.\n[15:42:01] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -14000.802150106838 in 0:00:05.607445\n[15:42:01] 0:\tlearn: 54213.0315664\ttest: 54909.3966120\tbest: 54909.3966120 (0)\ttotal: 6.62ms\tremaining: 13.2s\n[15:42:05] Stopped by overfitting detector  (300 iterations wait)\n[15:42:05] bestTest = 14770.44595\n[15:42:05] bestIteration = 749\n[15:42:05] Shrink model to first 750 iterations.\n[15:42:05] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -14770.44561298077 in 0:00:04.344616\n[15:42:06] 0:\tlearn: 54472.0196093\ttest: 54938.1470190\tbest: 54938.1470190 (0)\ttotal: 1.24ms\tremaining: 2.47s\n[15:42:07] Stopped by overfitting detector  (300 iterations wait)\n[15:42:07] bestTest = 14550.16947\n[15:42:07] bestIteration = 708\n[15:42:07] Shrink model to first 709 iterations.\n[15:42:07] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -14550.169387686965 in 0:00:01.233279\n[15:42:07] 0:\tlearn: 54254.4268067\ttest: 54898.3414081\tbest: 54898.3414081 (0)\ttotal: 2.98ms\tremaining: 5.96s\n[15:42:10] Stopped by overfitting detector  (300 iterations wait)\n[15:42:10] bestTest = 13800.04879\n[15:42:10] bestIteration = 955\n[15:42:10] Shrink model to first 956 iterations.\n[15:42:10] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -13800.04874465812 in 0:00:03.611630\n[15:42:10] 0:\tlearn: 54420.3642401\ttest: 54934.1070134\tbest: 54934.1070134 (0)\ttotal: 1.97ms\tremaining: 3.93s\n[15:42:13] Stopped by overfitting detector  (300 iterations wait)\n[15:42:13] bestTest = 13953.87248\n[15:42:13] bestIteration = 1144\n[15:42:13] Shrink model to first 1145 iterations.\n[15:42:13] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 14} scored -13953.872612847223 in 0:00:02.337396\n[15:42:13] 0:\tlearn: 54296.1279395\ttest: 54877.0371275\tbest: 54877.0371275 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[15:42:17] bestTest = 13981.2718\n[15:42:17] bestIteration = 1932\n[15:42:17] Shrink model to first 1933 iterations.\n[15:42:17] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.04911057229628098, 'min_data_in_leaf': 1} scored -13981.271968482906 in 0:00:04.151026\n[15:42:17] 0:\tlearn: 54300.1412388\ttest: 54878.3781545\tbest: 54878.3781545 (0)\ttotal: 2.13ms\tremaining: 4.27s\n[15:42:21] Stopped by overfitting detector  (300 iterations wait)\n[15:42:21] bestTest = 13352.86414\n[15:42:21] bestIteration = 1689\n[15:42:21] Shrink model to first 1690 iterations.\n[15:42:21] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10888374230503725, 'min_data_in_leaf': 1} scored -13352.864533253205 in 0:00:04.683285\n[15:42:22] 0:\tlearn: 54425.9093858\ttest: 54935.9608272\tbest: 54935.9608272 (0)\ttotal: 1.67ms\tremaining: 3.34s\n[15:42:24] Stopped by overfitting detector  (300 iterations wait)\n[15:42:24] bestTest = 13961.92079\n[15:42:24] bestIteration = 1190\n[15:42:24] Shrink model to first 1191 iterations.\n[15:42:24] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695908, 'min_data_in_leaf': 1} scored -13961.920840010684 in 0:00:02.374759\n[15:42:24] 0:\tlearn: 54309.1390882\ttest: 54881.8031291\tbest: 54881.8031291 (0)\ttotal: 2.21ms\tremaining: 4.42s\n[15:42:28] bestTest = 13651.59019\n[15:42:28] bestIteration = 1924\n[15:42:28] Shrink model to first 1925 iterations.\n[15:42:28] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.25245062801063695, 'min_data_in_leaf': 4} scored -13651.590377938035 in 0:00:04.201385\n[15:42:28] 0:\tlearn: 54420.3648898\ttest: 54934.1072165\tbest: 54934.1072165 (0)\ttotal: 1.67ms\tremaining: 3.34s\n[15:42:30] Stopped by overfitting detector  (300 iterations wait)\n[15:42:30] bestTest = 13954.40237\n[15:42:30] bestIteration = 1144\n[15:42:30] Shrink model to first 1145 iterations.\n[15:42:30] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.882274316776804e-05, 'min_data_in_leaf': 7} scored -13954.402477297008 in 0:00:02.306114\n[15:42:31] 0:\tlearn: 54293.3910618\ttest: 54876.1915637\tbest: 54876.1915637 (0)\ttotal: 2.31ms\tremaining: 4.62s\n[15:42:33] Stopped by overfitting detector  (300 iterations wait)\n[15:42:33] bestTest = 13751.89856\n[15:42:33] bestIteration = 1027\n[15:42:33] Shrink model to first 1028 iterations.\n[15:42:33] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.009857598732054109, 'min_data_in_leaf': 13} scored -13751.898971688035 in 0:00:02.919875\n[15:42:34] 0:\tlearn: 54516.1536222\ttest: 54967.5704120\tbest: 54967.5704120 (0)\ttotal: 1.65ms\tremaining: 3.3s\n[15:42:36] bestTest = 14161.4857\n[15:42:36] bestIteration = 1958\n[15:42:36] Shrink model to first 1959 iterations.\n[15:42:36] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 9.86874546485378, 'min_data_in_leaf': 3} scored -14163.228448851496 in 0:00:03.095440\n[15:42:37] 0:\tlearn: 54292.7005614\ttest: 54875.9872311\tbest: 54875.9872311 (0)\ttotal: 2.24ms\tremaining: 4.47s\n[15:42:39] Stopped by overfitting detector  (300 iterations wait)\n[15:42:39] bestTest = 14060.82939\n[15:42:39] bestIteration = 1089\n[15:42:39] Shrink model to first 1090 iterations.\n[15:42:39] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00014746071688813276, 'min_data_in_leaf': 8} scored -14060.828826121795 in 0:00:02.948392\n[15:42:40] 0:\tlearn: 54264.6610799\ttest: 54931.2727586\tbest: 54931.2727586 (0)\ttotal: 4.63ms\tremaining: 9.25s\n[15:42:46] Stopped by overfitting detector  (300 iterations wait)\n[15:42:46] bestTest = 14645.02754\n[15:42:46] bestIteration = 1033\n[15:42:46] Shrink model to first 1034 iterations.\n[15:42:46] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.4671327175816486, 'min_data_in_leaf': 18} scored -14630.923110309828 in 0:00:06.365799\n[15:42:46] 0:\tlearn: 54420.3642751\ttest: 54934.1070243\tbest: 54934.1070243 (0)\ttotal: 2.34ms\tremaining: 4.68s\n[15:42:48] Stopped by overfitting detector  (300 iterations wait)\n[15:42:48] bestTest = 13953.8726\n[15:42:48] bestIteration = 1144\n[15:42:48] Shrink model to first 1145 iterations.\n[15:42:48] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0257164555084864e-06, 'min_data_in_leaf': 11} scored -13953.872362446582 in 0:00:02.338536\n[15:42:48] 0:\tlearn: 54300.4622514\ttest: 54878.4905164\tbest: 54878.4905164 (0)\ttotal: 2.33ms\tremaining: 4.67s\n[15:42:51] Stopped by overfitting detector  (300 iterations wait)\n[15:42:51] bestTest = 13402.11974\n[15:42:51] bestIteration = 1044\n[15:42:51] Shrink model to first 1045 iterations.\n[15:42:51] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1137785419085571, 'min_data_in_leaf': 3} scored -13402.119958600428 in 0:00:02.874848\n[15:42:51] 0:\tlearn: 54295.3317938\ttest: 54876.7853189\tbest: 54876.7853189 (0)\ttotal: 2.87ms\tremaining: 5.74s\n[15:42:55] Stopped by overfitting detector  (300 iterations wait)\n[15:42:55] bestTest = 13899.49113\n[15:42:55] bestIteration = 1158\n[15:42:55] Shrink model to first 1159 iterations.\n[15:42:55] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.03756586356687712, 'min_data_in_leaf': 3} scored -13899.491486378205 in 0:00:03.791887\n[15:42:55] 0:\tlearn: 54420.5543900\ttest: 54934.1666149\tbest: 54934.1666149 (0)\ttotal: 1.68ms\tremaining: 3.36s\n[15:42:58] bestTest = 13797.94221\n[15:42:58] bestIteration = 1990\n[15:42:58] Shrink model to first 1991 iterations.\n[15:42:58] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0055106327593723746, 'min_data_in_leaf': 2} scored -13797.942023904914 in 0:00:03.171319\n[15:42:58] 0:\tlearn: 54297.8724773\ttest: 54877.6054565\tbest: 54877.6054565 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:43:00] Stopped by overfitting detector  (300 iterations wait)\n[15:43:00] bestTest = 13718.74142\n[15:43:00] bestIteration = 658\n[15:43:00] Shrink model to first 659 iterations.\n[15:43:00] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.07476985772132953, 'min_data_in_leaf': 5} scored -13718.741519764957 in 0:00:02.074271\n[15:43:00] 0:\tlearn: 54296.9064597\ttest: 54920.8392497\tbest: 54920.8392497 (0)\ttotal: 3.36ms\tremaining: 6.72s\n[15:43:03] Stopped by overfitting detector  (300 iterations wait)\n[15:43:03] bestTest = 13728.89407\n[15:43:03] bestIteration = 692\n[15:43:03] Shrink model to first 693 iterations.\n[15:43:03] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.45056363045755304, 'min_data_in_leaf': 3} scored -13728.299278846154 in 0:00:02.936856\n[15:43:03] 0:\tlearn: 54420.3892923\ttest: 54934.1148496\tbest: 54934.1148496 (0)\ttotal: 1.67ms\tremaining: 3.33s\n[15:43:06] bestTest = 13741.16422\n[15:43:06] bestIteration = 1998\n[15:43:06] Shrink model to first 1999 iterations.\n[15:43:06] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0007254266239476279, 'min_data_in_leaf': 6} scored -13741.16414596688 in 0:00:03.124866\n[15:43:06] 0:\tlearn: 54363.1155418\ttest: 54912.0818201\tbest: 54912.0818201 (0)\ttotal: 2.21ms\tremaining: 4.42s\n[15:43:10] bestTest = 13889.69752\n[15:43:10] bestIteration = 1983\n[15:43:10] Shrink model to first 1984 iterations.\n[15:43:10] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3813151930442016, 'min_data_in_leaf': 2} scored -13889.69718215812 in 0:00:04.177955\n[15:43:10] 0:\tlearn: 54421.1296897\ttest: 54934.3486644\tbest: 54934.3486644 (0)\ttotal: 1.7ms\tremaining: 3.39s\n[15:43:13] bestTest = 13680.15046\n[15:43:13] bestIteration = 1943\n[15:43:13] Shrink model to first 1944 iterations.\n[15:43:14] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.022247820240504725, 'min_data_in_leaf': 8} scored -13680.150390625 in 0:00:03.193410\n[15:43:14] 0:\tlearn: 54451.6483607\ttest: 54922.9054604\tbest: 54922.9054604 (0)\ttotal: 1.23ms\tremaining: 2.47s\n[15:43:15] Stopped by overfitting detector  (300 iterations wait)\n[15:43:15] bestTest = 14765.20985\n[15:43:15] bestIteration = 789\n[15:43:15] Shrink model to first 790 iterations.\n[15:43:15] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0027547975837692237, 'min_data_in_leaf': 11} scored -14765.209768963676 in 0:00:01.392146\n[15:43:15] 0:\tlearn: 54266.0967328\ttest: 54903.9210185\tbest: 54903.9210185 (0)\ttotal: 3.04ms\tremaining: 6.08s\n[15:43:19] Stopped by overfitting detector  (300 iterations wait)\n[15:43:19] bestTest = 13947.40115\n[15:43:19] bestIteration = 1138\n[15:43:19] Shrink model to first 1139 iterations.\n[15:43:19] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.11226138315501089, 'min_data_in_leaf': 5} scored -13937.926866319445 in 0:00:04.134730\n[15:43:19] 0:\tlearn: 54316.4915487\ttest: 54885.0052887\tbest: 54885.0052887 (0)\ttotal: 2.27ms\tremaining: 4.55s\n[15:43:23] bestTest = 13638.40935\n[15:43:23] bestIteration = 1991\n[15:43:23] Shrink model to first 1992 iterations.\n[15:43:23] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.37951648821236056, 'min_data_in_leaf': 4} scored -13638.409421741453 in 0:00:04.233220\n[15:43:23] 0:\tlearn: 54372.1793090\ttest: 54918.4066135\tbest: 54918.4066135 (0)\ttotal: 2.16ms\tremaining: 4.33s\n[15:43:26] Stopped by overfitting detector  (300 iterations wait)\n[15:43:26] bestTest = 13596.8606\n[15:43:26] bestIteration = 698\n[15:43:26] Shrink model to first 699 iterations.\n[15:43:26] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.6135066651987369, 'min_data_in_leaf': 2} scored -13596.859658787393 in 0:00:02.588365\n[15:43:26] 0:\tlearn: 54523.1167432\ttest: 54964.8126198\tbest: 54964.8126198 (0)\ttotal: 2.22ms\tremaining: 4.44s\n[15:43:30] bestTest = 13832.83717\n[15:43:30] bestIteration = 1996\n[15:43:30] Shrink model to first 1997 iterations.\n[15:43:30] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 9.468285231736562, 'min_data_in_leaf': 2} scored -13840.297375801281 in 0:00:04.091504\n[15:43:30] 0:\tlearn: 54451.6774659\ttest: 54922.9262713\tbest: 54922.9262713 (0)\ttotal: 1.26ms\tremaining: 2.52s\n[15:43:32] bestTest = 14609.77454\n[15:43:32] bestIteration = 1998\n[15:43:32] Shrink model to first 1999 iterations.\n[15:43:32] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 0.004801197205990097, 'min_data_in_leaf': 1} scored -14609.774105235043 in 0:00:02.399610\n[15:43:33] 0:\tlearn: 54404.2634248\ttest: 54985.7692053\tbest: 54985.7692053 (0)\ttotal: 3.35ms\tremaining: 6.71s\n[15:43:38] Stopped by overfitting detector  (300 iterations wait)\n[15:43:38] bestTest = 13843.70678\n[15:43:38] bestIteration = 1557\n[15:43:38] Shrink model to first 1558 iterations.\n[15:43:38] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.7170834105185984, 'min_data_in_leaf': 5} scored -13843.706280048076 in 0:00:05.217372\n[15:43:38] 0:\tlearn: 54292.6919759\ttest: 54875.9847135\tbest: 54875.9847135 (0)\ttotal: 2.17ms\tremaining: 4.34s\n[15:43:41] Stopped by overfitting detector  (300 iterations wait)\n[15:43:41] bestTest = 14060.90428\n[15:43:41] bestIteration = 1089\n[15:43:41] Shrink model to first 1090 iterations.\n[15:43:41] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.7217278948374945e-05, 'min_data_in_leaf': 3} scored -14060.903879540598 in 0:00:02.944962\n[15:43:41] 0:\tlearn: 54342.3369853\ttest: 54950.3319137\tbest: 54950.3319137 (0)\ttotal: 3.08ms\tremaining: 6.17s\n[15:43:43] Stopped by overfitting detector  (300 iterations wait)\n[15:43:43] bestTest = 13810.87018\n[15:43:43] bestIteration = 676\n[15:43:43] Shrink model to first 677 iterations.\n[15:43:43] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0638149330681443, 'min_data_in_leaf': 2} scored -13810.870125534188 in 0:00:02.886762\n[15:43:44] 0:\tlearn: 54292.7759037\ttest: 54876.0093487\tbest: 54876.0093487 (0)\ttotal: 2.52ms\tremaining: 5.05s\n[15:43:48] bestTest = 13995.76907\n[15:43:48] bestIteration = 1996\n[15:43:48] Shrink model to first 1997 iterations.\n[15:43:48] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.001203178022850167, 'min_data_in_leaf': 7} scored -13995.768563034188 in 0:00:04.212035\n[15:43:48] 0:\tlearn: 54420.3743855\ttest: 54934.1101862\tbest: 54934.1101862 (0)\ttotal: 1.63ms\tremaining: 3.26s\n[15:43:50] Stopped by overfitting detector  (300 iterations wait)\n[15:43:50] bestTest = 13953.90683\n[15:43:50] bestIteration = 1144\n[15:43:50] Shrink model to first 1145 iterations.\n[15:43:50] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0002937596932076309, 'min_data_in_leaf': 17} scored -13953.906951121795 in 0:00:02.588087\n[15:43:50] 0:\tlearn: 54257.2735904\ttest: 54899.6559135\tbest: 54899.6559135 (0)\ttotal: 2.96ms\tremaining: 5.92s\n[15:43:56] bestTest = 14066.84563\n[15:43:56] bestIteration = 1976\n[15:43:56] Shrink model to first 1977 iterations.\n[15:43:56] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.02716521556096095, 'min_data_in_leaf': 4} scored -14066.84578659188 in 0:00:05.743815\n[15:43:56] 0:\tlearn: 54322.8427543\ttest: 54888.0418322\tbest: 54888.0418322 (0)\ttotal: 2.71ms\tremaining: 5.42s\n[15:44:01] bestTest = 13797.57895\n[15:44:01] bestIteration = 1905\n[15:44:01] Shrink model to first 1906 iterations.\n[15:44:01] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.4962594947318974, 'min_data_in_leaf': 1} scored -13797.57892628205 in 0:00:04.661405\n[15:44:01] 0:\tlearn: 54301.9545314\ttest: 54879.0226025\tbest: 54879.0226025 (0)\ttotal: 2.16ms\tremaining: 4.33s\n[15:44:05] bestTest = 13918.81178\n[15:44:05] bestIteration = 1935\n[15:44:05] Shrink model to first 1936 iterations.\n[15:44:05] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1367538221912469, 'min_data_in_leaf': 4} scored -13918.811732104701 in 0:00:04.235672\n[15:44:05] 0:\tlearn: 54440.0023152\ttest: 54885.8317772\tbest: 54885.8317772 (0)\ttotal: 2.24ms\tremaining: 4.48s\n[15:44:08] Stopped by overfitting detector  (300 iterations wait)\n[15:44:08] bestTest = 13670.76151\n[15:44:08] bestIteration = 1126\n[15:44:08] Shrink model to first 1127 iterations.\n[15:44:08] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.013130360508607, 'min_data_in_leaf': 6} scored -13670.761485042734 in 0:00:03.010050\n[15:44:08] 0:\tlearn: 54324.4655363\ttest: 54888.8557291\tbest: 54888.8557291 (0)\ttotal: 2.19ms\tremaining: 4.37s\n[15:44:12] Stopped by overfitting detector  (300 iterations wait)\n[15:44:12] bestTest = 13730.98868\n[15:44:12] bestIteration = 1694\n[15:44:12] Shrink model to first 1695 iterations.\n[15:44:12] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5271160091959933, 'min_data_in_leaf': 3} scored -13730.98844818376 in 0:00:04.181872\n[15:44:12] 0:\tlearn: 54420.8215256\ttest: 54934.2508257\tbest: 54934.2508257 (0)\ttotal: 1.67ms\tremaining: 3.33s\n[15:44:14] Stopped by overfitting detector  (300 iterations wait)\n[15:44:14] bestTest = 13972.95405\n[15:44:14] bestIteration = 689\n[15:44:14] Shrink model to first 690 iterations.\n[15:44:14] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.013270302625538369, 'min_data_in_leaf': 2} scored -13972.954026442309 in 0:00:01.635940\n[15:44:14] 0:\tlearn: 54221.6987894\ttest: 54912.5742411\tbest: 54912.5742411 (0)\ttotal: 4.5ms\tremaining: 8.99s\n[15:44:20] Stopped by overfitting detector  (300 iterations wait)\n[15:44:20] bestTest = 14816.91086\n[15:44:20] bestIteration = 1221\n[15:44:20] Shrink model to first 1222 iterations.\n[15:44:20] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.08159494846266789, 'min_data_in_leaf': 5} scored -14816.910790598291 in 0:00:06.209077\n[15:44:20] 0:\tlearn: 54478.8192407\ttest: 54943.5092784\tbest: 54943.5092784 (0)\ttotal: 1.25ms\tremaining: 2.49s\n[15:44:22] bestTest = 14676.55867\n[15:44:22] bestIteration = 1771\n[15:44:22] Shrink model to first 1772 iterations.\n[15:44:22] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 2.0754893459184736, 'min_data_in_leaf': 1} scored -14676.559228098291 in 0:00:02.446229\n[15:44:23] 0:\tlearn: 54279.6450680\ttest: 54910.9965907\tbest: 54910.9965907 (0)\ttotal: 3.09ms\tremaining: 6.18s\n[15:44:28] bestTest = 13848.63655\n[15:44:28] bestIteration = 1968\n[15:44:28] Shrink model to first 1969 iterations.\n[15:44:28] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.25317232307486975, 'min_data_in_leaf': 4} scored -13852.657518696582 in 0:00:05.689643\n[15:44:28] 0:\tlearn: 54295.6920099\ttest: 54876.8986598\tbest: 54876.8986598 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[15:44:33] bestTest = 14019.44467\n[15:44:33] bestIteration = 1942\n[15:44:33] Shrink model to first 1943 iterations.\n[15:44:33] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0427764393076223, 'min_data_in_leaf': 7} scored -14019.444344284188 in 0:00:04.683056\n[15:44:33] 0:\tlearn: 54420.3643227\ttest: 54934.1070392\tbest: 54934.1070392 (0)\ttotal: 1.66ms\tremaining: 3.33s\n[15:44:35] Stopped by overfitting detector  (300 iterations wait)\n[15:44:35] bestTest = 13953.87276\n[15:44:35] bestIteration = 1144\n[15:44:35] Shrink model to first 1145 iterations.\n[15:44:35] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.4042448283919355e-06, 'min_data_in_leaf': 9} scored -13953.87249599359 in 0:00:02.317170\n[15:44:35] 0:\tlearn: 54336.4345248\ttest: 54895.3023481\tbest: 54895.3023481 (0)\ttotal: 2.35ms\tremaining: 4.69s\n[15:44:38] Stopped by overfitting detector  (300 iterations wait)\n[15:44:38] bestTest = 13908.70104\n[15:44:38] bestIteration = 1070\n[15:44:38] Shrink model to first 1071 iterations.\n[15:44:38] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.7674342273710021, 'min_data_in_leaf': 4} scored -13908.700687767094 in 0:00:02.888685\n[15:44:38] 0:\tlearn: 54307.2538426\ttest: 54881.0391690\tbest: 54881.0391690 (0)\ttotal: 2.61ms\tremaining: 5.21s\n[15:44:42] Stopped by overfitting detector  (300 iterations wait)\n[15:44:42] bestTest = 13505.26708\n[15:44:42] bestIteration = 1493\n[15:44:42] Shrink model to first 1494 iterations.\n[15:44:42] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.2212784731762001, 'min_data_in_leaf': 3} scored -13505.267227564103 in 0:00:03.796814\n[15:44:42] 0:\tlearn: 54304.3129776\ttest: 54879.8958688\tbest: 54879.8958688 (0)\ttotal: 2.22ms\tremaining: 4.44s\n[15:44:46] bestTest = 13762.11731\n[15:44:46] bestIteration = 1956\n[15:44:46] Shrink model to first 1957 iterations.\n[15:44:46] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1738060340648885, 'min_data_in_leaf': 3} scored -13762.116987179486 in 0:00:04.170900\n[15:44:46] 0:\tlearn: 54254.3358297\ttest: 54898.2999100\tbest: 54898.2999100 (0)\ttotal: 3.07ms\tremaining: 6.13s\n[15:44:49] Stopped by overfitting detector  (300 iterations wait)\n[15:44:49] bestTest = 14064.99276\n[15:44:49] bestIteration = 795\n[15:44:49] Shrink model to first 796 iterations.\n[15:44:49] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2391844377699182e-08, 'min_data_in_leaf': 1} scored -14070.483406784188 in 0:00:03.157697\n[15:44:50] 0:\tlearn: 54450.2673170\ttest: 54895.4452895\tbest: 54895.4452895 (0)\ttotal: 2.22ms\tremaining: 4.43s\n[15:44:53] Stopped by overfitting detector  (300 iterations wait)\n[15:44:53] bestTest = 14094.10792\n[15:44:53] bestIteration = 1113\n[15:44:53] Shrink model to first 1114 iterations.\n[15:44:53] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.513496777437289, 'min_data_in_leaf': 2} scored -14094.108239850428 in 0:00:03.285745\n[15:44:53] 0:\tlearn: 54310.5276289\ttest: 54882.3810128\tbest: 54882.3810128 (0)\ttotal: 2.16ms\tremaining: 4.31s\n[15:44:57] Stopped by overfitting detector  (300 iterations wait)\n[15:44:57] bestTest = 13972.18569\n[15:44:57] bestIteration = 1633\n[15:44:57] Shrink model to first 1634 iterations.\n[15:44:57] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.2757786308335377, 'min_data_in_leaf': 3} scored -13972.185964209402 in 0:00:04.036459\n[15:44:57] 0:\tlearn: 54293.4132486\ttest: 54876.1981897\tbest: 54876.1981897 (0)\ttotal: 2.15ms\tremaining: 4.29s\n[15:44:59] Stopped by overfitting detector  (300 iterations wait)\n[15:44:59] bestTest = 13726.39101\n[15:44:59] bestIteration = 1046\n[15:44:59] Shrink model to first 1047 iterations.\n[15:44:59] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.010170890402753957, 'min_data_in_leaf': 5} scored -13726.390691773504 in 0:00:02.855342\n[15:45:00] 0:\tlearn: 54455.6134595\ttest: 54949.6060306\tbest: 54949.6060306 (0)\ttotal: 1.84ms\tremaining: 3.68s\n[15:45:02] Stopped by overfitting detector  (300 iterations wait)\n[15:45:02] bestTest = 13941.22037\n[15:45:02] bestIteration = 1128\n[15:45:02] Shrink model to first 1129 iterations.\n[15:45:02] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2002724912255671, 'min_data_in_leaf': 12} scored -13941.220085470086 in 0:00:02.601625\n[15:45:02] 0:\tlearn: 54422.6386868\ttest: 54934.8384722\tbest: 54934.8384722 (0)\ttotal: 2.04ms\tremaining: 4.08s\n[15:45:04] Stopped by overfitting detector  (300 iterations wait)\n[15:45:04] bestTest = 13774.48338\n[15:45:04] bestIteration = 891\n[15:45:04] Shrink model to first 892 iterations.\n[15:45:04] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.06661116096091053, 'min_data_in_leaf': 4} scored -13774.483056223291 in 0:00:02.111472\n[15:45:04] 0:\tlearn: 54294.3012635\ttest: 54876.4664745\tbest: 54876.4664745 (0)\ttotal: 2.23ms\tremaining: 4.45s\n[15:45:07] Stopped by overfitting detector  (300 iterations wait)\n[15:45:07] bestTest = 13609.30391\n[15:45:07] bestIteration = 1244\n[15:45:07] Shrink model to first 1245 iterations.\n[15:45:07] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.022776169545662875, 'min_data_in_leaf': 2} scored -13609.303619123932 in 0:00:03.252534\n[15:45:08] 0:\tlearn: 54293.0571635\ttest: 54876.0923006\tbest: 54876.0923006 (0)\ttotal: 2.36ms\tremaining: 4.71s\n[15:45:10] Stopped by overfitting detector  (300 iterations wait)\n[15:45:10] bestTest = 13939.81678\n[15:45:10] bestIteration = 812\n[15:45:10] Shrink model to first 813 iterations.\n[15:45:10] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.005152452407996911, 'min_data_in_leaf': 2} scored -13939.816907051281 in 0:00:02.407260\n[15:45:10] 0:\tlearn: 54295.6804146\ttest: 54876.8949961\tbest: 54876.8949961 (0)\ttotal: 2.2ms\tremaining: 4.41s\n[15:45:13] Stopped by overfitting detector  (300 iterations wait)\n[15:45:13] bestTest = 13844.80557\n[15:45:13] bestIteration = 1332\n[15:45:13] Shrink model to first 1333 iterations.\n[15:45:13] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.04260838169823807, 'min_data_in_leaf': 3} scored -13844.805655715812 in 0:00:03.503088\n[15:45:14] 0:\tlearn: 54292.8747425\ttest: 54876.0384301\tbest: 54876.0384301 (0)\ttotal: 2.23ms\tremaining: 4.45s\n[15:45:18] bestTest = 14096.28116\n[15:45:18] bestIteration = 1798\n[15:45:18] Shrink model to first 1799 iterations.\n[15:45:18] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0025895406449348004, 'min_data_in_leaf': 1} scored -14096.28125 in 0:00:04.205598\n[15:45:18] 0:\tlearn: 54293.9072009\ttest: 54876.3466801\tbest: 54876.3466801 (0)\ttotal: 2.18ms\tremaining: 4.35s\n[15:45:20] Stopped by overfitting detector  (300 iterations wait)\n[15:45:20] bestTest = 13855.97483\n[15:45:20] bestIteration = 761\n[15:45:20] Shrink model to first 762 iterations.\n[15:45:20] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.017166603718935986, 'min_data_in_leaf': 2} scored -13855.974843082266 in 0:00:02.285549\n[15:45:20] 0:\tlearn: 54429.1740710\ttest: 54937.1627445\tbest: 54937.1627445 (0)\ttotal: 1.66ms\tremaining: 3.31s\n[15:45:23] bestTest = 13872.49212\n[15:45:23] bestIteration = 1983\n[15:45:23] Shrink model to first 1984 iterations.\n[15:45:23] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.26644122040458174, 'min_data_in_leaf': 5} scored -13872.491753472223 in 0:00:03.153607\n[15:45:23] 0:\tlearn: 54265.6705226\ttest: 54903.7085398\tbest: 54903.7085398 (0)\ttotal: 2.93ms\tremaining: 5.87s\n[15:45:26] Stopped by overfitting detector  (300 iterations wait)\n[15:45:26] bestTest = 14056.02671\n[15:45:26] bestIteration = 815\n[15:45:26] Shrink model to first 816 iterations.\n[15:45:26] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10802967540681432, 'min_data_in_leaf': 2} scored -14047.352897970086 in 0:00:03.270572\n[15:45:27] 0:\tlearn: 54292.7827664\ttest: 54876.0113655\tbest: 54876.0113655 (0)\ttotal: 2.33ms\tremaining: 4.66s\n[15:45:30] Stopped by overfitting detector  (300 iterations wait)\n[15:45:30] bestTest = 14061.90296\n[15:45:30] bestIteration = 1198\n[15:45:30] Shrink model to first 1199 iterations.\n[15:45:30] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.001299386059814104, 'min_data_in_leaf': 4} scored -14061.903679220086 in 0:00:03.184592\n[15:45:30] 0:\tlearn: 54321.2061371\ttest: 54936.0405306\tbest: 54936.0405306 (0)\ttotal: 2.97ms\tremaining: 5.95s\n[15:45:36] bestTest = 13873.39179\n[15:45:36] bestIteration = 1853\n[15:45:36] Shrink model to first 1854 iterations.\n[15:45:36] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.761885976509065, 'min_data_in_leaf': 15} scored -13873.53796073718 in 0:00:06.176241\n[15:45:36] 0:\tlearn: 54293.2698070\ttest: 54876.1554178\tbest: 54876.1554178 (0)\ttotal: 2.16ms\tremaining: 4.31s\n[15:45:38] Stopped by overfitting detector  (300 iterations wait)\n[15:45:38] bestTest = 13943.35576\n[15:45:38] bestIteration = 926\n[15:45:38] Shrink model to first 927 iterations.\n[15:45:38] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00814682645095213, 'min_data_in_leaf': 6} scored -13943.355201655982 in 0:00:02.619570\n[15:45:39] 0:\tlearn: 54294.1262530\ttest: 54876.4131259\tbest: 54876.4131259 (0)\ttotal: 2.24ms\tremaining: 4.47s\n[15:45:41] Stopped by overfitting detector  (300 iterations wait)\n[15:45:41] bestTest = 13789.98677\n[15:45:41] bestIteration = 962\n[15:45:41] Shrink model to first 963 iterations.\n[15:45:41] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.02028172856955804, 'min_data_in_leaf': 1} scored -13789.98641159188 in 0:00:02.700449\n[15:45:41] 0:\tlearn: 54304.0667050\ttest: 54879.8028482\tbest: 54879.8028482 (0)\ttotal: 2.16ms\tremaining: 4.32s\n[15:45:45] bestTest = 13835.9057\n[15:45:45] bestIteration = 1941\n[15:45:45] Shrink model to first 1942 iterations.\n[15:45:45] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16989456212375476, 'min_data_in_leaf': 3} scored -13835.905582264957 in 0:00:04.180446\n[15:45:46] 0:\tlearn: 54315.9482856\ttest: 54884.7569099\tbest: 54884.7569099 (0)\ttotal: 2.28ms\tremaining: 4.56s\n[15:45:49] Stopped by overfitting detector  (300 iterations wait)\n[15:45:49] bestTest = 13979.13984\n[15:45:49] bestIteration = 1246\n[15:45:49] Shrink model to first 1247 iterations.\n[15:45:49] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.3698298407800851, 'min_data_in_leaf': 4} scored -13979.139890491453 in 0:00:03.299516\n[15:45:49] 0:\tlearn: 54390.8901391\ttest: 54932.2677417\tbest: 54932.2677417 (0)\ttotal: 2.21ms\tremaining: 4.42s\n[15:45:53] bestTest = 13706.21865\n[15:45:53] bestIteration = 1985\n[15:45:53] Shrink model to first 1986 iterations.\n[15:45:53] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.1293500792953597, 'min_data_in_leaf': 3} scored -13706.218048878205 in 0:00:04.539837\n[15:45:53] 0:\tlearn: 54296.4930169\ttest: 54877.1541852\tbest: 54877.1541852 (0)\ttotal: 2.2ms\tremaining: 4.4s\n[15:45:56] Stopped by overfitting detector  (300 iterations wait)\n[15:45:56] bestTest = 13683.90849\n[15:45:56] bestIteration = 1241\n[15:45:56] Shrink model to first 1242 iterations.\n[15:45:56] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.054439106919442516, 'min_data_in_leaf': 2} scored -13683.908336672008 in 0:00:03.250120\n[15:45:57] 0:\tlearn: 54294.7944297\ttest: 54876.6180570\tbest: 54876.6180570 (0)\ttotal: 2.23ms\tremaining: 4.45s\n[15:46:01] bestTest = 13696.57026\n[15:46:01] bestIteration = 1926\n[15:46:01] Shrink model to first 1927 iterations.\n[15:46:01] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.029832220983310554, 'min_data_in_leaf': 5} scored -13696.5703125 in 0:00:04.162915\n[15:46:01] 0:\tlearn: 54444.3444772\ttest: 54943.7525017\tbest: 54943.7525017 (0)\ttotal: 1.65ms\tremaining: 3.29s\n[15:46:04] bestTest = 13736.33305\n[15:46:04] bestIteration = 1989\n[15:46:04] Shrink model to first 1990 iterations.\n[15:46:04] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.7779600915571726, 'min_data_in_leaf': 1} scored -13736.33351696047 in 0:00:03.180353\n[15:46:04] 0:\tlearn: 54292.7328608\ttest: 54875.9967076\tbest: 54875.9967076 (0)\ttotal: 2.22ms\tremaining: 4.43s\n[15:46:09] bestTest = 14071.4834\n[15:46:09] bestIteration = 1959\n[15:46:09] Shrink model to first 1960 iterations.\n[15:46:09] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0005999360577182056, 'min_data_in_leaf': 6} scored -14071.483774038461 in 0:00:04.730418\n[15:46:09] 0:\tlearn: 54506.2770856\ttest: 54966.2168377\tbest: 54966.2168377 (0)\ttotal: 1.26ms\tremaining: 2.53s\n[15:46:11] bestTest = 14500.07248\n[15:46:11] bestIteration = 1976\n[15:46:11] Shrink model to first 1977 iterations.\n[15:46:11] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 4.464936258420335, 'min_data_in_leaf': 4} scored -14500.07234909188 in 0:00:02.316230\n[15:46:11] 0:\tlearn: 54423.6566548\ttest: 54935.1789201\tbest: 54935.1789201 (0)\ttotal: 1.67ms\tremaining: 3.33s\n[15:46:14] Stopped by overfitting detector  (300 iterations wait)\n[15:46:14] bestTest = 14092.35382\n[15:46:14] bestIteration = 1437\n[15:46:14] Shrink model to first 1438 iterations.\n[15:46:14] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.09691606466850071, 'min_data_in_leaf': 20} scored -14092.35359909188 in 0:00:02.782020\n[15:46:14] 0:\tlearn: 54274.9716624\ttest: 54908.4873127\tbest: 54908.4873127 (0)\ttotal: 2.99ms\tremaining: 5.97s\n[15:46:18] Stopped by overfitting detector  (300 iterations wait)\n[15:46:18] bestTest = 13966.3265\n[15:46:18] bestIteration = 1072\n[15:46:18] Shrink model to first 1073 iterations.\n[15:46:18] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.2031670285046818, 'min_data_in_leaf': 7} scored -13956.81296741453 in 0:00:03.936712\n[15:46:18] 0:\tlearn: 54452.0777813\ttest: 54897.1452713\tbest: 54897.1452713 (0)\ttotal: 2.32ms\tremaining: 4.64s\n[15:46:21] Stopped by overfitting detector  (300 iterations wait)\n[15:46:21] bestTest = 13791.77772\n[15:46:21] bestIteration = 1124\n[15:46:21] Shrink model to first 1125 iterations.\n[15:46:21] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.603215728150985, 'min_data_in_leaf': 3} scored -13794.382044604701 in 0:00:03.012364\n[15:46:21] 0:\tlearn: 54420.7502915\ttest: 54956.1918434\tbest: 54956.1918434 (0)\ttotal: 2.21ms\tremaining: 4.43s\n[15:46:25] bestTest = 13906.62934\n[15:46:25] bestIteration = 1983\n[15:46:25] Shrink model to first 1984 iterations.\n[15:46:25] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.0514263249710085, 'min_data_in_leaf': 6} scored -13906.629640758547 in 0:00:04.204871\n[15:46:25] 0:\tlearn: 54368.6139574\ttest: 54915.8855932\tbest: 54915.8855932 (0)\ttotal: 2.25ms\tremaining: 4.5s\n[15:46:29] bestTest = 13426.39576\n[15:46:29] bestIteration = 1923\n[15:46:29] Shrink model to first 1924 iterations.\n[15:46:29] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.5207739385901007, 'min_data_in_leaf': 5} scored -13426.395833333334 in 0:00:04.162332\n[15:46:29] 0:\tlearn: 54327.4660753\ttest: 54890.3997671\tbest: 54890.3997671 (0)\ttotal: 2.3ms\tremaining: 4.61s\n[15:46:33] bestTest = 13660.55707\n[15:46:33] bestIteration = 1861\n[15:46:33] Shrink model to first 1862 iterations.\n[15:46:33] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5852632233464073, 'min_data_in_leaf': 3} scored -13660.557525373932 in 0:00:04.249744\n[15:46:34] 0:\tlearn: 54353.4786982\ttest: 54905.6805165\tbest: 54905.6805165 (0)\ttotal: 2.17ms\tremaining: 4.33s\n[15:46:37] bestTest = 13543.71402\n[15:46:37] bestIteration = 1804\n[15:46:37] Shrink model to first 1805 iterations.\n[15:46:38] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1474273605447476, 'min_data_in_leaf': 5} scored -13543.713942307691 in 0:00:04.193740\n[15:46:38] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[15:46:38] The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10888374230503725, 'min_data_in_leaf': 1}\u001b[0m\n achieve -13352.8645 mae\n[15:46:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:46:38] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:46:38] 0:\tlearn: 55124.5415369\ttest: 55668.7089343\tbest: 55668.7089343 (0)\ttotal: 2.19ms\tremaining: 6.56s\n[15:46:41] Stopped by overfitting detector  (100 iterations wait)\n[15:46:41] bestTest = 13460.11066\n[15:46:41] bestIteration = 1200\n[15:46:41] Shrink model to first 1201 iterations.\n[15:46:41] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:46:41] 0:\tlearn: 56845.7851742\ttest: 49435.1255236\tbest: 49435.1255236 (0)\ttotal: 2.15ms\tremaining: 6.45s\n[15:46:43] Stopped by overfitting detector  (100 iterations wait)\n[15:46:43] bestTest = 12998.09826\n[15:46:43] bestIteration = 870\n[15:46:43] Shrink model to first 871 iterations.\n[15:46:43] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:46:43] 0:\tlearn: 52679.1631101\ttest: 61945.0395037\tbest: 61945.0395037 (0)\ttotal: 2.79ms\tremaining: 8.36s\n[15:46:44] Stopped by overfitting detector  (100 iterations wait)\n[15:46:44] bestTest = 19178.72059\n[15:46:44] bestIteration = 453\n[15:46:44] Shrink model to first 454 iterations.\n[15:46:44] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:46:44] 0:\tlearn: 56751.1582993\ttest: 51565.6361812\tbest: 51565.6361812 (0)\ttotal: 2.6ms\tremaining: 7.8s\n[15:46:46] Stopped by overfitting detector  (100 iterations wait)\n[15:46:46] bestTest = 13976.1182\n[15:46:46] bestIteration = 963\n[15:46:46] Shrink model to first 964 iterations.\n[15:46:46] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:46:46] 0:\tlearn: 53853.4815526\ttest: 57607.9681965\tbest: 57607.9681965 (0)\ttotal: 2.2ms\tremaining: 6.59s\n[15:46:48] Stopped by overfitting detector  (100 iterations wait)\n[15:46:48] bestTest = 16309.62978\n[15:46:48] bestIteration = 786\n[15:46:48] Shrink model to first 787 iterations.\n[15:46:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-15184.60682322881\u001b[0m\n[15:46:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:46:48] Time left 728.23 secs\n\n[15:46:48] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[15:46:48] Blending: optimization starts with equal weights and score \u001b[1m-14873.392093188142\u001b[0m\n[15:46:48] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14789.929975117722\u001b[0m, weights = \u001b[1m[0.21304773 0.         0.17027976 0.53824025 0.07843224]\u001b[0m\n[15:46:48] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14789.34965619649\u001b[0m, weights = \u001b[1m[0.20049502 0.         0.17400561 0.5500175  0.07548194]\u001b[0m\n[15:46:48] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14789.349214736729\u001b[0m, weights = \u001b[1m[0.200495   0.         0.1740056  0.5500175  0.07548194]\u001b[0m\n[15:46:48] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14789.34923145869\u001b[0m, weights = \u001b[1m[0.200495   0.         0.1740056  0.5500175  0.07548193]\u001b[0m\n[15:46:48] Blending: no score update. Terminated\n\n[15:46:48] \u001b[1mAutoml preset training completed in 552.20 seconds\u001b[0m\n\n[15:46:48] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.20050 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.17401 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.55002 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.07548 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[15:46:48] ==================================================\n[15:46:48] Start 2 automl preset configuration:\n[15:46:48] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 51}, 'nn_params': {'random_state': 51}, 'general_params': {'return_all_predictions': False}}\n[15:46:48] Found reader_params in kwargs, need to combine\n[15:46:48] Merged variant for reader_params = {'n_jobs': 4, 'random_state': 51, 'cv': 5}\n[15:46:48] Stdout logging level is INFO3.\n[15:46:48] Task: reg\n\n[15:46:48] Start automl preset with listed constraints:\n[15:46:48] - time: 728.09 seconds\n[15:46:48] - CPU: 4 cores\n[15:46:48] - memory: 16 GB\n\n[15:46:48] \u001b[1mTrain data shape: (1168, 145)\u001b[0m\n\n[15:46:48] Layer \u001b[1m1\u001b[0m train process start. Time left 728.01 secs\n[15:46:49] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[15:46:49] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:46:49] Linear model: C = 1e-05 score = -40009.9656116453\n[15:46:49] Linear model: C = 5e-05 score = -27120.979934561965\n[15:46:49] Linear model: C = 0.0001 score = -24152.313585069445\n[15:46:50] Linear model: C = 0.0005 score = -22022.964009081195\n[15:46:50] Linear model: C = 0.001 score = -21188.305972889957\n[15:46:50] Linear model: C = 0.005 score = -19807.679420405984\n[15:46:50] Linear model: C = 0.01 score = -19807.680054754273\n[15:46:51] Linear model: C = 0.05 score = -21003.260249732906\n[15:46:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:46:51] Linear model: C = 1e-05 score = -41576.536458333336\n[15:46:51] Linear model: C = 5e-05 score = -25945.06921073718\n[15:46:51] Linear model: C = 0.0001 score = -21906.556056356836\n[15:46:51] Linear model: C = 0.0005 score = -18094.353498931625\n[15:46:51] Linear model: C = 0.001 score = -17621.299278846152\n[15:46:52] Linear model: C = 0.005 score = -18500.667134081195\n[15:46:52] Linear model: C = 0.01 score = -18500.667901976496\n[15:46:52] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:46:52] Linear model: C = 1e-05 score = -41275.64803685898\n[15:46:52] Linear model: C = 5e-05 score = -26828.872395833332\n[15:46:52] Linear model: C = 0.0001 score = -22632.637453258547\n[15:46:53] Linear model: C = 0.0005 score = -17626.332899305555\n[15:46:53] Linear model: C = 0.001 score = -16548.640341212606\n[15:46:53] Linear model: C = 0.005 score = -16548.639673477563\n[15:46:53] Linear model: C = 0.01 score = -15747.359308226496\n[15:46:53] Linear model: C = 0.05 score = -15747.360643696582\n[15:46:53] Linear model: C = 0.1 score = -18195.726696047008\n[15:46:53] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:46:54] Linear model: C = 1e-05 score = -40291.12567060086\n[15:46:54] Linear model: C = 5e-05 score = -27111.410307135193\n[15:46:54] Linear model: C = 0.0001 score = -23488.877045332618\n[15:46:54] Linear model: C = 0.0005 score = -20014.501156786482\n[15:46:54] Linear model: C = 0.001 score = -20014.499228809014\n[15:46:54] Linear model: C = 0.005 score = -18826.739689511804\n[15:46:54] Linear model: C = 0.01 score = -18826.740075107296\n[15:46:55] Linear model: C = 0.05 score = -18826.740259522532\n[15:46:55] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[15:46:55] Linear model: C = 1e-05 score = -45393.0383583691\n[15:46:55] Linear model: C = 5e-05 score = -30069.300261534336\n[15:46:55] Linear model: C = 0.0001 score = -25519.84214055794\n[15:46:55] Linear model: C = 0.0005 score = -20269.965346700643\n[15:46:55] Linear model: C = 0.001 score = -20269.965346700643\n[15:46:55] Linear model: C = 0.005 score = -20269.965346700643\n[15:46:55] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-18452.73575957834\u001b[0m\n[15:46:55] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[15:46:55] Time left 720.99 secs\n\n[15:46:55] Training until validation scores don't improve for 200 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n/opt/conda/lib/python3.10/site-packages/lightautoml/transformers/categorical.py:1030: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n  cnts = concat([cnts, Series([cnts.shape[0] + 1], index=[np.nan])])\n","output_type":"stream"},{"name":"stdout","text":"[15:46:57] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n[15:46:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[15:46:58] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:46:58] Training until validation scores don't improve for 200 rounds\n[15:46:59] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:46:59] Training until validation scores don't improve for 200 rounds\n[15:47:01] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:47:01] Training until validation scores don't improve for 200 rounds\n[15:47:04] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:47:04] Training until validation scores don't improve for 200 rounds\n[15:47:07] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[15:47:07] Training until validation scores don't improve for 200 rounds\n[15:47:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-15565.65343067744\u001b[0m\n[15:47:10] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[15:47:10] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 105.74 secs\n[15:47:10] Training until validation scores don't improve for 200 rounds\n[15:47:13] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -15350.46858306624 in 0:00:03.596273\n[15:47:13] Training until validation scores don't improve for 200 rounds\n[15:47:15] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -15644.836605235043 in 0:00:01.719549\n[15:47:15] Training until validation scores don't improve for 200 rounds\n[15:47:17] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -15751.051315438035 in 0:00:01.620106\n[15:47:17] Training until validation scores don't improve for 200 rounds\n[15:47:18] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -15329.848924946582 in 0:00:01.682042\n[15:47:19] Training until validation scores don't improve for 200 rounds\n[15:47:20] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -15774.424579326924 in 0:00:01.310340\n[15:47:20] Training until validation scores don't improve for 200 rounds\n[15:47:21] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -15576.040264423076 in 0:00:01.215626\n[15:47:21] Training until validation scores don't improve for 200 rounds\n[15:47:23] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -15361.930388621795 in 0:00:01.748212\n[15:47:23] Training until validation scores don't improve for 200 rounds\n[15:47:24] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -15641.904180021367 in 0:00:01.207729\n[15:47:24] Training until validation scores don't improve for 200 rounds\n[15:47:26] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -15627.180822649572 in 0:00:02.093845\n[15:47:26] Training until validation scores don't improve for 200 rounds\n[15:47:27] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -15626.439670138889 in 0:00:01.244096\n[15:47:27] Training until validation scores don't improve for 200 rounds\n[15:47:29] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 126, 'bagging_fraction': 0.7149885992524331, 'min_sum_hessian_in_leaf': 0.001179906252315926, 'reg_alpha': 0.0024039730866095197, 'reg_lambda': 0.016301353379407527} scored -15293.33343349359 in 0:00:01.838041\n[15:47:29] Training until validation scores don't improve for 200 rounds\n[15:47:31] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.9888555200076986, 'num_leaves': 121, 'bagging_fraction': 0.7046188504850932, 'min_sum_hessian_in_leaf': 0.0010353204153309649, 'reg_alpha': 0.005652041655713891, 'reg_lambda': 0.023329781877371426} scored -15242.473390758547 in 0:00:01.803036\n[15:47:31] Training until validation scores don't improve for 200 rounds\n[15:47:33] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.9867091516596629, 'num_leaves': 140, 'bagging_fraction': 0.6936783197219435, 'min_sum_hessian_in_leaf': 0.0011028928813293943, 'reg_alpha': 0.007858390361874286, 'reg_lambda': 0.022580571363752543} scored -15153.832164797008 in 0:00:02.001583\n[15:47:33] Training until validation scores don't improve for 200 rounds\n[15:47:35] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.8990685561470543, 'num_leaves': 164, 'bagging_fraction': 0.7007479449208773, 'min_sum_hessian_in_leaf': 0.024142096469713267, 'reg_alpha': 0.08810028012678793, 'reg_lambda': 0.02281074110425321} scored -15426.13655181624 in 0:00:01.708448\n[15:47:35] Training until validation scores don't improve for 200 rounds\n[15:47:37] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.9947657941543059, 'num_leaves': 120, 'bagging_fraction': 0.6718425033358284, 'min_sum_hessian_in_leaf': 0.001183749171633132, 'reg_alpha': 0.13742872519199045, 'reg_lambda': 0.011695935907906768} scored -15450.659321581197 in 0:00:01.788130\n[15:47:37] Training until validation scores don't improve for 200 rounds\n[15:47:39] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.8889983453926262, 'num_leaves': 172, 'bagging_fraction': 0.7531734552200906, 'min_sum_hessian_in_leaf': 0.014899839263051494, 'reg_alpha': 0.00029769294502556345, 'reg_lambda': 0.2852186725016656} scored -15344.707698985043 in 0:00:02.100459\n[15:47:39] Training until validation scores don't improve for 200 rounds\n[15:47:41] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.8649174147658507, 'num_leaves': 101, 'bagging_fraction': 0.9171981962581278, 'min_sum_hessian_in_leaf': 0.0010292009869543354, 'reg_alpha': 0.02564027085362521, 'reg_lambda': 0.003781300442065976} scored -15368.351295405982 in 0:00:02.004769\n[15:47:41] Training until validation scores don't improve for 200 rounds\n[15:47:43] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.9503662986965962, 'num_leaves': 166, 'bagging_fraction': 0.7472223931930823, 'min_sum_hessian_in_leaf': 0.0029506894022166496, 'reg_alpha': 0.00011422657402653326, 'reg_lambda': 0.14184312049385903} scored -15334.517928685897 in 0:00:01.991898\n[15:47:43] Training until validation scores don't improve for 200 rounds\n[15:47:46] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.8526802042313292, 'num_leaves': 143, 'bagging_fraction': 0.651367161498651, 'min_sum_hessian_in_leaf': 0.016715038181256095, 'reg_alpha': 0.0108369303829359, 'reg_lambda': 6.243069797304186} scored -15522.493255876068 in 0:00:03.029106\n[15:47:46] Training until validation scores don't improve for 200 rounds\n[15:47:47] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.9430037106755654, 'num_leaves': 21, 'bagging_fraction': 0.5013026518152478, 'min_sum_hessian_in_leaf': 0.055191805483702804, 'reg_alpha': 0.36714255469878165, 'reg_lambda': 0.0017894100508480564} scored -15372.294437767094 in 0:00:01.367511\n[15:47:47] Training until validation scores don't improve for 200 rounds\n[15:47:49] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.9954804576223869, 'num_leaves': 190, 'bagging_fraction': 0.7552986430037012, 'min_sum_hessian_in_leaf': 0.002462971549617265, 'reg_alpha': 7.71641390632421e-05, 'reg_lambda': 2.5321843876616687e-05} scored -15321.117721688035 in 0:00:02.159030\n[15:47:49] Training until validation scores don't improve for 200 rounds\n[15:47:51] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.963207101508711, 'num_leaves': 130, 'bagging_fraction': 0.7070682437812602, 'min_sum_hessian_in_leaf': 0.0012036002347185482, 'reg_alpha': 0.0014561469589187465, 'reg_lambda': 0.0409801951030148} scored -15243.586004273504 in 0:00:01.922979\n[15:47:51] Training until validation scores don't improve for 200 rounds\n[15:47:53] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.9371158895275773, 'num_leaves': 103, 'bagging_fraction': 0.694318798767932, 'min_sum_hessian_in_leaf': 0.010393836202002845, 'reg_alpha': 0.0026470865224887956, 'reg_lambda': 0.05190925408128149} scored -15286.962540064103 in 0:00:01.841639\n[15:47:53] Training until validation scores don't improve for 200 rounds\n[15:47:54] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.8362230941231674, 'num_leaves': 153, 'bagging_fraction': 0.6218928156613331, 'min_sum_hessian_in_leaf': 0.002088715294050403, 'reg_alpha': 0.01145893627346758, 'reg_lambda': 0.8232034142326641} scored -15661.447983440172 in 0:00:01.450809\n[15:47:55] Training until validation scores don't improve for 200 rounds\n[15:47:56] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.6091330191487014, 'num_leaves': 131, 'bagging_fraction': 0.7233966338251935, 'min_sum_hessian_in_leaf': 0.006557404063079518, 'reg_alpha': 0.0010526891805708069, 'reg_lambda': 0.005762748530154324} scored -15591.407218215812 in 0:00:01.430676\n[15:47:56] Training until validation scores don't improve for 200 rounds\n[15:47:58] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.9670875331564046, 'num_leaves': 108, 'bagging_fraction': 0.7918232071932182, 'min_sum_hessian_in_leaf': 0.0020094611627504756, 'reg_alpha': 2.822736901948412e-05, 'reg_lambda': 0.049226309941907694} scored -15443.925113514957 in 0:00:02.013000\n[15:47:58] Training until validation scores don't improve for 200 rounds\n[15:48:00] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.9077648122678748, 'num_leaves': 82, 'bagging_fraction': 0.6735119269022507, 'min_sum_hessian_in_leaf': 0.001003294964281065, 'reg_alpha': 0.0005544561937948424, 'reg_lambda': 0.00017081041887644143} scored -15526.939403044871 in 0:00:01.673411\n[15:48:00] Training until validation scores don't improve for 200 rounds\n[15:48:02] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.993437366053878, 'num_leaves': 184, 'bagging_fraction': 0.65477426123904, 'min_sum_hessian_in_leaf': 0.004222248730404788, 'reg_alpha': 0.9108485083074284, 'reg_lambda': 0.808431187413253} scored -15408.532719017094 in 0:00:02.007176\n[15:48:02] Training until validation scores don't improve for 200 rounds\n[15:48:03] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.8739995145373465, 'num_leaves': 146, 'bagging_fraction': 0.5750737460040551, 'min_sum_hessian_in_leaf': 9.074966324558188, 'reg_alpha': 0.042869198101378805, 'reg_lambda': 0.0012112018727127908} scored -15650.80188301282 in 0:00:01.395500\n[15:48:03] Training until validation scores don't improve for 200 rounds\n[15:48:05] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.9280439600477046, 'num_leaves': 255, 'bagging_fraction': 0.906708728779495, 'min_sum_hessian_in_leaf': 0.008439775520931597, 'reg_alpha': 0.005817966286343731, 'reg_lambda': 2.898347864988663e-06} scored -15411.013454861111 in 0:00:02.071162\n[15:48:05] Training until validation scores don't improve for 200 rounds\n[15:48:07] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.8286047118442283, 'num_leaves': 114, 'bagging_fraction': 0.8442390286855842, 'min_sum_hessian_in_leaf': 0.024511027500039605, 'reg_alpha': 0.0003098021488711601, 'reg_lambda': 0.05751673949831548} scored -15299.957765758547 in 0:00:01.989310\n[15:48:07] Training until validation scores don't improve for 200 rounds\n[15:48:09] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.9471708691309522, 'num_leaves': 91, 'bagging_fraction': 0.7102000112080822, 'min_sum_hessian_in_leaf': 0.00210134455852673, 'reg_alpha': 0.004378159093174183, 'reg_lambda': 0.05704749298568329} scored -15408.103231837607 in 0:00:02.032163\n[15:48:09] Training until validation scores don't improve for 200 rounds\n[15:48:11] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.9699121133979803, 'num_leaves': 136, 'bagging_fraction': 0.6879939821496581, 'min_sum_hessian_in_leaf': 0.009533152324931644, 'reg_alpha': 0.022551165345938245, 'reg_lambda': 0.00581952331905839} scored -15294.576355502137 in 0:00:01.703893\n[15:48:11] Training until validation scores don't improve for 200 rounds\n[15:48:13] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.9276185712105138, 'num_leaves': 100, 'bagging_fraction': 0.7730252300915884, 'min_sum_hessian_in_leaf': 0.001673069115789474, 'reg_alpha': 0.0011465224776872553, 'reg_lambda': 2.298352274958617} scored -15269.872896634615 in 0:00:01.999035\n[15:48:13] Training until validation scores don't improve for 200 rounds\n[15:48:15] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.9100247259773337, 'num_leaves': 75, 'bagging_fraction': 0.7707551965524873, 'min_sum_hessian_in_leaf': 0.0016514948807391872, 'reg_alpha': 4.7992483533076145e-05, 'reg_lambda': 2.3557615948355033} scored -15319.584034455129 in 0:00:01.907376\n[15:48:15] Training until validation scores don't improve for 200 rounds\n[15:48:18] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5632613446856177, 'num_leaves': 98, 'bagging_fraction': 0.8169060909872567, 'min_sum_hessian_in_leaf': 0.003583445454030629, 'reg_alpha': 1.7533257567225306e-05, 'reg_lambda': 0.4455641810862751} scored -15530.80328525641 in 0:00:03.191830\n[15:48:18] Training until validation scores don't improve for 200 rounds\n[15:48:20] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.9788179631490803, 'num_leaves': 153, 'bagging_fraction': 0.7340174378643689, 'min_sum_hessian_in_leaf': 0.004169014303766847, 'reg_alpha': 1.1501537129655524e-06, 'reg_lambda': 5.818372334083851e-05} scored -15297.395833333334 in 0:00:01.941148\n[15:48:20] Training until validation scores don't improve for 200 rounds\n[15:48:22] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.67990548355057, 'num_leaves': 207, 'bagging_fraction': 0.7760604749684721, 'min_sum_hessian_in_leaf': 0.0017705301188346053, 'reg_alpha': 0.0009108162182741498, 'reg_lambda': 3.120757243906163} scored -15495.256510416666 in 0:00:02.019351\n[15:48:22] Training until validation scores don't improve for 200 rounds\n[15:48:24] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.9234534715339084, 'num_leaves': 118, 'bagging_fraction': 0.6233648494953729, 'min_sum_hessian_in_leaf': 0.2235308118671907, 'reg_alpha': 0.0001543069295351887, 'reg_lambda': 4.884657654745279e-07} scored -15494.021901709402 in 0:00:01.630126\n[15:48:24] Training until validation scores don't improve for 200 rounds\n[15:48:26] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.957386614431142, 'num_leaves': 70, 'bagging_fraction': 0.8183660495247613, 'min_sum_hessian_in_leaf': 1.2408417934874234, 'reg_alpha': 0.361864605016622, 'reg_lambda': 9.12157073636554} scored -15323.420138888889 in 0:00:01.993958\n[15:48:26] Training until validation scores don't improve for 200 rounds\n[15:48:28] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.7548146247805787, 'num_leaves': 130, 'bagging_fraction': 0.8824934599898315, 'min_sum_hessian_in_leaf': 0.003558002733912278, 'reg_alpha': 0.0011660110576708648, 'reg_lambda': 0.0013903062617524563} scored -15219.427717681623 in 0:00:02.116260\n[15:48:28] Training until validation scores don't improve for 200 rounds\n[15:48:30] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.759359978569621, 'num_leaves': 134, 'bagging_fraction': 0.9810641322900424, 'min_sum_hessian_in_leaf': 0.0014791314043526268, 'reg_alpha': 0.001118234546253731, 'reg_lambda': 0.0009050762891640225} scored -15469.310563568377 in 0:00:02.092121\n[15:48:30] Training until validation scores don't improve for 200 rounds\n[15:48:32] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.6249828115416672, 'num_leaves': 124, 'bagging_fraction': 0.8943750306935767, 'min_sum_hessian_in_leaf': 0.0028215368653877375, 'reg_alpha': 0.007829958126758137, 'reg_lambda': 0.00013369073688367656} scored -15385.429620726496 in 0:00:01.931478\n[15:48:32] Training until validation scores don't improve for 200 rounds\n[15:48:34] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.6951136691969912, 'num_leaves': 48, 'bagging_fraction': 0.8703237456557011, 'min_sum_hessian_in_leaf': 0.003453287078158669, 'reg_alpha': 0.002542360042982332, 'reg_lambda': 0.17636703797086636} scored -15278.82719017094 in 0:00:01.956001\n[15:48:34] Training until validation scores don't improve for 200 rounds\n[15:48:36] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.8045223007355249, 'num_leaves': 89, 'bagging_fraction': 0.9552338790300056, 'min_sum_hessian_in_leaf': 0.0054724581669835124, 'reg_alpha': 0.06254518922987769, 'reg_lambda': 0.0027304589613242536} scored -15495.50530849359 in 0:00:02.154739\n[15:48:36] Training until validation scores don't improve for 200 rounds\n[15:48:37] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.7215867160872357, 'num_leaves': 154, 'bagging_fraction': 0.6486366576629012, 'min_sum_hessian_in_leaf': 0.001020812027628507, 'reg_alpha': 0.00021333029853669533, 'reg_lambda': 0.012998481749814186} scored -15746.87079326923 in 0:00:01.462316\n[15:48:37] Training until validation scores don't improve for 200 rounds\n[15:48:39] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.8886319819958259, 'num_leaves': 140, 'bagging_fraction': 0.5871319248742302, 'min_sum_hessian_in_leaf': 0.0017313497735719078, 'reg_alpha': 0.000704875306962557, 'reg_lambda': 0.11822915228628943} scored -15694.30218349359 in 0:00:01.457452\n[15:48:39] Training until validation scores don't improve for 200 rounds\n[15:48:41] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.9981274658927459, 'num_leaves': 112, 'bagging_fraction': 0.8421814796460589, 'min_sum_hessian_in_leaf': 0.0014959125203675278, 'reg_alpha': 0.020152994447650265, 'reg_lambda': 1.7819653870832216e-08} scored -15264.692107371795 in 0:00:02.325451\n[15:48:41] Training until validation scores don't improve for 200 rounds\n[15:48:44] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.9935155970443046, 'num_leaves': 112, 'bagging_fraction': 0.8443232298436647, 'min_sum_hessian_in_leaf': 0.050055265049689164, 'reg_alpha': 0.015171093494834453, 'reg_lambda': 1.3591123205528005e-08} scored -15185.155849358975 in 0:00:02.291349\n[15:48:44] Training until validation scores don't improve for 200 rounds\n[15:48:45] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.560171498935114, 'num_leaves': 176, 'bagging_fraction': 0.8753398828078675, 'min_sum_hessian_in_leaf': 0.095870724793815, 'reg_alpha': 0.30807392572951947, 'reg_lambda': 5.758516482463266e-08} scored -15384.989149305555 in 0:00:01.832305\n[15:48:45] Training until validation scores don't improve for 200 rounds\n[15:48:49] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.9815386204669562, 'num_leaves': 122, 'bagging_fraction': 0.9416123801191965, 'min_sum_hessian_in_leaf': 0.033101676735387185, 'reg_alpha': 0.09887750410313648, 'reg_lambda': 0.0004932500848662464} scored -15233.039296207266 in 0:00:03.922514\n[15:48:49] Training until validation scores don't improve for 200 rounds\n[15:48:52] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.9782203907041825, 'num_leaves': 126, 'bagging_fraction': 0.952484659235645, 'min_sum_hessian_in_leaf': 0.038330832585757146, 'reg_alpha': 0.13170072261140836, 'reg_lambda': 0.0003393508322929052} scored -15300.834735576924 in 0:00:02.402013\n[15:48:52] Training until validation scores don't improve for 200 rounds\n[15:48:54] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.9602323236531779, 'num_leaves': 158, 'bagging_fraction': 0.9258567345043324, 'min_sum_hessian_in_leaf': 0.15116833415228303, 'reg_alpha': 1.5737373524843081, 'reg_lambda': 0.021583650941124518} scored -15276.629273504273 in 0:00:02.166659\n[15:48:54] Training until validation scores don't improve for 200 rounds\n[15:48:56] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.9785917057717559, 'num_leaves': 146, 'bagging_fraction': 0.9389703549318458, 'min_sum_hessian_in_leaf': 0.41773395134277164, 'reg_alpha': 0.039828132189299315, 'reg_lambda': 0.0006364959770843137} scored -15284.223157051281 in 0:00:02.409623\n[15:48:56] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[15:48:56] The set of hyperparameters \u001b[1m{'feature_fraction': 0.9867091516596629, 'num_leaves': 140, 'bagging_fraction': 0.6936783197219435, 'min_sum_hessian_in_leaf': 0.0011028928813293943, 'reg_alpha': 0.007858390361874286, 'reg_lambda': 0.022580571363752543}\u001b[0m\n achieve -15153.8322 mae\n[15:48:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n[15:48:56] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:48:56] Training until validation scores don't improve for 100 rounds\n[15:48:57] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:48:57] Training until validation scores don't improve for 100 rounds\n[15:48:58] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:48:58] Training until validation scores don't improve for 100 rounds\n[15:48:59] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:48:59] Training until validation scores don't improve for 100 rounds\n[15:49:00] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n[15:49:00] Training until validation scores don't improve for 100 rounds\n[15:49:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-15609.509638538098\u001b[0m\n[15:49:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n[15:49:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[15:49:00] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:49:00] 0:\tlearn: 54893.7195053\ttest: 51276.2941916\tbest: 51276.2941916 (0)\ttotal: 2.12ms\tremaining: 4.23s\n[15:49:03] Stopped by overfitting detector  (300 iterations wait)\n[15:49:03] bestTest = 15689.43312\n[15:49:03] bestIteration = 1225\n[15:49:03] Shrink model to first 1226 iterations.\n[15:49:03] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:49:03] 0:\tlearn: 53523.5008949\ttest: 55800.8298211\tbest: 55800.8298211 (0)\ttotal: 2.02ms\tremaining: 4.05s\n[15:49:05] Stopped by overfitting detector  (300 iterations wait)\n[15:49:05] bestTest = 16351.57452\n[15:49:05] bestIteration = 613\n[15:49:05] Shrink model to first 614 iterations.\n[15:49:05] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:49:05] 0:\tlearn: 54316.5386986\ttest: 53522.5428332\tbest: 53522.5428332 (0)\ttotal: 1.97ms\tremaining: 3.94s\n[15:49:07] Stopped by overfitting detector  (300 iterations wait)\n[15:49:07] bestTest = 13264.978\n[15:49:07] bestIteration = 755\n[15:49:07] Shrink model to first 756 iterations.\n[15:49:07] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:49:07] 0:\tlearn: 54878.1030933\ttest: 52155.4548912\tbest: 52155.4548912 (0)\ttotal: 1.98ms\tremaining: 3.96s\n[15:49:09] Stopped by overfitting detector  (300 iterations wait)\n[15:49:09] bestTest = 15709.31249\n[15:49:09] bestIteration = 938\n[15:49:09] Shrink model to first 939 iterations.\n[15:49:09] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[15:49:10] 0:\tlearn: 53025.4857400\ttest: 58268.0655700\tbest: 58268.0655700 (0)\ttotal: 1.96ms\tremaining: 3.92s\n[15:49:12] Stopped by overfitting detector  (300 iterations wait)\n[15:49:12] bestTest = 15359.04364\n[15:49:12] bestIteration = 1138\n[15:49:12] Shrink model to first 1139 iterations.\n[15:49:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-15274.424119087114\u001b[0m\n[15:49:12] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[15:49:12] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n[15:49:12] 0:\tlearn: 55155.2970039\ttest: 51522.9175210\tbest: 51522.9175210 (0)\ttotal: 1.47ms\tremaining: 2.94s\n[15:49:15] Stopped by overfitting detector  (300 iterations wait)\n[15:49:15] bestTest = 15814.85333\n[15:49:15] bestIteration = 1465\n[15:49:15] Shrink model to first 1466 iterations.\n[15:49:15] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -15814.852881276709 in 0:00:02.560123\n[15:49:15] 0:\tlearn: 55206.2917407\ttest: 51513.6267313\tbest: 51513.6267313 (0)\ttotal: 1.19ms\tremaining: 2.37s\n[15:49:17] bestTest = 16387.22279\n[15:49:17] bestIteration = 1889\n[15:49:17] Shrink model to first 1890 iterations.\n[15:49:17] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -16387.22320713141 in 0:00:02.129076\n[15:49:17] 0:\tlearn: 55206.1801902\ttest: 51513.5986025\tbest: 51513.5986025 (0)\ttotal: 1.18ms\tremaining: 2.35s\n[15:49:19] bestTest = 16407.88021\n[15:49:19] bestIteration = 1983\n[15:49:19] Shrink model to first 1984 iterations.\n[15:49:19] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -16380.131977831197 in 0:00:02.148955\n[15:49:19] 0:\tlearn: 55206.1835100\ttest: 51513.5994384\tbest: 51513.5994384 (0)\ttotal: 1.4ms\tremaining: 2.79s\n[15:49:22] bestTest = 16471.84994\n[15:49:22] bestIteration = 1810\n[15:49:22] Shrink model to first 1811 iterations.\n[15:49:22] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -16471.85049412393 in 0:00:02.720781\n[15:49:22] 0:\tlearn: 54889.8225082\ttest: 51289.9451341\tbest: 51289.9451341 (0)\ttotal: 3.62ms\tremaining: 7.24s\n[15:49:25] Stopped by overfitting detector  (300 iterations wait)\n[15:49:25] bestTest = 14798.84218\n[15:49:25] bestIteration = 1038\n[15:49:25] Shrink model to first 1039 iterations.\n[15:49:25] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -14798.841947115385 in 0:00:03.586903\n[15:49:26] 0:\tlearn: 54889.9756022\ttest: 51289.9972346\tbest: 51289.9972346 (0)\ttotal: 3.08ms\tremaining: 6.15s\n[15:49:28] Stopped by overfitting detector  (300 iterations wait)\n[15:49:28] bestTest = 15093.52094\n[15:49:28] bestIteration = 743\n[15:49:28] Shrink model to first 744 iterations.\n[15:49:28] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -15093.521367521367 in 0:00:02.866396\n[15:49:28] 0:\tlearn: 54960.2498123\ttest: 51174.6225366\tbest: 51174.6225366 (0)\ttotal: 3.06ms\tremaining: 6.11s\n[15:49:32] Stopped by overfitting detector  (300 iterations wait)\n[15:49:32] bestTest = 15499.5719\n[15:49:32] bestIteration = 1065\n[15:49:32] Shrink model to first 1066 iterations.\n[15:49:32] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -15486.839993990385 in 0:00:03.661775\n[15:49:32] 0:\tlearn: 54748.8511393\ttest: 51092.4508701\tbest: 51092.4508701 (0)\ttotal: 4.71ms\tremaining: 9.41s\n[15:49:37] Stopped by overfitting detector  (300 iterations wait)\n[15:49:37] bestTest = 15736.39217\n[15:49:37] bestIteration = 1118\n[15:49:37] Shrink model to first 1119 iterations.\n[15:49:37] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -15717.673711271367 in 0:00:05.428619\n[15:49:38] 0:\tlearn: 55220.1830487\ttest: 51418.1707314\tbest: 51418.1707314 (0)\ttotal: 1.23ms\tremaining: 2.45s\n[15:49:40] bestTest = 16314.3262\n[15:49:40] bestIteration = 1964\n[15:49:40] Shrink model to first 1965 iterations.\n[15:49:40] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -16311.944878472223 in 0:00:02.145206\n[15:49:40] 0:\tlearn: 54889.8810446\ttest: 51289.9650441\tbest: 51289.9650441 (0)\ttotal: 2.68ms\tremaining: 5.36s\n[15:49:43] Stopped by overfitting detector  (300 iterations wait)\n[15:49:43] bestTest = 14862.29051\n[15:49:43] bestIteration = 916\n[15:49:43] Shrink model to first 917 iterations.\n[15:49:43] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -14862.290898771367 in 0:00:03.289678\n[15:49:43] 0:\tlearn: 54893.2076038\ttest: 51276.1248889\tbest: 51276.1248889 (0)\ttotal: 2.08ms\tremaining: 4.15s\n[15:49:47] bestTest = 15983.50931\n[15:49:47] bestIteration = 1785\n[15:49:47] Shrink model to first 1786 iterations.\n[15:49:47] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 13} scored -15983.509548611111 in 0:00:03.852614\n[15:49:47] 0:\tlearn: 54889.8229702\ttest: 51289.9452912\tbest: 51289.9452912 (0)\ttotal: 2.77ms\tremaining: 5.53s\n[15:49:50] Stopped by overfitting detector  (300 iterations wait)\n[15:49:50] bestTest = 14798.84179\n[15:49:50] bestIteration = 1038\n[15:49:50] Shrink model to first 1039 iterations.\n[15:49:50] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.623917803986404e-05, 'min_data_in_leaf': 11} scored -14798.841730101496 in 0:00:03.571826\n[15:49:51] 0:\tlearn: 54747.3917213\ttest: 51091.6735934\tbest: 51091.6735934 (0)\ttotal: 4.44ms\tremaining: 8.88s\n[15:49:54] Stopped by overfitting detector  (300 iterations wait)\n[15:49:54] bestTest = 15092.29381\n[15:49:54] bestIteration = 462\n[15:49:54] Shrink model to first 463 iterations.\n[15:49:54] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0933323241530802e-05, 'min_data_in_leaf': 11} scored -15092.294103899572 in 0:00:03.960670\n[15:49:54] 0:\tlearn: 54893.2077199\ttest: 51276.1249271\tbest: 51276.1249271 (0)\ttotal: 2.02ms\tremaining: 4.03s\n[15:49:56] Stopped by overfitting detector  (300 iterations wait)\n[15:49:56] bestTest = 16053.67873\n[15:49:56] bestIteration = 829\n[15:49:56] Shrink model to first 830 iterations.\n[15:49:56] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.2681422754858815e-06, 'min_data_in_leaf': 16} scored -16053.678852831197 in 0:00:02.249559\n[15:49:57] 0:\tlearn: 54889.8210863\ttest: 51289.9446506\tbest: 51289.9446506 (0)\ttotal: 2.79ms\tremaining: 5.57s\n[15:50:00] Stopped by overfitting detector  (300 iterations wait)\n[15:50:00] bestTest = 14798.8434\n[15:50:00] bestIteration = 1038\n[15:50:00] Shrink model to first 1039 iterations.\n[15:50:00] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 9.297801071561631e-08, 'min_data_in_leaf': 9} scored -14798.84349959936 in 0:00:03.576272\n[15:50:00] 0:\tlearn: 54747.3942190\ttest: 51091.6749201\tbest: 51091.6749201 (0)\ttotal: 4.11ms\tremaining: 8.22s\n[15:50:03] Stopped by overfitting detector  (300 iterations wait)\n[15:50:03] bestTest = 15092.28716\n[15:50:03] bestIteration = 462\n[15:50:03] Shrink model to first 463 iterations.\n[15:50:03] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 3.542425690054301e-05, 'min_data_in_leaf': 12} scored -15092.287326388889 in 0:00:03.045968\n[15:50:03] 0:\tlearn: 54897.5753014\ttest: 51277.6213187\tbest: 51277.6213187 (0)\ttotal: 1.99ms\tremaining: 3.98s\n[15:50:06] Stopped by overfitting detector  (300 iterations wait)\n[15:50:06] bestTest = 15745.17648\n[15:50:06] bestIteration = 1099\n[15:50:06] Shrink model to first 1100 iterations.\n[15:50:06] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.08858623697797322, 'min_data_in_leaf': 16} scored -15745.177233573719 in 0:00:02.742994\n[15:50:06] 0:\tlearn: 55155.1778536\ttest: 51522.8823023\tbest: 51522.8823023 (0)\ttotal: 1.47ms\tremaining: 2.93s\n[15:50:08] Stopped by overfitting detector  (300 iterations wait)\n[15:50:08] bestTest = 15737.54557\n[15:50:08] bestIteration = 1330\n[15:50:08] Shrink model to first 1331 iterations.\n[15:50:08] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 4.443993340270556e-06, 'min_data_in_leaf': 9} scored -15737.545706463676 in 0:00:02.385121\n[15:50:08] 0:\tlearn: 54889.8305805\ttest: 51289.9478790\tbest: 51289.9478790 (0)\ttotal: 2.9ms\tremaining: 5.8s\n[15:50:11] Stopped by overfitting detector  (300 iterations wait)\n[15:50:11] bestTest = 14803.86097\n[15:50:11] bestIteration = 703\n[15:50:11] Shrink model to first 704 iterations.\n[15:50:11] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00013186575456934678, 'min_data_in_leaf': 20} scored -14803.860643696582 in 0:00:02.695391\n[15:50:11] 0:\tlearn: 55155.1776586\ttest: 51522.8822447\tbest: 51522.8822447 (0)\ttotal: 1.5ms\tremaining: 2.99s\n[15:50:13] Stopped by overfitting detector  (300 iterations wait)\n[15:50:13] bestTest = 15737.54692\n[15:50:13] bestIteration = 1330\n[15:50:13] Shrink model to first 1331 iterations.\n[15:50:13] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 4.5925730842893576e-07, 'min_data_in_leaf': 14} scored -15737.547008547008 in 0:00:02.443948\n[15:50:14] 0:\tlearn: 54747.3906150\ttest: 51091.6730058\tbest: 51091.6730058 (0)\ttotal: 4.02ms\tremaining: 8.03s\n[15:50:16] Stopped by overfitting detector  (300 iterations wait)\n[15:50:16] bestTest = 15092.29676\n[15:50:16] bestIteration = 462\n[15:50:16] Shrink model to first 463 iterations.\n[15:50:16] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 8.599397234176193e-08, 'min_data_in_leaf': 18} scored -15092.296741452992 in 0:00:02.987522\n[15:50:17] 0:\tlearn: 54889.8210836\ttest: 51289.9446497\tbest: 51289.9446497 (0)\ttotal: 2.7ms\tremaining: 5.4s\n[15:50:20] Stopped by overfitting detector  (300 iterations wait)\n[15:50:20] bestTest = 14798.8434\n[15:50:20] bestIteration = 1038\n[15:50:20] Shrink model to first 1039 iterations.\n[15:50:20] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 5.566105313062511e-08, 'min_data_in_leaf': 9} scored -14798.84336605235 in 0:00:03.572940\n[15:50:20] 0:\tlearn: 54889.8223082\ttest: 51289.9450661\tbest: 51289.9450661 (0)\ttotal: 2.7ms\tremaining: 5.41s\n[15:50:24] Stopped by overfitting detector  (300 iterations wait)\n[15:50:24] bestTest = 14798.84235\n[15:50:24] bestIteration = 1038\n[15:50:24] Shrink model to first 1039 iterations.\n[15:50:24] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.7051501716878055e-05, 'min_data_in_leaf': 7} scored -14798.841980502137 in 0:00:03.641077\n[15:50:24] 0:\tlearn: 54893.2087396\ttest: 51276.1252627\tbest: 51276.1252627 (0)\ttotal: 1.95ms\tremaining: 3.9s\n[15:50:28] bestTest = 15941.80997\n[15:50:28] bestIteration = 1999\n[15:50:28] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.2086621390992753e-05, 'min_data_in_leaf': 6} scored -15941.810697115385 in 0:00:04.375806\n[15:50:28] 0:\tlearn: 54889.8385701\ttest: 51289.9505959\tbest: 51289.9505959 (0)\ttotal: 2.72ms\tremaining: 5.44s\n[15:50:31] Stopped by overfitting detector  (300 iterations wait)\n[15:50:31] bestTest = 14803.85894\n[15:50:31] bestIteration = 703\n[15:50:31] Shrink model to first 704 iterations.\n[15:50:31] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00024276631057475772, 'min_data_in_leaf': 11} scored -14803.858774038461 in 0:00:02.709570\n[15:50:31] 0:\tlearn: 54747.3908927\ttest: 51091.6731533\tbest: 51091.6731533 (0)\ttotal: 3.98ms\tremaining: 7.97s\n[15:50:34] Stopped by overfitting detector  (300 iterations wait)\n[15:50:34] bestTest = 15092.29602\n[15:50:34] bestIteration = 462\n[15:50:34] Shrink model to first 463 iterations.\n[15:50:34] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.8086684661235136e-06, 'min_data_in_leaf': 7} scored -15092.296140491453 in 0:00:03.019186\n[15:50:34] 0:\tlearn: 54889.8218837\ttest: 51289.9449218\tbest: 51289.9449218 (0)\ttotal: 2.71ms\tremaining: 5.41s\n[15:50:38] Stopped by overfitting detector  (300 iterations wait)\n[15:50:38] bestTest = 15885.53618\n[15:50:38] bestIteration = 1332\n[15:50:38] Shrink model to first 1333 iterations.\n[15:50:38] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1159756496099929e-05, 'min_data_in_leaf': 8} scored -15872.005809294871 in 0:00:04.330328\n[15:50:38] 0:\tlearn: 54893.2311043\ttest: 51276.1326259\tbest: 51276.1326259 (0)\ttotal: 1.94ms\tremaining: 3.88s\n[15:50:41] Stopped by overfitting detector  (300 iterations wait)\n[15:50:41] bestTest = 15881.01107\n[15:50:41] bestIteration = 1156\n[15:50:41] Shrink model to first 1157 iterations.\n[15:50:41] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000456880082613639, 'min_data_in_leaf': 12} scored -15881.011318108975 in 0:00:02.875885\n[15:50:41] 0:\tlearn: 54893.2076322\ttest: 51276.1248982\tbest: 51276.1248982 (0)\ttotal: 1.97ms\tremaining: 3.94s\n[15:50:45] bestTest = 15983.50916\n[15:50:45] bestIteration = 1785\n[15:50:45] Shrink model to first 1786 iterations.\n[15:50:45] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.631632576809451e-07, 'min_data_in_leaf': 1} scored -15983.509615384615 in 0:00:03.957854\n[15:50:45] 0:\tlearn: 54892.2274171\ttest: 51290.7742241\tbest: 51290.7742241 (0)\ttotal: 2.7ms\tremaining: 5.39s\n[15:50:47] Stopped by overfitting detector  (300 iterations wait)\n[15:50:47] bestTest = 15558.55453\n[15:50:47] bestIteration = 532\n[15:50:47] Shrink model to first 533 iterations.\n[15:50:47] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.03387557668886891, 'min_data_in_leaf': 10} scored -15540.497128739316 in 0:00:02.292247\n[15:50:47] 0:\tlearn: 54747.3964904\ttest: 51091.6761266\tbest: 51091.6761266 (0)\ttotal: 4.11ms\tremaining: 8.22s\n[15:50:50] Stopped by overfitting detector  (300 iterations wait)\n[15:50:50] bestTest = 15092.28111\n[15:50:50] bestIteration = 462\n[15:50:50] Shrink model to first 463 iterations.\n[15:50:50] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 5.7696009808555557e-05, 'min_data_in_leaf': 3} scored -15092.281116452992 in 0:00:02.971282\n[15:50:51] 0:\tlearn: 54889.8210854\ttest: 51289.9446503\tbest: 51289.9446503 (0)\ttotal: 2.7ms\tremaining: 5.4s\n[15:50:54] Stopped by overfitting detector  (300 iterations wait)\n[15:50:54] bestTest = 14798.8434\n[15:50:54] bestIteration = 1038\n[15:50:54] Shrink model to first 1039 iterations.\n[15:50:54] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 8.089339609894541e-08, 'min_data_in_leaf': 8} scored -14798.84349959936 in 0:00:03.938535\n[15:50:54] 0:\tlearn: 54889.8210808\ttest: 51289.9446488\tbest: 51289.9446488 (0)\ttotal: 2.75ms\tremaining: 5.49s\n[15:50:58] Stopped by overfitting detector  (300 iterations wait)\n[15:50:58] bestTest = 14798.8434\n[15:50:58] bestIteration = 1038\n[15:50:58] Shrink model to first 1039 iterations.\n[15:50:58] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.724926991453834e-08, 'min_data_in_leaf': 7} scored -14798.843299278846 in 0:00:04.102728\n[15:50:58] 0:\tlearn: 54889.8210805\ttest: 51289.9446487\tbest: 51289.9446487 (0)\ttotal: 3.34ms\tremaining: 6.67s\n[15:51:02] Stopped by overfitting detector  (300 iterations wait)\n[15:51:02] bestTest = 14798.8434\n[15:51:02] bestIteration = 1038\n[15:51:02] Shrink model to first 1039 iterations.\n[15:51:02] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3651831039275445e-08, 'min_data_in_leaf': 5} scored -14798.843299278846 in 0:00:03.675223\n[15:51:02] 0:\tlearn: 54889.8211816\ttest: 51289.9446831\tbest: 51289.9446831 (0)\ttotal: 2.71ms\tremaining: 5.42s\n[15:51:06] Stopped by overfitting detector  (300 iterations wait)\n[15:51:06] bestTest = 14798.84332\n[15:51:06] bestIteration = 1038\n[15:51:06] Shrink model to first 1039 iterations.\n[15:51:06] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.416830932421596e-06, 'min_data_in_leaf': 7} scored -14798.842881944445 in 0:00:03.601567\n[15:51:06] 0:\tlearn: 54747.3908127\ttest: 51091.6731108\tbest: 51091.6731108 (0)\ttotal: 4.04ms\tremaining: 8.08s\n[15:51:09] Stopped by overfitting detector  (300 iterations wait)\n[15:51:09] bestTest = 15092.29623\n[15:51:09] bestIteration = 462\n[15:51:09] Shrink model to first 463 iterations.\n[15:51:09] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.024662879141371e-06, 'min_data_in_leaf': 10} scored -15092.295806623932 in 0:00:03.027379\n[15:51:09] 0:\tlearn: 54893.2080312\ttest: 51276.1250295\tbest: 51276.1250295 (0)\ttotal: 1.96ms\tremaining: 3.91s\n[15:51:11] Stopped by overfitting detector  (300 iterations wait)\n[15:51:11] bestTest = 15279.14833\n[15:51:11] bestIteration = 1013\n[15:51:11] Shrink model to first 1014 iterations.\n[15:51:11] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 8.31819570043442e-06, 'min_data_in_leaf': 3} scored -15279.148571047008 in 0:00:02.642661\n[15:51:11] 0:\tlearn: 54889.8211027\ttest: 51289.9446562\tbest: 51289.9446562 (0)\ttotal: 2.66ms\tremaining: 5.32s\n[15:51:15] Stopped by overfitting detector  (300 iterations wait)\n[15:51:15] bestTest = 14798.84338\n[15:51:15] bestIteration = 1038\n[15:51:15] Shrink model to first 1039 iterations.\n[15:51:15] \u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.2095060906575555e-07, 'min_data_in_leaf': 12} scored -14798.84349959936 in 0:00:03.585904\n[15:51:15] 0:\tlearn: 54893.2133982\ttest: 51276.1267962\tbest: 51276.1267962 (0)\ttotal: 1.96ms\tremaining: 3.91s\n[15:51:18] Stopped by overfitting detector  (300 iterations wait)\n[15:51:18] bestTest = 15905.82001\n[15:51:18] bestIteration = 1384\n[15:51:18] Shrink model to first 1385 iterations.\n[15:51:18] \u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00011263966557176746, 'min_data_in_leaf': 14} scored -15905.819861778846 in 0:00:03.265121\n[15:51:18] 0:\tlearn: 54890.0426780\ttest: 51290.0200907\tbest: 51290.0200907 (0)\ttotal: 2.77ms\tremaining: 5.53s\n[15:51:21] Stopped by overfitting detector  (300 iterations wait)\n[15:51:21] bestTest = 15833.13291\n[15:51:21] bestIteration = 880\n[15:51:21] Shrink model to first 881 iterations.\n[15:51:21] \u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.003079493092378215, 'min_data_in_leaf': 7} scored -15834.43906917735 in 0:00:03.199660\n[15:51:22] 0:\tlearn: 54747.3907392\ttest: 51091.6730718\tbest: 51091.6730718 (0)\ttotal: 4.05ms\tremaining: 8.09s\n[15:51:24] Stopped by overfitting detector  (300 iterations wait)\n[15:51:24] bestTest = 15092.29643\n[15:51:24] bestIteration = 462\n[15:51:24] Shrink model to first 463 iterations.\n[15:51:24] \u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.3040717973683437e-06, 'min_data_in_leaf': 5} scored -15092.296607905982 in 0:00:02.968078\n[15:51:25] 0:\tlearn: 54889.8228201\ttest: 51289.9452402\tbest: 51289.9452402 (0)\ttotal: 2.8ms\tremaining: 5.59s\n[15:51:28] Stopped by overfitting detector  (300 iterations wait)\n[15:51:28] bestTest = 14798.84192\n[15:51:28] bestIteration = 1038\n[15:51:28] Shrink model to first 1039 iterations.\n[15:51:28] \u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.4156698397196293e-05, 'min_data_in_leaf': 7} scored -14798.841362847223 in 0:00:03.612762\n[15:51:28] 0:\tlearn: 54889.8229058\ttest: 51289.9452693\tbest: 51289.9452693 (0)\ttotal: 2.79ms\tremaining: 5.57s\n[15:51:32] Stopped by overfitting detector  (300 iterations wait)\n[15:51:32] bestTest = 14798.84184\n[15:51:32] bestIteration = 1038\n[15:51:32] Shrink model to first 1039 iterations.\n[15:51:32] \u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.5345512154236994e-05, 'min_data_in_leaf': 8} scored -14798.841296073719 in 0:00:04.082186\n[15:51:32] 0:\tlearn: 54889.8225050\ttest: 51289.9451330\tbest: 51289.9451330 (0)\ttotal: 2.67ms\tremaining: 5.33s\n[15:51:36] Stopped by overfitting detector  (300 iterations wait)\n[15:51:36] bestTest = 14798.84219\n[15:51:36] bestIteration = 1038\n[15:51:36] Shrink model to first 1039 iterations.\n[15:51:36] \u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.978314608664181e-05, 'min_data_in_leaf': 8} scored -14798.84188034188 in 0:00:03.536962\n[15:51:36] 0:\tlearn: 54889.9170968\ttest: 51289.9773133\tbest: 51289.9773133 (0)\ttotal: 2.77ms\tremaining: 5.53s\n[15:51:41] Stopped by overfitting detector  (300 iterations wait)\n[15:51:41] bestTest = 15134.09488\n[15:51:41] bestIteration = 1640\n[15:51:41] Shrink model to first 1641 iterations.\n[15:51:41] \u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0013333270522195117, 'min_data_in_leaf': 10} scored -15134.095285790598 in 0:00:05.113012\n[15:51:41] 0:\tlearn: 54893.2104544\ttest: 51276.1258272\tbest: 51276.1258272 (0)\ttotal: 2.02ms\tremaining: 4.05s\n[15:51:44] Stopped by overfitting detector  (300 iterations wait)\n[15:51:44] bestTest = 15905.83817\n[15:51:44] bestIteration = 1384\n[15:51:44] Shrink model to first 1385 iterations.\n[15:51:44] \u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 5.541799746572838e-05, 'min_data_in_leaf': 8} scored -15905.837990785256 in 0:00:03.331262\n[15:51:44] 0:\tlearn: 54747.4182315\ttest: 51091.6876754\tbest: 51091.6876754 (0)\ttotal: 3.88ms\tremaining: 7.75s\n[15:51:47] Stopped by overfitting detector  (300 iterations wait)\n[15:51:47] bestTest = 15092.22319\n[15:51:47] bestIteration = 462\n[15:51:47] Shrink model to first 463 iterations.\n[15:51:47] \u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00027089423755693727, 'min_data_in_leaf': 11} scored -15092.223424145299 in 0:00:02.995675\n[15:51:48] 0:\tlearn: 54890.2329671\ttest: 51290.0850283\tbest: 51290.0850283 (0)\ttotal: 2.77ms\tremaining: 5.54s\n[15:51:51] Stopped by overfitting detector  (300 iterations wait)\n[15:51:51] bestTest = 15130.69139\n[15:51:51] bestIteration = 1079\n[15:51:51] Shrink model to first 1080 iterations.\n[15:51:51] \u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.005730377073340946, 'min_data_in_leaf': 13} scored -15130.69093883547 in 0:00:03.937871\n[15:51:51] 0:\tlearn: 54893.2078958\ttest: 51276.1249850\tbest: 51276.1249850 (0)\ttotal: 1.94ms\tremaining: 3.89s\n[15:51:54] Stopped by overfitting detector  (300 iterations wait)\n[15:51:54] bestTest = 15279.14895\n[15:51:54] bestIteration = 1013\n[15:51:54] Shrink model to first 1014 iterations.\n[15:51:54] \u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.686589428929203e-06, 'min_data_in_leaf': 9} scored -15279.149005074787 in 0:00:02.655922\n[15:51:54] 0:\tlearn: 54889.8234535\ttest: 51289.9454555\tbest: 51289.9454555 (0)\ttotal: 2.78ms\tremaining: 5.57s\n[15:51:57] Stopped by overfitting detector  (300 iterations wait)\n[15:51:57] bestTest = 14798.84138\n[15:51:57] bestIteration = 1038\n[15:51:57] Shrink model to first 1039 iterations.\n[15:51:57] \u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.294707451267159e-05, 'min_data_in_leaf': 8} scored -14798.840711805555 in 0:00:03.575426\n[15:51:57] 0:\tlearn: 55206.1813551\ttest: 51513.5988958\tbest: 51513.5988958 (0)\ttotal: 1.18ms\tremaining: 2.35s\n[15:51:59] bestTest = 16461.50564\n[15:51:59] bestIteration = 1796\n[15:51:59] Shrink model to first 1797 iterations.\n[15:51:59] \u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 2.7610418623323684e-05, 'min_data_in_leaf': 5} scored -16461.505024706195 in 0:00:02.139125\n[15:52:00] 0:\tlearn: 54889.8297398\ttest: 51289.9475931\tbest: 51289.9475931 (0)\ttotal: 2.64ms\tremaining: 5.28s\n[15:52:02] Stopped by overfitting detector  (300 iterations wait)\n[15:52:02] bestTest = 14803.86119\n[15:52:02] bestIteration = 703\n[15:52:02] Shrink model to first 704 iterations.\n[15:52:02] \u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00012019593207192622, 'min_data_in_leaf': 8} scored -14803.861611912393 in 0:00:02.980567\n[15:52:03] 0:\tlearn: 54889.8234514\ttest: 51289.9454548\tbest: 51289.9454548 (0)\ttotal: 3.2ms\tremaining: 6.4s\n[15:52:06] Stopped by overfitting detector  (300 iterations wait)\n[15:52:06] bestTest = 14798.84138\n[15:52:06] bestIteration = 1038\n[15:52:06] Shrink model to first 1039 iterations.\n[15:52:06] \u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.29178323989441e-05, 'min_data_in_leaf': 10} scored -14798.840678418803 in 0:00:03.797281\n[15:52:06] 0:\tlearn: 54889.8593774\ttest: 51289.9576729\tbest: 51289.9576729 (0)\ttotal: 2.68ms\tremaining: 5.36s\n[15:52:09] Stopped by overfitting detector  (300 iterations wait)\n[15:52:09] bestTest = 14935.13815\n[15:52:09] bestIteration = 569\n[15:52:09] Shrink model to first 570 iterations.\n[15:52:09] \u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.000531632797721835, 'min_data_in_leaf': 6} scored -14935.13828792735 in 0:00:02.352153\n[15:52:09] 0:\tlearn: 54889.8255764\ttest: 51289.9461774\tbest: 51289.9461774 (0)\ttotal: 2.77ms\tremaining: 5.53s\n[15:52:12] Stopped by overfitting detector  (300 iterations wait)\n[15:52:12] bestTest = 14798.83956\n[15:52:12] bestIteration = 1038\n[15:52:12] Shrink model to first 1039 iterations.\n[15:52:12] \u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 6.241009903143843e-05, 'min_data_in_leaf': 10} scored -14798.839576655982 in 0:00:03.656000\n[15:52:12] 0:\tlearn: 54889.8238162\ttest: 51289.9455789\tbest: 51289.9455789 (0)\ttotal: 3.17ms\tremaining: 6.33s\n[15:52:16] Stopped by overfitting detector  (300 iterations wait)\n[15:52:16] bestTest = 14798.84107\n[15:52:16] bestIteration = 1038\n[15:52:16] Shrink model to first 1039 iterations.\n[15:52:16] \u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.7980674967634084e-05, 'min_data_in_leaf': 12} scored -14798.841028979701 in 0:00:03.557362\n[15:52:16] 0:\tlearn: 54747.3961358\ttest: 51091.6759383\tbest: 51091.6759383 (0)\ttotal: 3.81ms\tremaining: 7.61s\n[15:52:19] Stopped by overfitting detector  (300 iterations wait)\n[15:52:19] bestTest = 15092.28205\n[15:52:19] bestIteration = 462\n[15:52:19] Shrink model to first 463 iterations.\n[15:52:19] \u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 5.421927399958814e-05, 'min_data_in_leaf': 13} scored -15092.281951121795 in 0:00:02.956484\n[15:52:19] 0:\tlearn: 54889.8370727\ttest: 51289.9500867\tbest: 51289.9500867 (0)\ttotal: 2.72ms\tremaining: 5.45s\n[15:52:22] Stopped by overfitting detector  (300 iterations wait)\n[15:52:22] bestTest = 14803.85932\n[15:52:22] bestIteration = 703\n[15:52:22] Shrink model to first 704 iterations.\n[15:52:22] \u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00022198044371147177, 'min_data_in_leaf': 10} scored -14803.85882411859 in 0:00:02.760599\n[15:52:22] 0:\tlearn: 54889.8213953\ttest: 51289.9447557\tbest: 51289.9447557 (0)\ttotal: 2.81ms\tremaining: 5.62s\n[15:52:25] Stopped by overfitting detector  (300 iterations wait)\n[15:52:25] bestTest = 14798.84313\n[15:52:25] bestIteration = 1038\n[15:52:25] Shrink model to first 1039 iterations.\n[15:52:25] \u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 4.382348344316356e-06, 'min_data_in_leaf': 11} scored -14798.843015491453 in 0:00:03.580339\n[15:52:25] 0:\tlearn: 54747.3917182\ttest: 51091.6735918\tbest: 51091.6735918 (0)\ttotal: 3.87ms\tremaining: 7.74s\n[15:52:28] Stopped by overfitting detector  (300 iterations wait)\n[15:52:28] bestTest = 15092.29382\n[15:52:28] bestIteration = 462\n[15:52:28] Shrink model to first 463 iterations.\n[15:52:28] \u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0903070418799317e-05, 'min_data_in_leaf': 9} scored -15092.294103899572 in 0:00:02.966473\n[15:52:28] 0:\tlearn: 55155.1820106\ttest: 51522.8835295\tbest: 51522.8835295 (0)\ttotal: 1.51ms\tremaining: 3.03s\n[15:52:31] bestTest = 15716.81679\n[15:52:31] bestIteration = 1996\n[15:52:31] Shrink model to first 1997 iterations.\n[15:52:31] \u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 8.94148330925207e-05, 'min_data_in_leaf': 12} scored -15716.816422943377 in 0:00:02.894078\n[15:52:31] 0:\tlearn: 54889.8233549\ttest: 51289.9454220\tbest: 51289.9454220 (0)\ttotal: 3.68ms\tremaining: 7.35s\n[15:52:35] Stopped by overfitting detector  (300 iterations wait)\n[15:52:35] bestTest = 14798.84146\n[15:52:35] bestIteration = 1038\n[15:52:35] Shrink model to first 1039 iterations.\n[15:52:35] \u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.157867747496407e-05, 'min_data_in_leaf': 11} scored -14798.841479700855 in 0:00:03.787086\n[15:52:35] 0:\tlearn: 54889.8236217\ttest: 51289.9455127\tbest: 51289.9455127 (0)\ttotal: 3.25ms\tremaining: 6.49s\n[15:52:39] Stopped by overfitting detector  (300 iterations wait)\n[15:52:39] bestTest = 14798.84123\n[15:52:39] bestIteration = 1038\n[15:52:39] Shrink model to first 1039 iterations.\n[15:52:39] \u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.5280644180658646e-05, 'min_data_in_leaf': 9} scored -14798.841312767094 in 0:00:03.755967\n[15:52:39] 0:\tlearn: 54927.4522311\ttest: 51307.7716894\tbest: 51307.7716894 (0)\ttotal: 2.66ms\tremaining: 5.31s\n[15:52:41] Stopped by overfitting detector  (300 iterations wait)\n[15:52:41] bestTest = 15499.0409\n[15:52:41] bestIteration = 645\n[15:52:41] Shrink model to first 646 iterations.\n[15:52:41] \u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.6375651446901905, 'min_data_in_leaf': 10} scored -15499.040865384615 in 0:00:02.579370\n[15:52:41] 0:\tlearn: 54889.8905780\ttest: 51289.9682880\tbest: 51289.9682880 (0)\ttotal: 2.68ms\tremaining: 5.36s\n[15:52:44] Stopped by overfitting detector  (300 iterations wait)\n[15:52:44] bestTest = 14967.31489\n[15:52:44] bestIteration = 751\n[15:52:44] Shrink model to first 752 iterations.\n[15:52:44] \u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0009649255912788872, 'min_data_in_leaf': 9} scored -14967.314403044871 in 0:00:02.875590\n[15:52:45] 0:\tlearn: 54893.2174080\ttest: 51276.1281163\tbest: 51276.1281163 (0)\ttotal: 2.01ms\tremaining: 4.01s\n[15:52:48] Stopped by overfitting detector  (300 iterations wait)\n[15:52:48] bestTest = 15904.33429\n[15:52:48] bestIteration = 1690\n[15:52:48] Shrink model to first 1691 iterations.\n[15:52:48] \u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00019058580891117213, 'min_data_in_leaf': 6} scored -15904.334184695514 in 0:00:04.102260\n[15:52:48] 0:\tlearn: 54889.8243555\ttest: 51289.9457622\tbest: 51289.9457622 (0)\ttotal: 2.81ms\tremaining: 5.62s\n[15:52:53] Stopped by overfitting detector  (300 iterations wait)\n[15:52:53] bestTest = 15885.53834\n[15:52:53] bestIteration = 1332\n[15:52:53] Shrink model to first 1333 iterations.\n[15:52:53] \u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 4.5465012243893744e-05, 'min_data_in_leaf': 8} scored -15872.008647168803 in 0:00:04.368349\n[15:52:53] 0:\tlearn: 54889.8221045\ttest: 51289.9449968\tbest: 51289.9449968 (0)\ttotal: 2.7ms\tremaining: 5.39s\n[15:52:56] Stopped by overfitting detector  (300 iterations wait)\n[15:52:56] bestTest = 14798.84253\n[15:52:56] bestIteration = 1038\n[15:52:56] Shrink model to first 1039 iterations.\n[15:52:56] \u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.4224102428475308e-05, 'min_data_in_leaf': 9} scored -14798.841897035256 in 0:00:03.558433\n[15:52:56] 0:\tlearn: 54889.8215183\ttest: 51289.9447976\tbest: 51289.9447976 (0)\ttotal: 2.67ms\tremaining: 5.33s\n[15:53:00] Stopped by overfitting detector  (300 iterations wait)\n[15:53:00] bestTest = 14798.84303\n[15:53:00] bestIteration = 1038\n[15:53:00] Shrink model to first 1039 iterations.\n[15:53:00] \u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 6.089647573351944e-06, 'min_data_in_leaf': 12} scored -14798.84294871795 in 0:00:03.557687\n[15:53:00] 0:\tlearn: 54889.8509188\ttest: 51289.9547957\tbest: 51289.9547957 (0)\ttotal: 2.69ms\tremaining: 5.39s\n[15:53:02] Stopped by overfitting detector  (300 iterations wait)\n[15:53:02] bestTest = 14935.14454\n[15:53:02] bestIteration = 569\n[15:53:02] Shrink model to first 570 iterations.\n[15:53:02] \u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0004141935292007362, 'min_data_in_leaf': 15} scored -14935.144931891025 in 0:00:02.437176\n[15:53:02] 0:\tlearn: 54893.2078004\ttest: 51276.1249536\tbest: 51276.1249536 (0)\ttotal: 1.97ms\tremaining: 3.93s\n[15:53:04] Stopped by overfitting detector  (300 iterations wait)\n[15:53:04] bestTest = 16053.67823\n[15:53:04] bestIteration = 829\n[15:53:04] Shrink model to first 830 iterations.\n[15:53:04] \u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 3.832893027459467e-06, 'min_data_in_leaf': 7} scored -16053.677918002137 in 0:00:02.236103\n[15:53:05] 0:\tlearn: 54889.8239862\ttest: 51289.9456367\tbest: 51289.9456367 (0)\ttotal: 2.64ms\tremaining: 5.28s\n[15:53:08] Stopped by overfitting detector  (300 iterations wait)\n[15:53:08] bestTest = 14798.84092\n[15:53:08] bestIteration = 1038\n[15:53:08] Shrink model to first 1039 iterations.\n[15:53:08] \u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 4.033959133434874e-05, 'min_data_in_leaf': 10} scored -14798.840461404914 in 0:00:04.036697\n[15:53:09] 0:\tlearn: 54889.8234814\ttest: 51289.9454650\tbest: 51289.9454650 (0)\ttotal: 2.76ms\tremaining: 5.51s\n[15:53:12] Stopped by overfitting detector  (300 iterations wait)\n[15:53:12] bestTest = 14798.84135\n[15:53:12] bestIteration = 1038\n[15:53:12] Shrink model to first 1039 iterations.\n[15:53:12] \u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 3.3334537828455975e-05, 'min_data_in_leaf': 10} scored -14798.841312767094 in 0:00:03.595087\n[15:53:12] 0:\tlearn: 54889.8278777\ttest: 51289.9469599\tbest: 51289.9469599 (0)\ttotal: 2.66ms\tremaining: 5.32s\n[15:53:15] Stopped by overfitting detector  (300 iterations wait)\n[15:53:15] bestTest = 14803.86166\n[15:53:15] bestIteration = 703\n[15:53:15] Shrink model to first 704 iterations.\n[15:53:15] \u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 9.435113127892782e-05, 'min_data_in_leaf': 10} scored -14803.861478365385 in 0:00:02.728358\n[15:53:15] 0:\tlearn: 54889.8330606\ttest: 51289.9487223\tbest: 51289.9487223 (0)\ttotal: 2.68ms\tremaining: 5.35s\n[15:53:18] Stopped by overfitting detector  (300 iterations wait)\n[15:53:18] bestTest = 14803.86034\n[15:53:18] bestIteration = 703\n[15:53:18] Shrink model to first 704 iterations.\n[15:53:18] \u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00016628923200738655, 'min_data_in_leaf': 11} scored -14803.86047676282 in 0:00:02.746440\n[15:53:18] 0:\tlearn: 54889.8217464\ttest: 51289.9448751\tbest: 51289.9448751 (0)\ttotal: 2.71ms\tremaining: 5.43s\n[15:53:21] Stopped by overfitting detector  (300 iterations wait)\n[15:53:21] bestTest = 14798.84283\n[15:53:21] bestIteration = 1038\n[15:53:21] Shrink model to first 1039 iterations.\n[15:53:21] \u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 9.255309771632624e-06, 'min_data_in_leaf': 10} scored -14798.842564770299 in 0:00:03.581473\n[15:53:21] 0:\tlearn: 54747.3951402\ttest: 51091.6754094\tbest: 51091.6754094 (0)\ttotal: 3.96ms\tremaining: 7.92s\n[15:53:24] Stopped by overfitting detector  (300 iterations wait)\n[15:53:24] bestTest = 15092.2847\n[15:53:24] bestIteration = 462\n[15:53:24] Shrink model to first 463 iterations.\n[15:53:24] \u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 4.4457194505636815e-05, 'min_data_in_leaf': 13} scored -15092.284755608975 in 0:00:02.995096\n[15:53:24] 0:\tlearn: 54889.8225304\ttest: 51289.9451417\tbest: 51289.9451417 (0)\ttotal: 2.68ms\tremaining: 5.36s\n[15:53:28] Stopped by overfitting detector  (300 iterations wait)\n[15:53:28] bestTest = 14798.84216\n[15:53:28] bestIteration = 1038\n[15:53:28] Shrink model to first 1039 iterations.\n[15:53:28] \u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.013517945398119e-05, 'min_data_in_leaf': 9} scored -14798.841780181623 in 0:00:03.593483\n[15:53:28] 0:\tlearn: 54889.8632814\ttest: 51289.9590009\tbest: 51289.9590009 (0)\ttotal: 2.67ms\tremaining: 5.35s\n[15:53:33] Stopped by overfitting detector  (300 iterations wait)\n[15:53:33] bestTest = 15927.01041\n[15:53:33] bestIteration = 1663\n[15:53:33] Shrink model to first 1664 iterations.\n[15:53:33] \u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0005858409275457049, 'min_data_in_leaf': 12} scored -15913.486912393162 in 0:00:05.236382\n[15:53:33] 0:\tlearn: 54889.8262118\ttest: 51289.9463934\tbest: 51289.9463934 (0)\ttotal: 2.64ms\tremaining: 5.27s\n[15:53:37] Stopped by overfitting detector  (300 iterations wait)\n[15:53:37] bestTest = 14798.83902\n[15:53:37] bestIteration = 1038\n[15:53:37] Shrink model to first 1039 iterations.\n[15:53:37] \u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 7.122871106778543e-05, 'min_data_in_leaf': 11} scored -14798.839259481838 in 0:00:03.560855\n[15:53:37] 0:\tlearn: 54893.2115128\ttest: 51276.1261756\tbest: 51276.1261756 (0)\ttotal: 1.93ms\tremaining: 3.86s\n[15:53:40] Stopped by overfitting detector  (300 iterations wait)\n[15:53:40] bestTest = 15905.83164\n[15:53:40] bestIteration = 1384\n[15:53:40] Shrink model to first 1385 iterations.\n[15:53:40] \u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 7.59901042220972e-05, 'min_data_in_leaf': 14} scored -15905.831697382479 in 0:00:03.558968\n[15:53:40] 0:\tlearn: 54889.8219564\ttest: 51289.9449465\tbest: 51289.9449465 (0)\ttotal: 3.27ms\tremaining: 6.54s\n[15:53:44] Stopped by overfitting detector  (300 iterations wait)\n[15:53:44] bestTest = 14798.84265\n[15:53:44] bestIteration = 1038\n[15:53:44] Shrink model to first 1039 iterations.\n[15:53:44] \u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2168810087235225e-05, 'min_data_in_leaf': 11} scored -14798.84273170406 in 0:00:03.752822\n[15:53:44] 0:\tlearn: 54889.8240425\ttest: 51289.9456558\tbest: 51289.9456558 (0)\ttotal: 2.71ms\tremaining: 5.41s\n[15:53:48] Stopped by overfitting detector  (300 iterations wait)\n[15:53:48] bestTest = 14798.84087\n[15:53:48] bestIteration = 1038\n[15:53:48] Shrink model to first 1039 iterations.\n[15:53:48] \u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 4.112088400173155e-05, 'min_data_in_leaf': 10} scored -14798.840928819445 in 0:00:03.632503\n[15:53:48] 0:\tlearn: 54889.8261247\ttest: 51289.9463638\tbest: 51289.9463638 (0)\ttotal: 2.63ms\tremaining: 5.26s\n[15:53:51] Stopped by overfitting detector  (300 iterations wait)\n[15:53:51] bestTest = 14798.83909\n[15:53:51] bestIteration = 1038\n[15:53:51] Shrink model to first 1039 iterations.\n[15:53:51] \u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 7.002066300456878e-05, 'min_data_in_leaf': 9} scored -14798.839393028846 in 0:00:03.569980\n[15:53:51] 0:\tlearn: 54889.8285318\ttest: 51289.9471823\tbest: 51289.9471823 (0)\ttotal: 2.79ms\tremaining: 5.58s\n[15:53:54] Stopped by overfitting detector  (300 iterations wait)\n[15:53:54] bestTest = 14803.86149\n[15:53:54] bestIteration = 703\n[15:53:54] Shrink model to first 704 iterations.\n[15:53:54] \u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00010343019982713955, 'min_data_in_leaf': 8} scored -14803.861361511752 in 0:00:02.746962\n[15:53:54] 0:\tlearn: 54889.8259280\ttest: 51289.9462969\tbest: 51289.9462969 (0)\ttotal: 2.69ms\tremaining: 5.37s\n[15:53:58] Stopped by overfitting detector  (300 iterations wait)\n[15:53:58] bestTest = 14798.83926\n[15:53:58] bestIteration = 1038\n[15:53:58] Shrink model to first 1039 iterations.\n[15:53:58] \u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 6.72907292300004e-05, 'min_data_in_leaf': 11} scored -14798.839893830129 in 0:00:03.847857\n[15:53:58] 0:\tlearn: 54889.8381517\ttest: 51289.9504536\tbest: 51289.9504536 (0)\ttotal: 2.65ms\tremaining: 5.29s\n[15:54:01] Stopped by overfitting detector  (300 iterations wait)\n[15:54:01] bestTest = 14803.85905\n[15:54:01] bestIteration = 703\n[15:54:01] Shrink model to first 704 iterations.\n[15:54:01] \u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00023695840447551426, 'min_data_in_leaf': 12} scored -14803.85954193376 in 0:00:02.708715\n[15:54:01] 0:\tlearn: 54889.8444091\ttest: 51289.9525817\tbest: 51289.9525817 (0)\ttotal: 2.68ms\tremaining: 5.36s\n[15:54:04] Stopped by overfitting detector  (300 iterations wait)\n[15:54:04] bestTest = 14890.37327\n[15:54:04] bestIteration = 1062\n[15:54:04] Shrink model to first 1063 iterations.\n[15:54:04] \u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00032382175746943295, 'min_data_in_leaf': 13} scored -14890.372729700855 in 0:00:03.674213\n[15:54:04] 0:\tlearn: 54747.3971396\ttest: 51091.6764714\tbest: 51091.6764714 (0)\ttotal: 3.92ms\tremaining: 7.83s\n[15:54:07] Stopped by overfitting detector  (300 iterations wait)\n[15:54:07] bestTest = 15092.27938\n[15:54:07] bestIteration = 462\n[15:54:07] Shrink model to first 463 iterations.\n[15:54:07] \u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 6.406143717367719e-05, 'min_data_in_leaf': 11} scored -15092.27891292735 in 0:00:02.955091\n[15:54:07] 0:\tlearn: 54889.8330026\ttest: 51289.9487026\tbest: 51289.9487026 (0)\ttotal: 2.65ms\tremaining: 5.29s\n[15:54:10] Stopped by overfitting detector  (300 iterations wait)\n[15:54:10] bestTest = 14803.86036\n[15:54:10] bestIteration = 703\n[15:54:10] Shrink model to first 704 iterations.\n[15:54:10] \u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00016548371542773847, 'min_data_in_leaf': 9} scored -14803.860409989316 in 0:00:02.717810\n[15:54:10] 0:\tlearn: 54889.9593244\ttest: 51289.9916906\tbest: 51289.9916906 (0)\ttotal: 2.73ms\tremaining: 5.45s\n[15:54:13] Stopped by overfitting detector  (300 iterations wait)\n[15:54:13] bestTest = 15951.5282\n[15:54:13] bestIteration = 831\n[15:54:13] Shrink model to first 832 iterations.\n[15:54:13] \u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0019201970377835712, 'min_data_in_leaf': 11} scored -15938.019631410256 in 0:00:03.541468\n[15:54:13] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n[15:54:13] The set of hyperparameters \u001b[1m{'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 7.122871106778543e-05, 'min_data_in_leaf': 11}\u001b[0m\n achieve -14798.8393 mae\n[15:54:13] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n[15:54:13] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:54:14] 0:\tlearn: 55789.2139528\ttest: 52022.9775392\tbest: 52022.9775392 (0)\ttotal: 2.73ms\tremaining: 8.2s\n[15:54:17] Stopped by overfitting detector  (100 iterations wait)\n[15:54:17] bestTest = 15234.33406\n[15:54:17] bestIteration = 1170\n[15:54:17] Shrink model to first 1171 iterations.\n[15:54:17] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:54:17] 0:\tlearn: 54395.3321885\ttest: 56752.0122605\tbest: 56752.0122605 (0)\ttotal: 3.02ms\tremaining: 9.05s\n[15:54:18] Stopped by overfitting detector  (100 iterations wait)\n[15:54:18] bestTest = 15534.81796\n[15:54:18] bestIteration = 471\n[15:54:18] Shrink model to first 472 iterations.\n[15:54:18] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:54:18] 0:\tlearn: 55207.0823745\ttest: 54398.6629567\tbest: 54398.6629567 (0)\ttotal: 2.75ms\tremaining: 8.25s\n[15:54:21] Stopped by overfitting detector  (100 iterations wait)\n[15:54:21] bestTest = 13393.14702\n[15:54:21] bestIteration = 905\n[15:54:21] Shrink model to first 906 iterations.\n[15:54:21] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:54:21] 0:\tlearn: 55704.2365440\ttest: 52955.9238398\tbest: 52955.9238398 (0)\ttotal: 2.65ms\tremaining: 7.96s\n[15:54:25] Stopped by overfitting detector  (100 iterations wait)\n[15:54:25] bestTest = 15520.62164\n[15:54:25] bestIteration = 1323\n[15:54:25] Shrink model to first 1324 iterations.\n[15:54:25] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n[15:54:25] 0:\tlearn: 53819.5933859\ttest: 59091.4397052\tbest: 59091.4397052 (0)\ttotal: 2.72ms\tremaining: 8.15s\n[15:54:28] Stopped by overfitting detector  (100 iterations wait)\n[15:54:28] bestTest = 14827.37632\n[15:54:28] bestIteration = 1253\n[15:54:28] Shrink model to first 1254 iterations.\n[15:54:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-14901.59363963506\u001b[0m\n[15:54:28] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n[15:54:28] Time left 267.93 secs\n\n[15:54:28] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[15:54:28] Blending: optimization starts with equal weights and score \u001b[1m-14769.220820178723\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14706.744331255351\u001b[0m, weights = \u001b[1m[0.11056919 0.08529252 0.14217943 0.16614608 0.49581277]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14700.80303537029\u001b[0m, weights = \u001b[1m[0.08613601 0.14909673 0.1403625  0.13695474 0.48745   ]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14700.483455292166\u001b[0m, weights = \u001b[1m[0.09763767 0.1526126  0.14657441 0.12067245 0.48250288]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14700.360324807363\u001b[0m, weights = \u001b[1m[0.09760752 0.14312053 0.15233767 0.12007181 0.48686245]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14700.31788781571\u001b[0m, weights = \u001b[1m[0.09664701 0.1377675  0.15558185 0.1201234  0.48988026]\u001b[0m\n[15:54:28] \u001b[1mAutoml preset training completed in 460.28 seconds\u001b[0m\n\n[15:54:28] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.09665 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n\t 0.13777 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.15558 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n\t 0.12012 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n\t 0.48988 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n\n[15:54:28] ==================================================\n[15:54:28] Blending: optimization starts with equal weights and score \u001b[1m-14246.037671232876\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-14208.35542192851\u001b[0m, weights = \u001b[1m[0.19098058 0.         0.17159376 0.2124446  0.17804767 0.24693339\n 0.        ]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-14207.904276808647\u001b[0m, weights = \u001b[1m[0.18741444 0.         0.20327613 0.21499576 0.18525948 0.20905422\n 0.        ]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-14207.034460616438\u001b[0m, weights = \u001b[1m[0.25472718 0.         0.1925767  0.18385264 0.17848268 0.19036077\n 0.        ]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-14207.03409942209\u001b[0m, weights = \u001b[1m[0.2547092  0.         0.19256313 0.18383968 0.1785406  0.19034734\n 0.        ]\u001b[0m\n[15:54:28] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-14207.03409942209\u001b[0m, weights = \u001b[1m[0.2547092  0.         0.19256313 0.18383968 0.1785406  0.19034734\n 0.        ]\u001b[0m\n[15:54:28] Blending: no score update. Terminated\n\nCPU times: user 5h 33min 54s, sys: 17min 51s, total: 5h 51min 45s\nWall time: 1h 35min 32s\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\ntest_pred = automl_ut.predict(test)\n\nprint(f'train score: {mean_absolute_error(train[target_col].values, oof_pred.data[:, 0])}')\nprint(f'test score: {mean_absolute_error(test[target_col].values, test_pred.data[:, 0])}')","metadata":{"execution":{"iopub.status.busy":"2024-10-06T15:56:58.950830Z","iopub.execute_input":"2024-10-06T15:56:58.951898Z","iopub.status.idle":"2024-10-06T15:57:03.541209Z","shell.execute_reply.started":"2024-10-06T15:56:58.951840Z","shell.execute_reply":"2024-10-06T15:57:03.540048Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"train score: 14207.03409942209\ntest score: 15070.650457512842\n","output_type":"stream"}]}]}